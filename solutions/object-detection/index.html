<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/solutions/object-detection/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 11:07:34 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Object Detection | Quantumworks Lab</title><meta name="description" content="Object detection is a CV technique that helps locate items in images and video. Learn how Quantumworks Lab helps align task specific object detection models." data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Object Detection | Quantumworks Lab" data-next-head=""/><meta property="og:description" content="Object detection is a CV technique that helps locate items in images and video. Learn how Quantumworks Lab helps align task specific object detection models." data-next-head=""/><meta property="og:url" content="https://labelbox.com/solutions/object-detection/" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Object Detection | Quantumworks Lab" data-next-head=""/><meta name="twitter:description" content="Object detection is a CV technique that helps locate items in images and video. Learn how Quantumworks Lab helps align task specific object detection models." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.com/solutions/object-detection/" data-next-head=""/><link rel="canonical" href="index.html" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g34[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><link rel="preload" href="../../_next/static/css/ae4ed9c503fd1e33.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/ae4ed9c503fd1e33.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/7126-d53144bc025ba01b.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/2980-f8e925c3ea95e119.js" defer=""></script><script src="../../_next/static/chunks/pages/solutions/%5bid%5d-c0f6c499f7ad3869.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><div class="py-12 md:pt-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 gap-y-12 md:gap-x-6"><div class="col-span-12 md:col-span-7 xl:col-span-6  flex flex-col  "><div class="mt-12"><h6 class="font-medium text-lg md:text-xl leading-tight text-neutral-900 dark:text-neutral-50 !text-blue-600 font-ibm mb-8" style="font-feature-settings:unset">Use case</h6><h1 class="font-normal text-5xl md:text-6xl lg:text-7xl leading-tight text-neutral-900 dark:text-neutral-50 mb-8 !text-3xl md:!text-4xl xl:!text-6xl !leading-tight font-future break-words" style="font-feature-settings:unset">Object detection</h1><span class="font-medium text-base text-neutral-500 dark:text-neutral-400 font-ibm max-w-xl" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Guide image and video generation, text-to-image/text-to-video synthesis, scene composition and more with detailed spatial and semantic information about objects in an asset.</p></span><div class="flex flex-row flex-wrap gap-2 md:gap-x-6 my-6"><a href="../../sales/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-base py-2 px-3 rounded-lg font-medium tracking-wide bg-blue-600 hover:bg-blue-700 dark:bg-blue-600 dark:hover:bg-blue-700 text-white sm:hidden" id="" target="_self" style="outline:0 !important">Contact us</a><a href="../../sales/index.html" class="group transition-all justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-blue-600 hover:bg-blue-700 dark:bg-blue-600 dark:hover:bg-blue-700 text-white hidden sm:block" id="" target="_self" style="outline:0 !important">Contact us</a><a href="https://app.labelbox.com/signup" class="group transition-all justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] border border-neutral-900 hover:bg-neutral-900/5 dark:bg-transparent text-neutral-900 dark:text-neutral-50 hidden sm:block" id="" target="_self" style="outline:0 !important">Start for free</a><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-base py-2 px-3 rounded-lg font-medium tracking-wide border border-neutral-900 hover:bg-neutral-900/5 dark:bg-transparent text-neutral-900 dark:text-neutral-50 sm:hidden" id="" target="_self" style="outline:0 !important">Start for free</a></div></div></div><div class="col-span-12 md:col-span-5 xl:col-span-6 md:p-6 flex items-center self-center"><div class="relative w-full"><img alt="Object detection" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" style="color:transparent;object-fit:contain;width:100%;height:auto" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" srcSet="/_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=256&amp;q=75 256w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=384&amp;q=75 384w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=3840&amp;q=75 3840w" src="../../_next/image/index099b.html?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F7iaEGHj2YXCtigMpwuOW1q%2Fff475e53c972ca0a31e3d015743a48a6%2FObject_Detection.png&amp;w=3840&amp;q=75"/></div></div></div></div><div class="py-12 md:pb-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="flex justify-center mb-12"><h3 class="font-medium text-3xl md:text-4xl leading-tight font-future text-neutral-900 dark:text-neutral-50 mb-6" style="font-feature-settings:unset">Why use Quantumworks Lab for Object Detection</h3></div><div class="grid grid-cols-12 gap-8"><div class="col-span-12 sm:col-span-6 xl:col-span-3 rounded-xl flex flex-col p-8 bg-white"><img class="h-12 mr-auto" src="../../../images.ctfassets.net/j20krz61k3rk/4WQUNvyqpsugVnibk5ltT4/77013543688d4f0cc27c61e399ad80d9/reduce.svg" alt="Increase model performance"/><h5 class="font-normal text-xl md:text-2xl leading-tight font-future text-neutral-900 dark:text-neutral-50 text-left my-6" style="font-feature-settings:unset">Increase model performance</h5><span class="font-normal text-base text-neutral-900 dark:text-neutral-50 text-left" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Enable models to better understand the relationships between objects and their placement with advanced tooling, humans, AI, and on-demand services in a unified solution.</p></span></div><div class="col-span-12 sm:col-span-6 xl:col-span-3 rounded-xl flex flex-col p-8 bg-white"><img class="h-12 mr-auto" src="../../../images.ctfassets.net/j20krz61k3rk/6X68rya8Qep7XG2DX3KBcA/da5039109a90f0b49da4579c62a5cadb/1-2.svg" alt="Power GenAI models"/><h5 class="font-normal text-xl md:text-2xl leading-tight font-future text-neutral-900 dark:text-neutral-50 text-left my-6" style="font-feature-settings:unset">Power GenAI models</h5><span class="font-normal text-base text-neutral-900 dark:text-neutral-50 text-left" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Create pixel-perfect bounding boxes, segmentations, and landmark annotations to help text-to-image and text-to-video models generate accurate and realistic assets.</p></span></div><div class="col-span-12 sm:col-span-6 xl:col-span-3 rounded-xl flex flex-col p-8 bg-white"><img class="h-12 mr-auto" src="../../../images.ctfassets.net/j20krz61k3rk/3yrsn6MYlVNreNLr4CFSET/3c326e0f3e7c586df90e116ec9e9eafb/access.svg" alt="Access on-demand object detection expertise"/><h5 class="font-normal text-xl md:text-2xl leading-tight font-future text-neutral-900 dark:text-neutral-50 text-left my-6" style="font-feature-settings:unset">Access on-demand object detection expertise</h5><span class="font-normal text-base text-neutral-900 dark:text-neutral-50 text-left" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Embrace on-demand, highly-skilled labeling services and industry-specific insights that help execute object detection tasks at scale.</p></span></div><div class="col-span-12 sm:col-span-6 xl:col-span-3 rounded-xl flex flex-col p-8 bg-white"><img class="h-12 mr-auto" src="../../../images.ctfassets.net/j20krz61k3rk/5wv4GhUXmZneJdUVUbiKtJ/8b8256e0f83bcd71057567581c6a3013/realtime.svg" alt="Collaborate in real-time"/><h5 class="font-normal text-xl md:text-2xl leading-tight font-future text-neutral-900 dark:text-neutral-50 text-left my-6" style="font-feature-settings:unset">Collaborate in real-time</h5><span class="font-normal text-base text-neutral-900 dark:text-neutral-50 text-left" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Enjoy direct access to internal and external labelers with real-time feedback on object detection tasks via the Quantumworks Lab platform.</p></span></div></div></div><div class=""><div class="flex flex-col py-12 md:py-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="space-y-32"><div class="md:grid md:grid-cols-12 md:flex-row items-center gap-12 space-y-12 md:space-y-0 "><div class="order-2  col-span-12 md:col-span-6 p-0"><img src="../../../images.ctfassets.net/j20krz61k3rk/4Cunkt6MwOTHE4qTYpCtKG/b2983053d104809c08cdd64efc491b2d/enrichmi.png" alt="Understanding object detection" class="w-full max-w-2xl "/></div><div class="order-1 col-span-12 md:col-span-6 p-0"><div class="max-w-lg"><div class="mb-2"><small class="font-medium text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Overview</small></div><div class="md:flex-col flex gap-6 items-center md:items-start mb-6"><h3 class="font-medium text-3xl md:text-4xl leading-tight font-future text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Understanding object detection</h3></div><div class="text-lg max-w-2xl text-neutral-500 mb-6"><p class="undefined [&amp;&gt;a]:text-blue-500">Object detection not only identifies what is in an image, but also provides the spatial location of each object. This enables generative models to understand, position, and scale objects correctly in a generated scene.</p></div></div></div></div><div class="md:grid md:grid-cols-12 md:flex-row items-center gap-12 space-y-12 md:space-y-0 "><div class="order-2  col-span-12 md:col-span-6 p-0"><img src="../../../images.ctfassets.net/j20krz61k3rk/5jcZzuIpw6X7AQe1O8ri1j/7ce9ee94de88cb9aa386e1120a62cdc1/object-detection.jpg" alt="Challenges in objection detection tasks" class="w-full max-w-2xl "/></div><div class="order-1 col-span-12 md:col-span-6 p-0"><div class="max-w-lg"><div class="mb-2"><small class="font-medium text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Challenges</small></div><div class="md:flex-col flex gap-6 items-center md:items-start mb-6"><h3 class="font-medium text-3xl md:text-4xl leading-tight font-future text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Challenges in objection detection tasks</h3></div><div class="text-lg max-w-2xl text-neutral-500 mb-6"><p class="undefined [&amp;&gt;a]:text-blue-500">Object detection datasets require precise bounding box annotations for each object, which is both time-consuming and costly to produce. Annotating large datasets with high accuracy is often labor-intensive, and the lack of sufficient labeled data can limit the model performance.</p></div></div></div></div><div class="md:grid md:grid-cols-12 md:flex-row items-center gap-12 space-y-12 md:space-y-0 "><div class="order-2  col-span-12 md:col-span-6 p-0"><img src="../../../images.ctfassets.net/j20krz61k3rk/6BCAcCeHgfRdeo1r2X8hdP/1ca1e495b2d739745a85243f73ed6c57/_configure-diagram.svg" alt="Object detection with Quantumworks Lab" class="w-full max-w-2xl "/></div><div class="order-1 col-span-12 md:col-span-6 p-0"><div class="max-w-lg"><div class="mb-2"><small class="font-medium text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Solution</small></div><div class="md:flex-col flex gap-6 items-center md:items-start mb-6"><h3 class="font-medium text-3xl md:text-4xl leading-tight font-future text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Object detection with Quantumworks Lab</h3></div><div class="text-lg max-w-2xl text-neutral-500 mb-6"><p class="undefined [&amp;&gt;a]:text-blue-500">Quantumworks Lab offers a comprehensive platform with strong roots in advanced computer vision tasks for images and video. Access intuitive annotation tools, customizable workflows, and robust quality control mechanisms that help complete object detection tasks at scale.</p></div></div></div></div></div></div> <div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="rounded-lg overflow-hidden grid grid-cols-12 max-w-5xl mx-auto cursor-pointer"><div style="background-image:url(../../../images.ctfassets.net/j20krz61k3rk/YETOg52F5wHyqSr38vC4V/7d5986079fe27357f5d6995ad81d72af/Speak_Hero.png)" class="min-h-[250px] col-span-12 md:col-span-4 lg:col-span-6 bg-cover bg-center"></div><div class="bg-white flex flex-col justify-between col-span-12 md:col-span-8 lg:col-span-6 p-6 md:p-12"><p class="font-medium text-base text-neutral-900 dark:text-neutral-50 !text-blue-600 font-ibm mb-4" style="font-feature-settings:unset">Customer spotlight</p><span class="font-medium text-base text-neutral-900 dark:text-neutral-50 font-ibm !text-neutral-500" style="font-feature-settings:unset"><p class="undefined [&amp;&gt;a]:text-blue-500">Quantumworks Lab&#x27;s intuitive tooling coupled with post-training labeling services offered a collaborative environment where Speak&#x27;s internal team, along with external data annotators, could work together seamlessly. Learn more about how Speak uses Quantumworks Lab to improving the quality and efficiency of their data labeling.</p></span><a href="../../customers/speak-customer-story/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none text-sm py-1.5 px-2.5 rounded-md font-medium tracking-wide border border-neutral-900 hover:bg-neutral-900/5 dark:bg-transparent text-neutral-900 dark:text-neutral-50 w-fit mt-4" id="" target="_self" style="outline:0 !important">Learn more</a></div></div></div><div class=""> <div class=" rounded-xl mb-12 bg-neutral-200/30 py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><h4 class="font-normal text-2xl md:text-3xl leading-tight font-future text-neutral-900 dark:text-neutral-50 !font-extralight mb-8 text-center" style="font-feature-settings:unset">Explore models for <!-- -->object detection</h4><div class="flex flex-row flex-wrap gap-6 max-w-7xl mx-auto justify-content-center"><a href="../../product/model/foundry-models/groundingdino/index.html" class="xl:flex-1 xl:max-w-xs w-[200px]"><div class="flex flex-row rounded-lg h-full overflow-hidden bg-white"><div style="background-image:url(../../../images.ctfassets.net/j20krz61k3rk/3ugnDSgmvpqRovvrkX40Db/89e60374258a43c86c7f3fe03daccd56/yolo.svg)" class="bg-center bg-cover min-w-[20%]"></div><div class="p-3 flex items-center"><small class="font-bold text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Grounding DINO</small></div></div></a><a href="../../product/model/foundry-models/owl-vit/index.html" class="xl:flex-1 xl:max-w-xs w-[200px]"><div class="flex flex-row rounded-lg h-full overflow-hidden bg-white"><div style="background-image:url(../../../images.ctfassets.net/j20krz61k3rk/3ugnDSgmvpqRovvrkX40Db/89e60374258a43c86c7f3fe03daccd56/yolo.svg)" class="bg-center bg-cover min-w-[20%]"></div><div class="p-3 flex items-center"><small class="font-bold text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">OWL-ViT</small></div></div></a><a href="../../product/model/foundry-models/amazon-rekognition/index.html" class="xl:flex-1 xl:max-w-xs w-[200px]"><div class="flex flex-row rounded-lg h-full overflow-hidden bg-white"><div style="background-image:url(../../../images.ctfassets.net/j20krz61k3rk/4beW2AgTGJdAqhZ6V6JaYB/29014839913c716a0956f82bca94e230/Frame_3406.svg)" class="bg-center bg-cover min-w-[20%]"></div><div class="p-3 flex items-center"><small class="font-bold text-sm text-neutral-900 dark:text-neutral-50" style="font-feature-settings:unset">Amazon Rekognition </small></div></div></a><div class="flex-1  max-w-fit  flex items-center"><a href="../../product/model/foundry-models/index.html" class="border border-neutral-700 hover:bg-neutral-200 rounded-lg p-3 "><p class="font-normal text-base dark:text-neutral-50 text-neutral-800" style="font-feature-settings:unset">View all models</p></a></div></div></div></div><div class="flex flex-col pb-12 md:pb-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-12 md:my-24 w-full h-[1px] bg-neutral-200"></div><div class="flex justify-center mb-12"><h2 class="font-normal text-4xl sm:text-5xl lg:text-6xl leading-tight font-future text-neutral-900 dark:text-neutral-50 mb-6" style="font-feature-settings:unset">Resources</h2></div><div class="grid grid-cols-12 gap-6"><div class="col-span-12 md:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../../guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index8b95.html?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F5LhI08Vt3zfCygqpofT7wF%2Fc3d02d7668865739be76d39a26bdde15%2Fusinglb.webp&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><a href="../../guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Use Quantumworks Lab and foundation models to generate custom embeddings and curate retail data</p></a></div><div><a href="../../guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-base py-2 px-3 rounded-lg font-medium tracking-wide hover:text-blue-900 !px-0 text-blue-500 mt-2" id="" target="_self" style="outline:0 !important">Learn more</a></div></div></div></div></div><div class="col-span-12 md:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../../guides/how-to-evaluate-object-detection-models-using-labelbox-model-foundry/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index3e4b.html?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F01FBNZA5rtMB5eyNWYXFc7%2F1314fcfdac6429b758c7056787b4786d%2FHow_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><a href="../../guides/how-to-evaluate-object-detection-models-using-labelbox-model-foundry/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to evaluate object detection models with Quantumworks Lab Model Foundry</p></a></div><div><a href="../../guides/how-to-evaluate-object-detection-models-using-labelbox-model-foundry/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-base py-2 px-3 rounded-lg font-medium tracking-wide hover:text-blue-900 !px-0 text-blue-500 mt-2" id="" target="_self" style="outline:0 !important">Learn more</a></div></div></div></div></div><div class="col-span-12 md:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../../guides/how-to-train-evaluate-and-improve-your-ml-models/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/indexc897.html?url=https%3A%2F%2Fimages.ctfassets.net%2Fj20krz61k3rk%2F4iXHxnQE3Sr62VSyIr9I5p%2F3ff84a005ac7cb41715ad0833a5503d4%2FHow_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><a href="../../guides/how-to-train-evaluate-and-improve-your-ml-models/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models</p></a></div><div><a href="../../guides/how-to-train-evaluate-and-improve-your-ml-models/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-base py-2 px-3 rounded-lg font-medium tracking-wide hover:text-blue-900 !px-0 text-blue-500 mt-2" id="" target="_self" style="outline:0 !important">Learn more</a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl font-future !leading-tight text-neutral-900">Talk to an expert</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-5xl m-auto">Let&#x27;s explore how Quantumworks Lab can support your product recommendation needs.</p></div><a href="../../sales/index.html" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Contact us</a></section></div></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    Â© Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Object detection","useCaseType":"computer-vision","url":"object-detection","metaTags":{"title":"Object Detection | Quantumworks Lab","description":"Object detection is a CV technique that helps locate items in images and video. Learn how Quantumworks Lab helps align task specific object detection models.","url":"https://labelbox.com/solutions/object-detection/","noIndex":false,"canonical":true},"description":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Guide image and video generation, text-to-image/text-to-video synthesis, scene composition and more with detailed spatial and semantic information about objects in an asset.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"heroImage":{"title":"Object Detection","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/7iaEGHj2YXCtigMpwuOW1q/ff475e53c972ca0a31e3d015743a48a6/Object_Detection.png","details":{"size":629769,"image":{"width":992,"height":616}},"fileName":"Object Detection.png","contentType":"image/png"}},"whyLabelboxSection":{"nameOfContentSection":"Why use Quantumworks Lab for Object Detection","heading":"Why use Quantumworks Lab for Object Detection","linksToEntries":[{"name":"Increase model performance","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"choices","checked":false,"choiceName":"Choices"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Increase model performance","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Enable models to better understand the relationships between objects and their placement with advanced tooling, humans, AI, and on-demand services in a unified solution.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"Reduce costs and increase","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/4WQUNvyqpsugVnibk5ltT4/77013543688d4f0cc27c61e399ad80d9/reduce.svg","details":{"size":556,"image":{"width":48,"height":48}},"fileName":"reduce.svg","contentType":"image/svg+xml"}}},{"name":"Power GenAI models","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"choices","checked":false,"choiceName":"Choices"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Power GenAI models","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Create pixel-perfect bounding boxes, segmentations, and landmark annotations to help text-to-image and text-to-video models generate accurate and realistic assets.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"Rapid data delivery","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/6X68rya8Qep7XG2DX3KBcA/da5039109a90f0b49da4579c62a5cadb/1-2.svg","details":{"size":2333,"image":{"width":48,"height":48}},"fileName":"1-2.svg","contentType":"image/svg+xml"}}},{"name":"Access on-demand object detection expertise","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Access on-demand object detection expertise","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Embrace on-demand, highly-skilled labeling services and industry-specific insights that help execute object detection tasks at scale.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"Access coding experts on-demand","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/3yrsn6MYlVNreNLr4CFSET/3c326e0f3e7c586df90e116ec9e9eafb/access.svg","details":{"size":5846,"image":{"width":49,"height":48}},"fileName":"access.svg","contentType":"image/svg+xml"}}},{"name":"Collaborate in real-time","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Collaborate in real-time","flexibleContent":{"nodeType":"document","data":{},"content":[{"nodeType":"paragraph","content":[{"nodeType":"text","value":"Enjoy direct access to internal and external labelers with real-time feedback on object detection tasks via the Quantumworks Lab platform.","marks":[],"data":{}}],"data":{}}]},"image":{"title":"Collaborate in real-time","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/5wv4GhUXmZneJdUVUbiKtJ/8b8256e0f83bcd71057567581c6a3013/realtime.svg","details":{"size":3586,"image":{"width":48,"height":48}},"fileName":"realtime.svg","contentType":"image/svg+xml"}}}]},"featuredModels":[{"title":"Grounding DINO","metaTags":{"title":"Grounding DINO | Quantumworks Lab","noIndex":false},"description":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Open-set object detector that by combines a Transformer-based detector DINO with grounded pre-training. It can detect arbitrary objects with human inputs such as category names or referring expressions.","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Intended Use","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"Useful for zero shot object detection tasks.","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"\n Performance","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"Grounding DINO performs remarkably well on all three settings, including benchmarks on COCO, LVIS, ODinW, and RefCOCO/+/g. Grounding DINO achieves a 52.5 AP on the COCO detection zero-shot transfer benchmark, i.e., without any training data from COCO. It sets a new record on the ODinW zero-shot benchmark with a mean 26.1 AP","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Citation","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"","nodeType":"text"},{"data":{"uri":"https://github.com/IDEA-Research/GroundingDINO"},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"https://github.com/IDEA-Research/GroundingDINO","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[{"type":"underline"}],"value":"","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"","nodeType":"text"},{"data":{"uri":"https://arxiv.org/abs/2303.05499"},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"https://arxiv.org/abs/2303.05499","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"box","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/3ugnDSgmvpqRovvrkX40Db/89e60374258a43c86c7f3fe03daccd56/yolo.svg","details":{"size":4101,"image":{"width":283,"height":152}},"fileName":"yolo.svg","contentType":"image/svg+xml"}},"pageurl":"groundingdino","category":["Object detection"],"publishedOn":"2023-07-26","price":"$0.0003 per compute second","privacyPolicy":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Quantumworks Lab","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"icon":{"title":"Object detection","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/7xZDqdEMyIYROXzWZAIL1M/4c5e0492c71eb8b80e935358decb3ca0/objectdetection.svg","details":{"size":4195,"image":{"width":20,"height":20}},"fileName":"objectdetection.svg","contentType":"image/svg+xml"}}},{"title":"OWL-ViT","metaTags":{"title":"OWL-ViT | Quantumworks Lab","noIndex":false},"description":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"The OWL-ViT (short for Vision Transformer for Open-World Localization) was proposed in Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby. ","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"OWL-ViT is an open-vocabulary object detection network trained on a variety of (image, text) pairs. It can be used to query an image with one or multiple text queries to search for and detect target objects described in text.\n","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"\nIntended Use","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"OWL-ViT is a zero-shot text-conditioned object detection model. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. To use CLIP for detection, OWL-ViT removes the final token pooling layer of the vision model and attaches a lightweight classification and box head to each transformer output token. Open-vocabulary classification is enabled by replacing the fixed classification layer weights with the class-name embeddings obtained from the text model. The authors first train CLIP from scratch and fine-tune it end-to-end with the classification and box heads on standard detection datasets using a bipartite matching loss. One or multiple text queries per image can be used to perform zero-shot text-conditioned object detection.","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"\n\nPerformance","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"OWL-ViT achieves zero-shot detection results competitive with much more complex approaches on the challenging LVIS benchmark and outperforms pre-existing methods on image-conditioned detection by a large margin.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"box","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/3ugnDSgmvpqRovvrkX40Db/89e60374258a43c86c7f3fe03daccd56/yolo.svg","details":{"size":4101,"image":{"width":283,"height":152}},"fileName":"yolo.svg","contentType":"image/svg+xml"}},"pageurl":"owl-vit","category":["Object detection"],"publishedOn":"2023-05-10","price":"$0.0003 per compute second","privacyPolicy":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Quantumworks Lab","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"icon":{"title":"Object detection","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/7xZDqdEMyIYROXzWZAIL1M/4c5e0492c71eb8b80e935358decb3ca0/objectdetection.svg","details":{"size":4195,"image":{"width":20,"height":20}},"fileName":"objectdetection.svg","contentType":"image/svg+xml"}}},{"title":"Amazon Rekognition ","metaTags":{"title":"Amazon Rekognition | Quantumworks Lab","description":"Amazon Rekognition is a cloud-based AI service by Amazon Web Services (AWS) for images.","url":"https://labelbox.com/product/model/foundry-models/amazon-rekognition/","noIndex":false,"canonical":true},"description":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Common objects detection and image classification model by AWS Rekognition. ","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Intended Use","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"Amazon Rekognition's objectÂ detection modelÂ is primarilyÂ used for detectingÂ objects, scenes, activities, landmarks, faces, dominantÂ colors, and imageÂ quality in imagesÂ and videos. Some common use cases include: ","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Detect and label common objects in imagesÂ ","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Identify activities and scenes in visual content","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Enable content moderation and filtering","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Enhance image search capabilities","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"}],"nodeType":"unordered-list"},{"data":{},"content":[{"data":{},"marks":[],"value":"\n","nodeType":"text"},{"data":{"uri":"https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html"},"content":[{"data":{},"marks":[],"value":"Learn more","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Performance\n","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"Amazon Rekognition's object detection model has been reported to have high accuracy ind detecting objects and scenes in images and videos. Its capabilities include:","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Can detect thousands of object categories","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Provides bounding boxes for object locations","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Assigns confidence scores to detections","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"}],"nodeType":"unordered-list"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"},{"data":{"uri":"https://aws.amazon.com/rekognition/faqs/"},"content":[{"data":{},"marks":[],"value":"Learn more","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Limitations","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"the performance of the model may be limited by factors such as the quality and quantity of training data, the complexity of the image content, or the accuracy of the annotations.Â Additionally, Amazon Rekognition may have detection issues with black and white images and elderly people. ","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"Other limitations include:","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"May struggle with small or partially obscured objects","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Performance can vary based on image quality and lighting","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Limited ability to understand context or relationships between objects","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Cannot identify specific individuals (separate face recognition API for that)","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"},{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"May have biases in detection rates across different demographics","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"list-item"}],"nodeType":"unordered-list"},{"data":{},"content":[],"nodeType":"hr"},{"data":{},"content":[{"data":{},"marks":[],"value":"Citation","nodeType":"text"}],"nodeType":"heading-3"},{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"},{"data":{"uri":"https://docs.aws.amazon.com/rekognition/"},"content":[{"data":{},"marks":[],"value":"Amazon Rekognition documentation ","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"[Model Foundry] object detection ","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/4beW2AgTGJdAqhZ6V6JaYB/29014839913c716a0956f82bca94e230/Frame_3406.svg","details":{"size":4193,"image":{"width":363,"height":232}},"fileName":"Frame 3406.svg","contentType":"image/svg+xml"}},"pageurl":"amazon-rekognition","category":["Object detection","Image classification"],"publishedOn":"2024-08-05","price":"0.001 $ per api call","privacyPolicy":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"","nodeType":"text"},{"data":{"uri":"https://aws.amazon.com/compliance/data-privacy-faq/"},"content":[{"data":{},"marks":[],"value":"Amazon","nodeType":"text"}],"nodeType":"hyperlink"},{"data":{},"marks":[],"value":"","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"icon":{"title":"Object detection","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/7xZDqdEMyIYROXzWZAIL1M/4c5e0492c71eb8b80e935358decb3ca0/objectdetection.svg","details":{"size":4195,"image":{"width":20,"height":20}},"fileName":"objectdetection.svg","contentType":"image/svg+xml"}}}],"features":[{"name":"Understanding object detection","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":true,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Understanding object detection","contentType":"Overview","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Object detection not only identifies what is in an image, but also provides the spatial location of each object. This enables generative models to understand, position, and scale objects correctly in a generated scene.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"Enrich your data and automate common tasks with foundation models","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/4Cunkt6MwOTHE4qTYpCtKG/b2983053d104809c08cdd64efc491b2d/enrichmi.png","details":{"size":229359,"image":{"width":673,"height":599}},"fileName":"enrichmi.png","contentType":"image/png"}}},{"name":"Challenges in objection detection tasks","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"choices","checked":false,"choiceName":"Choices"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":true,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Challenges in objection detection tasks","contentType":"Challenges","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Object detection datasets require precise bounding box annotations for each object, which is both time-consuming and costly to produce. Annotating large datasets with high accuracy is often labor-intensive, and the lack of sufficient labeled data can limit the model performance.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"object detection","description":"object detection","file":{"url":"//images.ctfassets.net/j20krz61k3rk/5jcZzuIpw6X7AQe1O8ri1j/7ce9ee94de88cb9aa386e1120a62cdc1/object-detection.jpg","details":{"size":214935,"image":{"width":1208,"height":840}},"fileName":"object-detection.jpg","contentType":"image/jpeg"}}},{"name":"Object detection with Quantumworks Lab","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"choices","checked":false,"choiceName":"Choices"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":true,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":false,"choiceName":"Url"},{"choice":"ctaText","checked":false,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"Object detection with Quantumworks Lab","contentType":"Solution","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Quantumworks Lab offers a comprehensive platform with strong roots in advanced computer vision tasks for images and video. Access intuitive annotation tools, customizable workflows, and robust quality control mechanisms that help complete object detection tasks at scale.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"image":{"title":"rapid delivery","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/6BCAcCeHgfRdeo1r2X8hdP/1ca1e495b2d739745a85243f73ed6c57/_configure-diagram.svg","details":{"size":44922,"image":{"width":850,"height":479}},"fileName":"_configure-diagram.svg","contentType":"image/svg+xml"}}}],"testimonial":{"name":"Speak customer story","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":true,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":true,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":true,"choiceName":"Url"},{"choice":"ctaText","checked":true,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"audio","checked":false,"choiceName":"Audio"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":true,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"},{"choice":"metaTags","checked":false,"choiceName":"Meta Tags"},{"choice":"isFullWidth","checked":false,"choiceName":"isFullWidth"}]},"heading":"How Speak elevates language learning with high-quality AI data","contentType":"Article","flexibleContent":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Quantumworks Lab's intuitive tooling coupled with post-training labeling services offered a collaborative environment where Speak's internal team, along with external data annotators, could work together seamlessly. Learn more about how Speak uses Quantumworks Lab to improving the quality and efficiency of their data labeling.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"url":"https://labelbox.com/customers/speak-customer-story/","ctaText":"Learn more","image":{"title":"speak-customer-image","description":"speak app hero story","file":{"url":"//images.ctfassets.net/j20krz61k3rk/YETOg52F5wHyqSr38vC4V/7d5986079fe27357f5d6995ad81d72af/Speak_Hero.png","details":{"size":1616982,"image":{"width":1236,"height":1236}},"fileName":"Speak Hero.png","contentType":"image/png"}},"publishedOn":"2024-12-02"},"resources":[{"name":"Use Quantumworks Lab and foundation models to generate custom embeddings and curate retail data","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":false,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":true,"choiceName":"Url"},{"choice":"ctaText","checked":true,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"}]},"heading":"Use Quantumworks Lab and foundation models to generate custom embeddings and curate retail data","url":"https://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/","ctaText":"Learn more","image":{"title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/5LhI08Vt3zfCygqpofT7wF/c3d02d7668865739be76d39a26bdde15/usinglb.webp","details":{"size":107732,"image":{"width":1920,"height":1080}},"fileName":"usinglb.webp","contentType":"image/webp"}}},{"name":"How to evaluate object detection models with Quantumworks Lab Model Foundry","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":false,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":true,"choiceName":"Url"},{"choice":"ctaText","checked":true,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"}]},"heading":"How to evaluate object detection models with Quantumworks Lab Model Foundry","url":"https://labelbox.com/guides/how-to-evaluate-object-detection-models-using-labelbox-model-foundry/","ctaText":"Learn more","image":{"title":"How to evaluate object detection models with Quantumworks Lab Model Foundry","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/01FBNZA5rtMB5eyNWYXFc7/1314fcfdac6429b758c7056787b4786d/How_to_evaluate_object_detection_models_with_Labelbox_Model_Foundry.png","details":{"size":668553,"image":{"width":1920,"height":1080}},"fileName":"How to evaluate object detection models with Quantumworks Lab Model Foundry.png","contentType":"image/png"}}},{"name":"How to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models","choices":{"showFields":[{"choice":"name","checked":true,"choiceName":"Name"},{"choice":"heading","checked":true,"choiceName":"Heading"},{"choice":"headerStyles","checked":false,"choiceName":"HeaderStyles"},{"choice":"contentType","checked":false,"choiceName":"Content type"},{"choice":"body","checked":false,"choiceName":"Body"},{"choice":"flexibleContent","checked":false,"choiceName":"Flexible content"},{"choice":"flexibleContent2","checked":false,"choiceName":"Flexible Content 2"},{"choice":"searchableContent","checked":false,"choiceName":"Searchable content"},{"choice":"url","checked":true,"choiceName":"Url"},{"choice":"ctaText","checked":true,"choiceName":"Cta text"},{"choice":"secondaryCtaText","checked":false,"choiceName":"Secondary Cta Text"},{"choice":"secondaryCtaUrl","checked":false,"choiceName":"Secondary Cta Url"},{"choice":"icon","checked":false,"choiceName":"Icon"},{"choice":"image","checked":true,"choiceName":"Image"},{"choice":"mobileImage","checked":false,"choiceName":"Mobile Image"},{"choice":"video","checked":false,"choiceName":"Video"},{"choice":"isVideo","checked":false,"choiceName":"isVideo"},{"choice":"isActive","checked":false,"choiceName":"Is active"},{"choice":"assets","checked":false,"choiceName":"Assets"},{"choice":"customData","checked":false,"choiceName":"customData"},{"choice":"videoUrl","checked":false,"choiceName":"videoUrl"},{"choice":"videoUrl2","checked":false,"choiceName":"videoUrl2"},{"choice":"backgroundColor","checked":false,"choiceName":"background color"},{"choice":"image2","checked":false,"choiceName":"Image2"},{"choice":"publishedOn","checked":false,"choiceName":"Published on"},{"choice":"isSmallImage","checked":false,"choiceName":"Is Small Image"},{"choice":"linkToEntries","checked":false,"choiceName":"linkToEntries"},{"choice":"isAnimatedGraphic","checked":false,"choiceName":"isAnimatedGraphic"}]},"heading":"How to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models","url":"https://labelbox.com/guides/how-to-train-evaluate-and-improve-your-ml-models/","ctaText":"Learn more","image":{"title":"How to get started in Quantumworks Lab Model- Train, evaluate, and improve your ML models","description":"","file":{"url":"//images.ctfassets.net/j20krz61k3rk/4iXHxnQE3Sr62VSyIr9I5p/3ff84a005ac7cb41715ad0833a5503d4/How_to_get_started_in_Labelbox_Model-_Train__evaluate__and_improve_your_ML_models.png","details":{"size":411105,"image":{"width":1920,"height":1080}},"fileName":"How to get started in Quantumworks Lab Model- Train, evaluate, and improve your ML models.png","contentType":"image/png"}}}],"contentType":"useCases"},"__N_SSG":true},"page":"/solutions/[id]","query":{"id":"object-detection"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/solutions/object-detection/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 11:10:06 GMT -->
</html>