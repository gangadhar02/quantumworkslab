<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/guides/tag/explore-manage-data/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 11:32:03 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Guides | Quantumworks Lab</title><meta name="description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><link rel="preconnect" href="../../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta property="og:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta property="og:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="og:image" content="/static/images/guides-social.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta name="twitter:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="twitter:image" content="/static/images/guides-social.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../../static/scripts/munchkin.js"></script><script src="../../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../../_next/static/chunks/5008-6b2f21a0ee7e9705.js" defer=""></script><script src="../../../_next/static/chunks/pages/guides/tag/%5bid%5d-cc2bd40a983392d8.js" defer=""></script><script src="../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
<link rel="stylesheet" href="fix-footer-visibility.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../../index.html"><img width="106" height="24" alt="logo" src="../../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><div class="py-12 md:py-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3"><div class="sticky top-24"><img src="../../../static/images/guide.svg" class="h-10"/><h1 class="font-future text-2xl md:text-4xl font-bold my-5">Guides</h1><p class="text-base max-w-xs text-neutral-500  pr-6">Covering everything you need to know in order to build AI products faster.</p><div class="pb-4 md:pb-0"><div class="flex relative  md:max-w-xs my-10  md:pr-6"><input type="text" class="bg-transparent border-[1px] border-solid border-black w-full rounded-md pl-10 p-2 focus-visible:outline-none" placeholder="Search..."/><img class="absolute top-3 left-0 ml-2 w-6" src="../../../static/images/library/large_search_icon.svg"/></div></div><div class="hidden md:flex md:flex-col"><a href="../../index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Latest</a><a href="../build-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Build AI</a><a href="../use-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Use AI</a><a href="index.html" class="text-base text-neutral-900 font-medium hover:text-neutral-800 mb-4">Explore &amp; manage data</a><a href="../label-data-for-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Label data for AI</a><a href="../train-fine-tune-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Train &amp; fine-tune AI</a><a href="../mlops/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">MLOps</a></div></div></div><div class="col-span-12 md:col-span-9"><div class="mb-10"><h2 class="text-3xl md:text-4xl font-medium mb-4">Explore &amp; manage data</h2><p class="text-base max-w-2xl font-medium text-neutral-500"></p></div><div class="grid grid-cols-12 gap-6"><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-improve-search-relevance/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index4a80.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F04%2Fthumbnail--6-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-improve-search-relevance/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to use AI to improve website search relevance</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how you can dramatically improve search relevance for any website or app by using AI and foundation models to better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-sync-your-cloud-buckets-with-labelbox/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/indexa295.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2024%2F02%2FFrame-3410--2-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-sync-your-cloud-buckets-with-labelbox/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to sync your cloud buckets with Quantumworks Lab</p><p class="text-base max-w-2xl undefined line-clamp-3">Sync your unstructured data automatically and skip glue scripts with native support for S3 (AWS), GCS (GCP) and Blob Storage (Azure).  </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-automatically-ingest-data-from-databricks-into-labelbox/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index8e0a.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F12%2FDatabricksLabelboxIngestionPipeline_Guide_Header.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-automatically-ingest-data-from-databricks-into-labelbox/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to automatically ingest data from Databricks into Quantumworks Lab</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index0a79.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FGroup-2457--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to analyze customer reviews and improve customer care with NLP</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to leverage Quantumworks Lab&#x27;s data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-build-a-content-moderation-model-to-detect-disinformation/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index0db2.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F11%2FFrame-2299--2-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-build-a-content-moderation-model-to-detect-disinformation/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to build a content moderation model to detect disinformation</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust &amp; safety applications. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-build-a-powerful-product-recommendation-system-for-retail/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/indexe6a1.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F08%2FGroup-3078--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-build-a-powerful-product-recommendation-system-for-retail/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to build a powerful product recommendation system for retail</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to leverage Quantumworks Lab&#x27;s data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/indexedfb.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FScreen-Shot-2023-05-24-at-1.45.31-PM.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Leveraging YOLO and Quantumworks Lab to make videos queryable by content</p><p class="text-base max-w-2xl undefined line-clamp-3">In this guide, we&#x27;ll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../automatically-label-images-with-99-accuracy-using-foundation-models/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index200d.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FGroup-3058--2-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../automatically-label-images-with-99-accuracy-using-foundation-models/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Automatically label images with 99% accuracy using foundation models</p><p class="text-base max-w-2xl undefined line-clamp-3">Automatically label images with 99% accuracy leveraging Quantumworks Lab&#x27;s search capabilities, bulk classification, and foundation models. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../how-to-export-your-data-with-more-granular-control/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index8519.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F05%2FFrame-2299--3-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../how-to-export-your-data-with-more-granular-control/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Introducing Export V2: How to export data with more granular control</p><p class="text-base max-w-2xl undefined line-clamp-3">With Export V2, you can export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=3840&amp;q=70 3840w" src="../../../_next/image/index4b8a.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data</p><p class="text-base max-w-2xl undefined line-clamp-3">In this guide, we&#x27;ll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.</p></a></div></div></div></div></div><div class="col-span-12"><div class="flex align-items-center justify-content-center mx-auto mt-8">Page 1 of 2<a class="ml-9 text-neutral-700 mb-1" href="page/2/index.html">&gt;</a></div></div></div></div></div></div>
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><span style="color: inherit; cursor: default;">Docs</span></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <span style="color: inherit; cursor: default;">Terms of Service</span>
                    <div class="footer-divider"></div>
                    <span style="color: inherit; cursor: default;">Privacy Notice</span>
                    <div class="footer-divider"></div>
                    <span style="color: inherit; cursor: default;">Copyright Dispute Policy</span>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"id":"66183ccc8d5c4a00014061cc","uuid":"2afa1d4e-85b9-48d3-ae01-81c57db2916b","title":"How to use AI to improve website search relevance","slug":"how-to-improve-search-relevance","html":"\u003cp\u003eWith the latest advances in foundation models, organizations can now enhance search relevance for websites by better matching between user intent with product listings. While companies now have access to a wealth of search queries, sifting through all of these search results can be incredibly time-consuming and resource-intensive. By leveraging AI, teams can now analyze search queries and feedback at scale, to gain insights into common topics or customer sentiment. This allows businesses to identify common themes and pinpoint areas of improvement to enhance\u0026nbsp;their overall website experience to maximize for key metrics such as user retention, conversion and revenue.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for search relevance. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eImproving search relevance requires a vast amount of data in the form of search queries and accurate product descriptions. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDynamic review landscape: \u003c/strong\u003eThe changing nature and format of customer review data from multiple sources (e.g webpages, apps, social media, etc.) poses the challenge for businesses to account for continuous data updates and re-training needs.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers businesses to transform their website search relevance for product descriptions and listings. Instead of relying on time-consuming manual reviews, companies can leverage Quantumworks Lab’s assisted data enrichment and flexible training frameworks to quickly build AI systems that uncover actionable insights from customer searches. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-full\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1746\" height=\"952\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1746w\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to dramatically improve search relevance for any website or app. Specifically, this guide will walk through how you can explore and better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-use-ai-to-improve-search-relevance-for-your-website\"\u003eSee it in action: How to use AI to improve search relevance for your website\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Create a model run and evaluate model performance\u003c/p\u003e\u003cp\u003eYou can follow along with both parts of the tutorial below in either: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1-kTALPqchHXGogUdRVnya7GklKHrsWVL?ref=labelbox-guides.ghost.io#scrollTo=Vw_nNPl8baNJ\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1-kTALPqchHXGogUdRVnya7GklKHrsWVL?ref=labelbox-guides.ghost.io#scrollTo=Vw_nNPl8baNJ\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAs customer queries and product descriptions across channels proliferate, brands want to learn from customer feedback to build the most user-friendly experience on their website or app. For this use case, we’ll be working with a dataset of e-commerce website queries – with the goal of analyzing the queries to demonstrate how a company could gain insight into how their customers search for products and how to optimize for relevance.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/vpl1wf0vui\" title=\"Search relevance 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eThe first step will be to gather data:\u003c/p\u003e\u003cp\u003eFor the purpose of this tutorial, we’ve provided a sample open-source \u003ca href=\"https://www.kaggle.com/datasets/jiashenliu/515k-hotel-reviews-data-in-europe?ref=labelbox-guides.ghost.io\"\u003eKaggle dataset\u003c/a\u003e that can be downloaded.  \u003c/p\u003e\u003cp\u003ePlease \u003ca href=\"https://drive.google.com/file/d/1hh2MYzol6-4PSsqX7mbX2YSLLGA4jAYZ/view?usp=drivesdk\u0026ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003edownload the dataset\u003c/a\u003e and store it in an appropriate location on your environment. You'll also need to update the read/write file paths throughout the notebook to reflect relevant locations on your environment. You'll also need to update all references to API keys, and Quantumworks Lab ontology, project, and model run IDs\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf you wish to follow along and work with your own data, you can import your text data as a CSV. \u003c/li\u003e\u003cli\u003eIf your text snippets sit as individual files in cloud storage, you can reference the URL of these files through our \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003eIAM delegated access integration\u003c/a\u003e.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve uploaded your dataset, you should see your text data rendered in Quantumworks Lab Catalog. You can browse through the dataset and visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data-by-clustering\"\u003eSearch and curate data by clustering\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1538\" height=\"708\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 1538w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUse Smart select to cluster data and focus your model improvement on specific data rows\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExplore topics of interest\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWith your data in Quantumworks Lab, you can begin to leverage Catalog to uncover interesting topics to get a sense of what customers are searching for. \u003c/p\u003e\u003cul\u003e\u003cli\u003eVisualize your data –\u0026nbsp; you can click through individual data rows to get a sense for which queries are the most popular.\u003c/li\u003e\u003cli\u003eDrill into specific topics of interest\u003cstrong\u003e \u003c/strong\u003e– leverage natural language search, for example searching “beds, mirrors, etc,” to bring up all related queries related to that topic. You can adjust the confidence threshold of your searches accordingly which can be helpful in gauging the volume of data related to the topic of interest.\u0026nbsp;\u003c/li\u003e\u003cli\u003eEasily find all instances of similar examples to data of interest.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-2-create-an-initial-model-run-of-search-relevance-assessments\"\u003ePart 2: Create an initial model run of search relevance assessments \u003c/h2\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/t3er59wcfk\" title=\"Search relevance 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eAfter we’ve explored our data, we now have a better understanding of what topics exist in our dataset and can proceed to using Quantumworks Lab's Foundry product to model run an initial model run to accelerate search relevance assessments.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFirst, you'll need to set up your ontology for search relevance assessment based on your project's requirements.\u003c/li\u003e\u003cli\u003eAfterwards, you can define the criteria for rating the relevance of search results to each type of query.\u003c/li\u003e\u003cli\u003eNext, you can communicate the business definition of relevance to the models directly into the prompt. You can use Foundry to add context to the prompt, allowing it to rank results as if it were part of your respective business. In this example, we'll include the prompts for what \"good relevance\", \"excellent relevance\", etc and help the model predict what would fit under this criteria. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAs an illustrative example, you can set up \"excellent relevance\" as a result that perfectly matches the search query, including all specific attributes (category, material, color, purpose, etc). This indicates that the term is exactly what the user is searching for. For the query, \"kitchen blender stainless steel\", a result for \"stainless steel countertop blender\" is highly relevant, matching the user's intended category.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"673\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eGenerate an initial preview to assess how well the adjusted prompt performs and you can save the adjusted prompt as an app, including data type (text), ontology, and the original prompt. This allows for easy re-use and the ability to build upon the saved app for future assessments of search relevance criteria. \u003c/p\u003e\u003cp\u003eAfter this has been set up, you can now generate the next preview to ensure quality before submitting the model run for assessments.\u003c/p\u003e\u003ch3 id=\"view-search-relevance-assessments-results\"\u003eView search relevance assessments results \u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/gq8nnv2ykw\" title=\"Search relevance 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eOnce your model inferencing job has been completed, you can then navigate to the model tab and locate a variety of foundation models (e.g., Claude 3 will be used in this tutorial) to view the completed model run with your rankings.\u003c/li\u003e\u003cli\u003eOptionally, you can add an explanation classification or review the results of the ranking, which includes all 560 items/data rows.\u003c/li\u003e\u003cli\u003eBy adding the results to your project, you can next perform further analytics such as analyzing the distributions of predictions from the Metrics view.\u003c/li\u003e\u003cli\u003eNext, select all items and you can send them to Annotate, and choose \"search relevance assessment\", where you'll then be able to have humans review as an additional quality check.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"further-analyze-and-optimize-your-search-relevance-assessments-results\"\u003eFurther analyze and optimize your search relevance assessments results \u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/kw7in8bosa\" title=\"Search relevance 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eThe last part of the walkthrough is to analyze your distribution of relevance categories within your project, noting varying levels of relevance and to review the query class for all 560 data rows to identify trends in relevance. You can do this by using automated approaches to understand query types and relevance patterns, as we show in the video above.\u003c/li\u003e\u003cli\u003eBy filtering your dataset by the search relevance assessment project, you can navigate to the Analytics view to identify trends and examples of excellent relevance and poor relevance within specific query classes (as shown below).\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"883\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample analytics distribution showing excellent relevance on terms like kids wall decor, sectionals and area rugs.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"838\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample analytics distribution showing poor relevance for beds, furniture cushions, mirrors\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eAs this time, you can consider adjusting prompts to accurately reflect relevance criteria, or use metadata fields, such as query class, to further analyze relevance.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo further evaluate and enrich the data, teams can also explore incorporating human supervision in the labeling process, with a hybrid or combination approaches: fully automated, half human in the loop, half automated, or all human-in-the-loop.\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, you can improve your data further in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://www.alignerr.com/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eAlignerr\u003c/a\u003e: Leverage our global network of\u0026nbsp;specialized labelers for a variety of tasks.\u0026nbsp;This community of subject matter experts from several disciplines align AI models by creating high-quality data in their field of expertise. The community spans nearly every major discipline of sciences, industries and languages, worldwide.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eBy tapping into the most recent developments in foundation models, businesses can transform the effectiveness of website searches by refining the alignment between user intent and product offerings. Given the abundance of search queries that a prospective customer may use, the process of sorting through them manually is labor-intensive and time-consuming. \u003c/p\u003e\u003cp\u003eBy harnessing the power of AI, organizations can efficiently examine search queries and feedback on a large scale, uncovering recurring themes and gauging customer sentiment. \u003c/p\u003e\u003cp\u003eThis enables enterprises to detect prevalent trends and target areas for enhancement, allowing them to optimizing the overall website experience to drive key metrics like user retention, conversion rates, and revenue. Remember to optimize the \u003ca href=\"https://www.web4business.com.au/portfolio-item/the-most-important-24-pages-to-include-on-website/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ewebsite content\u003c/a\u003e as well to ensure it's meeting your end user's goals. Give the walkthrough a try and we also recommend checking out our other solution accelerators such as \u003ca href=\"https://labelbox.com/guides/how-to-build-a-powerful-product-recommendation-system-for-retail/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003epersonalized experiences\u003c/a\u003e for retail to improve customer experiences.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful search relevance websites. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"66183ccc8d5c4a00014061cc","feature_image":"https://labelbox-guides.ghost.io/content/images/2024/04/thumbnail--6-.png","featured":false,"visibility":"public","created_at":"2024-04-11T19:41:00.000+00:00","updated_at":"2024-09-12T23:45:53.000+00:00","published_at":"2024-04-12T17:02:16.000+00:00","custom_excerpt":"Learn how you can dramatically improve search relevance for any website or app by using AI and foundation models to better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-improve-search-relevance/","excerpt":"Learn how you can dramatically improve search relevance for any website or app by using AI and foundation models to better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"65dd3fe1255738000153641c","uuid":"17cc9bd7-9e84-499a-850d-e6ead9b48f85","title":"How to sync your cloud buckets with Quantumworks Lab","slug":"how-to-sync-your-cloud-buckets-with-labelbox","html":"\u003cp\u003eLabelbox recently introduced the ability to synchronize your cloud buckets from Amazon, Google and Microsoft Azure into Quantumworks Lab Catalog. This improvement greatly simplifies the existing integration by eliminating the need to customize JSON or configure Python scripts.\u003c/p\u003e\u003cp\u003eLabelbox supports native integrations with cloud storage from leading providers including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAmazon S3\u003c/li\u003e\u003cli\u003eGoogle Cloud Storage\u003c/li\u003e\u003cli\u003eMicrosoft Azure Blob Storage\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eCloud architecture plays a critical role in ensuring scalability, flexibility, and security for your data management – and it’s always good to\u0026nbsp;\u003ca href=\"https://www.ssw.com.au/rules/cloud-architect/?ref=labelbox-guides.ghost.io\"\u003ehave a cloud expert on your team\u003c/a\u003e.\u0026nbsp;If you are familiar with how cloud storage works, you can\u0026nbsp;\u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1%3F\u0026landingPageAnonymousId=%223bed3496-d471-4095-ba10-c34e51bd36cd%22\u0026ref=labelbox-guides.ghost.io\"\u003eintegrate your cloud bucket\u003c/a\u003e\u0026nbsp;when adding a dataset to Labelbox. This guide is intended to show you how to set up and use cloud storage integration with Quantumworks Lab Catalog.\u003c/p\u003e\u003ch3 id=\"why-use-cloud-storage-integrations\"\u003eWhy use cloud storage integrations?\u003c/h3\u003e\u003cp\u003eCloud buckets are a simple and efficient way to manage large volumes of unstructured data, especially for computer vision use cases involving working documents, images and video. The Quantumworks Lab cloud storage integration can automatically scan any set of folders in your cloud bucket and synchronize the following data types into the Quantumworks Lab Catalog:\u003c/p\u003e\u003cul\u003e\u003cli\u003eImage\u003c/li\u003e\u003cli\u003eVideo\u003c/li\u003e\u003cli\u003eText\u003c/li\u003e\u003cli\u003eAudio\u003c/li\u003e\u003cli\u003eHTML\u003c/li\u003e\u003cli\u003eTiled imagery (COG, NITF, GeoTIFF)\u003c/li\u003e\u003cli\u003eDocuments\u003c/li\u003e\u003cli\u003eChat (Conversations)\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"how-to-sync-a-dataset-with-your-cloud-bucket\"\u003eHow to sync a dataset with your cloud bucket?\u003c/h3\u003e\u003cp\u003eAfter completing the one-time setup of delegated access to your object store (see \u003ca href=\"https://docs.google.com/document/d/17BG09nOqil7rQ6oub493o-bYrUxNSghEbMCvfxX6-MI/edit?ref=labelbox-guides.ghost.io#heading=h.8iysj0uw5p9s\"\u003e\u003cu\u003esection below\u003c/u\u003e\u003c/a\u003e), you can use the Quantumworks Lab UI to configure the synchronization of any folder to a dataset in the Quantumworks Lab Catalog with just a few clicks.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/tz0beimgxb?wtime=56s\" title=\"Quantumworks Lab Cloud Storage Integration Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"552\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eOnce configured, you can sync any connected dataset with your cloud storage with a single click.\u003c/p\u003e\u003ch3 id=\"how-to-set-up-delegated-access-to-your-cloud-storage-provider\"\u003eHow to set up delegated access to your cloud storage provider\u003c/h3\u003e\u003cp\u003eThe one prerequisite for using the Quantumworks Lab Cloud Storage integration is \u003ca href=\"https://docs.labelbox.com/reference/cloud-storage-iam-integration?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003esetting up IAM delegated access\u003c/u\u003e\u003c/a\u003e. This is a one-time setup process for each object store allowing Quantumworks Lab to access assets stored in your cloud buckets that you would like to add to Catalog or label using Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIAM delegated access works similarly whether you are using Amazon S3, Microsoft Azure or Google Cloud Storage (GCS). For example, when you use IAM delegated access to add your unlabeled data to Quantumworks Lab, you can keep your assets in Amazon S3 and grant Quantumworks Lab read-only access to your AWS cloud buckets.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-us.googleusercontent.com/he2QAvnCZbh2UwVpU_dLEi7X8jriKJPCwsMGwiStTew6dkbQT4FasCpwngZ1Y0gjo7R1DOxn5H6Cf4GzcLmuqpiVcTEORt3rMBVbDgVMv9bh9g4RyuePgnSIBYU40VcXHlE0OZCRK6gmwmXzxUkg02w\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"645\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eDelegated Access setup in AWS (similar in GCP)\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIAM delegated access is highly flexible and allows you to control access at the granularity that you desire. \u003c/p\u003e\u003cul\u003e\u003cli\u003eYou can grant Quantumworks Lab access to all of your buckets, a single bucket, or even a particular path within a bucket. \u003c/li\u003e\u003cli\u003eYou can even set up different integrations within Quantumworks Lab for different datasets or projects. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIAM delegated access allows you to use private cloud-hosted buckets with Quantumworks Lab, which helps to ensure that your assets are kept safe.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ghtx8fcwka\" title=\"Quantumworks Lab IAM Setup for Cloud Storage integration Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"552\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eRefer to the documentation for additional information on \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003esetting up IAM delegated access in Quantumworks Lab\u003c/u\u003e\u003c/a\u003e, and \u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1\u0026ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eadd data to Quantumworks Lab\u003c/u\u003e\u003c/a\u003e from your cloud bucket with ease.\u003c/p\u003e\u003ch3 id=\"summary\"\u003eSummary\u003c/h3\u003e\u003cp\u003eStoring data in cloud buckets is a simple and effective way to manage large volumes of unstructured data – especially images, video and documents. Connecting and synchronizing your cloud storage with datasets in Quantumworks Lab has never been easier.\u003c/p\u003e\u003cp\u003eIf you’re already using cloud storage, \u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1\u0026ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eadd data to Quantumworks Lab\u003c/u\u003e\u003c/a\u003e today. \u003c/p\u003e","comment_id":"65dd3fe1255738000153641c","feature_image":"https://labelbox-guides.ghost.io/content/images/2024/02/Frame-3410--2-.png","featured":false,"visibility":"public","created_at":"2024-02-27T01:50:25.000+00:00","updated_at":"2024-05-28T17:03:00.000+00:00","published_at":"2024-02-28T17:21:47.000+00:00","custom_excerpt":"Sync your unstructured data automatically and skip glue scripts with native support for S3 (AWS), GCS (GCP) and Blob Storage (Azure).  ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-sync-your-cloud-buckets-with-labelbox/","excerpt":"Sync your unstructured data automatically and skip glue scripts with native support for S3 (AWS), GCS (GCP) and Blob Storage (Azure).  ","reading_time":2,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"656e6d5472e557000141cf9d","uuid":"44473dbc-7bfa-43a0-a5d6-7e061877d134","title":"How to automatically ingest data from Databricks into Quantumworks Lab","slug":"how-to-automatically-ingest-data-from-databricks-into-labelbox","html":"\u003cp\u003eMoving data seamlessly through your MLOps pipeline is essential to building successful AI products. In this guide, learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/cjp13xg9no\" title=\"Databricks Ingestion Pipeline Demo Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"506\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1.\u0026nbsp; Navigate to the \u003ca href=\"https://huggingface.co/spaces/Quantumworks Lab/databricks_upload?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003epipeline creator webpage\u003c/u\u003e\u003c/a\u003e and enter your Databricks domain. You can find this by going to your Databricks environment. The domain will be in the URL, so you can copy and paste it into the pipeline creator.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_1_Domain.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_1_Domain.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_1_Domain.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_1_Domain.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_1_Domain.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eYour Databricks domain is in the URL whenever you access your Databricks environment.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e2. Now select the cloud environment that your Databricks workspace runs in. This information is usually also in the Databricks domain that you just copy/pasted.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3. If you don’t already have a Databricks API, create one by going to your Databricks domain. Go to the user tab in the top right, then go to \u003cstrong\u003eUser settings \u0026gt; Developer \u0026gt; Access Tokens\u003c/strong\u003e, and create an access token. Paste your Databricks API key into the pipeline creator.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_2_AccessToken.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_2_AccessToken.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_2_AccessToken.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_2_AccessToken.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_2_AccessToken.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eYou can create an access token for the Databricks API by going to the user tab, then to User Settings \u0026gt; Developer \u0026gt; Access tokens.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e4. Next, you’ll need your Quantumworks Lab API key. If you don’t already have one, you can create one from within your Quantumworks Lab environment by going to \u003cstrong\u003eWorkspace Settings \u0026gt; API \u0026gt; Create a new key\u003c/strong\u003e. Paste this key into the creator pipeline. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_3_LBAPIKey.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_3_LBAPIKey.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eCreate an API key in Quantumworks Lab from the Workspace Settings section of your environment.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e5. Next, the pipeline creator will give you the option of making a new dataset or appending an existing one. Be sure to give the dataset a relevant name, as it will appear under than name within Quantumworks Lab Catalog once the dataset has been created and the data ingested from Databricks. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_4_NameDataset.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_4_NameDataset.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_4_NameDataset.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_4_NameDataset.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_4_NameDataset.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eName your dataset within the pipeline creator webpage.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e6. Select a cluster from within your Databricks environment on the pipeline creator page.\u0026nbsp;\u003c/p\u003e\u003cp\u003e7. Once the cluster is ready, you’ll see the option to select a run frequency, or the cadence with which the workflow is going to execute. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_5_RunFrequency.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"713\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_5_RunFrequency.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_5_RunFrequency.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_5_RunFrequency.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eChoose how often you want this workflow to run.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e8. Next, choose the relevant table and database in Databricks from which you want to pull data. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_6_SelectTable.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"713\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_6_SelectTable.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_6_SelectTable.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_6_SelectTable.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eChoose the database and table you want to pull data from.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e9. The page will show you a sample of data rows within the selected table. The row data column signifies the URL by which you want to pool the data from. This can either be a public URL or objects hosted within your cloud storage.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_7_RowData.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_7_RowData.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_7_RowData.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_7_RowData.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_7_RowData.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA sample of the data rows in the selected dataset will appear on the pipeline creator page.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e10. Choose the data row column pointing to the object that you want to render. You also have an additional option of choosing the global key, which will specify the unique identifier assigned to each data row once they’re ingested into Labelbox.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"753\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSelect your row data column and if needed, select global key.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e11. Click on \u003cstrong\u003eDeploy pipeline. \u003c/strong\u003eAfter executing for a few seconds, you’ll see a confirmation that your pipeline has been deployed. Now you can navigate to your Databricks environment, go to the workflows tab on the left, and see the new upload workflow that you’ve just created. Once the workflow has run, you’ll be able to see the ingested data in Quantumworks Lab Catalog.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSee the new upload workflow within your Databricks environment by navigating to the Workflows tab.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYour new workflow will now ingest the specified data into Quantumworks Lab at the cadence you chose. \u003ca href=\"https://labelbox.com/blog/seamlessly-integrate-databricks-data-pipelines-with-labelbox/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eRead this blog post\u003c/u\u003e\u003c/a\u003e to learn more about how you can integrate Databricks and Quantumworks Lab into a seamless data engine for AI.\u0026nbsp;\u003c/p\u003e","comment_id":"656e6d5472e557000141cf9d","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/12/DatabricksLabelboxIngestionPipeline_Guide_Header.png","featured":false,"visibility":"public","created_at":"2023-12-05T00:22:44.000+00:00","updated_at":"2023-12-05T17:38:22.000+00:00","published_at":"2023-12-05T17:38:22.000+00:00","custom_excerpt":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-automatically-ingest-data-from-databricks-into-labelbox/","excerpt":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":"How to automatically ingest data from Databricks into Quantumworks Lab","og_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","twitter_image":null,"twitter_title":"How to automatically ingest data from Databricks into Quantumworks Lab","twitter_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","meta_title":"How to automatically ingest data from Databricks into Quantumworks Lab","meta_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"654bbab4016f5100016579c3","uuid":"6c33e4d1-fcaa-44de-b994-0fe65fce3dcc","title":"How to analyze customer reviews and improve customer care with NLP","slug":"how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp","html":"\u003cp\u003eCustomer reviews have become a critical tool for businesses looking to improve their products, services, and customer satisfaction. In today’s digital world, review sites like Yelp and social media make it easier than ever for customers to share their experiences with the world. Customer care can range in the services and support that businesses provide to their customers before, during, and after purchase. Great customer care can create positive brand experiences that lead to greater loyalty and customer satisfaction. In the ever-evolving world of retail, it also helps keep your business competitive and at the forefront of your customer’s sentiment and desires.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWhile companies now have access to a wealth of customer feedback data, sifting through all of these reviews can be incredibly time-consuming and manual. By leveraging AI, teams can analyze \u003ca href=\"https://birdeye.com/blog/review-management/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ecustomer reviews and feedback\u003c/a\u003e at scale, to gain insights into common review topics or customer sentiment. This allows businesses to identify common themes and pinpoint areas of improvement to enhance\u0026nbsp; the customer experience.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for customer care. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eImproving customer care requires a vast amount of data in the form of customer reviews. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDynamic review landscape: \u003c/strong\u003eThe changing nature and format of customer review data from multiple sources (e.g webpages, apps, social media, etc.) poses the challenge for businesses to account for continuous data updates and re-training needs.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers businesses to transform their customer care through advanced natural language processing. Instead of relying on time-consuming manual reviews, companies can leverage Quantumworks Lab’s assisted data enrichment and flexible training frameworks to quickly build AI systems that uncover actionable insights from customer reviews. Tackle unique customer care challenges with AI-driven insights to create more thoughtful and strategic customer interactions. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1444\" height=\"784\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 1444w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build an NLP model to improve customer care. Specifically, this guide will walk through how you can explore and better understand review topics and classify review sentiment to make more data-driven business decisions around customer care initiatives.\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-accelerate-and-train-an-nlp-model-to-improve-customer-care\"\u003eSee it in action: How to accelerate and train an NLP model to improve customer care\u0026nbsp;\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Create a model run and evaluate model performance\u003c/p\u003e\u003cp\u003eYou can follow along with both parts of the tutorial below in either: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e or \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAs customer reviews and feedback across channels proliferate, brands want to learn from customer feedback to foster positive experiences. For this use case, we’ll be working with a dataset of customer hotel reviews – with the goal of analyzing the reviews to demonstrate how a hospitality company could gain insight into how their customers feel about the quality of service they receive.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/q4dqjyg9xf\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"498\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eThe first step will be to gather data:\u003c/p\u003e\u003cp\u003eFor the purpose of this tutorial, we’ve provided a sample open-source \u003ca href=\"https://www.kaggle.com/datasets/jiashenliu/515k-hotel-reviews-data-in-europe?ref=labelbox-guides.ghost.io\"\u003eKaggle dataset\u003c/a\u003e that can be downloaded.  \u003c/p\u003e\u003cp\u003ePlease \u003ca href=\"https://drive.google.com/file/d/1hh2MYzol6-4PSsqX7mbX2YSLLGA4jAYZ/view?usp=drivesdk\u0026ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003edownload the dataset\u003c/a\u003e and store it in an appropriate location on your environment. You'll also need to update the read/write file paths throughout the notebook to reflect relevant locations on your environment. You'll also need to update all references to API keys, and Quantumworks Lab ontology, project, and model run IDs\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf you wish to follow along and work with your own data, you can import your text data as a CSV. \u003c/li\u003e\u003cli\u003eIf your text snippets sit as individual files in cloud storage, you can reference the URL of these files through our \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003eIAM delegated access integration\u003c/a\u003e.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve uploaded your dataset, you should see your text data rendered in Quantumworks Lab Catalog. You can browse through the dataset and visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data\"\u003eSearch and curate data\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/xn3sj0uc8j\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExplore topics of interest\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWith your data in Quantumworks Lab, you can begin to leverage Catalog to uncover interesting topics to get a sense of what customers are talking about from hotel reviews.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eVisualize your data –\u0026nbsp; you can click through individual data rows to get a sense for what customers are writing reviews on\u0026nbsp;\u003c/li\u003e\u003cli\u003eDrill into specific topics of interest\u003cstrong\u003e \u003c/strong\u003e– leverage a natural language search, for example searching “interior design,” to bring up all related reviews related to interior design. You can adjust the confidence threshold of your searches accordingly (this can be helpful in gauging the volume of data related to the topic of interest)\u0026nbsp;\u003c/li\u003e\u003cli\u003eBegin to surface subtopics or trends within your initial search – for example is the interior design review related to the style of design, attention to detail, or the type of environment created from the interior design\u003c/li\u003e\u003cli\u003eEasily find all instances of similar examples to data of interest\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate and save data slices\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIf you have a search query that you’re interested in saving or reusing in the future, you can save it as \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003ea slice\u003c/a\u003e. You can construct a slice by using one or more filters to curate a collection of data rows. Users often combine filters to surface high-impact data and then save the results as a slice.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this example, we’ve surfaced reviews on the topic of breakfast that all talk about the value and price of the hotel’s breakfast. We can save this as a slice for future reference (“Breakfast_value”) and as we ingest more data that matches the slice’s criteria, they will automatically get filed into the slice.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-an-ontology\"\u003eCreate an ontology\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAfter we’ve explored our data, we now have a better understanding of what topics exist in our dataset and can create our ontology. \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eOntologies\u003c/a\u003e can be reused across different projects and they are required for data labeling, model training, and evaluation.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/gdczmynqjt\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo create a new ontology:\u003c/p\u003e\u003cp\u003e1) Navigate to the ‘Schema’ tab\u003c/p\u003e\u003cp\u003e2) Hit ‘Create new ontology’\u003c/p\u003e\u003cp\u003e3) Select the media type that you wish to work with – for this use case ‘Text’\u003c/p\u003e\u003cp\u003e4) Give your ontology a name\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Add objects and classifications based on you use case\u003c/p\u003e\u003cp\u003e6) Objects are named entities\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli\u003ePerson’s name\u0026nbsp;\u003c/li\u003e\u003cli\u003eLocation\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003e7) Classifications\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli\u003eReview sentiment such as positive or negative (radio)\u0026nbsp;\u003c/li\u003e\u003cli\u003eReview topics such as breakfast, dinner, location, staff, interior design (checklist)\u0026nbsp;\u003c/li\u003e\u003cli\u003eAdd sub-classifications as desired\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003e8) Save and create your ontology\u0026nbsp;\u003c/p\u003e\u003cp\u003eAfter creating an ontology, you can begin labeling your data to fine-tune or train a model.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"label-data-of-interest\"\u003eLabel data of interest\u0026nbsp;\u003c/h3\u003e\u003cp\u003eWith Quantumworks Lab, you can label your data in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e: leverage our global network of\u0026nbsp; specialized labelers for a variety of tasks.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWorkforce Boost provides a collaborative platform for labeling services in a self-serve manner — this is great for teams that don’t have the technical expertise to build a machine learning system yet are looking for an easy-to-use technology to get a quick turnaround on quality training data. You can learn more about our Boost offerings \u003ca href=\"https://docs.labelbox.com/docs/using-data-labeling-service?ref=labelbox-guides.ghost.io\"\u003ehere\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create pre-labels with foundation models\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn addition to creating pre-labels for classification projects, you have the ability to send model predictions as pre-labels to your labeling project. This can be done in one of two ways:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/model-assisted-labeling?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel-assisted labeling\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eImport computer-generated predictions (or simply annotations created outside of Quantumworks Lab) as pre-labels on an asset. The imported annotations will be pre-populated in the labeling editor and a human can correct or verify and submit the prediction as ground truth.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel Foundry\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eAutomate data workflows, including data labeling with world-class foundation models. Leverage a variety of open source or third-party models to accelerate pre-labeling and cut labeling costs by up to 90%.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003ePre-label data with Model Foundry\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eModel Foundry\u003c/a\u003e acts as the copilot to create your training data –\u0026nbsp; instead of going into unstructured text datasets blindly, you can use pre-existing LLMs to pre-label data or pre-tag parts of it, reducing manual labeling efforts and cost.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/9zspjgoau7\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1) Select data you wish to label in Catalog\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Hit \"Predict with Model Foundry\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Choose a foundation model\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou can select a foundation model based on your use case to have the model take a first pass at labeling your data\u003c/li\u003e\u003cli\u003eThese pre-labels can be verified with human-in-the-loop review in Quantumworks Lab Annotate\u003c/li\u003e\u003cli\u003eFor this use case, we’ve selected the GPT-4 model\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e4) Configure the model’s settings\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eSelect the previously created ontology in the earlier part of the tutorial\u0026nbsp;\u003c/li\u003e\u003cli\u003eLabelbox will auto-generate a prompt based on your ontology and use case – in this case we wish to classify the sentiment (positive or negative) and classify a topic with one or more options (breakfast, dinner, location, staff, room, facilities, value for money, or interior design)\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e5) Generate preview predictions\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eBefore submitting the model run, you can generate prediction previews to understand how the model will perform\u003c/li\u003e\u003cli\u003eIt is recommended that you preview some predictions to confirm the model parameters are configured as desired\u003c/li\u003e\u003cli\u003eBased on the preview, you can then make any adjustments to the settings or choose to submit the model run as-is\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e6) Name and submit the model run\u0026nbsp;\u003c/p\u003e\u003cp\u003e7) View the model run in the Model tab to explore results\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eOnce your model run is complete, you navigate to the Model tab\u003c/li\u003e\u003cli\u003eExplore the model’s results and click into each data row to dig deeper into the model’s predictions\u003c/li\u003e\u003cli\u003eFor this example, we can see that there are instances where GPT-4 has correctly tagged named entities and identified sentiment\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve evaluated and are satisfied with GPT-4’s predictions, you can send them to a labeling project in Quantumworks Lab Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdd a batch to a labeling project as pre-labels\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eBefore you can send these model predictions to a labeling project as pre-labels, you need to create a labeling project. \u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/7zgl76n76w\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 5 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreate a new labeling project\u003c/em\u003e\u003c/p\u003e\u003cp\u003e1) Navigate to the Annotate tab\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Create a ‘New project’\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Select the project type – in this case we want to create a ‘Text’ project\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Name your project\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Attach your model’s ontology (created in a previous step)\u0026nbsp;\u003c/p\u003e\u003cp\u003eOnce you’ve created your labeling project and configured the ontology, head back to the Model tab to send your batch of data with pre-labels to that labeling project.\u0026nbsp;\u003c/p\u003e\u003cp\u003e1) Highlight all data rows of interest\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Select ‘Manage selection’ \u0026gt; ‘Add batch to project’\u003c/p\u003e\u003cp\u003e3) Select the appropriate project that you created in the above step\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) You can give the batch a priority (from 1-5)\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Select the appropriate model run of the predictions you wish to send\u0026nbsp;\u003c/p\u003e\u003cp\u003e6) You can explore and select the various tags that have been applied and uncheck those that aren’t of interest\u0026nbsp;\u003c/p\u003e\u003cp\u003e7) Submit the batch\u0026nbsp;\u003c/p\u003e\u003cp\u003eYou can now navigate back to your project in Annotate and hit ‘Start labeling’.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"verify-data-quality-with-custom-workflows\"\u003eVerify data quality with custom workflows\u003c/h3\u003e\u003cp\u003eRather than starting from scratch, your internal or external team of labelers can now see predictions from the Model Foundry run. From here, you can validate or edit predictions as necessary and submit data rows to create ground truth labels.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/56bratjais\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 6 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eAs you begin to progress through your data rows, you’ll notice data rows that are initially marked up and reviewed by labelers in the ‘Initial review’ task (for your reviewers to verify and approve), with all submitted data rows falling into ‘Done’.\u0026nbsp;\u003c/p\u003e\u003cp\u003eYou can create customizable, multi-step review and rework pipelines to drive efficiency and automation for your review tasks. Set a review task based on specific parameters that are unique to your labeling team or desired outcome.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eInitial labeling task: reserved for all data rows that have been queued for labeling\u003c/li\u003e\u003cli\u003eInitial review task: first review task for data rows with submitted labels\u003c/li\u003e\u003cli\u003eRework task: reserved for data rows that have been rejected\u003c/li\u003e\u003cli\u003eDone task: reserved for data rows that have a) moved through their qualified tasks in the workflow or b) did not qualify for any of the tasks\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce all data rows have been reviewed and moved to the ‘Done’ step, you can begin the model training process.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn Part 1 of this tutorial, we have looked at how we can leverage Catalog to understand the topics that exist within your dataset and construct an appropriate ontology. To accelerate our initial labeling job, we leveraged Model Foundry as part of our model-assisted labeling pipeline to use pre-labels from GPT-4 to our labeling workforce for validation. Those initial annotations can be exported via a model run and can be used to train or fine-tune a model outside of Labelbox.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"part-2-train-or-fine-tune-a-model-and-evaluate-model-performance\"\u003ePart 2: Train or fine-tune a model and evaluate model performance\u0026nbsp;\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e or \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"train-a-custom-model-on-a-subset-of-data-outside-of-labelbox\"\u003eTrain a custom model on a subset of data outside of Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/07yc0p652w\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 7 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eIn the previous step, we leveraged Model Foundry to create pre-labels that were passed through Annotate for review with human-in-the-loop validation. Now that we have our appropriate annotation data, we can train a series of initial models on sentiment, topic classification, and named entity recognition.\u0026nbsp;\u003c/p\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cp\u003eYou can reference \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io#scrollTo=EDmBNjYP_0u7\"\u003ethis step\u003c/a\u003e (Databricks) or \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io#scrollTo=EDmBNjYP_0u7\" rel=\"noreferrer\"\u003ethis step\u003c/a\u003e (Google Colab) in either notebook.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBring the trained model’s predictions back into a model run\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce the model has been trained, you can create an inference pipeline that leverages each model to classify different attributes for review. We can then leverage this for two things:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRun inference on the model run dataset and upload it to Quantumworks Lab for evaluation\u003c/li\u003e\u003cli\u003eRun inference on our remaining dataset and use the predictions for model-assisted labeling, to be refined in the platform and used to accelerate labeling efforts\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003ePlease follow \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io#scrollTo=B9_dYR_D_0vE\"\u003ethis step\u003c/a\u003e (Databricks) or \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io#scrollTo=B9_dYR_D_0vE\" rel=\"noreferrer\"\u003ethis step\u003c/a\u003e (Google Colab) to create an inference pipeline and to upload predictions to the model run and evaluate it against ground truth.\u003c/p\u003e\u003cp\u003eAfter following the notebook, you’ll be able to compare ground truth (green) versus the model’s predictions (red) for sentiment and topic.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"evaluate-and-diagnose-model-effectiveness\"\u003eEvaluate and diagnose model effectiveness\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/dqzdzj1seb\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 8 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eDiagnose model performance with model metrics\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn addition to visualizing the difference between model predictions and ground truth, you can click into the ‘Metrics’ view to get a better sense of how your model is performing.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eUse the \"Metrics view\" to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/li\u003e\u003cli\u003eModel metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor example, we can click into false negatives or false positives to narrow down situations where there might be false positives – where ‘negative’ sentiment is predicted whereas ground truth sentiment is ‘positive’.\u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate high-impact data to drastically improve model performance\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve identified an example of a corner-case where the model might be struggling, you can easily leverage Catalog to surface similar unlabeled examples to improve model performance.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eSelect any corner-cases and select \"Find similar in Catalog\" from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows (both labeled and unlabeled) to the selected example.\u0026nbsp;\u003c/li\u003e\u003cli\u003eTo only surface unlabeled reviews that you can send to your model for labeling, you can filter on the \"Annotation is\" filter and select \"none.\" This will only show unlabeled text reviews that are similar to the selected corner case.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect all reviews that apply and select \"Add batch to project\"\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eUse model predictions as model-assisted labeling pipeline\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/r4p2h6iklg\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 9 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eOnce you’ve filtered for and have selected reviews that you wish to label you can \"Add batch to project\" to send them to your labeling project in Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003e1) Name your batch\u003c/p\u003e\u003cp\u003e2) Select your labeling project from the dropdown\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Include model predictions (from your model run) – this will perform better than the initial GPT-4 run with Model Foundry since it has been trained on your custom data\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Select or uncheck any predictions as desired\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Submit the batch\u003c/p\u003e\u003cp\u003eWhen you return to Quantumworks Lab Annotate, you will now see the original batch that we added at the start of the project, as well as the newly added batch ready for labeling.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRather than starting from scratch, similar to the predictions created by GPT-4 in Model Foundry, your labelers will now see the custom model predictions and validate them with human-in-the-loop review in the same manner. This workflow helps accelerate model iterations, allowing your team to bring in the latest model prediction as pre-labels for your project to reduce the amount of human labeling effort required to create ground truth labels.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWith new high-impact data labeled, you can retrain the model and can track model improvements across various runs for comparison and how this has affected model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003eCustomer reviews and feedback data represent an invaluable yet untapped opportunity for businesses. Manually analyzing this growing mountain of data is no longer practical. Instead, forward-thinking companies are turning to AI to efficiently sift through and extract actionable insights from reviews.\u003c/p\u003e\u003cp\u003eNatural language processing can help identify customer sentiment, pain points, and unmet needs. By leveraging AI to tap into this feedback treasure trove, businesses can drive measurable improvements in customer satisfaction, retention, and advocacy. They can refine products, enhance user experiences, and preemptively address concerns.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"654bbab4016f5100016579c3","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Group-2457--1-.png","featured":false,"visibility":"public","created_at":"2023-11-08T16:43:32.000+00:00","updated_at":"2024-06-25T16:28:21.000+00:00","published_at":"2023-11-08T21:47:13.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa506375d13000123d7e8","name":"Using LLMs","slug":"using-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-llms/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp/","excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":"How to analyze customer reviews and improve customer care with NLP","og_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Group-2457--1--1.png","twitter_title":"How to analyze customer reviews and improve customer care with NLP","twitter_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","meta_title":"How to analyze customer reviews and improve customer care with NLP","meta_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"654407cdd96ee80001d8c876","uuid":"e29733c1-b966-4d1e-858d-f96deab4850e","title":"How to build a content moderation model to detect disinformation","slug":"how-to-build-a-content-moderation-model-to-detect-disinformation","html":"\u003cp\u003eAs user-generated content increases and the amount of data grows, trust and safety on digital platforms is becoming increasingly critical. Content that goes unmoderated can not only directly hurt brand reputation, but it can directly impact a businesses bottom line through lost users, advertisers, and revenue. Regulators worldwide are also implementing \u003ca href=\"https://insightplus.bakermckenzie.com/bm/data-technology/united-states-now-is-the-time-to-evaluate-your-online-content-moderation-program?ref=labelbox-guides.ghost.io\"\u003estricter rules\u003c/a\u003e around content moderation, online safety, misinformation, and disinformation.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo address these growing risks, more businesses are looking to AI and machine learning as part of robust trust and safety strategies. State-of-the-art AI solutions enable unprecedented scale, nuance, consistency, and efficiency in identifying and taking action on high-risk user content.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for trust and safety. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDynamic content landscape: \u003c/strong\u003eModels are only as good as the data they are trained on. As new trends or content emerges, AI models need constant retraining on compelling diverse, unbiased, and large labeled datasets to reinforce content moderation.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEthical risks \u0026amp; biases: \u003c/strong\u003eWithout careful design, machine learning models risk exacerbating biases and are prone to \u003ca href=\"https://labelbox.com/blog/what-does-it-mean-when-an-llm-hallucinates/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ehallucination\u003c/a\u003e. Teams need a way to monitor and evaluate model training with ethical oversight.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that enables businesses to build state-of-the-art AI solutions for enhanced controls, transparency, efficiency in content moderation, and greater brand safety. Rather than spending valuable time building an in-house solution or relying on disparate systems, businesses can explore data, use foundation models for assisted-enrichment, and evaluate models to quickly build more accurate AI systems for analyzing user behavior, detecting disinformation, and enhancing ad-targeting. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1430\" height=\"786\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 1430w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build a model for content moderation, such as detecting and classifying disinformation, allowing you to elevate brand trust and improve the trust and safety of your applications.\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-build-a-content-moderation-model-to-detect-disinformation\"\u003eSee it in action: How to build a content moderation model to detect disinformation\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data: \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab Notebook\u0026nbsp;\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2: \u003c/strong\u003eCreate a model run, fine-tune an LLM, and evaluate model performance: \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eWith the growing amount of user-generated content, businesses want to ensure that there is no inappropriate content or disinformation happening on their platform. To implement content moderation at scale, teams can leverage AI to analyze and detect harmful content and classify disinformation from existing data stored in a cloud bucket or a local folder.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/9e76g8llbu\" title=\"How to enhance brand safety and content moderation with AI - Part 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo upload a sample of your content to Quantumworks Lab for labeling, you have a few options:\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUpload a dataset through the SDK\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eUsing the \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab notebook\u003c/a\u003e, upload the sample dataset into Quantumworks Lab or use it to import data from various sources like Bigquery, Databricks, or Snowflake.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this notebook, we’re going to bring in two libraries of interest:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/sdk-fundamental-concepts-1?ref=labelbox-guides.ghost.io\"\u003eLabelbox SDK\u003c/a\u003e\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelpandas?ref=labelbox-guides.ghost.io\"\u003eLabelpandas\u003c/a\u003e (for bringing tabular data into Quantumworks Lab)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou’ll need your Quantumworks Lab API key to initiate the Quantumworks Lab Client and create a dataset. For this guide, we’ll be using a dataset stored in a Google Cloud bucket as a CSV and we can use Labelpandas to bring this data in.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe provided sample dataset includes:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAn article with a corresponding headline\u003c/li\u003e\u003cli\u003eWhen it was retrieved\u003c/li\u003e\u003cli\u003eMetadata (sorted by source)\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003ePre-labels based on if the article contains “disinformation” or not\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eUpload a dataset through the UI \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIf you have a dataset from your local file, you can upload it through the Quantumworks Lab UI by clicking \"new dataset\" in Catalog.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOnce you’ve successfully uploaded your text, you can browse the dataset in Catalog — along its metadata. You can visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data\"\u003eSearch and curate data\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/vl9jr5463n\" title=\"How to enhance brand safety and content moderation with AI - Part 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLeverage custom and out-of-the-box smart filters and embeddings to quickly explore product listings, surface similar data, and optimize data curation for ML. You can:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eSearch across datasets\u003c/a\u003e to narrow in on data containing specific attributes (e.g metadata, media attributes, datasets, project, etc.)\u0026nbsp;\u003c/li\u003e\u003cli\u003eAutomatically \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003efind similar data\u003c/a\u003e in seconds with off-the-shelf embeddings\u0026nbsp;\u003c/li\u003e\u003cli\u003eFilter data based on \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language\u003c/a\u003e and flexibly \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io#how-filters-work\"\u003elayer structured and unstructured filters\u003c/a\u003e for more granular data curation\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate and save data slices\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ksmc9w7acz\" title=\"How to enhance brand safety and content moderation with AI - Part 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eIf you have a search query that you’re interested in saving or reusing in the future, you can save it as \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003ea slice\u003c/a\u003e. You can construct a slice by using one or more filters to curate a collection of data rows. Users often combine filters to surface high-impact data and then save the results as a slice.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this example, we are interested in saving the surfaced data rows as “Climate Articles” so that this filtered dataset can easily be surfaced later on for annotation or data discovery purposes.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-a-labeling-project-in-annotate\"\u003eCreate a labeling project in Annotate\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/uxspsczkpn\" title=\"How to enhance brand safety and content moderation with AI - Part 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1) Create a text project in \u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Sample and send your uploaded dataset as a \u003ca href=\"https://docs.labelbox.com/docs/batches?ref=labelbox-guides.ghost.io\"\u003ebatch\u003c/a\u003e to your newly created project. In this case we can send the two dataset slices that we created: “Climate related articles” and “Non-climate related articles”\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create an \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eontology\u003c/a\u003e to determine how to structure your data. If you have a previous ontology you’d like to use, you can do so. If not, you’ll need to create a new ontology. For this use case, our ontology consists of two classifications:\u003c/p\u003e\u003cul\u003e\u003cli\u003e“Does the article contain disinformation?” with two options\u003c/li\u003e\u003cli\u003e“Is the article climate related?” with two options\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e4) If you’re relying on an external team of labelers or want to provide your internal labeling team with more instructions, you can upload instructions as a PDF for your labelers during the ontology creation process.\u003c/p\u003e\u003ch3 id=\"label-the-data-of-interest\"\u003eLabel the data of interest\u0026nbsp;\u003c/h3\u003e\u003cp\u003eNow that we have a project with our data set up in Annotate, we’ll need to label this training data.\u0026nbsp;\u003c/p\u003e\u003cp\u003eSince this project is a classification use case, we can also leverage \u003ca href=\"https://docs.labelbox.com/docs/bulk-classification?ref=labelbox-guides.ghost.io\"\u003ebulk classification\u003c/a\u003e to speed up our labeling process and maximize labeling efficiency. Teams who have used bulk classification in Quantumworks Lab have seen labeling time decrease from a full quarter to a few days. Since we’ve leveraged filters in Catalog to identify “Climate related articles,” we can send these articles to our newly created labeling project with pre-labels.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/eh5mwisy6q\" title=\"How to enhance brand safety and content moderation with AI - Part 5 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo bulk classify and pre-label data rows, you can:\u003c/p\u003e\u003cp\u003e1) Highlight any data rows of interest, in our use case these would be data rows in the slice \"Climate related articles\",\u0026nbsp; and select \"Manage selection\" \u0026gt; \"Add classifications\"\u003c/p\u003e\u003cp\u003e2) Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. In the above demo, we are sending these to the \"Initial labeling task\" because we want to have a labeler verify that these are indeed all climate related articles\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Select the desired classification — in this case it would be \"Climate related\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) You can determine the batch’s data row priority (from 1-5) and submit the bulk classification job \u003c/p\u003e\u003cp\u003eRather than labeling from scratch, a team of labelers can now simply verify or correct the pre-labels used during this bulk classification step.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, you can label your data in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e: leverage our global network of\u0026nbsp; specialized labelers for a variety of tasks.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWorkforce Boost provides a collaborative platform for labeling services in a self-serve manner — this is great for teams that don’t have the technical expertise to build a machine learning system yet are looking for an easy-to-use technology to get a quick turnaround on quality training data. You can learn more about our Boost offerings \u003ca href=\"https://docs.labelbox.com/docs/using-data-labeling-service?ref=labelbox-guides.ghost.io\"\u003ehere\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create pre-labels with foundation models\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn addition to creating pre-labels for classification projects, you have the ability to send model predictions as pre-labels to your labeling project. This can be done in one of two ways:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/model-assisted-labeling?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel-assisted labeling\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eImport computer-generated predictions (or simply annotations created outside of Quantumworks Lab) as pre-labels on an asset. The imported annotations will be pre-populated in the labeling editor and a human can correct or verify and submit the prediction as ground truth.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel Foundry\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eAutomate data workflows, including data labeling with world-class foundation models. Leverage a variety of open source or third-party models to accelerate pre-labeling and cut labeling costs by up to 90%.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"verify-data-quality-with-custom-workflows\"\u003eVerify data quality with custom workflows\u003c/h3\u003e\u003cp\u003eContent moderation relies heavily on training the model on accurate and verified data. To ensure that you’re producing the most reliable and high-quality training datasets, you can customize your \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox-guides.ghost.io\"\u003elabeling review workflow\u003c/a\u003e.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/lqa22gzj7o\" title=\"How to enhance brand safety and content moderation with AI - Part 6 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou can create customizable, multi-step review and rework pipelines to drive efficiency and automation for your review tasks. Set a review task based on specific parameters that are unique to your labeling team or desired outcome.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eInitial labeling task: reserved for all data rows that have been queued for labeling\u003c/li\u003e\u003cli\u003eInitial review task: first review task for data rows with submitted labels\u003c/li\u003e\u003cli\u003eRework task: reserved for data rows that have been rejected\u003c/li\u003e\u003cli\u003eDone task: reserved for data rows that have a) moved through their qualified tasks in the workflow or b) did not qualify for any of the tasks\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-2-create-a-model-run-fine-tune-an-llm-and-evaluate-model-performance\"\u003ePart 2: Create a model run, fine-tune an LLM, and evaluate model performance\u0026nbsp;\u0026nbsp;\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn this part of the tutorial, we’ll be taking the ground truth labels created in Part 1 to fine-tune a large language model (LLM). From there, we’ll evaluate model performance in Quantumworks Lab Model to diagnose model strengths and weaknesses and look to continuously boost and improve model performance.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-a-new-model\"\u003eCreate a new model\u0026nbsp;\u003c/h3\u003e\u003cp\u003eOnce you have your labeled data in your project in Annotate, you’re ready to move on to creating a model run in \u003ca href=\"https://app.labelbox.com/mea?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003eLabelbox Model\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/z31zew9hbd\" title=\"How to enhance brand safety and content moderation with AI - Part 7 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo create a new model, you’ll need to:\u003c/p\u003e\u003cp\u003e1) Navigate to the \"Experiments\" tab in Model. The \"Experiments\" tab will be where you can find all model experiments across iterations.\u003c/p\u003e\u003cp\u003e2) Create a new model by selecting the \"New model\" button.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eProvide a model name\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect the model ontology — in this case we will select the same ontology we used to create our labeling project that contains the corresponding ground truth data.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSubmit and create a model — before creating a model run, you will also be able to see and verify the number of data rows that are being submitted.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate a model run\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve created a new model, we will need to create a new \u003ca href=\"https://docs.labelbox.com/docs/model-runs?ref=labelbox-guides.ghost.io\"\u003emodel run\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eA model run is a model training experiment — each model run provides a versioned data snapshot of the data rows, annotations, and \u003ca href=\"https://docs.labelbox.com/docs/curate-data-splits?ref=labelbox-guides.ghost.io\"\u003edata splits\u003c/a\u003e for that model run. You can upload predictions to the model run and compare its performance against other model runs in a model directory.\u003c/p\u003e\u003cp\u003eThe model run we create will be the initial model run for our LLM fine-tuning experiment. To add a new model run:\u003c/p\u003e\u003cp\u003e1) Select \"New model run\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Give the model run a name (e.g “model run #1”)\u003c/p\u003e\u003cp\u003e3) Set data splits for the model run (for train, validate, and test)\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Create the model run\u0026nbsp;\u003c/p\u003e\u003cp\u003eAfter creating a model run, you’ll be able to see the corresponding data rows with ground truth populated into the appropriate train, validate, and test splits. This model run will be the gateway for us to export ground truth data to fine-tune a large language model.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-us.googleusercontent.com/bObh0Kje6BWPfrIPWcd3V0TFt09svuX0-7Wka4IQI9j-bKdmhJAEjTWsWPWOmdFUg-CgU9fLQC-p_vFdafFXv4nYhMZupffw7Bl6TN8Z-2j771nF4riavmSL-xiDAmjU8E32deblRc4eEmNjptF3GpI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"327\"\u003e\u003c/figure\u003e\u003ch3 id=\"export-ground-truth-from-the-model-run-experiment-for-fine-tuning\"\u003eExport ground truth from the model run experiment for fine-tuning\u0026nbsp;\u003c/h3\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/s2gzlnehyy\" title=\"How to enhance brand safety and content moderation with AI - Part 8 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eWe’ll be using this \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab notebook\u003c/a\u003e to fine-tune a model and bring back inferences from the fine-tuned model for evaluation and diagnosis.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor this step, you will need:\u003c/p\u003e\u003cul\u003e\u003cli\u003eYour API Key\u0026nbsp;\u003c/li\u003e\u003cli\u003eYour Model Run ID to export the corresponding ground truth and articles from the model run\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eExport ground truth from the model run experiment\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eLabelbox will return the ground truth export in a JSON format. With the provided \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab notebook\u003c/a\u003e, we can visualize the exported JSON into a DataFrame format for us to view corresponding ground truth for each article.\u0026nbsp;\u003c/p\u003e\u003cp\u003eGiven that we want to fine-tune a Google Vertex model with this data, we’ll need to convert the ground truth export to a GCP vertex tuning format (JSONL):\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# build LLM prompt and convert to GCP vertex tuning format (jsonl)\n\nprompt = 'Given the following headline and content, determine whether the article is related to climate change or similar topics. Also determine whether the article contains inaccurate or disinformation. Answer in the following format with Yes/No Answers: [climate related? / disinformation?]'\ndf['input_text'] = prompt + df['content']\ndf['output_text'] = 'climate related: ' + df['climate_related'] + ' disinformation: ' + df['disinformation_flag']\n\n\nwith open('modelPrompt_GCP.jsonl', 'w') as file:\nfor _, row in df[['input_text', 'output_text']].iterrows():\njson_line = row.to_json()\nfile.write(json_line + '\\n')\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"fine-tune-an-llm-with-google-vertex-ai\"\u003eFine-tune an LLM with Google Vertex AI \u003c/h3\u003e\u003cp\u003eFine-tuning is a technique whereby we take an off-the-shelf open-source or proprietary model and retrain it on a variety of concrete examples, and save the updated weights as a new model checkpoint. You can learn more about other techniques to leverage LLMs \u003ca href=\"https://labelbox.com/guides/zero-shot-learning-few-shot-learning-fine-tuning/?ref=labelbox-guides.ghost.io#zero-shot-learning-few-shot-learning-and-fine-tuning-in-action\"\u003ein this guide\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/um0f8w1rzn\" title=\"How to enhance brand safety and content moderation with AI - Part 9 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eFor this use case, we’ll be using \u003ca href=\"https://cloud.google.com/vertex-ai?ref=labelbox-guides.ghost.io\"\u003eGoogle Vertex AI \u003c/a\u003eto fine-tune an LLM with the ground truth from Part 1 of this tutorial. Once in the Vertex AI console, we’ll want to create a tuned model:\u003c/p\u003e\u003cul\u003e\u003cli\u003eChoose a supervised learning task\u0026nbsp;\u003c/li\u003e\u003cli\u003eEnter additional model parameters (e.g model name)\u0026nbsp;\u003c/li\u003e\u003cli\u003eUpload the JSONL file from the previous step\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, we can start the model tuning process. Once the model fine-tuning job has been completed, we can head over to the Google Vertex sandbox and give the newly tuned model a prompt.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor example, we can ask if the article is climate related and if it contains disinformation and it will provide a response based on the training dataset we provided.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-inferences-with-the-tuned-model-and-evaluate-model-effectiveness-in-labelbox\"\u003eCreate inferences with the tuned model and evaluate model effectiveness in Quantumworks Lab\u003c/h3\u003e\u003cp\u003eNow that we’ve fine-tuned a model, we can use it to make predictions on the initial dataset and compare it with our ground truth data to assess the fine-tuned model’s performance.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/cjbrcpktcr\" title=\"How to enhance brand safety and content moderation with AI - Part 10 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eCreate inferences with the tuned model\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe’ll need to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eInstall Google Vertex and Google Cloud SDK\u0026nbsp;\u003c/li\u003e\u003cli\u003eProvide the endpoint ID for the tuned model\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe can then start creating model inferences and predictions from the tuned model on our news articles. Use Pandas to clean up the responses, to remove corresponding prompts, and save them as a DataFrame — this will return the model’s initial headline and the client’s response if the data row is climate related or contains disinformation. \u003c/p\u003e\u003cp\u003eOnce we have model inferences, we can send the inferences back to a model run in Quantumworks Lab for further evaluation and analysis.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eEvaluate and diagnose model effectiveness\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo evaluate the effectiveness of the fine-tuned model in Quantumworks Lab, we’ll need to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eSpecify the model run ID\u0026nbsp;\u003c/li\u003e\u003cli\u003eUpload the list of model inferences for each specific data row\u0026nbsp;\u003c/li\u003e\u003cli\u003eAttach each list of data rows and submit it to a model run in Quantumworks Lab as an upload job via the SDK\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce that’s complete, you can hop back to the original Quantumworks Lab model run and view the corresponding ground truth data and model inferences on each data row. You can visually compare the effectiveness of the fine-tuned model predictions (in red) with ground truth (in green).\u003c/p\u003e\u003cul\u003e\u003cli\u003eUse the \"Metrics view\" to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/li\u003e\u003cli\u003eModel metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor this use case, our goal is to minimize the spread of disinformation, so we can take a look at the metric that shows corresponding articles that are considered \"disinformation\" by labelers, but where the model incorrectly predicted articles as \"not disinformation\". \u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003ch3 id=\"curate-high-impact-data-to-drastically-improve-model-performance\"\u003eCurate high-impact data to drastically improve model performance\u003c/h3\u003e\u003cp\u003eOnce you’ve identified an example of a corner-case where the model might be struggling, you can easily leverage Catalog to surface similar unlabeled examples to improve model performance.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/7podbew17q\" title=\"How to enhance brand safety and content moderation with AI - Part 11 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eSelect any corner-cases and select \"Find similar in Catalog\" from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows (both labeled and unlabeled) to the selected example.\u0026nbsp;\u003c/li\u003e\u003cli\u003eTo only surface unlabeled articles that you can send to your model for labeling, you can filter on the \"Annotation is\" filter and select \"none\". This will only show unlabeled text articles that are similar to the selected corner case.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect all articles that apply and send them as a batch to your original labeling project. Labeling these in priority will help improve model performance. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWith new high-impact data labeled, you can retrain the model and can track model improvements across various runs for comparison and how this has affected model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eUnmoderated content poses mounting risks to businesses with the risk of spreading misinformation, disinformation, and an unsafe online environment. With responsible implementation, businesses can leverage AI for trust and safety to efficiently and consistently identify high-risk content at scale. This not only helps create an online environment that is safe for users, but also helps protect brand reputation.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"654407cdd96ee80001d8c876","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2-.png","featured":false,"visibility":"public","created_at":"2023-11-02T20:34:21.000+00:00","updated_at":"2024-07-17T20:55:32.000+00:00","published_at":"2023-11-02T21:18:18.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-build-a-content-moderation-model-to-detect-disinformation","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},"url":"https://labelbox-guides.ghost.io/how-to-build-a-content-moderation-model-to-detect-disinformation/","excerpt":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","reading_time":12,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2--2.png","og_title":"How to build a content moderation model to detect disinformation","og_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2--1.png","twitter_title":"How to build a content moderation model to detect disinformation","twitter_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","meta_title":"How to build a content moderation model to detect disinformation","meta_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"64e7a2c3b0c09f000179dbed","uuid":"2b64de59-c4f8-4bf5-aa4b-07d1aabcb933","title":"How to build a powerful product recommendation system for retail","slug":"how-to-build-a-powerful-product-recommendation-system-for-retail","html":"\u003cp\u003ePersonalized experiences are at the heart of customer satisfaction and are key to long-term brand loyalty and success. Amidst the abundance of choices available to the modern consumer, businesses must find innovative ways to stand out and forge meaningful relationships with their audience. \u003c/p\u003e\u003cp\u003eThe rise of AI has enabled companies to craft personalized experiences at an unprecedented scale. Organizations can now rely on algorithms taught to recognize customer preferences, behavior, and provide recommendations based on purchase history, and more. With a powerful product recommendation system, retailers can create individualized customer interactions and foster stronger connections to boost customer loyalty and increase key metrics such as conversion rate, average order value, and repeat purchase rates. \u003c/p\u003e\u003cp\u003eHowever, building a robust and effective AI-powered product recommendation system can be challenging for many teams. Some key challenges include: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eBuilding a strong recommendation system that makes accurate predictions requires a vast amount of high-quality data. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability: \u003c/strong\u003eAs a business grows and their product catalog expands, the recommendation system should be able to handle new and incoming data. Ensuring scalability and maintaining model performance with new data can be particularly challenging for teams relying on in-house solutions or disparate ML tools.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePrivacy and Security: \u003c/strong\u003eWhen it comes to customer data and specific product information, ensuring user privacy and safeguarding against potential security violations is critical to maintain trust with customers and build a successful recommendation system. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform to help build the best personalized product recommendation engine. Rather than spending valuable time building in-house or relying on disparate systems and applications, teams can leverage Quantumworks Lab’s platform to seamlessly build an end-to-end workflow that integrates with your existing tech stack and helps teams build AI systems faster.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1425\" height=\"635\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/image-3.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/image-3.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/image-3.png 1425w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build a powerful recommendation system, ensuring your customers embark on a seamless and delightful shopping journey that keeps them coming back for more.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"see-it-in-action-how-to-build-a-powerful-product-recommendation-system-in-labelbox\"\u003eSee it in action: How to build a powerful product recommendation system in Quantumworks Lab\u003c/h2\u003e\u003cp\u003e\u003cem\u003eThe  walkthrough below covers Quantumworks Lab’s platform across \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eCatalog\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eAnnotate\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, and \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eModel\u003c/em\u003e\u003c/a\u003e\u003cem\u003e. We recommend that you \u003c/em\u003e\u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003ecreate a Quantumworks Lab account\u003c/em\u003e\u003c/a\u003e\u003cem\u003e to best follow along with this tutorial.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1: \u003c/strong\u003eExplore and enhance your data (\u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eGoogle Colab Notebook\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Prepare data and evaluate model performance: (\u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eGoogle Colab Notebook\u003c/a\u003e)\u003c/p\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u003c/strong\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\" class=\"kg-btn kg-btn-accent\"\u003ePart 1: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"painlessly-consolidate-all-your-product-data\"\u003ePainlessly consolidate all your product data\u003c/h3\u003e\u003cp\u003eBuilding a recommendation engine requires consolidating data of different types from various sources. Such data can include product, business, and customer information that might be siloed or stored in different databases. To holistically browse and visualize your entire product catalog, leverage Quantumworks Lab Catalog to bring and view all of your data in a single place.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/rdlcin4zh8\" title=\"[Personalized Experiences Demo] Data ingestion Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eIngest data into Quantumworks Lab\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFor this tutorial, we’ve provided a sample retail dataset for you to view in your Quantumworks Lab app: \u003c/p\u003e\u003cp\u003e1) Input your Quantumworks Lab API key into the provided \u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eGoogle Colab notebook\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e2) Specify an amount of data that you wish to ingest — we’ve provided up to 44,000 data rows for ingestion, but keep in mind that this will accrue \u003ca href=\"https://docs.labelbox.com/docs/billing?ref=labelbox-guides.ghost.io#labelbox-units-lbus\"\u003eLBUs\u003c/a\u003e in your account. \u003cem\u003eIf you are using Quantumworks Lab for free, we suggest that you ingest around 5,000 data rows.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e3) Select ‘Runtime’ in the navigation bar and hit ‘Run all’ to bring the selected amount of data rows into your \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eLabelbox Catalog \u003c/a\u003e— where you can browse, explore, and curate the data for insights and model development.\u003c/p\u003e\u003ch3 id=\"accelerate-product-discovery-across-your-entire-catalog\"\u003eAccelerate product discovery across your entire catalog\u003c/h3\u003e\u003cp\u003eAn effective product recommendation relies on training a model with a thorough understanding of your product data, encompassing product tags, categories, and more. However, retailers often have an ever-growing product list with hundreds or thousands of products. Dealing with this volume of data at scale and effectively searching, organizing, and managing data for machine learning tasks can be a challenge.\u003c/p\u003e\u003cp\u003eYou can leverage Quantumworks Lab Catalog to visualize, browse, and curate your product listings.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ehcuz2b4rk\" title=\"[Personalized Experiences Demo] Search and curate Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eSearch and curate data\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eYou’ll now be able to see the sample retail dataset in your Quantumworks Lab Catalog. Try searching across key product-specific metadata such as category, the year the item was released, season, gender, and more. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1226\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 2304w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eLeverage custom and out-of-the-box smart filters and embeddings to quickly explore product listings, surface similar data, and optimize data curation for ML. You can:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eSearch across datasets\u003c/a\u003e to narrow in on data containing specific attributes (e.g metadata, media attributes, datasets, project, etc.)\u003c/li\u003e\u003cli\u003eAutomatically \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003efind similar data\u003c/a\u003e in seconds with off-the-shelf embeddings \u003c/li\u003e\u003cli\u003eFilter data based on \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language\u003c/a\u003e and flexibly \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io#how-filters-work\"\u003elayer structured and unstructured filters\u003c/a\u003e for more granular data curation\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"categorize-and-curate-product-listings-faster\"\u003eCategorize and curate product listings faster\u003c/h3\u003e\u003cp\u003eAdvanced ML teams often adopt partially automated labeling workflows to mitigate costs and accelerate model development. Product recommendation models require a vast amount of accurately labeled data with a wide array of features. Manually labeling this data can not only be time consuming, but can also get exponentially expensive. Scaling data curation and enrichment effectively is key to quickly creating a powerful ML solution. \u003c/p\u003e\u003cp\u003eOne simple way to achieve this is by leveraging bulk classification and using human-in-the-loop review for quality assurance. Some AI teams using this technique have cut labeling costs by nearly 90%.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/epl8hstb7c\" title=\"[Personalized Experiences Demo] Streamlined labeling automation through bulk classification Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eStreamline labeling automation through bulk classification\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate a new labeling project\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"905\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOnce you’ve narrowed in on a specific slice of data that you’d like to take action on, you can send them to a labeling project of interest in just a few clicks.\u003c/p\u003e\u003cp\u003e1) Create a new image project in \u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e2) Configure the editor and create a new ontology. For the ontology, create a new classification called ‘Occasions’ with options such as ‘Casual’, ‘Sports’, ‘Formal’, etc. feel free to add any other classifications of interest.\u003c/p\u003e\u003cp\u003e3) Save your labeling project.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eSend a subset of data to the labeling project\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"739\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eReturn to Catalog and surface a specific subset of data that you want to bulk classify. For example, you can surface all instances of ‘Sporty apparel’ clothing with a natural language search.\u003c/p\u003e\u003cp\u003e1) Highlight any data rows of interest and select ‘Manage selection’ \u0026gt; ‘Add classifications’.\u003c/p\u003e\u003cp\u003e2) Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. In the above demo, we are sending these to the ‘Done’ stage because we have verified that these images fall under the ‘Sports’ category and want to automatically create ground truth labels.\u003c/p\u003e\u003cp\u003e3) Pick ‘Sports’ under the Classification section and you can submit the classification batch. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eSave high-impact searches\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1029\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can save any combination of searches as a \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslice\u003c/a\u003e in Catalog. For example, saving the natural language search of ‘Sporty apparel’ as a slice called ‘Sporty apparel’, creates a dynamic slice of data that can easily be revisited or edited as project needs evolve. Any future data that gets uploaded to Quantumworks Lab will automatically populate in any relevant slices based on its filters, creating an automatic data curation pipeline as your product catalog grows.\u003c/p\u003e\u003ch2 id=\"part-2-prepare-data-and-evaluate-model-performance\"\u003ePart 2: Prepare data and evaluate model performance\u003c/h2\u003e\u003cp\u003e\u003cbr\u003eFollow along with the below with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u003c/strong\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\" class=\"kg-btn kg-btn-accent\"\u003ePart 2: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"prepare-a-training-dataset-for-model-diagnosis\"\u003ePrepare a training dataset for model diagnosis\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eModel diagnosis can play a pivotal role when training a model for personalized shopping experiences. The success of personalized recommendation systems hinge on the accuracy of a model’s understanding of a retailer’s product catalog or individual customer preferences. A properly curated and organized training dataset serves as the foundation for accurate model performance evaluation and fine-tuning.\u003c/p\u003e\u003cp\u003eSend the curated training dataset from Quantumworks Lab Annotate to Model in a few clicks to efficiently diagnose model performance of the training dataset.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate a training dataset for evaluation\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/zo945lphbi\" title=\"[Personalized Experiences Demo] Prepare a training dataset for model diagnosis Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreating a new model\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1866\" height=\"1408\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1866w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Navigate to the Model tab, select ‘Experiments’, and create a new model.\u003c/p\u003e\u003cp\u003e2) Name your model (e.g ‘Occasions’) and select a model thumbnail.\u003c/p\u003e\u003cp\u003e3) Select the same ontology that was used to bulk classify the data rows in the previous step.\u003c/p\u003e\u003cp\u003e4) Select the project that the classifications were sent to in the previous step. After selecting both the correct ontology and project, you should see the number of data rows that were bulk classified and ready to be added to the new model.\u003c/p\u003e\u003cp\u003e5) Hit ‘Create model’.\u003c/p\u003e\u003cp\u003e\u003cem\u003eCreating a new model run\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"938\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 2306w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Once you’ve created your model, you can navigate back to the ‘Experiments’ tab and find the newly created model.\u003c/p\u003e\u003cp\u003e2) Create a ‘new model run.’ \u003ca href=\"https://docs.labelbox.com/docs/model-runs?ref=labelbox-guides.ghost.io\"\u003eA model run\u003c/a\u003e is a model training experiment within a model, providing a versioned data snapshot of all data rows, annotations, and data splits for that model run.\u003c/p\u003e\u003cp\u003e3) To create a model run, you’ll need to give it a name (e.g ‘dataset version 1’) and can adjust the balance of the data split. For this demo, we will leave them in the default setting (80% train, 10% validate, 10% test).\u003c/p\u003e\u003cp\u003e4) After creating the model run, you’ll be able to see the populated training data classifications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTrain a model on a provided training dataset\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ab1phltynu\" title=\"[Personalized Experiences] Train a model on the provided training dataset Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cp\u003eWe’ll be using the \u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eColab notebook\u003c/a\u003e to train a model on the training dataset and bring back inferences from the trained model for evaluation and diagnosis.\u003c/p\u003e\u003cp\u003eFor this step, you will need:\u003c/p\u003e\u003cul\u003e\u003cli\u003eYour Ontology ID — found in the Settings tab on the model run page\u003c/li\u003e\u003cli\u003eYour Model Run ID — found in the gear icon on the top-right of the model run page\u003c/li\u003e\u003cli\u003eYour API key\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e1) Enter your API key, Ontology ID, and Model Run ID in the Colab Notebook.\u003c/p\u003e\u003cp\u003e2)  Once those are inputted, you can select ‘Runtime’ in the navigation bar and hit ‘Run all’ – this will take the classifications from your model run and train a provided image classification model. After training, the notebook will also take the trained model and use it to run inference on the data.\u003c/p\u003e\u003cp\u003e3)  If you want to adjust your data splits, you can leverage search filters in Model to surface any data rows and move them to the train, test, and validation splits.\u003c/p\u003e\u003ch3 id=\"evaluate-and-diagnose-model-effectiveness-for-retail\"\u003eEvaluate and diagnose model effectiveness for retail\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eA well-performing model can accurately predict consumer behavior or recommend products based on past preferences. Effective model diagnosis helps fine-tune recommendation algorithms, resulting in more accurate and appealing product suggestions. \u003c/p\u003e\u003cp\u003eModel diagnosis and evaluation are not one-time tasks. By leveraging effective diagnostic tools and an active learning workflow, retailers can continuously identify areas of improvement and adapt to changing customer behavior or an evolving product catalog. This iterative approach keeps personalized experiences relevant and effective for driving business outcomes over time.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/qwqdx21ml2\" title=\"[Personalized Experiences Demo] Diagnose model performance and fix model errors Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eDiagnose model performance with model metrics\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"692\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 2330w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) After running the notebook, you’ll be able to visually compare ground truth labels (in green) to the model predictions (in red).\u003c/p\u003e\u003cp\u003e2) Use the ‘Metrics view’ to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/p\u003e\u003cp\u003e3) Model metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples.\u003c/p\u003e\u003cp\u003e4) Detect and visualize corner-cases where the model is underperforming. For example, in the demo above, we notice that the model is classifying this type of white shoe as a ‘Sports’ shoe when in fact it is a ‘Casual’ shoe.\u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate high-impact data to drastically improve model performance\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1172\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 2324w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Select any corner-cases and select ‘Find similar in Catalog’ from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows to the selected example.\u003c/p\u003e\u003cp\u003e2) In addition to the similarity search, you can filter on ‘Annotation’ \u0026gt; ‘is none’ to surface only unlabeled data rows that you can retrain the model on to boost model performance.\u003c/p\u003e\u003cp\u003e3) Select any relevant examples and ‘Manage selection’ \u0026gt; ‘Add classifications’. In this case, we’d want to bulk classify these examples to reinforce to the model that these images are ‘casual’ shoes.\u003c/p\u003e\u003cp\u003e4) This step is similar to the bulk classification step in part 1. Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. We can send these to the ‘Done’ stage because we want to tell the model these white shoes fall under the ‘Casual’ category and want to automatically create ground truth labels.\u003c/p\u003e\u003cp\u003e5) Create a new model run (within the same model) and have the newly added classifications as a part of the training dataset.\u003c/p\u003e\u003cp\u003e6) Run the notebook again to train the model on this new training dataset and evaluate model performance with model metrics. You can compare results from the initial model run with the new model run to evaluate how the adjustment influenced model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eAs consumer businesses strive to distinguish themselves in a competitive market, the power of AI-driven product recommendation systems cannot be underestimated. Companies can tap into their vast data stores and harness the capabilities of advanced algorithms to forge deeper connections with their customers.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..\u0026ref=labelbox-guides.ghost.io\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e. \u003c/p\u003e","comment_id":"64e7a2c3b0c09f000179dbed","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1-.png","featured":false,"visibility":"public","created_at":"2023-08-24T18:34:43.000+00:00","updated_at":"2023-11-20T19:39:23.000+00:00","published_at":"2023-08-24T19:15:09.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-build-a-powerful-product-recommendation-system-for-retail","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-build-a-powerful-product-recommendation-system-for-retail/","excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","reading_time":10,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1--2.png","og_title":"How to build a powerful product recommendation system for retail","og_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1--1.png","twitter_title":"How to build a powerful product recommendation system for retail","twitter_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","meta_title":"How to build a powerful product recommendation system for retail","meta_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"646f88789568720001240642","uuid":"b8289ca0-7d94-41c4-84df-a5e0541ba9bb","title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","slug":"leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content","html":"\u003cp\u003eVideo data can offer a wealth of information for AI use cases, but because of their dense and dynamic nature, manually extracting insights can be a tedious task. To accelerate this process, leading AI teams often use off-the-shelf, pre-trained models like \u003ca href=\"https://ultralytics.com/yolov8?ref=labelbox-guides.ghost.io\"\u003eYOLO\u003c/a\u003e (short for You Only Look Once) to take a quick first pass at detecting the contents of a video dataset. \u003c/p\u003e\u003cp\u003eYOLO is a real-time object detection model. Unlike traditional models, which scan an image multiple times at different scales, YOLO looks at the entire image only once, making it particularly well-suited for video object detection. It can detect various objects and provide a bounding box for each detected object. Using this model to enrich video data can make it easier for AI teams to understand their data.\u003c/p\u003e\u003cp\u003eHowever, the real magic lies in going a step further by organizing and categorizing this information, making the video content searchable. In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.\u003c/p\u003e\u003ch2 id=\"how-to-make-videos-queryable\"\u003eHow to make videos queryable\u003c/h2\u003e\u003cp\u003eTo make a video queryable, the first step is to run the YOLO model on the video to detect the objects in each frame. Once objects are detected, they are classified, and a bounding box is added to the objects in Labelbox. You can then search your video content based on these annotations with Catalog. Want to find all instances where a \"bowl\" appears in your video? Simply search for \"bowl\" in the Quantumworks Lab UI. Catalog will return all the videos that contain this annotation.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"633\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_1.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_1.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOnce YOLO has added annotations to your video data, you can simply search for specific content within that dataset using Quantumworks Lab Catalog.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou can also create a custom workflow in Quantumworks Lab to create a bespoke review process, where you can create tasks that only have assets containing a specific annotation in the video, such as vehicles or other objects of interest. You can let YOLO take the first pass at labeling your video data, and then have human labelers review and/or add annotations in frames that contain specific objects of interest, reducing the time and costs required to label high-quality training data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"961\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_2.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_2.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_2.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eYou can create a custom labeling workflow that targets specific data in Quantumworks Lab to save labeling time and costs while ensuring high labeling quality.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRead on for step-by-step instructions on using YOLO and Quantumworks Lab to make your videos queryable.\u003c/p\u003e\u003ch2 id=\"part-1-create-project-and-ontology\"\u003ePart 1: Create project and ontology\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eproject = client.create_project(name=\"Video project with YOLO\",\n                                   media_type=lb.MediaType.Video)\n\n\n#connect ontology to your project\nproject.setup_editor(ontology)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-2-queue-assets-to-project-based-on-global-keys\"\u003ePart 2: Queue assets to project based on global keys\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003ebatch = project.create_batch(\n \"first-batch-video\"+str(uuid.uuid4()), # Each batch in a project must have a unique name\n global_keys= global_keys, # A paginated collection of data row objects, a list of data rows or global keys\n priority=5 # priority between 1(Highest) - 5(lowest)\n)\nprint(\"Batch: \", batch)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-3-load-yolo-model\"\u003ePart 3: Load YOLO model\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel = YOLO(f'{HOME}/yolov8n.pt')\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-4-create-predictions-and-upload-them-to-labelbox\"\u003ePart 4: Create predictions and upload them to Quantumworks Lab\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Export queued data rows from the project\nqueued_data_rows = project.export_queued_data_rows()\n\n\n# Initialize an empty list to store labels\nlabels = []\n\n\n# Loop over each data row. Here, it's only looping over the first data row.\nfor data_row in queued_data_rows[:1]:\n\n\n # Extract the URL of the video from the data row.\n video_url = data_row[\"rowData\"]\n\n\n # Extract the global key from the data row.\n global_key = data_row[\"globalKey\"]\n\n\n # Make a GET request to the video URL.\n response = requests.get(video_url)\n\n\n # Open a file in write-binary mode and write the content of the response to it.\n # This is downloading the video and saving it as 'sample_video.mp4'.\n with open('sample_video.mp4', 'wb') as f:\n     f.write(response.content)\n\n\n # Create a VideoCapture object to read frames from the downloaded video.\n cap = cv2.VideoCapture(\"sample_video.mp4\")\n\n\n # Set up the VideoWriter for the output video. The 'mp4v' argument specifies the codec to be used.\n fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\n\n # Initialize a counter for the frame number.\n frame_number = 0\n\n\n # Start a loop to read frames from the video.\n while True:\n     # Read the next frame from the video.\n     ret, frame = cap.read()\n\n\n     # If the frame could not be read (i.e., we're at the end of the video), break the loop.\n     if not ret:\n         break\n\n\n     # Increment the frame number.\n     frame_number += 1\n\n\n     # Use the model to predict objects in the current frame. The confidence threshold is set to 0.5.\n     results = model.predict(frame, conf=0.50)\n\n\n     # Loop over each predicted class.\n     for c in results[0].boxes.cls:\n       # Loop over each bounding box predicted for the current class.\n       for idx, box in enumerate(results[0].boxes.xyxy):\n         # Get the class number from the model's class names.\n         class_number = model.names[int(c)]\n\n\n         # Get the coordinates of the bounding box.\n         xmin, ymin, xmax, ymax  = float(box[0]), float(box[1]), float(box[2]), float(box[3])\n\n\n         # Create an annotation for the bounding box.\n         bbox_annotation = [\n           lb_types.VideoObjectAnnotation(\n             name = class_number,\n             keyframe= True,\n             frame=frame_number,\n             segment_index=0,\n            \n             # Define the bounding box as a rectangle with a start and end point.\n             value = lb_types.Rectangle(\n                   start=lb_types.Point(x=xmin, y=ymin), # x = left, y = top\n                   end=lb_types.Point(x= xmax, y=ymax)))] # x= left + width , y = top + height\n        \n         # Append a new Label object to the labels list. Each Label represents one detected object in one frame.\n         labels.append(\n             Label(\n                 data=lb_types.VideoData(global_key=global_key),\n                 annotations = bbox_annotation\n             )\n         )\n\n\n # Release the VideoCapture object.\n cap.release()\u003c/code\u003e\u003c/pre\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"923\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_3.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_3.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_3.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample of Quantumworks Lab video editor with YOLO predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1182\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_4.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_4.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_4.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eAnalytics view of a dataset with YOLO predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/Large-GIF--1466x882-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1466\" height=\"882\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/Large-GIF--1466x882-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/Large-GIF--1466x882-.gif 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/Large-GIF--1466x882-.gif 1466w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eVideo is enriched with annotations from YOLO, and the contents can be queried in Quantumworks Lab Catalog.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eCombining the power of the YOLO — or any off-the-shelf AI model that suits your needs — with Quantumworks Lab opens up exciting possibilities for video content. It not only makes the video content queryable, but also helps bring a new level of understanding to what's inside the videos. This combination can be especially beneficial for use cases like surveillance, content creation, content moderation, and advertising, where insights from video content are crucial.\u003c/p\u003e\u003cp\u003eUsing an AI model as a first pass enables users to search videos based on their content, enabling AI teams to learn how many annotations of each object exist within their dataset and what types of annotations the training dataset might lack. This further reduces friction when it comes to finding the next set of assets that will improve the model's performance by doing active learning. Try enriching your videos using YOLO or any other AI model using this \u003ca href=\"https://colab.research.google.com/drive/1vOVo4MtsoUxNJ-tIdmI-GKWjVFo9RrQe?ref=labelbox-guides.ghost.io#scrollTo=rJXXOJdpWD48\"\u003escript\u003c/a\u003e to discover exactly what content already exists in your troves of unstructured videos and find specific videos quickly and easily.\u003c/p\u003e","comment_id":"646f88789568720001240642","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Screen-Shot-2023-05-24-at-1.45.31-PM.png","featured":false,"visibility":"public","created_at":"2023-05-25T16:10:32.000+00:00","updated_at":"2023-10-27T16:58:02.000+00:00","published_at":"2023-05-25T16:33:51.000+00:00","custom_excerpt":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content/","excerpt":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","og_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","twitter_image":null,"twitter_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","twitter_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","meta_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","meta_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6452689090e75e0001b3546c","uuid":"5a55750c-5b23-4ce7-b075-117a24a4f392","title":"Automatically label images with 99% accuracy using foundation models","slug":"automatically-label-images-with-99-accuracy-using-foundation-models","html":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\u003cp\u003eIn this guide, you’ll learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab and foundation models. We will be walking through a sample \u003ca href=\"https://labelbox.com/guides/image-annotation/?ref=labelbox-guides.ghost.io\"\u003eimage classification task\u003c/a\u003e: figuring out if images contain cats or dogs.\u003c/p\u003e\u003cp\u003eHere's a high-level summary of the process that we'll be walking through step-by-step below:\u003c/p\u003e\u003cul\u003e\u003cli\u003eConnect your data to Quantumworks Lab with just a few lines of code.\u003c/li\u003e\u003cli\u003eLabelbox leverages foundation models to magically enrich your data.\u003c/li\u003e\u003cli\u003eUse the powerful search capabilities of Quantumworks Lab to quickly find data with similar traits and classify them in one click. With the help of foundation models, you can instantaneously label large amounts of data. \u003cem\u003ePro tip: Combine a variety of search techniques, such as a similarity search, natural language search, and investigate clusters of similar data, to boost your results.\u003c/em\u003e\u003c/li\u003e\u003cli\u003eWhile foundation models are a helpful starting point, they might not always correctly classify data, especially on challenging or rare data points. In this case, utilize human-in-the-loop labeling and QA by pre-labeling data using foundation models and sending it for your internal or external labeling team to review.\u003c/li\u003e\u003cli\u003eAutomatically apply these rules to all new incoming data by creating a \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslice\u003c/a\u003e in Labelbox.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, let’s take a look at how we can do the above in Labelbox. As a sneak peek into the process, by leveraging foundation models, we managed to \u003cstrong\u003eclassify 86% of our images in minutes with a 99.9% accuracy rate\u003c/strong\u003e. An additional 13.5% of our images were successfully pre-labeled using foundation models, with 98% accuracy, and were sent for human review. This left us with less than 0.5% of images to manually label – a massive efficiency gain for any labeling team.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"step-1-connect-your-data-to-labelbox-with-a-few-lines-of-code\"\u003eStep 1: Connect your data to Quantumworks Lab with a few lines of code\u003c/h2\u003e\u003cp\u003eSince this is a classification task, our goal is to correctly have the model identify cats and dogs in images. We will be using the following Hugging Face dataset - \u003ca href=\"https://huggingface.co/datasets/cats_vs_dogs?ref=labelbox-guides.ghost.io\"\u003ecats_vs_dogs\u003c/a\u003e, containing 18,699 images for our analysis.\u003c/p\u003e\u003cp\u003eTo begin, let's connect this data to Labelbox. Simply retrieve the dataset from Hugging Face and integrate it with Quantumworks Lab in just a few lines of code.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom datasets import load_dataset\ndataset = load_dataset(\"cats_vs_dogs\",split='train')\n\n# iterate over the data\npayload_imgs = []\ncounter = 0\n\nfor data in dataset:\n  image = data['image']\n  label = data['labels'] # 0 is cat, 1 is dog\n  global_key = \"cat_vs_dog_\" + str(counter)\n\n  # save image locally\n  path = \"/content/images/\"+global_key+\".jpg\"\n  image.save(path) \n\n  # create payload for images\n  payload_imgs.append({\"row_data\": path, \"global_key\": global_key})\n  counter += 1\n\n# create dataset in Quantumworks Lab\nlb_dataset = client.create_dataset(name=\"Cat_vs_dog\") \n\n\n# add data in Quantumworks Lab\ntask = lb_dataset.create_data_rows(payload_imgs[i:i+1000])  task.wait_till_done() # async\nprint(task.errors) # check errors \u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-2-leverage-foundation-models-to-instantly-enhance-your-data\"\u003eStep 2: Leverage foundation models to instantly enhance your data\u003c/h2\u003e\u003cp\u003eLabelbox will automatically compute and store CLIP embeddings for your data. Our CLIP model leverages \u003ca href=\"https://openai.com/research/clip?ref=labelbox-guides.ghost.io\"\u003eOpenAI\u003c/a\u003e and we are using \u003ca href=\"https://huggingface.co/sentence-transformers/clip-ViT-B-32?ref=labelbox-guides.ghost.io\"\u003ethis implementation\u003c/a\u003e available through Hugging Face. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"922\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOnce your data has been uploaded, you can enrich your data with foundation model embeddings. These embeddings are powerful in that they can be harnessed to automatically label, or pre-label, your data.  \u003c/p\u003e\u003cp\u003eIf you don’t want to use the default embeddings by Quantumworks Lab, you can also \u003ca href=\"https://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/?ref=labelbox-guides.ghost.io\"\u003eupload custom embeddings\u003c/a\u003e from any other foundation model, with up to 100 custom embeddings for each data point. \u003c/p\u003e\u003cp\u003eWhether you’re using the default or custom embeddings, embeddings are helpful in curating and finding subsets of data that share similar characteristics. For instance, embeddings power Quantumworks Lab’s \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003esimilarity search\u003c/a\u003e, natural language search, and 2D projector view. You can search and explore all of your data with tools that help you powerfully surface specific subsets of data.\u003c/p\u003e\u003ch2 id=\"step-3-use-powerful-search-capabilities-to-quickly-find-data\"\u003eStep 3: Use powerful search capabilities to quickly find data\u003c/h2\u003e\u003cp\u003eWith \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003epowerful search capabilities\u003c/a\u003e in Quantumworks Lab, you can easily find and classify data that share similar characteristics. This is a special case of \u003ca href=\"https://labelbox.com/blog/few-shot-learning-and-zero-shot-learning-with-openai-embeddings/?ref=labelbox-guides.ghost.io\"\u003ezero-shot and few-shot learning\u003c/a\u003e: the challenge is to find all examples of cats and dogs, based on zero (or a few) examples from each class. \u003c/p\u003e\u003cp\u003eWith the help of foundation models, and minimal human signal, you can quickly label a lot of data in just a few clicks. The following are tools in Quantumworks Lab that help provide labeling signal to make it easy to automatically classify your data:\u003c/p\u003e\u003ch3 id=\"zero-shot-labeling-projector-view-for-classification\"\u003eZero-shot Labeling: Projector View for classification\u003c/h3\u003e\u003cp\u003eLabelbox allows you to visualize data clusters in 2D. For this example, we can see two distinct clusters: one for cats and another for dogs. By inspecting a few examples, we can ensure the data clustering is accurate. We then manually select each cluster and tag it with \"UMAP: cats: high confidence\" and \"UMAP: dogs: high confidence\". We intentionally left out data points situated between clusters, as these represent challenging data points. This is expected since each labeling function won’t be perfect in isolation and some data points are difficult and challenging.\u003c/p\u003e\u003cp\u003eWe then repeat the process with t-SNE, instead of UMAP, and tag each cluster with \"t-SNE: cats: high confidence\" and \"t-SNE: dogs: high confidence\".\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"924\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUMAP: a cluster of cats with high confidence\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"923\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUMAP: a sub-cluster of images with two cats\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"926\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003et-SNE: the same sub-cluster of images with two cats\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"zero-shot-labeling-natural-language-search-for-classification\"\u003eZero-shot Labeling: Natural language search for classification\u003c/h3\u003e\u003cp\u003eLabelbox enables you to conduct \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language searches\u003c/a\u003e, for example you can type in “photos of cats” to surface all cat images. Adjusting the similarity threshold will narrow the search parameters to show only the images that contain cats. For this use case, we can filter for a similarity score higher than 0.61 and tag all of the 7,125 images as “Natural language search: Cats (high confidence)”. If we adjust the similarity score to be between 0.6 and 0.61, we can tag the 1,299 images as “Natural language search: Cats (low confidence)”. \u003c/p\u003e\u003cp\u003eWe take the same approach for images containing dogs. Using the same technique above, we tag 7,738 images of dogs as “Natural language search: Dogs (high confidence)” and surface and tag 2,750 images as “Natural language search: Dogs (low confidence)”.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"926\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eA natural language search will surface thousands of images of cats. By adjusting the similarity score, we can keep the most confident zero-shot predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"few-shot-labeling-similarity-search-for-classification\"\u003eFew-shot Labeling: Similarity search for classification\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eLabelbox also streamlines few-shot labeling. Quickly browse all your data in Catalog to surface 5 images of cats and 5 images of dogs. Perform a similarity search in one click using these 10 images as anchors. For each anchor image, run a similarity search and tag the top results (e.g  with a similarity score of higher than 0.895) as “Labeling function: similarity search (cats: high confidence)”. This provides us with 10 new labeling functions that surface images similar to the anchor images.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"925\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eA similarity search example with anchor images of dogs. We can filter to keep the most confident few-shot predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"weak-labeling-combining-different-sources-of-signal\"\u003eWeak Labeling: Combining different sources of signal\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eWhile each of these labeling signals is powerful on its own, you can combine multiple sources in Labelbox. This allows you to apply simple rules in a weak supervision fashion to further enhance your results. Integrate different labeling signals, such as similarity searches, natural language searches, and data clusters, to boost your outcomes. You can \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003ecombine various filters\u003c/a\u003e by using the AND and OR functions.\u003c/p\u003e\u003ch2 id=\"step-4-automatically-classify-data-with-foundation-models-and-use-human-in-the-loop-qa-for-challenging-cases\"\u003eStep 4: Automatically classify data with foundation models and use human-in-the-loop QA for challenging cases\u003c/h2\u003e\u003ch3 id=\"high-confidence-data-points-direct-classification\"\u003eHigh confidence data points: direct classification\u003c/h3\u003e\u003cp\u003eFoundation models are highly confident about most data points. So much so that we can directly classify data points leveraging Quantumworks Lab’s \u003ca href=\"https://labelbox.com/blog/pre-label-and-enrich-your-data-with-bulk-classifications/?ref=labelbox-guides.ghost.io\"\u003ebulk classification feature\u003c/a\u003e. With this new feature, you can specify and send your data rows to a specific step of the \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox.ghost.io#how-it-works\"\u003elabeling and review workflow\u003c/a\u003e. We can directly move these high-confidence data points straight to the “Done” task.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"927\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWe can classify thousands of data points in bulk, and send them to the “Done” task of our labeling project, in just a click, since foundation models are confident on those.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn practice, these high-confident data points are those that belong to the cat or dog cluster, both with UMAP and t-SNE, and where the natural language score is higher than 0.61. This results in 7,627 dog classifications. But just how accurate are these classification predictions? \u003c/p\u003e\u003cp\u003eTo answer this question, we looked at the Hugging Face ground truths. On the surface, 10 out of the 7,627 dog predictions are incorrect (0.13%). However, upon closer inspection, it turns out that the Hugging Face dataset contains a few labeling mistakes and only 6 out of the 7,627 predictions (0.078%) of the foundation model’s predictions are actually incorrect. Similarly, there were 6,587 cat classifications. Only 6 out of the 6,587 cat predictions (0.09%) of the foundation model’s predictions are incorrect. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"761\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOut of 7,627 images, foundation models failed on these 10 by predicting dogs instead of cats.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eHigh-confident data points are also those that are found with a similarity search proximity to 2 or more anchors with a 0.895 or higher score. There were 907 dog classifications that fit this criteria, all of which were accurate except 1, and 1,022 cat classifications, all of which were accurate except 6. \u003c/p\u003e\u003cp\u003eBy leveraging the above methods, we were able to classify 16,143 data rows - with only 19 errors - achieving an \u003cstrong\u003eaccuracy of 99.9%. \u003c/strong\u003eSince 16,143 out of 18,699 data rows have been classified directly by foundation models, the \u003cstrong\u003ecoverage is 86%.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eNow, let’s move on to classify the remaining 14% of data rows, on which the foundation model appears to be less confident.\u003c/p\u003e\u003ch3 id=\"medium-confidence-data-points-human-in-the-loop-labeling\"\u003eMedium confidence data points: Human-in-the-Loop labeling\u003c/h3\u003e\u003cp\u003eFor some data points, foundation models exhibit moderate confidence. We can bulk classify these data points in Quantumworks Lab, but move them to the “To Review” task. This will ensure a human is looped in and will review the classifications coming from foundation models.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"922\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWe can pre-label thousands of data points in bulk and send them to “Review” in our labeling project, since foundation models are moderately confident on these images.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn practice, these data points are those that belong to the cat or dog cluster, with UMAP or t-SNE, and that we hadn’t classified before:\u003c/p\u003e\u003cul\u003e\u003cli\u003e1,622 dogs classifications, which turn out to be all accurate except 10.\u003c/li\u003e\u003cli\u003e907 cat classifications, which turn out to be all accurate except 38. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eUsing this approach, we manage to classify 2,529 data rows, with an \u003cstrong\u003eaccuracy of 98%\u003c/strong\u003e (48 errors). Good that we send them to humans for review! So far, we’ve classified all data rows except 27, so the coverage is \u003cstrong\u003e99.85%\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eNow, let’s move on to classify the remaining 27 images.\u003c/p\u003e\u003ch3 id=\"low-confidence-data-points-manual-labeling\"\u003eLow confidence data points: Manual labeling\u003c/h3\u003e\u003cp\u003eAfter applying these rules, 18,672 data rows out of 18,699 (99.85%) have been labeled, leaving only 27 data rows unclassified. Foundation models lack the confidence to label these remaining data points.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1135\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSome data rows, 27 in our case, were not classified through foundation models. This includes images that are blurry, where animals are turning their backs or are barely visible behind a cage.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThese 27 data points will require manual labeling by humans, which represents only 0.14% of data rows - a massive efficiency gain in labeling effort and speed!\u003c/p\u003e\u003ch3 id=\"results\"\u003eResults\u003c/h3\u003e\n\u003c!--kg-card-begin: html--\u003e\n\u003ctable style=\"border:none;border-collapse:collapse;table-layout:fixed;width:468pt\"\u003e\u003ccolgroup\u003e\u003ccol\u003e\u003ccol\u003e\u003ccol\u003e\u003ccol\u003e\u003c/colgroup\u003e\u003ctbody\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eDirect classification with foundation models\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eHuman in the loop with foundation models\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eManual classification\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e# of data rows classified\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e16,143\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e2,529\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e27\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e# of errors\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e19\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e48\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e0\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eAccuracy\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e99.9%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e98%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e100%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCoverage\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e86%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e13.5%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e0.15%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCumulative coverage\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e86%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e99.8%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e100%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003c!--kg-card-end: html--\u003e\n\u003cp\u003e\u003c/p\u003e\u003cp\u003eWith powerful search capabilities and the bulk classification feature, we managed to classify 16,143 images (86%) in minutes, with \u003cstrong\u003e99.9% accuracy\u003c/strong\u003e thanks to foundation models. An additional 2,529 data points (13.5%) have been pre-labeled with foundation models, with \u003cstrong\u003e98% accuracy\u003c/strong\u003e, and sent for human review. This leaves with only 27 very challenging images to label manually!\u003c/p\u003e\u003ch2 id=\"step-5-set-it-and-forget-it-%E2%80%93-automatically-apply-these-rules-to-fresh-incoming-data\"\u003eStep 5: Set it and forget it – automatically apply these rules to fresh, incoming data\u003c/h2\u003e\u003cp\u003eWith Quantumworks Lab \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslices\u003c/a\u003e, we can automatically classify fresh, incoming data as cats or dogs. \u003c/p\u003e\u003cp\u003eFor example, we can set up a slice that automatically surfaces all new images that have been connected to Quantumworks Lab in the past week, that haven’t been classified yet. We can set the slice’s criteria to include only images where the natural language search for the prompt “photo of a cat” is higher than 0.61 (since we know that these images are very likely to contain cats). \u003c/p\u003e\u003cp\u003eWith slices, you can easily surface and inspect any new and high-impact data that gets added to your data lake. \u003c/p\u003e\u003cp\u003eFrom there, it only takes one click to classify all of these images as cats.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1216\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWith slices and the ability to automatically surface high-impact data, we surfaced 7,000+ new images of cats that were connected to Quantumworks Lab in the past week. We can easily add a cat classification to all these images in one click.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou can learn more about how to bulk classify data in our \u003ca href=\"https://docs.labelbox.com/docs/bulk-classification?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e or in our \u003ca href=\"https://labelbox.com/blog/pre-label-and-enrich-your-data-with-bulk-classifications/?ref=labelbox-guides.ghost.io\"\u003erecent blog post\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eWith powerful search capabilities, the bulk classification feature, and foundation models, we managed to classify 16,143 images (86%) in minutes, with \u003cstrong\u003e99.9% accuracy\u003c/strong\u003e. An additional 2,529 data points (13.5%) have been pre-labeled with \u003cstrong\u003e98% accuracy\u003c/strong\u003e and sent for human review. This only left us with 27 very challenging images that we needed to label manually. \u003c/p\u003e\u003chr\u003e\u003cp\u003eIf you’re a current Quantumworks Lab user who wants to leverage any foundation model to supercharge your data labeling process in just a few clicks,\u003ca href=\"https://app.labelbox.com/catalog?ref=labelbox-guides.ghost.io\"\u003e try our bulk classification feature today\u003c/a\u003e or \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003eget started with a free Quantumworks Lab account\u003c/a\u003e.\u003c/p\u003e","comment_id":"6452689090e75e0001b3546c","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Group-3058--2-.png","featured":false,"visibility":"public","created_at":"2023-05-03T13:58:40.000+00:00","updated_at":"2023-10-27T17:01:07.000+00:00","published_at":"2023-05-03T17:28:24.000+00:00","custom_excerpt":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/automatically-label-images-with-99-accuracy-using-foundation-models","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa513375d13000123d7ea","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/automatically-label-images-with-99-accuracy-using-foundation-models/","excerpt":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","reading_time":10,"access":true,"comments":false,"og_image":null,"og_title":"Automatically label images with 99% accuracy using foundation models","og_description":"Learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","twitter_image":null,"twitter_title":"Automatically label images with 99% accuracy using foundation models","twitter_description":"Learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","meta_title":"Automatically label images with 99% accuracy using foundation models","meta_description":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"645007f474911d003db0cb11","uuid":"3d216637-f0d9-4995-bfd5-d289ba48b7d0","title":"Introducing Export V2: How to export data with more granular control","slug":"how-to-export-your-data-with-more-granular-control","html":"\u003cp\u003eIf you already leverage Quantumworks Lab to enrich and label your unstructured data, you know how important it is to export your data insights in the right format and connect it with your downstream data workflow. Whether you want to store your data in a database, a cloud-hosted table, an ML training pipeline, or a production environment, you need a flexible and powerful export system that can handle your specific needs.\u003c/p\u003e\u003cp\u003eThat’s why \u003cstrong\u003ewe’re excited to introduce a new way to export your data\u003c/strong\u003e. This new system gives you more granular control over your data exports across the Quantumworks Lab platform and SDK. With this new way to export, you can:\u003c/p\u003e\u003cul\u003e\u003cli\u003eExport the exact Data Rows you are interested in. You can use various filters in the Catalog and Data row tabs, or hand-select the data rows to export. For example, you can grab only the data rows that have received new labels, metadata, or issues updates within the last 24 hours.\u003c/li\u003e\u003cli\u003eConfigure the export to include exactly the right information you need. You can build a custom export payload that meets your specific data workflow needs with much faster performance. Learn more about these improvements \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#required--optional-fields\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eOrganize your assets into a data-row-centric framework that’s easy to structure and analyze.\u003c/li\u003e\u003cli\u003eLeverage\u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io\"\u003e improved annotation formats\u003c/a\u003e to rapidly export annotations.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhile we will continue supporting the Export v1 system until December 31, 2023, we encourage you to gradually start migrating all of your export workflows to this updated export workflow (Export v2). The Export v1 and Export v2 workflows may be used in tandem until Export v1 is sunset on December 31st.\u003c/strong\u003e \u003c/p\u003e\u003cp\u003ePlease refer to our documentation to learn more about export specifications and compare the old Export v1 and new Export v2 systems: \u003ca href=\"https://docs.labelbox.com/reference/export-image-annotations?ref=labelbox-guides.ghost.io\"\u003eimage\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-video-annotations?ref=labelbox-guides.ghost.io\"\u003evideo\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-text-annotations?ref=labelbox-guides.ghost.io\"\u003etext\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-document-annotations?ref=labelbox-guides.ghost.io\"\u003edocuments\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-geospatial-annotations?ref=labelbox-guides.ghost.io\"\u003egeospatial/tiled imagery\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-audio-annotations?ref=labelbox-guides.ghost.io\"\u003eaudio\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-conversational-text-annotations?ref=labelbox-guides.ghost.io\"\u003econversational text\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-html-annotations?ref=labelbox-guides.ghost.io\"\u003eHTML\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-dicom-annotations?ref=labelbox-guides.ghost.io\"\u003eDICOM\u003c/a\u003e\u003cbr\u003e\u003c/p\u003e\u003ch2 id=\"what%E2%80%99s-new-in-export-v2\"\u003eWhat’s new in Export v2\u003c/h2\u003e\u003ch3 id=\"data-row-centric-asynchronous-exports\"\u003eData row-centric asynchronous exports\u003c/h3\u003e\u003cp\u003eThe previous export system (Export v1) relied upon a less flexible label-centric export that limited access to all the information you might need about a Data Row. Within Export v2’s Data Row-centric context, you can access much more information — including fields like:\u003c/p\u003e\u003cul\u003e\u003cli\u003emetadata,\u003c/li\u003e\u003cli\u003eattachment,\u003c/li\u003e\u003cli\u003eworkflow history,\u003c/li\u003e\u003cli\u003emodel predictions,\u003c/li\u003e\u003cli\u003emedia attributes\u003c/li\u003e\u003cli\u003ebatch id,\u003c/li\u003e\u003cli\u003eand issues, alongside with the labels.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy reframing exports based on Data Rows, we’ve made it much more intuitive for you to integrate with your data tables that are organized around your team’s unique assets and data rows. \u003c/p\u003e\u003cul\u003e\u003cli\u003eAdditionally , now when you trigger an export job, it will occur asynchronously in the background, unblocking your workflow so you can avoid waiting. \u003c/li\u003e\u003cli\u003eIf you are using the Quantumworks Lab UI, you can access the task status in the notification center. \u003c/li\u003e\u003cli\u003eIf you are using SDK, you can query the task for status and results. \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"export-from-a-dataset-or-a-slice-with-the-option-to-grab-labels-from-multiple-projects-and-model-runs\"\u003eExport from a dataset or a slice, with the option to grab labels from multiple projects and model runs.\u003c/h3\u003e\u003cp\u003eA data row can have labels from multiple projects, or have predictions from multiple model runs. Using this new way to export through Catalog, or through the SDK, you can easily grab all the information about a Data Row. \u003c/p\u003e\u003cp\u003eUse data row filters to select a subset of data rows for export:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn the UI, you can build your \u003ca href=\"https://docs.labelbox.com/docs/data-rows-activity?ref=labelbox-guides.ghost.io#filter-data-rows\"\u003efilters within a project in the Data Rows tab\u003c/a\u003e, build \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003efilters in a dataset / slice in Catalog\u003c/a\u003e, or build \u003ca href=\"https://docs.labelbox.com/docs/filtering-and-sorting?ref=labelbox-guides.ghost.io\"\u003efilters in Model using model run filters\u003c/a\u003e. You can then choose to export only the filtered data rows. \u003c/li\u003e\u003cli\u003eIn the UI and SDK, you can use the \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'last_activity_at' filter\u003c/a\u003e to export only the data rows that have the creation and modification of labels, metadata, status, comments and reviews in a user-specified time range. This applies to a project in Annotate and a dataset or slice export. \u003c/li\u003e\u003cli\u003eIn the UI and SDK, we added a support for a \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'label_created_at' filter\u003c/a\u003e for you to export only the data rows that have the creation of labels in a user-specified time range. This applies to a project in Annotate and a dataset or slice export.\u003c/li\u003e\u003cli\u003eIn the UI, you can hand-pick data rows for export. Similarly in SDK, we added support for \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'data_row_ids'\u003c/a\u003e filter to export only the data rows that you are interested in.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"configure-exports-to-selectively-include-or-exclude-certain-information-on-a-data-row\"\u003eConfigure exports to selectively include or exclude certain information on a data row\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWe recognize different teams have unique needs around what they need from exports. For example, labeling team would love to understand the performance and consensus scores of a labeling project, whereas a developer would like to know the metadata and media attributes on a data row.\u003c/li\u003e\u003cli\u003eExport v2 now not only covers all possible fields on a data row, but also makes it configurable so that you can grab only the necessary payload of export information with faster performance. See \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#required--optional-fields\"\u003ethis table\u003c/a\u003e to check all available option fields that you can include/exclude in your exports. \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"remove-the-caching-for-exports\"\u003eRemove the caching for exports\u003c/h3\u003e\u003cp\u003eExport v1 used to cache exports for 30 minutes. In Export v2, you will always get a fresh export and you can run one export asynchronous task on a project at a time. \u003c/p\u003e\u003ch3 id=\"simplified-and-improved-export-payloads\"\u003eSimplified and improved export payloads\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWe've converted all fields in the export payload into snake case.\u003c/li\u003e\u003cli\u003eRather than isolating them into another JSON file, we've improved the video and DICOM exports to contain all frame annotations in the export ndjson file. and Export v2 provides three representations of objects in frames: “frames”, “segments”, and “key_frame_feature_map” to facilitate your different needs of downstream workflows. See examples in \u003ca href=\"https://docs.labelbox.com/reference/export-video-annotations?ref=labelbox-guides.ghost.io#annotation-export-formats\"\u003eVideo\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/reference/export-dicom-annotations?ref=labelbox-guides.ghost.io#annotation-export-formats\"\u003eDICOM\u003c/a\u003e exports.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"exporting-via-ui\"\u003eExporting via UI\u003c/h2\u003e\u003cp\u003eFrom Quantumworks Lab's UI, you can access the export function through the drop-down menu after selecting a subset of data rows. You can export the entire project, model, dataset, or slice from a set of filters or a selection of data rows within them. \u003c/p\u003e\u003cp\u003eBelow are some examples of Export v2 in action. For more detailed information, please refer to our \u003ca href=\"https://docs.labelbox.com/docs/export-labels?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"annotate-a-labeling-project\"\u003eAnnotate (A labeling project)\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-5691075b-e1cf-448b-9fa1-fa21e739f71f.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"884\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSelect data rows from filteres in the Data Rows tab.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-9e91c4d6-8d20-49fa-a1fb-739a4247487a.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"882\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eHand-select specific data rows.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"model-a-model-run\"\u003eModel (A model run)\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-be94fe0b-4fe4-40ba-a93d-a8268afcfe70.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"787\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSelect from metrics filters.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"catalog-a-dataset-and-slices\"\u003eCatalog (A dataset and slices)\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-51102232-fd36-41f0-a343-0f063d17c719.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"850\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExport a slice with labels from multiple projects.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"exporting-data-via-sdk\"\u003eExporting data via SDK\u003c/h2\u003e\u003cp\u003eFor developers that would like to programmatically feed exports directly into downstream data workflows or build automatic workflows to retrieve fresh data exports on a regular basis, we recommend Export v2 SDK. It provides flexibility to control what data you want to export. \u003c/p\u003e\u003ch3 id=\"project-export-v2\"\u003eProject Export v2\u003c/h3\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Set the export params to include/exclude certain fields. Make sure each of these fields are correctly grabbed \nexport_params= {\n  \"attachments\": True,\n  \"metadata_fields\": True,\n  \"data_row_details\": True,\n  \"project_details\": True,\n  \"performance_details\": True\n}\n\n# You can set the range for last_activity_at and label_created_at. You can also set a list of data \n# row ids to export. \n# For context, last_activity_at captures the creation and modification of labels, metadata, status, comments and reviews.\n\n# Note: This is an AND logic between the filters, so usually using one filter is sufficient.\nfilters= {\n  \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n  \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n  \"data_row_ids\": [\"data_row_id_1\", \"data_row_id_2\"] \n}\n\nexport_task = project.export_v2(params=export_params, filters=filters)\nexport_task.wait_till_done()\n\nif export_task.errors:\n  print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can check out SDK examples of exporting from datasets, slices, and model runs in this \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"receiving-updates-via-webhooks\"\u003eReceiving updates via Webhooks\u003cbr\u003e\u003c/h2\u003e\u003cp\u003eFor teams that would like to get near real-time updates for each change on a data row, we recommend webhooks as a better option. Export v2 format can now be used for webhooks to receive the following events from project:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLABEL_CREATED\u003c/li\u003e\u003cli\u003eLABEL_UPDATED\u003c/li\u003e\u003cli\u003eLABEL_DELETED\u003c/li\u003e\u003cli\u003eREVIEW_CREATED\u003c/li\u003e\u003cli\u003eREVIEW_UPDATED\u003c/li\u003e\u003cli\u003eREVIEW_DELETED\u003c/li\u003e\u003cli\u003eWORKFLOW\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can configure a webhook that returns Export v2 in Project whenever an event is triggered. See more details in this \u003ca href=\"https://docs.labelbox.com/reference/webhook?ref=labelbox-guides.ghost.io\"\u003eWebhook Guide\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFor example, you can use ngrok to expose a local port.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003engrok http 3001\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis will generate an address that looks like ` \u003ca href=\"https://887d-2601-645-8000-3a90-9cb4-7d1b-d9b4-6714.ngrok.io/?ref=labelbox-guides.ghost.io\"\u003ehttps://887d-2601-645-8000-3a90-9cb4-7d1b-d9b4-6714.ngrok.io\u003c/a\u003e` and it will forward all requests to your localhost:3001. \u003c/p\u003e\u003cp\u003eIn your terminal, create a python file that contains the following code to receive webhook payload. Make sure to change your secret.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom flask import Flask, request\nimport hmac, hashlib\nimport json\nimport threading\nfrom werkzeug.serving import run_simple\n\n\n# This can be any secret that matches your webhook config (we will set later)\nsecret = b\"CHANGE-ME\"\n\n\n# Example for server-side code to receive webhook events\napp = Flask(__name__)\n\n\n@app.route(\"/webhook-endpoint\", methods=[\"POST\"])\ndef print_webhook_info():\n   payload = request.data\n   computed_signature = hmac.new(secret, msg=payload,\n                                 digestmod=hashlib.sha1).hexdigest()\n   if request.headers[\"X-Hub-Signature\"] != \"sha1=\" + computed_signature:\n       print(\n           \"Error: computed_signature does not match signature provided in the headers\"\n       )\n       return \"Error\", 500, 200\n\n\n   print(\"=========== New Webhook Delivery ============\")\n   print(\"Delivery ID: %s\" % request.headers[\"X-Labelbox-Id\"])\n   print(\"Event: %s\" % request.headers[\"X-Labelbox-Event\"])\n   print(\"Payload: %s\" %\n         json.dumps(json.loads(payload.decode(\"utf8\")), indent=4))\n   return \"Success\"\n\n\n\n\nthread = threading.Thread(target=lambda: run_simple(\"0.0.0.0\", 3001, app))\nthread.start()\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen run this script to start receiving requests from the ngrok address:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003engrok http 3001\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow, you can configure a webhook in Quantumworks Lab's Project setting. \u003c/p\u003e\u003cul\u003e\u003cli\u003eClick \u003cem\u003eSet up webhook\u003c/em\u003e\u003c/li\u003e\u003cli\u003eChoose V2 as the version of the webhook\u003c/li\u003e\u003cli\u003ePaste in the ngrok address plus /webhook-endpoint. You will need to write the secret to match the secret you specified in your app.py script \u003c/li\u003e\u003cli\u003eFinally, select the topics you want to subscribe to\u003cbr\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-122ef535-e118-494c-b065-4981a49f313d.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"876\" height=\"1110\"\u003e\u003c/figure\u003e\u003cp\u003eNow that you've created a webhook, everytime there is a new event triggered (such as updating a label), you will receieve the payload at / webhook-endpoint. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-bfd67059-8a6a-4e42-a232-ab9621d473a1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"927\"\u003e\u003c/figure\u003e\u003chr\u003e\u003cp\u003eThe improved and datarow-centric format of Export v2 empowers you to export with more granularity by including or excluding variables based on your project’s unique needs. Offering a more seamless user experience, the new export format more consistently mirrors our import format and aligns with annotation schema available in the platform.\u003c/p\u003e\u003cp\u003eAs you migrate from Export v1 to Export v2 workflows, please refer to our \u003ca href=\"https://docs.labelbox.com/reference/export-v2-glossary?ref=labelbox-guides.ghost.io\"\u003edocumentation \u003c/a\u003efor more detailed instructions on how to export your data through the UI or through the Python SDK.\u003c/p\u003e","comment_id":"645007f474911d003db0cb11","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Frame-2299--3-.png","featured":false,"visibility":"public","created_at":"2023-05-01T18:41:56.000+00:00","updated_at":"2023-10-27T17:01:36.000+00:00","published_at":"2023-05-01T23:08:32.000+00:00","custom_excerpt":"With Export V2, you can export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-export-your-data-with-more-granular-control","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-export-your-data-with-more-granular-control/","excerpt":"With Export V2, you can export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":"Introducing Export V2: How to export data with more granular control","og_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","twitter_image":null,"twitter_title":"Introducing Export V2: How to export data with more granular control","twitter_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","meta_title":"Introducing Export V2: How to export data with more granular control","meta_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6406883577b361003d3619d5","uuid":"4ab62fd8-b9da-474e-a833-f24758c230db","title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","slug":"using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data","html":"\u003cp\u003eOne of the biggest challenges that ML teams face is how difficult it is to select the right data to improve their ML models. From working with hundreds of teams, we’ve seen that ML teams possess a vast amount of unlabeled data, but lack a structured process for effectively finding and prioritizing \u003cem\u003especific data\u003c/em\u003e that can dramatically improve model performance. \u003c/p\u003e\u003cp\u003eThis manifests itself in the form of trying to find specific examples of an edge case where your model is struggling, or in the case of wanting to surface all occurrences of a rare data point that needs to be labeled in priority. In these cases, what is the best way for your team to efficiently surface this high-impact data?\u003c/p\u003e\u003ch2 id=\"what-will-you-learn-in-this-guide\"\u003eWhat will you learn in this guide? \u003c/h2\u003e\u003cp\u003eIn this guide, we'll show you how you can use a foundation model, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data. This technique will help your team quickly enrich your data with the latest advances in off-the-shelf models and embeddings.\u003c/p\u003e\u003cp\u003eBy the end of this guide, you’ll know how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGenerate custom embeddings with Hugging Face using a single line of code and upload your data to Quantumworks Lab in order to better explore and visualize your data.\u003c/li\u003e\u003cli\u003eBetter understand the distribution of your data and quickly find similar high-impact data.\u003c/li\u003e\u003cli\u003eUse Quantumworks Lab as a native similarity search engine, where you can leverage both off-the-shelf embeddings computed by Quantumworks Lab (for image, text, and documents) and upload your own custom embeddings to quickly find all instances of similar data.\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"what-are-embeddings\"\u003eWhat are embeddings? \u003c/h2\u003e\u003cp\u003eIn machine learning, an embedding, or feature vector, is an array of numbers assigned to an asset by a neural net. Assets that have similar content will also have similar embeddings. \u003c/p\u003e\u003cp\u003eFor example, in a dataset comprising images of apples and oranges, an appropriate embedding used for image similarity will show that all the vectors corresponding to apples have similar values. The vectors for all images of oranges will also be grouped together. \u003c/p\u003e\u003cp\u003eIn other words, the neural network acts as a feature extractor: it extracts an embedding vector that contains rich information about the data.\u003c/p\u003e\u003ch3 id=\"off-the-shelf-embeddings-vs-custom-embeddings\"\u003eOff-the-shelf embeddings vs custom embeddings\u003c/h3\u003e\u003cp\u003eWhen you connect your data to Quantumworks Lab, we automatically compute \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#supported-embeddings\"\u003eoff-the-shelf\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003eembeddings on your data – this includes CLIP embeddings for images and PDFs and All-mpnet-base-v2 embeddings for text. These off-the-shelf embeddings are a useful starting point for you to explore your data and conduct similarity searches. \u003c/p\u003e\u003cp\u003eHowever, in some cases where your data has unique attributes, you may want to use your own \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#how-to-upload-custom-embeddings\"\u003ecustom embeddings\u003c/a\u003e to power your data selection. Quantumworks Lab allows you to upload up to 100 custom embeddings in addition to the off-the-shelf embeddings that are automatically computed. \u003c/p\u003e\u003cp\u003eYou can easily compare the results of these custom and provided off-the-shelf embeddings in Quantumworks Lab to discover the best embeddings to use for data selection.\u003c/p\u003e\u003ch2 id=\"how-to-upload-custom-embeddings\"\u003eHow to upload custom embeddings\u003c/h2\u003e\u003cp\u003eFirst, connect your data with Labelbox. You can integrate your cloud storage bucket with Quantumworks Lab via IAM delegated access:\u003c/p\u003e\u003cp\u003e\u003cem\u003eHow to set up a delegated access integration with Quantumworks Lab\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-amazons3-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eAmazon S3\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-gcp-storage-labelbox/?ref=labelbox-guides.ghost.io\"\u003eGCP Storage\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-azure-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eMicrosoft Azure Blob Storage\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve successfully uploaded your data, Quantumworks Lab will automatically compute off-the-shelf embeddings on your data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1013\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can then compute and upload custom embeddings from Hugging Face on your data:\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eGoogle Colab notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003cem\u003eFollow along in this \u003c/em\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eColab notebook \u003c/em\u003e\u003c/a\u003e\u003cem\u003ewith examples shown using ResNet-50 embeddings from Hugging Face.\u003c/em\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003eImport Quantumworks Lab into your notebook\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for Quantumworks Lab\n!pip3 install -q Quantumworks Lab[data]\nimport Quantumworks Lab as lb\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e2. Import the \u003ca href=\"https://github.com/Quantumworks Lab/advlib/tree/main/pylib/advlib?ref=labelbox-guides.ghost.io\"\u003eADVLib\u003c/a\u003e. This is a library built by Quantumworks Lab for you to upload custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for custom embeddings in Quantumworks Lab\n!pip3 install -q 'git+https://github.com/Quantumworks Lab/advlib.git'\n#ndjson\n!pip3 install -q ndjson\nimport ndjson\nimport time\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e3. Select the data rows (images or text) in Quantumworks Lab on which you want to add custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# get images from a Quantumworks Lab dataset\ndataset = client.get_dataset(\"clemr01l42uil07y36qkq7ygn\")\ndrs = list(dataset.export_data_rows(timeout_seconds=9999))\ndata_row_ids = [dr.uid for dr in drs]\ndata_row_urls = [dr.row_data for dr in drs]\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e4. Use Hugging Face to generate your custom embeddings by loading a specific neural network (e.g. Resnet50).\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# import HuggingFace\n!pip3 install -q transformers\n!pip3 install -q timm\n\n# load a neural network from HuggingFace \nimport transformers\ntransformers.logging.set_verbosity(50)\nimport torch\nimport torch.nn.functional as F\nimport PIL, requests\nfrom tqdm import tqdm\n\n# get ResNet-50\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nmodel = transformers.ResNetModel.from_pretrained(\"microsoft/resnet-50\")\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cbr\u003e5. Generate custom embeddings by iterating over your image or text data. \u003c/p\u003e\u003cp\u003e\u003cem\u003eNote: \u003c/em\u003eThis should take approximately ~2 minutes for 512 images. For the similarity search function to work in Quantumworks Lab, you must upload at least 1,000 embeddings. \u003c/p\u003e\u003cul\u003e\u003cli\u003eRetrieve your images/text and run model inference \u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# process images\nimg_hf = image_processor(imgs, return_tensors=\"pt\")\n\n# generate resnet embeddings, thanks to inference\nwith torch.no_grad():\n\tlast_layer = model(**img_hf, output_hidden_states=True).last_hidden_state\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\u003cli\u003eRemember to do global pooling on the last layer of your embedding to reduce dimensionality\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e6. Create the payload to upload custom embeddings to Quantumworks Lab in the form of an NDJSON file.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# create the payload\npayload = []\nfor (dr_id,resnet_embedding) in zip(dr_ids, resnet_embeddings):\n\tpayload.append({\"id\": dr_id, \"vector\": resnet_embedding})\n\n# write to NDJson file\nwith open('payload.ndjson', 'w') as f:\n\tndjson.dump(payload, f)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e7. Pick an existing custom embedding or create a custom embedding.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# max pool to reduce dimensionality\nresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\n\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e8. Upload your payload of custom embeddings into Labelbox.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!advtool embeddings import \u0026lt;EMB ID\u0026gt; ./payload.ndjson\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e9. Use Quantumworks Lab Catalog UI to start conducting similarity searches.\u003c/p\u003e\u003ch2 id=\"how-to-quickly-find-instances-of-similar-data\"\u003eHow to quickly find instances of similar data\u003c/h2\u003e\u003cp\u003eOnce you have uploaded your custom embeddings to Quantumworks Lab, you can focus on curating data in Catalog that will dramatically improve your model’s performance.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eIdentify an edge case or rare example image/text you want to use to find similar data.\u003c/strong\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThis can include examples of data on which your model might be struggling. For example, let’s say the model is incorrectly classifying images with sparse patches of grass as having been affected by a wildfire. \u003c/p\u003e\u003cp\u003eIn the example below, the model appears to struggle on recognizing images with ‘no wildfire'\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1530\" height=\"736\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1530w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e2. Surface all instances of similar data.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1775\" height=\"959\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-16-47--1--1.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-16-47--1--1.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-16-47--1--1.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif 1775w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can run \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io\"\u003esimilarity searches\u003c/a\u003e to find all instances of similar data. A similarity search will automatically surface all similar data rows – you can select multiple data rows as anchors to continue to refine your similarity search. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Combine a similarity search with other search filters.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo filter the dataset even further, you can combine a similarity search with other \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003esearch filters\u003c/a\u003e. This includes filtering on metadata, media attribute, annotation, and more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1516\" height=\"824\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1516w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e4. Compare similarity search results.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1772\" height=\"964\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-23-53--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-23-53--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-23-53--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif 1772w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can compare the results of the similarity search on different embeddings (across off-the-shelf and custom embeddings). This gives you an understanding of which embeddings are most effective towards providing your desired results. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e5. Add all instances of similar data to a labeling project or save it as a slice.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve found additional examples of similar data rows on which your model is struggling, you can queue them to your labeling project in priority or save the filters as a slice. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1774\" height=\"954\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-29-38--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-29-38--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-29-38--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif 1774w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cbr\u003eBy saving your similarity search as a slice, any new incoming data that matches the search criteria will automatically show up in the slice. This enables automatic data curation.\u003c/p\u003e\u003cp\u003eLearn more about other key ML workflows that you can perform using similarity search \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003ein this guide\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eLeveraging embeddings as a powerful similarity search technique can help you find specific data points within an ocean of data. With a similarity search, you can easily query and curate specific data that will dramatically improve your model performance. If you’re interested in learning more, please check out the additional resources below.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdditional resources:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-kickstart-and-scale-your-data-labeling-efforts/?ref=labelbox-guides.ghost.io\"\u003eHow to kickstart and scale your data labeling efforts\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eHow to filter and sort your data\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003eHow to find similar data in one click\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"6406883577b361003d3619d5","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3012--4-.png","featured":false,"visibility":"public","created_at":"2023-03-07T00:41:25.000+00:00","updated_at":"2024-02-02T18:28:44.000+00:00","published_at":"2023-03-08T19:31:53.000+00:00","custom_excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-imapctful-data","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa513375d13000123d7ea","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/","excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","reading_time":6,"access":true,"comments":false,"og_image":null,"og_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","og_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","twitter_image":null,"twitter_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","twitter_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","meta_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","meta_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}],"total":19,"allPosts":[{"id":"66183ccc8d5c4a00014061cc","uuid":"2afa1d4e-85b9-48d3-ae01-81c57db2916b","title":"How to use AI to improve website search relevance","slug":"how-to-improve-search-relevance","html":"\u003cp\u003eWith the latest advances in foundation models, organizations can now enhance search relevance for websites by better matching between user intent with product listings. While companies now have access to a wealth of search queries, sifting through all of these search results can be incredibly time-consuming and resource-intensive. By leveraging AI, teams can now analyze search queries and feedback at scale, to gain insights into common topics or customer sentiment. This allows businesses to identify common themes and pinpoint areas of improvement to enhance\u0026nbsp;their overall website experience to maximize for key metrics such as user retention, conversion and revenue.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for search relevance. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eImproving search relevance requires a vast amount of data in the form of search queries and accurate product descriptions. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDynamic review landscape: \u003c/strong\u003eThe changing nature and format of customer review data from multiple sources (e.g webpages, apps, social media, etc.) poses the challenge for businesses to account for continuous data updates and re-training needs.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers businesses to transform their website search relevance for product descriptions and listings. Instead of relying on time-consuming manual reviews, companies can leverage Quantumworks Lab’s assisted data enrichment and flexible training frameworks to quickly build AI systems that uncover actionable insights from customer searches. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-full\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1746\" height=\"952\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-4.22.09-PM.png 1746w\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to dramatically improve search relevance for any website or app. Specifically, this guide will walk through how you can explore and better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-use-ai-to-improve-search-relevance-for-your-website\"\u003eSee it in action: How to use AI to improve search relevance for your website\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Create a model run and evaluate model performance\u003c/p\u003e\u003cp\u003eYou can follow along with both parts of the tutorial below in either: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1-kTALPqchHXGogUdRVnya7GklKHrsWVL?ref=labelbox-guides.ghost.io#scrollTo=Vw_nNPl8baNJ\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1-kTALPqchHXGogUdRVnya7GklKHrsWVL?ref=labelbox-guides.ghost.io#scrollTo=Vw_nNPl8baNJ\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAs customer queries and product descriptions across channels proliferate, brands want to learn from customer feedback to build the most user-friendly experience on their website or app. For this use case, we’ll be working with a dataset of e-commerce website queries – with the goal of analyzing the queries to demonstrate how a company could gain insight into how their customers search for products and how to optimize for relevance.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/vpl1wf0vui\" title=\"Search relevance 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eThe first step will be to gather data:\u003c/p\u003e\u003cp\u003eFor the purpose of this tutorial, we’ve provided a sample open-source \u003ca href=\"https://www.kaggle.com/datasets/jiashenliu/515k-hotel-reviews-data-in-europe?ref=labelbox-guides.ghost.io\"\u003eKaggle dataset\u003c/a\u003e that can be downloaded.  \u003c/p\u003e\u003cp\u003ePlease \u003ca href=\"https://drive.google.com/file/d/1hh2MYzol6-4PSsqX7mbX2YSLLGA4jAYZ/view?usp=drivesdk\u0026ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003edownload the dataset\u003c/a\u003e and store it in an appropriate location on your environment. You'll also need to update the read/write file paths throughout the notebook to reflect relevant locations on your environment. You'll also need to update all references to API keys, and Quantumworks Lab ontology, project, and model run IDs\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf you wish to follow along and work with your own data, you can import your text data as a CSV. \u003c/li\u003e\u003cli\u003eIf your text snippets sit as individual files in cloud storage, you can reference the URL of these files through our \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003eIAM delegated access integration\u003c/a\u003e.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve uploaded your dataset, you should see your text data rendered in Quantumworks Lab Catalog. You can browse through the dataset and visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data-by-clustering\"\u003eSearch and curate data by clustering\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1538\" height=\"708\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-29-at-9.12.17-AM.png 1538w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUse Smart select to cluster data and focus your model improvement on specific data rows\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExplore topics of interest\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWith your data in Quantumworks Lab, you can begin to leverage Catalog to uncover interesting topics to get a sense of what customers are searching for. \u003c/p\u003e\u003cul\u003e\u003cli\u003eVisualize your data –\u0026nbsp; you can click through individual data rows to get a sense for which queries are the most popular.\u003c/li\u003e\u003cli\u003eDrill into specific topics of interest\u003cstrong\u003e \u003c/strong\u003e– leverage natural language search, for example searching “beds, mirrors, etc,” to bring up all related queries related to that topic. You can adjust the confidence threshold of your searches accordingly which can be helpful in gauging the volume of data related to the topic of interest.\u0026nbsp;\u003c/li\u003e\u003cli\u003eEasily find all instances of similar examples to data of interest.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-2-create-an-initial-model-run-of-search-relevance-assessments\"\u003ePart 2: Create an initial model run of search relevance assessments \u003c/h2\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/t3er59wcfk\" title=\"Search relevance 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eAfter we’ve explored our data, we now have a better understanding of what topics exist in our dataset and can proceed to using Quantumworks Lab's Foundry product to model run an initial model run to accelerate search relevance assessments.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFirst, you'll need to set up your ontology for search relevance assessment based on your project's requirements.\u003c/li\u003e\u003cli\u003eAfterwards, you can define the criteria for rating the relevance of search results to each type of query.\u003c/li\u003e\u003cli\u003eNext, you can communicate the business definition of relevance to the models directly into the prompt. You can use Foundry to add context to the prompt, allowing it to rank results as if it were part of your respective business. In this example, we'll include the prompts for what \"good relevance\", \"excellent relevance\", etc and help the model predict what would fit under this criteria. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAs an illustrative example, you can set up \"excellent relevance\" as a result that perfectly matches the search query, including all specific attributes (category, material, color, purpose, etc). This indicates that the term is exactly what the user is searching for. For the query, \"kitchen blender stainless steel\", a result for \"stainless steel countertop blender\" is highly relevant, matching the user's intended category.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"673\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.04.26-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eGenerate an initial preview to assess how well the adjusted prompt performs and you can save the adjusted prompt as an app, including data type (text), ontology, and the original prompt. This allows for easy re-use and the ability to build upon the saved app for future assessments of search relevance criteria. \u003c/p\u003e\u003cp\u003eAfter this has been set up, you can now generate the next preview to ensure quality before submitting the model run for assessments.\u003c/p\u003e\u003ch3 id=\"view-search-relevance-assessments-results\"\u003eView search relevance assessments results \u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/gq8nnv2ykw\" title=\"Search relevance 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eOnce your model inferencing job has been completed, you can then navigate to the model tab and locate a variety of foundation models (e.g., Claude 3 will be used in this tutorial) to view the completed model run with your rankings.\u003c/li\u003e\u003cli\u003eOptionally, you can add an explanation classification or review the results of the ranking, which includes all 560 items/data rows.\u003c/li\u003e\u003cli\u003eBy adding the results to your project, you can next perform further analytics such as analyzing the distributions of predictions from the Metrics view.\u003c/li\u003e\u003cli\u003eNext, select all items and you can send them to Annotate, and choose \"search relevance assessment\", where you'll then be able to have humans review as an additional quality check.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"further-analyze-and-optimize-your-search-relevance-assessments-results\"\u003eFurther analyze and optimize your search relevance assessments results \u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/kw7in8bosa\" title=\"Search relevance 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eThe last part of the walkthrough is to analyze your distribution of relevance categories within your project, noting varying levels of relevance and to review the query class for all 560 data rows to identify trends in relevance. You can do this by using automated approaches to understand query types and relevance patterns, as we show in the video above.\u003c/li\u003e\u003cli\u003eBy filtering your dataset by the search relevance assessment project, you can navigate to the Analytics view to identify trends and examples of excellent relevance and poor relevance within specific query classes (as shown below).\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"883\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.14.34-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample analytics distribution showing excellent relevance on terms like kids wall decor, sectionals and area rugs.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"838\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/04/Screenshot-2024-04-11-at-1.15.17-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample analytics distribution showing poor relevance for beds, furniture cushions, mirrors\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eAs this time, you can consider adjusting prompts to accurately reflect relevance criteria, or use metadata fields, such as query class, to further analyze relevance.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo further evaluate and enrich the data, teams can also explore incorporating human supervision in the labeling process, with a hybrid or combination approaches: fully automated, half human in the loop, half automated, or all human-in-the-loop.\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, you can improve your data further in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://www.alignerr.com/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eAlignerr\u003c/a\u003e: Leverage our global network of\u0026nbsp;specialized labelers for a variety of tasks.\u0026nbsp;This community of subject matter experts from several disciplines align AI models by creating high-quality data in their field of expertise. The community spans nearly every major discipline of sciences, industries and languages, worldwide.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eBy tapping into the most recent developments in foundation models, businesses can transform the effectiveness of website searches by refining the alignment between user intent and product offerings. Given the abundance of search queries that a prospective customer may use, the process of sorting through them manually is labor-intensive and time-consuming. \u003c/p\u003e\u003cp\u003eBy harnessing the power of AI, organizations can efficiently examine search queries and feedback on a large scale, uncovering recurring themes and gauging customer sentiment. \u003c/p\u003e\u003cp\u003eThis enables enterprises to detect prevalent trends and target areas for enhancement, allowing them to optimizing the overall website experience to drive key metrics like user retention, conversion rates, and revenue. Remember to optimize the \u003ca href=\"https://www.web4business.com.au/portfolio-item/the-most-important-24-pages-to-include-on-website/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ewebsite content\u003c/a\u003e as well to ensure it's meeting your end user's goals. Give the walkthrough a try and we also recommend checking out our other solution accelerators such as \u003ca href=\"https://labelbox.com/guides/how-to-build-a-powerful-product-recommendation-system-for-retail/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003epersonalized experiences\u003c/a\u003e for retail to improve customer experiences.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful search relevance websites. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"66183ccc8d5c4a00014061cc","feature_image":"https://labelbox-guides.ghost.io/content/images/2024/04/thumbnail--6-.png","featured":false,"visibility":"public","created_at":"2024-04-11T19:41:00.000+00:00","updated_at":"2024-09-12T23:45:53.000+00:00","published_at":"2024-04-12T17:02:16.000+00:00","custom_excerpt":"Learn how you can dramatically improve search relevance for any website or app by using AI and foundation models to better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-improve-search-relevance/","excerpt":"Learn how you can dramatically improve search relevance for any website or app by using AI and foundation models to better understand search query topics and classify product descriptions/listings to make more data-driven business decisions around the customer experience.","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"65dd3fe1255738000153641c","uuid":"17cc9bd7-9e84-499a-850d-e6ead9b48f85","title":"How to sync your cloud buckets with Quantumworks Lab","slug":"how-to-sync-your-cloud-buckets-with-labelbox","html":"\u003cp\u003eLabelbox recently introduced the ability to synchronize your cloud buckets from Amazon, Google and Microsoft Azure into Quantumworks Lab Catalog. This improvement greatly simplifies the existing integration by eliminating the need to customize JSON or configure Python scripts.\u003c/p\u003e\u003cp\u003eLabelbox supports native integrations with cloud storage from leading providers including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAmazon S3\u003c/li\u003e\u003cli\u003eGoogle Cloud Storage\u003c/li\u003e\u003cli\u003eMicrosoft Azure Blob Storage\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eCloud architecture plays a critical role in ensuring scalability, flexibility, and security for your data management – and it’s always good to\u0026nbsp;\u003ca href=\"https://www.ssw.com.au/rules/cloud-architect/?ref=labelbox-guides.ghost.io\"\u003ehave a cloud expert on your team\u003c/a\u003e.\u0026nbsp;If you are familiar with how cloud storage works, you can\u0026nbsp;\u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1%3F\u0026landingPageAnonymousId=%223bed3496-d471-4095-ba10-c34e51bd36cd%22\u0026ref=labelbox-guides.ghost.io\"\u003eintegrate your cloud bucket\u003c/a\u003e\u0026nbsp;when adding a dataset to Labelbox. This guide is intended to show you how to set up and use cloud storage integration with Quantumworks Lab Catalog.\u003c/p\u003e\u003ch3 id=\"why-use-cloud-storage-integrations\"\u003eWhy use cloud storage integrations?\u003c/h3\u003e\u003cp\u003eCloud buckets are a simple and efficient way to manage large volumes of unstructured data, especially for computer vision use cases involving working documents, images and video. The Quantumworks Lab cloud storage integration can automatically scan any set of folders in your cloud bucket and synchronize the following data types into the Quantumworks Lab Catalog:\u003c/p\u003e\u003cul\u003e\u003cli\u003eImage\u003c/li\u003e\u003cli\u003eVideo\u003c/li\u003e\u003cli\u003eText\u003c/li\u003e\u003cli\u003eAudio\u003c/li\u003e\u003cli\u003eHTML\u003c/li\u003e\u003cli\u003eTiled imagery (COG, NITF, GeoTIFF)\u003c/li\u003e\u003cli\u003eDocuments\u003c/li\u003e\u003cli\u003eChat (Conversations)\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"how-to-sync-a-dataset-with-your-cloud-bucket\"\u003eHow to sync a dataset with your cloud bucket?\u003c/h3\u003e\u003cp\u003eAfter completing the one-time setup of delegated access to your object store (see \u003ca href=\"https://docs.google.com/document/d/17BG09nOqil7rQ6oub493o-bYrUxNSghEbMCvfxX6-MI/edit?ref=labelbox-guides.ghost.io#heading=h.8iysj0uw5p9s\"\u003e\u003cu\u003esection below\u003c/u\u003e\u003c/a\u003e), you can use the Quantumworks Lab UI to configure the synchronization of any folder to a dataset in the Quantumworks Lab Catalog with just a few clicks.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/tz0beimgxb?wtime=56s\" title=\"Quantumworks Lab Cloud Storage Integration Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"552\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eOnce configured, you can sync any connected dataset with your cloud storage with a single click.\u003c/p\u003e\u003ch3 id=\"how-to-set-up-delegated-access-to-your-cloud-storage-provider\"\u003eHow to set up delegated access to your cloud storage provider\u003c/h3\u003e\u003cp\u003eThe one prerequisite for using the Quantumworks Lab Cloud Storage integration is \u003ca href=\"https://docs.labelbox.com/reference/cloud-storage-iam-integration?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003esetting up IAM delegated access\u003c/u\u003e\u003c/a\u003e. This is a one-time setup process for each object store allowing Quantumworks Lab to access assets stored in your cloud buckets that you would like to add to Catalog or label using Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIAM delegated access works similarly whether you are using Amazon S3, Microsoft Azure or Google Cloud Storage (GCS). For example, when you use IAM delegated access to add your unlabeled data to Quantumworks Lab, you can keep your assets in Amazon S3 and grant Quantumworks Lab read-only access to your AWS cloud buckets.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-us.googleusercontent.com/he2QAvnCZbh2UwVpU_dLEi7X8jriKJPCwsMGwiStTew6dkbQT4FasCpwngZ1Y0gjo7R1DOxn5H6Cf4GzcLmuqpiVcTEORt3rMBVbDgVMv9bh9g4RyuePgnSIBYU40VcXHlE0OZCRK6gmwmXzxUkg02w\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"645\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eDelegated Access setup in AWS (similar in GCP)\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIAM delegated access is highly flexible and allows you to control access at the granularity that you desire. \u003c/p\u003e\u003cul\u003e\u003cli\u003eYou can grant Quantumworks Lab access to all of your buckets, a single bucket, or even a particular path within a bucket. \u003c/li\u003e\u003cli\u003eYou can even set up different integrations within Quantumworks Lab for different datasets or projects. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIAM delegated access allows you to use private cloud-hosted buckets with Quantumworks Lab, which helps to ensure that your assets are kept safe.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ghtx8fcwka\" title=\"Quantumworks Lab IAM Setup for Cloud Storage integration Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"552\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eRefer to the documentation for additional information on \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003esetting up IAM delegated access in Quantumworks Lab\u003c/u\u003e\u003c/a\u003e, and \u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1\u0026ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eadd data to Quantumworks Lab\u003c/u\u003e\u003c/a\u003e from your cloud bucket with ease.\u003c/p\u003e\u003ch3 id=\"summary\"\u003eSummary\u003c/h3\u003e\u003cp\u003eStoring data in cloud buckets is a simple and effective way to manage large volumes of unstructured data – especially images, video and documents. Connecting and synchronizing your cloud storage with datasets in Quantumworks Lab has never been easier.\u003c/p\u003e\u003cp\u003eIf you’re already using cloud storage, \u003ca href=\"https://app.labelbox.com/home?cloudBucketDrawerSelectionOpen=1\u0026cloudBucketIntegrationDrawerOpen=1\u0026ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eadd data to Quantumworks Lab\u003c/u\u003e\u003c/a\u003e today. \u003c/p\u003e","comment_id":"65dd3fe1255738000153641c","feature_image":"https://labelbox-guides.ghost.io/content/images/2024/02/Frame-3410--2-.png","featured":false,"visibility":"public","created_at":"2024-02-27T01:50:25.000+00:00","updated_at":"2024-05-28T17:03:00.000+00:00","published_at":"2024-02-28T17:21:47.000+00:00","custom_excerpt":"Sync your unstructured data automatically and skip glue scripts with native support for S3 (AWS), GCS (GCP) and Blob Storage (Azure).  ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-sync-your-cloud-buckets-with-labelbox/","excerpt":"Sync your unstructured data automatically and skip glue scripts with native support for S3 (AWS), GCS (GCP) and Blob Storage (Azure).  ","reading_time":2,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"656e6d5472e557000141cf9d","uuid":"44473dbc-7bfa-43a0-a5d6-7e061877d134","title":"How to automatically ingest data from Databricks into Quantumworks Lab","slug":"how-to-automatically-ingest-data-from-databricks-into-labelbox","html":"\u003cp\u003eMoving data seamlessly through your MLOps pipeline is essential to building successful AI products. In this guide, learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/cjp13xg9no\" title=\"Databricks Ingestion Pipeline Demo Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"506\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1.\u0026nbsp; Navigate to the \u003ca href=\"https://huggingface.co/spaces/Quantumworks Lab/databricks_upload?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003epipeline creator webpage\u003c/u\u003e\u003c/a\u003e and enter your Databricks domain. You can find this by going to your Databricks environment. The domain will be in the URL, so you can copy and paste it into the pipeline creator.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_1_Domain.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_1_Domain.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_1_Domain.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_1_Domain.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_1_Domain.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eYour Databricks domain is in the URL whenever you access your Databricks environment.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e2. Now select the cloud environment that your Databricks workspace runs in. This information is usually also in the Databricks domain that you just copy/pasted.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3. If you don’t already have a Databricks API, create one by going to your Databricks domain. Go to the user tab in the top right, then go to \u003cstrong\u003eUser settings \u0026gt; Developer \u0026gt; Access Tokens\u003c/strong\u003e, and create an access token. Paste your Databricks API key into the pipeline creator.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_2_AccessToken.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_2_AccessToken.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_2_AccessToken.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_2_AccessToken.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_2_AccessToken.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eYou can create an access token for the Databricks API by going to the user tab, then to User Settings \u0026gt; Developer \u0026gt; Access tokens.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e4. Next, you’ll need your Quantumworks Lab API key. If you don’t already have one, you can create one from within your Quantumworks Lab environment by going to \u003cstrong\u003eWorkspace Settings \u0026gt; API \u0026gt; Create a new key\u003c/strong\u003e. Paste this key into the creator pipeline. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_3_LBAPIKey.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1734\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_3_LBAPIKey.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_3_LBAPIKey.png 1734w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eCreate an API key in Quantumworks Lab from the Workspace Settings section of your environment.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e5. Next, the pipeline creator will give you the option of making a new dataset or appending an existing one. Be sure to give the dataset a relevant name, as it will appear under than name within Quantumworks Lab Catalog once the dataset has been created and the data ingested from Databricks. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_4_NameDataset.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_4_NameDataset.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_4_NameDataset.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_4_NameDataset.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_4_NameDataset.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eName your dataset within the pipeline creator webpage.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e6. Select a cluster from within your Databricks environment on the pipeline creator page.\u0026nbsp;\u003c/p\u003e\u003cp\u003e7. Once the cluster is ready, you’ll see the option to select a run frequency, or the cadence with which the workflow is going to execute. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_5_RunFrequency.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"713\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_5_RunFrequency.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_5_RunFrequency.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_5_RunFrequency.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eChoose how often you want this workflow to run.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e8. Next, choose the relevant table and database in Databricks from which you want to pull data. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_6_SelectTable.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"713\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_6_SelectTable.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_6_SelectTable.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_6_SelectTable.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eChoose the database and table you want to pull data from.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e9. The page will show you a sample of data rows within the selected table. The row data column signifies the URL by which you want to pool the data from. This can either be a public URL or objects hosted within your cloud storage.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_7_RowData.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_7_RowData.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_7_RowData.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_7_RowData.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_7_RowData.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA sample of the data rows in the selected dataset will appear on the pipeline creator page.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e10. Choose the data row column pointing to the object that you want to render. You also have an additional option of choosing the global key, which will specify the unique identifier assigned to each data row once they’re ingested into Labelbox.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"753\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_SelectRowDataGlobalKey.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSelect your row data column and if needed, select global key.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e11. Click on \u003cstrong\u003eDeploy pipeline. \u003c/strong\u003eAfter executing for a few seconds, you’ll see a confirmation that your pipeline has been deployed. Now you can navigate to your Databricks environment, go to the workflows tab on the left, and see the new upload workflow that you’ve just created. Once the workflow has run, you’ll be able to see the ingested data in Quantumworks Lab Catalog.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1738\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/12/DBIngestionPipeline_8_NewUploadWorkflow.png 1738w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSee the new upload workflow within your Databricks environment by navigating to the Workflows tab.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYour new workflow will now ingest the specified data into Quantumworks Lab at the cadence you chose. \u003ca href=\"https://labelbox.com/blog/seamlessly-integrate-databricks-data-pipelines-with-labelbox/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eRead this blog post\u003c/u\u003e\u003c/a\u003e to learn more about how you can integrate Databricks and Quantumworks Lab into a seamless data engine for AI.\u0026nbsp;\u003c/p\u003e","comment_id":"656e6d5472e557000141cf9d","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/12/DatabricksLabelboxIngestionPipeline_Guide_Header.png","featured":false,"visibility":"public","created_at":"2023-12-05T00:22:44.000+00:00","updated_at":"2023-12-05T17:38:22.000+00:00","published_at":"2023-12-05T17:38:22.000+00:00","custom_excerpt":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-automatically-ingest-data-from-databricks-into-labelbox/","excerpt":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":"How to automatically ingest data from Databricks into Quantumworks Lab","og_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","twitter_image":null,"twitter_title":"How to automatically ingest data from Databricks into Quantumworks Lab","twitter_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","meta_title":"How to automatically ingest data from Databricks into Quantumworks Lab","meta_description":"Learn how you can leverage Quantumworks Lab’s Databricks pipeline creator to automatically ingest data from your Databricks domain into Quantumworks Lab for data exploration, curation, labeling, and much more.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"654bbab4016f5100016579c3","uuid":"6c33e4d1-fcaa-44de-b994-0fe65fce3dcc","title":"How to analyze customer reviews and improve customer care with NLP","slug":"how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp","html":"\u003cp\u003eCustomer reviews have become a critical tool for businesses looking to improve their products, services, and customer satisfaction. In today’s digital world, review sites like Yelp and social media make it easier than ever for customers to share their experiences with the world. Customer care can range in the services and support that businesses provide to their customers before, during, and after purchase. Great customer care can create positive brand experiences that lead to greater loyalty and customer satisfaction. In the ever-evolving world of retail, it also helps keep your business competitive and at the forefront of your customer’s sentiment and desires.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWhile companies now have access to a wealth of customer feedback data, sifting through all of these reviews can be incredibly time-consuming and manual. By leveraging AI, teams can analyze \u003ca href=\"https://birdeye.com/blog/review-management/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ecustomer reviews and feedback\u003c/a\u003e at scale, to gain insights into common review topics or customer sentiment. This allows businesses to identify common themes and pinpoint areas of improvement to enhance\u0026nbsp; the customer experience.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for customer care. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eImproving customer care requires a vast amount of data in the form of customer reviews. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDynamic review landscape: \u003c/strong\u003eThe changing nature and format of customer review data from multiple sources (e.g webpages, apps, social media, etc.) poses the challenge for businesses to account for continuous data updates and re-training needs.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers businesses to transform their customer care through advanced natural language processing. Instead of relying on time-consuming manual reviews, companies can leverage Quantumworks Lab’s assisted data enrichment and flexible training frameworks to quickly build AI systems that uncover actionable insights from customer reviews. Tackle unique customer care challenges with AI-driven insights to create more thoughtful and strategic customer interactions. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1444\" height=\"784\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.35.34-AM.png 1444w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build an NLP model to improve customer care. Specifically, this guide will walk through how you can explore and better understand review topics and classify review sentiment to make more data-driven business decisions around customer care initiatives.\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-accelerate-and-train-an-nlp-model-to-improve-customer-care\"\u003eSee it in action: How to accelerate and train an NLP model to improve customer care\u0026nbsp;\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Create a model run and evaluate model performance\u003c/p\u003e\u003cp\u003eYou can follow along with both parts of the tutorial below in either: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e or \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAs customer reviews and feedback across channels proliferate, brands want to learn from customer feedback to foster positive experiences. For this use case, we’ll be working with a dataset of customer hotel reviews – with the goal of analyzing the reviews to demonstrate how a hospitality company could gain insight into how their customers feel about the quality of service they receive.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/q4dqjyg9xf\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"498\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eThe first step will be to gather data:\u003c/p\u003e\u003cp\u003eFor the purpose of this tutorial, we’ve provided a sample open-source \u003ca href=\"https://www.kaggle.com/datasets/jiashenliu/515k-hotel-reviews-data-in-europe?ref=labelbox-guides.ghost.io\"\u003eKaggle dataset\u003c/a\u003e that can be downloaded.  \u003c/p\u003e\u003cp\u003ePlease \u003ca href=\"https://drive.google.com/file/d/1hh2MYzol6-4PSsqX7mbX2YSLLGA4jAYZ/view?usp=drivesdk\u0026ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003edownload the dataset\u003c/a\u003e and store it in an appropriate location on your environment. You'll also need to update the read/write file paths throughout the notebook to reflect relevant locations on your environment. You'll also need to update all references to API keys, and Quantumworks Lab ontology, project, and model run IDs\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf you wish to follow along and work with your own data, you can import your text data as a CSV. \u003c/li\u003e\u003cli\u003eIf your text snippets sit as individual files in cloud storage, you can reference the URL of these files through our \u003ca href=\"https://docs.labelbox.com/docs/iam-delegated-access?ref=labelbox-guides.ghost.io\"\u003eIAM delegated access integration\u003c/a\u003e.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve uploaded your dataset, you should see your text data rendered in Quantumworks Lab Catalog. You can browse through the dataset and visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data\"\u003eSearch and curate data\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/xn3sj0uc8j\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExplore topics of interest\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWith your data in Quantumworks Lab, you can begin to leverage Catalog to uncover interesting topics to get a sense of what customers are talking about from hotel reviews.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eVisualize your data –\u0026nbsp; you can click through individual data rows to get a sense for what customers are writing reviews on\u0026nbsp;\u003c/li\u003e\u003cli\u003eDrill into specific topics of interest\u003cstrong\u003e \u003c/strong\u003e– leverage a natural language search, for example searching “interior design,” to bring up all related reviews related to interior design. You can adjust the confidence threshold of your searches accordingly (this can be helpful in gauging the volume of data related to the topic of interest)\u0026nbsp;\u003c/li\u003e\u003cli\u003eBegin to surface subtopics or trends within your initial search – for example is the interior design review related to the style of design, attention to detail, or the type of environment created from the interior design\u003c/li\u003e\u003cli\u003eEasily find all instances of similar examples to data of interest\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate and save data slices\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIf you have a search query that you’re interested in saving or reusing in the future, you can save it as \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003ea slice\u003c/a\u003e. You can construct a slice by using one or more filters to curate a collection of data rows. Users often combine filters to surface high-impact data and then save the results as a slice.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this example, we’ve surfaced reviews on the topic of breakfast that all talk about the value and price of the hotel’s breakfast. We can save this as a slice for future reference (“Breakfast_value”) and as we ingest more data that matches the slice’s criteria, they will automatically get filed into the slice.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-an-ontology\"\u003eCreate an ontology\u0026nbsp;\u003c/h3\u003e\u003cp\u003eAfter we’ve explored our data, we now have a better understanding of what topics exist in our dataset and can create our ontology. \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eOntologies\u003c/a\u003e can be reused across different projects and they are required for data labeling, model training, and evaluation.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/gdczmynqjt\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo create a new ontology:\u003c/p\u003e\u003cp\u003e1) Navigate to the ‘Schema’ tab\u003c/p\u003e\u003cp\u003e2) Hit ‘Create new ontology’\u003c/p\u003e\u003cp\u003e3) Select the media type that you wish to work with – for this use case ‘Text’\u003c/p\u003e\u003cp\u003e4) Give your ontology a name\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Add objects and classifications based on you use case\u003c/p\u003e\u003cp\u003e6) Objects are named entities\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli\u003ePerson’s name\u0026nbsp;\u003c/li\u003e\u003cli\u003eLocation\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003e7) Classifications\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli\u003eReview sentiment such as positive or negative (radio)\u0026nbsp;\u003c/li\u003e\u003cli\u003eReview topics such as breakfast, dinner, location, staff, interior design (checklist)\u0026nbsp;\u003c/li\u003e\u003cli\u003eAdd sub-classifications as desired\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003e8) Save and create your ontology\u0026nbsp;\u003c/p\u003e\u003cp\u003eAfter creating an ontology, you can begin labeling your data to fine-tune or train a model.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"label-data-of-interest\"\u003eLabel data of interest\u0026nbsp;\u003c/h3\u003e\u003cp\u003eWith Quantumworks Lab, you can label your data in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e: leverage our global network of\u0026nbsp; specialized labelers for a variety of tasks.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWorkforce Boost provides a collaborative platform for labeling services in a self-serve manner — this is great for teams that don’t have the technical expertise to build a machine learning system yet are looking for an easy-to-use technology to get a quick turnaround on quality training data. You can learn more about our Boost offerings \u003ca href=\"https://docs.labelbox.com/docs/using-data-labeling-service?ref=labelbox-guides.ghost.io\"\u003ehere\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create pre-labels with foundation models\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn addition to creating pre-labels for classification projects, you have the ability to send model predictions as pre-labels to your labeling project. This can be done in one of two ways:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/model-assisted-labeling?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel-assisted labeling\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eImport computer-generated predictions (or simply annotations created outside of Quantumworks Lab) as pre-labels on an asset. The imported annotations will be pre-populated in the labeling editor and a human can correct or verify and submit the prediction as ground truth.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel Foundry\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eAutomate data workflows, including data labeling with world-class foundation models. Leverage a variety of open source or third-party models to accelerate pre-labeling and cut labeling costs by up to 90%.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003ePre-label data with Model Foundry\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eModel Foundry\u003c/a\u003e acts as the copilot to create your training data –\u0026nbsp; instead of going into unstructured text datasets blindly, you can use pre-existing LLMs to pre-label data or pre-tag parts of it, reducing manual labeling efforts and cost.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/9zspjgoau7\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1) Select data you wish to label in Catalog\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Hit \"Predict with Model Foundry\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Choose a foundation model\u003c/p\u003e\u003cul\u003e\u003cli\u003eYou can select a foundation model based on your use case to have the model take a first pass at labeling your data\u003c/li\u003e\u003cli\u003eThese pre-labels can be verified with human-in-the-loop review in Quantumworks Lab Annotate\u003c/li\u003e\u003cli\u003eFor this use case, we’ve selected the GPT-4 model\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e4) Configure the model’s settings\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eSelect the previously created ontology in the earlier part of the tutorial\u0026nbsp;\u003c/li\u003e\u003cli\u003eLabelbox will auto-generate a prompt based on your ontology and use case – in this case we wish to classify the sentiment (positive or negative) and classify a topic with one or more options (breakfast, dinner, location, staff, room, facilities, value for money, or interior design)\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e5) Generate preview predictions\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eBefore submitting the model run, you can generate prediction previews to understand how the model will perform\u003c/li\u003e\u003cli\u003eIt is recommended that you preview some predictions to confirm the model parameters are configured as desired\u003c/li\u003e\u003cli\u003eBased on the preview, you can then make any adjustments to the settings or choose to submit the model run as-is\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e6) Name and submit the model run\u0026nbsp;\u003c/p\u003e\u003cp\u003e7) View the model run in the Model tab to explore results\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eOnce your model run is complete, you navigate to the Model tab\u003c/li\u003e\u003cli\u003eExplore the model’s results and click into each data row to dig deeper into the model’s predictions\u003c/li\u003e\u003cli\u003eFor this example, we can see that there are instances where GPT-4 has correctly tagged named entities and identified sentiment\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve evaluated and are satisfied with GPT-4’s predictions, you can send them to a labeling project in Quantumworks Lab Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdd a batch to a labeling project as pre-labels\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eBefore you can send these model predictions to a labeling project as pre-labels, you need to create a labeling project. \u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/7zgl76n76w\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 5 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreate a new labeling project\u003c/em\u003e\u003c/p\u003e\u003cp\u003e1) Navigate to the Annotate tab\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Create a ‘New project’\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Select the project type – in this case we want to create a ‘Text’ project\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Name your project\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Attach your model’s ontology (created in a previous step)\u0026nbsp;\u003c/p\u003e\u003cp\u003eOnce you’ve created your labeling project and configured the ontology, head back to the Model tab to send your batch of data with pre-labels to that labeling project.\u0026nbsp;\u003c/p\u003e\u003cp\u003e1) Highlight all data rows of interest\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Select ‘Manage selection’ \u0026gt; ‘Add batch to project’\u003c/p\u003e\u003cp\u003e3) Select the appropriate project that you created in the above step\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) You can give the batch a priority (from 1-5)\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Select the appropriate model run of the predictions you wish to send\u0026nbsp;\u003c/p\u003e\u003cp\u003e6) You can explore and select the various tags that have been applied and uncheck those that aren’t of interest\u0026nbsp;\u003c/p\u003e\u003cp\u003e7) Submit the batch\u0026nbsp;\u003c/p\u003e\u003cp\u003eYou can now navigate back to your project in Annotate and hit ‘Start labeling’.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"verify-data-quality-with-custom-workflows\"\u003eVerify data quality with custom workflows\u003c/h3\u003e\u003cp\u003eRather than starting from scratch, your internal or external team of labelers can now see predictions from the Model Foundry run. From here, you can validate or edit predictions as necessary and submit data rows to create ground truth labels.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/56bratjais\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 6 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eAs you begin to progress through your data rows, you’ll notice data rows that are initially marked up and reviewed by labelers in the ‘Initial review’ task (for your reviewers to verify and approve), with all submitted data rows falling into ‘Done’.\u0026nbsp;\u003c/p\u003e\u003cp\u003eYou can create customizable, multi-step review and rework pipelines to drive efficiency and automation for your review tasks. Set a review task based on specific parameters that are unique to your labeling team or desired outcome.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eInitial labeling task: reserved for all data rows that have been queued for labeling\u003c/li\u003e\u003cli\u003eInitial review task: first review task for data rows with submitted labels\u003c/li\u003e\u003cli\u003eRework task: reserved for data rows that have been rejected\u003c/li\u003e\u003cli\u003eDone task: reserved for data rows that have a) moved through their qualified tasks in the workflow or b) did not qualify for any of the tasks\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce all data rows have been reviewed and moved to the ‘Done’ step, you can begin the model training process.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn Part 1 of this tutorial, we have looked at how we can leverage Catalog to understand the topics that exist within your dataset and construct an appropriate ontology. To accelerate our initial labeling job, we leveraged Model Foundry as part of our model-assisted labeling pipeline to use pre-labels from GPT-4 to our labeling workforce for validation. Those initial annotations can be exported via a model run and can be used to train or fine-tune a model outside of Labelbox.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"part-2-train-or-fine-tune-a-model-and-evaluate-model-performance\"\u003ePart 2: Train or fine-tune a model and evaluate model performance\u0026nbsp;\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in either the \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eGoogle Colab Notebook\u003c/a\u003e or \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eDatabricks Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"train-a-custom-model-on-a-subset-of-data-outside-of-labelbox\"\u003eTrain a custom model on a subset of data outside of Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/07yc0p652w\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 7 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eIn the previous step, we leveraged Model Foundry to create pre-labels that were passed through Annotate for review with human-in-the-loop validation. Now that we have our appropriate annotation data, we can train a series of initial models on sentiment, topic classification, and named entity recognition.\u0026nbsp;\u003c/p\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cp\u003eYou can reference \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io#scrollTo=EDmBNjYP_0u7\"\u003ethis step\u003c/a\u003e (Databricks) or \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io#scrollTo=EDmBNjYP_0u7\" rel=\"noreferrer\"\u003ethis step\u003c/a\u003e (Google Colab) in either notebook.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBring the trained model’s predictions back into a model run\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce the model has been trained, you can create an inference pipeline that leverages each model to classify different attributes for review. We can then leverage this for two things:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRun inference on the model run dataset and upload it to Quantumworks Lab for evaluation\u003c/li\u003e\u003cli\u003eRun inference on our remaining dataset and use the predictions for model-assisted labeling, to be refined in the platform and used to accelerate labeling efforts\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003ePlease follow \u003ca href=\"https://colab.research.google.com/drive/1ppNgzhP12Ph1xyIws3xE5ChVThZda0q2?ref=labelbox-guides.ghost.io#scrollTo=B9_dYR_D_0vE\"\u003ethis step\u003c/a\u003e (Databricks) or \u003ca href=\"https://colab.research.google.com/drive/1quSxnKhSNffw0GMhyxGYxFFFNaf34OQp?ref=labelbox-guides.ghost.io#scrollTo=B9_dYR_D_0vE\" rel=\"noreferrer\"\u003ethis step\u003c/a\u003e (Google Colab) to create an inference pipeline and to upload predictions to the model run and evaluate it against ground truth.\u003c/p\u003e\u003cp\u003eAfter following the notebook, you’ll be able to compare ground truth (green) versus the model’s predictions (red) for sentiment and topic.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"evaluate-and-diagnose-model-effectiveness\"\u003eEvaluate and diagnose model effectiveness\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/dqzdzj1seb\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 8 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eDiagnose model performance with model metrics\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn addition to visualizing the difference between model predictions and ground truth, you can click into the ‘Metrics’ view to get a better sense of how your model is performing.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eUse the \"Metrics view\" to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/li\u003e\u003cli\u003eModel metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor example, we can click into false negatives or false positives to narrow down situations where there might be false positives – where ‘negative’ sentiment is predicted whereas ground truth sentiment is ‘positive’.\u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate high-impact data to drastically improve model performance\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve identified an example of a corner-case where the model might be struggling, you can easily leverage Catalog to surface similar unlabeled examples to improve model performance.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eSelect any corner-cases and select \"Find similar in Catalog\" from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows (both labeled and unlabeled) to the selected example.\u0026nbsp;\u003c/li\u003e\u003cli\u003eTo only surface unlabeled reviews that you can send to your model for labeling, you can filter on the \"Annotation is\" filter and select \"none.\" This will only show unlabeled text reviews that are similar to the selected corner case.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect all reviews that apply and select \"Add batch to project\"\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eUse model predictions as model-assisted labeling pipeline\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/r4p2h6iklg\" title=\"How to analyze customer reviews and improve customer care with NLP - Part 9 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eOnce you’ve filtered for and have selected reviews that you wish to label you can \"Add batch to project\" to send them to your labeling project in Annotate.\u0026nbsp;\u003c/p\u003e\u003cp\u003e1) Name your batch\u003c/p\u003e\u003cp\u003e2) Select your labeling project from the dropdown\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Include model predictions (from your model run) – this will perform better than the initial GPT-4 run with Model Foundry since it has been trained on your custom data\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Select or uncheck any predictions as desired\u0026nbsp;\u003c/p\u003e\u003cp\u003e5) Submit the batch\u003c/p\u003e\u003cp\u003eWhen you return to Quantumworks Lab Annotate, you will now see the original batch that we added at the start of the project, as well as the newly added batch ready for labeling.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRather than starting from scratch, similar to the predictions created by GPT-4 in Model Foundry, your labelers will now see the custom model predictions and validate them with human-in-the-loop review in the same manner. This workflow helps accelerate model iterations, allowing your team to bring in the latest model prediction as pre-labels for your project to reduce the amount of human labeling effort required to create ground truth labels.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWith new high-impact data labeled, you can retrain the model and can track model improvements across various runs for comparison and how this has affected model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003eCustomer reviews and feedback data represent an invaluable yet untapped opportunity for businesses. Manually analyzing this growing mountain of data is no longer practical. Instead, forward-thinking companies are turning to AI to efficiently sift through and extract actionable insights from reviews.\u003c/p\u003e\u003cp\u003eNatural language processing can help identify customer sentiment, pain points, and unmet needs. By leveraging AI to tap into this feedback treasure trove, businesses can drive measurable improvements in customer satisfaction, retention, and advocacy. They can refine products, enhance user experiences, and preemptively address concerns.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"654bbab4016f5100016579c3","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Group-2457--1-.png","featured":false,"visibility":"public","created_at":"2023-11-08T16:43:32.000+00:00","updated_at":"2024-06-25T16:28:21.000+00:00","published_at":"2023-11-08T21:47:13.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa506375d13000123d7e8","name":"Using LLMs","slug":"using-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-llms/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-analyze-customer-reviews-and-improve-customer-care-with-nlp/","excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":"How to analyze customer reviews and improve customer care with NLP","og_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Group-2457--1--1.png","twitter_title":"How to analyze customer reviews and improve customer care with NLP","twitter_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","meta_title":"How to analyze customer reviews and improve customer care with NLP","meta_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to redefine customer care with AI and create solutions tailored to unique customer care challenges.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"654407cdd96ee80001d8c876","uuid":"e29733c1-b966-4d1e-858d-f96deab4850e","title":"How to build a content moderation model to detect disinformation","slug":"how-to-build-a-content-moderation-model-to-detect-disinformation","html":"\u003cp\u003eAs user-generated content increases and the amount of data grows, trust and safety on digital platforms is becoming increasingly critical. Content that goes unmoderated can not only directly hurt brand reputation, but it can directly impact a businesses bottom line through lost users, advertisers, and revenue. Regulators worldwide are also implementing \u003ca href=\"https://insightplus.bakermckenzie.com/bm/data-technology/united-states-now-is-the-time-to-evaluate-your-online-content-moderation-program?ref=labelbox-guides.ghost.io\"\u003estricter rules\u003c/a\u003e around content moderation, online safety, misinformation, and disinformation.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo address these growing risks, more businesses are looking to AI and machine learning as part of robust trust and safety strategies. State-of-the-art AI solutions enable unprecedented scale, nuance, consistency, and efficiency in identifying and taking action on high-risk user content.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, businesses can face multiple challenges when implementing AI for trust and safety. This includes:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDynamic content landscape: \u003c/strong\u003eModels are only as good as the data they are trained on. As new trends or content emerges, AI models need constant retraining on compelling diverse, unbiased, and large labeled datasets to reinforce content moderation.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEthical risks \u0026amp; biases: \u003c/strong\u003eWithout careful design, machine learning models risk exacerbating biases and are prone to \u003ca href=\"https://labelbox.com/blog/what-does-it-mean-when-an-llm-hallucinates/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ehallucination\u003c/a\u003e. Teams need a way to monitor and evaluate model training with ethical oversight.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCost \u0026amp; scalability: \u003c/strong\u003eDeveloping accurate custom AI can be expensive in data, tools, and expertise. Leveraging foundation models, with human-in-the-loop verification, can help accelerate model development by automating the labeling process.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform that enables businesses to build state-of-the-art AI solutions for enhanced controls, transparency, efficiency in content moderation, and greater brand safety. Rather than spending valuable time building an in-house solution or relying on disparate systems, businesses can explore data, use foundation models for assisted-enrichment, and evaluate models to quickly build more accurate AI systems for analyzing user behavior, detecting disinformation, and enhancing ad-targeting. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1430\" height=\"786\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/Screenshot-2023-11-20-at-11.36.31-AM.png 1430w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build a model for content moderation, such as detecting and classifying disinformation, allowing you to elevate brand trust and improve the trust and safety of your applications.\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"see-it-in-action-how-to-build-a-content-moderation-model-to-detect-disinformation\"\u003eSee it in action: How to build a content moderation model to detect disinformation\u003c/h2\u003e\u003cp\u003eThe walkthrough below covers Quantumworks Lab’s platform across \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e. We recommend that you \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003ecreate a free Quantumworks Lab account\u003c/a\u003e to best follow along with this tutorial.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1:\u003c/strong\u003e Explore and enhance your data: \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab Notebook\u0026nbsp;\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2: \u003c/strong\u003eCreate a model run, fine-tune an LLM, and evaluate model performance: \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"ingest-data-into-labelbox\"\u003eIngest data into Quantumworks Lab\u0026nbsp;\u003c/h3\u003e\u003cp\u003eWith the growing amount of user-generated content, businesses want to ensure that there is no inappropriate content or disinformation happening on their platform. To implement content moderation at scale, teams can leverage AI to analyze and detect harmful content and classify disinformation from existing data stored in a cloud bucket or a local folder.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/9e76g8llbu\" title=\"How to enhance brand safety and content moderation with AI - Part 1 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo upload a sample of your content to Quantumworks Lab for labeling, you have a few options:\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUpload a dataset through the SDK\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eUsing the \u003ca href=\"https://colab.research.google.com/drive/1bTIKkQUHiccIy1adgKqQ_CVCm2KAxiHP?ref=labelbox-guides.ghost.io\"\u003eGoogle Colab notebook\u003c/a\u003e, upload the sample dataset into Quantumworks Lab or use it to import data from various sources like Bigquery, Databricks, or Snowflake.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this notebook, we’re going to bring in two libraries of interest:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/sdk-fundamental-concepts-1?ref=labelbox-guides.ghost.io\"\u003eLabelbox SDK\u003c/a\u003e\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelpandas?ref=labelbox-guides.ghost.io\"\u003eLabelpandas\u003c/a\u003e (for bringing tabular data into Quantumworks Lab)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou’ll need your Quantumworks Lab API key to initiate the Quantumworks Lab Client and create a dataset. For this guide, we’ll be using a dataset stored in a Google Cloud bucket as a CSV and we can use Labelpandas to bring this data in.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe provided sample dataset includes:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAn article with a corresponding headline\u003c/li\u003e\u003cli\u003eWhen it was retrieved\u003c/li\u003e\u003cli\u003eMetadata (sorted by source)\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003ePre-labels based on if the article contains “disinformation” or not\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eUpload a dataset through the UI \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIf you have a dataset from your local file, you can upload it through the Quantumworks Lab UI by clicking \"new dataset\" in Catalog.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOnce you’ve successfully uploaded your text, you can browse the dataset in Catalog — along its metadata. You can visualize your data in a no-code interface to quickly pinpoint and curate data for model training.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"search-and-curate-data\"\u003eSearch and curate data\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/vl9jr5463n\" title=\"How to enhance brand safety and content moderation with AI - Part 2 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou’ll now be able to see your dataset in Quantumworks Lab Catalog. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLeverage custom and out-of-the-box smart filters and embeddings to quickly explore product listings, surface similar data, and optimize data curation for ML. You can:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eSearch across datasets\u003c/a\u003e to narrow in on data containing specific attributes (e.g metadata, media attributes, datasets, project, etc.)\u0026nbsp;\u003c/li\u003e\u003cli\u003eAutomatically \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003efind similar data\u003c/a\u003e in seconds with off-the-shelf embeddings\u0026nbsp;\u003c/li\u003e\u003cli\u003eFilter data based on \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language\u003c/a\u003e and flexibly \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io#how-filters-work\"\u003elayer structured and unstructured filters\u003c/a\u003e for more granular data curation\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate and save data slices\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ksmc9w7acz\" title=\"How to enhance brand safety and content moderation with AI - Part 3 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eIf you have a search query that you’re interested in saving or reusing in the future, you can save it as \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003ea slice\u003c/a\u003e. You can construct a slice by using one or more filters to curate a collection of data rows. Users often combine filters to surface high-impact data and then save the results as a slice.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn this example, we are interested in saving the surfaced data rows as “Climate Articles” so that this filtered dataset can easily be surfaced later on for annotation or data discovery purposes.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-a-labeling-project-in-annotate\"\u003eCreate a labeling project in Annotate\u0026nbsp;\u003c/h3\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/uxspsczkpn\" title=\"How to enhance brand safety and content moderation with AI - Part 4 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1) Create a text project in \u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Sample and send your uploaded dataset as a \u003ca href=\"https://docs.labelbox.com/docs/batches?ref=labelbox-guides.ghost.io\"\u003ebatch\u003c/a\u003e to your newly created project. In this case we can send the two dataset slices that we created: “Climate related articles” and “Non-climate related articles”\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create an \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eontology\u003c/a\u003e to determine how to structure your data. If you have a previous ontology you’d like to use, you can do so. If not, you’ll need to create a new ontology. For this use case, our ontology consists of two classifications:\u003c/p\u003e\u003cul\u003e\u003cli\u003e“Does the article contain disinformation?” with two options\u003c/li\u003e\u003cli\u003e“Is the article climate related?” with two options\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e4) If you’re relying on an external team of labelers or want to provide your internal labeling team with more instructions, you can upload instructions as a PDF for your labelers during the ontology creation process.\u003c/p\u003e\u003ch3 id=\"label-the-data-of-interest\"\u003eLabel the data of interest\u0026nbsp;\u003c/h3\u003e\u003cp\u003eNow that we have a project with our data set up in Annotate, we’ll need to label this training data.\u0026nbsp;\u003c/p\u003e\u003cp\u003eSince this project is a classification use case, we can also leverage \u003ca href=\"https://docs.labelbox.com/docs/bulk-classification?ref=labelbox-guides.ghost.io\"\u003ebulk classification\u003c/a\u003e to speed up our labeling process and maximize labeling efficiency. Teams who have used bulk classification in Quantumworks Lab have seen labeling time decrease from a full quarter to a few days. Since we’ve leveraged filters in Catalog to identify “Climate related articles,” we can send these articles to our newly created labeling project with pre-labels.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/eh5mwisy6q\" title=\"How to enhance brand safety and content moderation with AI - Part 5 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo bulk classify and pre-label data rows, you can:\u003c/p\u003e\u003cp\u003e1) Highlight any data rows of interest, in our use case these would be data rows in the slice \"Climate related articles\",\u0026nbsp; and select \"Manage selection\" \u0026gt; \"Add classifications\"\u003c/p\u003e\u003cp\u003e2) Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. In the above demo, we are sending these to the \"Initial labeling task\" because we want to have a labeler verify that these are indeed all climate related articles\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Select the desired classification — in this case it would be \"Climate related\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) You can determine the batch’s data row priority (from 1-5) and submit the bulk classification job \u003c/p\u003e\u003cp\u003eRather than labeling from scratch, a team of labelers can now simply verify or correct the pre-labels used during this bulk classification step.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, you can label your data in the following ways:\u003c/p\u003e\u003cp\u003e1) Internal team of labelers: your team can start labeling directly in the Quantumworks Lab editor, utilizing automation tools and maintaining quality with custom workflows to maintain human-in-the-loop review.\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) External team of expert labelers with \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e: leverage our global network of\u0026nbsp; specialized labelers for a variety of tasks.\u0026nbsp;\u003c/p\u003e\u003cp\u003eWorkforce Boost provides a collaborative platform for labeling services in a self-serve manner — this is great for teams that don’t have the technical expertise to build a machine learning system yet are looking for an easy-to-use technology to get a quick turnaround on quality training data. You can learn more about our Boost offerings \u003ca href=\"https://docs.labelbox.com/docs/using-data-labeling-service?ref=labelbox-guides.ghost.io\"\u003ehere\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e3) Create pre-labels with foundation models\u0026nbsp;\u003c/p\u003e\u003cp\u003eIn addition to creating pre-labels for classification projects, you have the ability to send model predictions as pre-labels to your labeling project. This can be done in one of two ways:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/model-assisted-labeling?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel-assisted labeling\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eImport computer-generated predictions (or simply annotations created outside of Quantumworks Lab) as pre-labels on an asset. The imported annotations will be pre-populated in the labeling editor and a human can correct or verify and submit the prediction as ground truth.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/model-foundry/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eModel Foundry\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eAutomate data workflows, including data labeling with world-class foundation models. Leverage a variety of open source or third-party models to accelerate pre-labeling and cut labeling costs by up to 90%.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"verify-data-quality-with-custom-workflows\"\u003eVerify data quality with custom workflows\u003c/h3\u003e\u003cp\u003eContent moderation relies heavily on training the model on accurate and verified data. To ensure that you’re producing the most reliable and high-quality training datasets, you can customize your \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox-guides.ghost.io\"\u003elabeling review workflow\u003c/a\u003e.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/lqa22gzj7o\" title=\"How to enhance brand safety and content moderation with AI - Part 6 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eYou can create customizable, multi-step review and rework pipelines to drive efficiency and automation for your review tasks. Set a review task based on specific parameters that are unique to your labeling team or desired outcome.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eInitial labeling task: reserved for all data rows that have been queued for labeling\u003c/li\u003e\u003cli\u003eInitial review task: first review task for data rows with submitted labels\u003c/li\u003e\u003cli\u003eRework task: reserved for data rows that have been rejected\u003c/li\u003e\u003cli\u003eDone task: reserved for data rows that have a) moved through their qualified tasks in the workflow or b) did not qualify for any of the tasks\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"part-2-create-a-model-run-fine-tune-an-llm-and-evaluate-model-performance\"\u003ePart 2: Create a model run, fine-tune an LLM, and evaluate model performance\u0026nbsp;\u0026nbsp;\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn this part of the tutorial, we’ll be taking the ground truth labels created in Part 1 to fine-tune a large language model (LLM). From there, we’ll evaluate model performance in Quantumworks Lab Model to diagnose model strengths and weaknesses and look to continuously boost and improve model performance.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-a-new-model\"\u003eCreate a new model\u0026nbsp;\u003c/h3\u003e\u003cp\u003eOnce you have your labeled data in your project in Annotate, you’re ready to move on to creating a model run in \u003ca href=\"https://app.labelbox.com/mea?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003eLabelbox Model\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/z31zew9hbd\" title=\"How to enhance brand safety and content moderation with AI - Part 7 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eTo create a new model, you’ll need to:\u003c/p\u003e\u003cp\u003e1) Navigate to the \"Experiments\" tab in Model. The \"Experiments\" tab will be where you can find all model experiments across iterations.\u003c/p\u003e\u003cp\u003e2) Create a new model by selecting the \"New model\" button.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eProvide a model name\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect the model ontology — in this case we will select the same ontology we used to create our labeling project that contains the corresponding ground truth data.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSubmit and create a model — before creating a model run, you will also be able to see and verify the number of data rows that are being submitted.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eCreate a model run\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve created a new model, we will need to create a new \u003ca href=\"https://docs.labelbox.com/docs/model-runs?ref=labelbox-guides.ghost.io\"\u003emodel run\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eA model run is a model training experiment — each model run provides a versioned data snapshot of the data rows, annotations, and \u003ca href=\"https://docs.labelbox.com/docs/curate-data-splits?ref=labelbox-guides.ghost.io\"\u003edata splits\u003c/a\u003e for that model run. You can upload predictions to the model run and compare its performance against other model runs in a model directory.\u003c/p\u003e\u003cp\u003eThe model run we create will be the initial model run for our LLM fine-tuning experiment. To add a new model run:\u003c/p\u003e\u003cp\u003e1) Select \"New model run\"\u0026nbsp;\u003c/p\u003e\u003cp\u003e2) Give the model run a name (e.g “model run #1”)\u003c/p\u003e\u003cp\u003e3) Set data splits for the model run (for train, validate, and test)\u0026nbsp;\u003c/p\u003e\u003cp\u003e4) Create the model run\u0026nbsp;\u003c/p\u003e\u003cp\u003eAfter creating a model run, you’ll be able to see the corresponding data rows with ground truth populated into the appropriate train, validate, and test splits. This model run will be the gateway for us to export ground truth data to fine-tune a large language model.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-us.googleusercontent.com/bObh0Kje6BWPfrIPWcd3V0TFt09svuX0-7Wka4IQI9j-bKdmhJAEjTWsWPWOmdFUg-CgU9fLQC-p_vFdafFXv4nYhMZupffw7Bl6TN8Z-2j771nF4riavmSL-xiDAmjU8E32deblRc4eEmNjptF3GpI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"327\"\u003e\u003c/figure\u003e\u003ch3 id=\"export-ground-truth-from-the-model-run-experiment-for-fine-tuning\"\u003eExport ground truth from the model run experiment for fine-tuning\u0026nbsp;\u003c/h3\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/s2gzlnehyy\" title=\"How to enhance brand safety and content moderation with AI - Part 8 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eWe’ll be using this \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab notebook\u003c/a\u003e to fine-tune a model and bring back inferences from the fine-tuned model for evaluation and diagnosis.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor this step, you will need:\u003c/p\u003e\u003cul\u003e\u003cli\u003eYour API Key\u0026nbsp;\u003c/li\u003e\u003cli\u003eYour Model Run ID to export the corresponding ground truth and articles from the model run\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eExport ground truth from the model run experiment\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eLabelbox will return the ground truth export in a JSON format. With the provided \u003ca href=\"https://colab.research.google.com/drive/1p7d3UGBu0x4lGwLB06iGjCiS71HYoueU?ref=labelbox-guides.ghost.io\"\u003eColab notebook\u003c/a\u003e, we can visualize the exported JSON into a DataFrame format for us to view corresponding ground truth for each article.\u0026nbsp;\u003c/p\u003e\u003cp\u003eGiven that we want to fine-tune a Google Vertex model with this data, we’ll need to convert the ground truth export to a GCP vertex tuning format (JSONL):\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# build LLM prompt and convert to GCP vertex tuning format (jsonl)\n\nprompt = 'Given the following headline and content, determine whether the article is related to climate change or similar topics. Also determine whether the article contains inaccurate or disinformation. Answer in the following format with Yes/No Answers: [climate related? / disinformation?]'\ndf['input_text'] = prompt + df['content']\ndf['output_text'] = 'climate related: ' + df['climate_related'] + ' disinformation: ' + df['disinformation_flag']\n\n\nwith open('modelPrompt_GCP.jsonl', 'w') as file:\nfor _, row in df[['input_text', 'output_text']].iterrows():\njson_line = row.to_json()\nfile.write(json_line + '\\n')\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"fine-tune-an-llm-with-google-vertex-ai\"\u003eFine-tune an LLM with Google Vertex AI \u003c/h3\u003e\u003cp\u003eFine-tuning is a technique whereby we take an off-the-shelf open-source or proprietary model and retrain it on a variety of concrete examples, and save the updated weights as a new model checkpoint. You can learn more about other techniques to leverage LLMs \u003ca href=\"https://labelbox.com/guides/zero-shot-learning-few-shot-learning-fine-tuning/?ref=labelbox-guides.ghost.io#zero-shot-learning-few-shot-learning-and-fine-tuning-in-action\"\u003ein this guide\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/um0f8w1rzn\" title=\"How to enhance brand safety and content moderation with AI - Part 9 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eFor this use case, we’ll be using \u003ca href=\"https://cloud.google.com/vertex-ai?ref=labelbox-guides.ghost.io\"\u003eGoogle Vertex AI \u003c/a\u003eto fine-tune an LLM with the ground truth from Part 1 of this tutorial. Once in the Vertex AI console, we’ll want to create a tuned model:\u003c/p\u003e\u003cul\u003e\u003cli\u003eChoose a supervised learning task\u0026nbsp;\u003c/li\u003e\u003cli\u003eEnter additional model parameters (e.g model name)\u0026nbsp;\u003c/li\u003e\u003cli\u003eUpload the JSONL file from the previous step\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, we can start the model tuning process. Once the model fine-tuning job has been completed, we can head over to the Google Vertex sandbox and give the newly tuned model a prompt.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor example, we can ask if the article is climate related and if it contains disinformation and it will provide a response based on the training dataset we provided.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"create-inferences-with-the-tuned-model-and-evaluate-model-effectiveness-in-labelbox\"\u003eCreate inferences with the tuned model and evaluate model effectiveness in Quantumworks Lab\u003c/h3\u003e\u003cp\u003eNow that we’ve fine-tuned a model, we can use it to make predictions on the initial dataset and compare it with our ground truth data to assess the fine-tuned model’s performance.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/cjbrcpktcr\" title=\"How to enhance brand safety and content moderation with AI - Part 10 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eCreate inferences with the tuned model\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe’ll need to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eInstall Google Vertex and Google Cloud SDK\u0026nbsp;\u003c/li\u003e\u003cli\u003eProvide the endpoint ID for the tuned model\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe can then start creating model inferences and predictions from the tuned model on our news articles. Use Pandas to clean up the responses, to remove corresponding prompts, and save them as a DataFrame — this will return the model’s initial headline and the client’s response if the data row is climate related or contains disinformation. \u003c/p\u003e\u003cp\u003eOnce we have model inferences, we can send the inferences back to a model run in Quantumworks Lab for further evaluation and analysis.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eEvaluate and diagnose model effectiveness\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo evaluate the effectiveness of the fine-tuned model in Quantumworks Lab, we’ll need to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eSpecify the model run ID\u0026nbsp;\u003c/li\u003e\u003cli\u003eUpload the list of model inferences for each specific data row\u0026nbsp;\u003c/li\u003e\u003cli\u003eAttach each list of data rows and submit it to a model run in Quantumworks Lab as an upload job via the SDK\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce that’s complete, you can hop back to the original Quantumworks Lab model run and view the corresponding ground truth data and model inferences on each data row. You can visually compare the effectiveness of the fine-tuned model predictions (in red) with ground truth (in green).\u003c/p\u003e\u003cul\u003e\u003cli\u003eUse the \"Metrics view\" to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/li\u003e\u003cli\u003eModel metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor this use case, our goal is to minimize the spread of disinformation, so we can take a look at the metric that shows corresponding articles that are considered \"disinformation\" by labelers, but where the model incorrectly predicted articles as \"not disinformation\". \u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003ch3 id=\"curate-high-impact-data-to-drastically-improve-model-performance\"\u003eCurate high-impact data to drastically improve model performance\u003c/h3\u003e\u003cp\u003eOnce you’ve identified an example of a corner-case where the model might be struggling, you can easily leverage Catalog to surface similar unlabeled examples to improve model performance.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/7podbew17q\" title=\"How to enhance brand safety and content moderation with AI - Part 11 Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eSelect any corner-cases and select \"Find similar in Catalog\" from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows (both labeled and unlabeled) to the selected example.\u0026nbsp;\u003c/li\u003e\u003cli\u003eTo only surface unlabeled articles that you can send to your model for labeling, you can filter on the \"Annotation is\" filter and select \"none\". This will only show unlabeled text articles that are similar to the selected corner case.\u0026nbsp;\u003c/li\u003e\u003cli\u003eSelect all articles that apply and send them as a batch to your original labeling project. Labeling these in priority will help improve model performance. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWith new high-impact data labeled, you can retrain the model and can track model improvements across various runs for comparison and how this has affected model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eUnmoderated content poses mounting risks to businesses with the risk of spreading misinformation, disinformation, and an unsafe online environment. With responsible implementation, businesses can leverage AI for trust and safety to efficiently and consistently identify high-risk content at scale. This not only helps create an online environment that is safe for users, but also helps protect brand reputation.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=modelfoundry\u0026\u0026referrer_url=https://connect.labelbox.co/?utm_keyword=Quantumworks Lab\u0026utm_medium=email\u0026utm_source=house\u0026utm_campaign=guide103123\u0026\u0026attr=intercom\u0026referrer_url=https://www.google.com/\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e.\u003c/p\u003e","comment_id":"654407cdd96ee80001d8c876","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2-.png","featured":false,"visibility":"public","created_at":"2023-11-02T20:34:21.000+00:00","updated_at":"2024-07-17T20:55:32.000+00:00","published_at":"2023-11-02T21:18:18.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-build-a-content-moderation-model-to-detect-disinformation","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},"url":"https://labelbox-guides.ghost.io/how-to-build-a-content-moderation-model-to-detect-disinformation/","excerpt":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","reading_time":12,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2--2.png","og_title":"How to build a content moderation model to detect disinformation","og_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/11/Frame-2299--2--1.png","twitter_title":"How to build a content moderation model to detect disinformation","twitter_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","meta_title":"How to build a content moderation model to detect disinformation","meta_description":"Learn how to leverage Quantumworks Lab’s data-centric AI platform to build a model for content moderation for trust \u0026 safety applications. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"64e7a2c3b0c09f000179dbed","uuid":"2b64de59-c4f8-4bf5-aa4b-07d1aabcb933","title":"How to build a powerful product recommendation system for retail","slug":"how-to-build-a-powerful-product-recommendation-system-for-retail","html":"\u003cp\u003ePersonalized experiences are at the heart of customer satisfaction and are key to long-term brand loyalty and success. Amidst the abundance of choices available to the modern consumer, businesses must find innovative ways to stand out and forge meaningful relationships with their audience. \u003c/p\u003e\u003cp\u003eThe rise of AI has enabled companies to craft personalized experiences at an unprecedented scale. Organizations can now rely on algorithms taught to recognize customer preferences, behavior, and provide recommendations based on purchase history, and more. With a powerful product recommendation system, retailers can create individualized customer interactions and foster stronger connections to boost customer loyalty and increase key metrics such as conversion rate, average order value, and repeat purchase rates. \u003c/p\u003e\u003cp\u003eHowever, building a robust and effective AI-powered product recommendation system can be challenging for many teams. Some key challenges include: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eData quality and quantity: \u003c/strong\u003eBuilding a strong recommendation system that makes accurate predictions requires a vast amount of high-quality data. Orchestrating data from various sources can not only be challenging to maintain, but even more difficult to sort, analyze, and enrich with quality insights.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability: \u003c/strong\u003eAs a business grows and their product catalog expands, the recommendation system should be able to handle new and incoming data. Ensuring scalability and maintaining model performance with new data can be particularly challenging for teams relying on in-house solutions or disparate ML tools.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePrivacy and Security: \u003c/strong\u003eWhen it comes to customer data and specific product information, ensuring user privacy and safeguarding against potential security violations is critical to maintain trust with customers and build a successful recommendation system. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox is a data-centric AI platform to help build the best personalized product recommendation engine. Rather than spending valuable time building in-house or relying on disparate systems and applications, teams can leverage Quantumworks Lab’s platform to seamlessly build an end-to-end workflow that integrates with your existing tech stack and helps teams build AI systems faster.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/11/image-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1425\" height=\"635\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/11/image-3.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/11/image-3.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/11/image-3.png 1425w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn this guide, we’ll walk through how your team can leverage Quantumworks Lab’s platform to build a powerful recommendation system, ensuring your customers embark on a seamless and delightful shopping journey that keeps them coming back for more.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"see-it-in-action-how-to-build-a-powerful-product-recommendation-system-in-labelbox\"\u003eSee it in action: How to build a powerful product recommendation system in Quantumworks Lab\u003c/h2\u003e\u003cp\u003e\u003cem\u003eThe  walkthrough below covers Quantumworks Lab’s platform across \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eCatalog\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eAnnotate\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, and \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eModel\u003c/em\u003e\u003c/a\u003e\u003cem\u003e. We recommend that you \u003c/em\u003e\u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003ecreate a Quantumworks Lab account\u003c/em\u003e\u003c/a\u003e\u003cem\u003e to best follow along with this tutorial.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 1: \u003c/strong\u003eExplore and enhance your data (\u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eGoogle Colab Notebook\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePart 2:\u003c/strong\u003e Prepare data and evaluate model performance: (\u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eGoogle Colab Notebook\u003c/a\u003e)\u003c/p\u003e\u003ch2 id=\"part-1-explore-and-prepare-your-data\"\u003ePart 1: Explore and prepare your data\u003c/h2\u003e\u003cp\u003eFollow along with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u003c/strong\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\" class=\"kg-btn kg-btn-accent\"\u003ePart 1: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"painlessly-consolidate-all-your-product-data\"\u003ePainlessly consolidate all your product data\u003c/h3\u003e\u003cp\u003eBuilding a recommendation engine requires consolidating data of different types from various sources. Such data can include product, business, and customer information that might be siloed or stored in different databases. To holistically browse and visualize your entire product catalog, leverage Quantumworks Lab Catalog to bring and view all of your data in a single place.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/rdlcin4zh8\" title=\"[Personalized Experiences Demo] Data ingestion Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eIngest data into Quantumworks Lab\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFor this tutorial, we’ve provided a sample retail dataset for you to view in your Quantumworks Lab app: \u003c/p\u003e\u003cp\u003e1) Input your Quantumworks Lab API key into the provided \u003ca href=\"https://colab.research.google.com/drive/1nOSff67KXhNgX_XSfnv3xnddobRoaK0d?ref=labelbox-guides.ghost.io#scrollTo=F9FCBVHysBdO\"\u003eGoogle Colab notebook\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e2) Specify an amount of data that you wish to ingest — we’ve provided up to 44,000 data rows for ingestion, but keep in mind that this will accrue \u003ca href=\"https://docs.labelbox.com/docs/billing?ref=labelbox-guides.ghost.io#labelbox-units-lbus\"\u003eLBUs\u003c/a\u003e in your account. \u003cem\u003eIf you are using Quantumworks Lab for free, we suggest that you ingest around 5,000 data rows.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e3) Select ‘Runtime’ in the navigation bar and hit ‘Run all’ to bring the selected amount of data rows into your \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eLabelbox Catalog \u003c/a\u003e— where you can browse, explore, and curate the data for insights and model development.\u003c/p\u003e\u003ch3 id=\"accelerate-product-discovery-across-your-entire-catalog\"\u003eAccelerate product discovery across your entire catalog\u003c/h3\u003e\u003cp\u003eAn effective product recommendation relies on training a model with a thorough understanding of your product data, encompassing product tags, categories, and more. However, retailers often have an ever-growing product list with hundreds or thousands of products. Dealing with this volume of data at scale and effectively searching, organizing, and managing data for machine learning tasks can be a challenge.\u003c/p\u003e\u003cp\u003eYou can leverage Quantumworks Lab Catalog to visualize, browse, and curate your product listings.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ehcuz2b4rk\" title=\"[Personalized Experiences Demo] Search and curate Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eSearch and curate data\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eYou’ll now be able to see the sample retail dataset in your Quantumworks Lab Catalog. Try searching across key product-specific metadata such as category, the year the item was released, season, gender, and more. With Catalog, you can contextualize your data with \u003ca href=\"https://docs.labelbox.com/docs/datarow-metadata?ref=labelbox-guides.ghost.io\"\u003ecustom metadata\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io#visualize-attachments\"\u003eattachments\u003c/a\u003e to each asset for greater context. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1226\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.27-PM-1.png 2304w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eLeverage custom and out-of-the-box smart filters and embeddings to quickly explore product listings, surface similar data, and optimize data curation for ML. You can:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eSearch across datasets\u003c/a\u003e to narrow in on data containing specific attributes (e.g metadata, media attributes, datasets, project, etc.)\u003c/li\u003e\u003cli\u003eAutomatically \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003efind similar data\u003c/a\u003e in seconds with off-the-shelf embeddings \u003c/li\u003e\u003cli\u003eFilter data based on \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language\u003c/a\u003e and flexibly \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io#how-filters-work\"\u003elayer structured and unstructured filters\u003c/a\u003e for more granular data curation\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"categorize-and-curate-product-listings-faster\"\u003eCategorize and curate product listings faster\u003c/h3\u003e\u003cp\u003eAdvanced ML teams often adopt partially automated labeling workflows to mitigate costs and accelerate model development. Product recommendation models require a vast amount of accurately labeled data with a wide array of features. Manually labeling this data can not only be time consuming, but can also get exponentially expensive. Scaling data curation and enrichment effectively is key to quickly creating a powerful ML solution. \u003c/p\u003e\u003cp\u003eOne simple way to achieve this is by leveraging bulk classification and using human-in-the-loop review for quality assurance. Some AI teams using this technique have cut labeling costs by nearly 90%.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/epl8hstb7c\" title=\"[Personalized Experiences Demo] Streamlined labeling automation through bulk classification Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eStreamline labeling automation through bulk classification\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate a new labeling project\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"905\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.05.00-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOnce you’ve narrowed in on a specific slice of data that you’d like to take action on, you can send them to a labeling project of interest in just a few clicks.\u003c/p\u003e\u003cp\u003e1) Create a new image project in \u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e2) Configure the editor and create a new ontology. For the ontology, create a new classification called ‘Occasions’ with options such as ‘Casual’, ‘Sports’, ‘Formal’, etc. feel free to add any other classifications of interest.\u003c/p\u003e\u003cp\u003e3) Save your labeling project.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eSend a subset of data to the labeling project\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"739\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.04.11-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eReturn to Catalog and surface a specific subset of data that you want to bulk classify. For example, you can surface all instances of ‘Sporty apparel’ clothing with a natural language search.\u003c/p\u003e\u003cp\u003e1) Highlight any data rows of interest and select ‘Manage selection’ \u0026gt; ‘Add classifications’.\u003c/p\u003e\u003cp\u003e2) Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. In the above demo, we are sending these to the ‘Done’ stage because we have verified that these images fall under the ‘Sports’ category and want to automatically create ground truth labels.\u003c/p\u003e\u003cp\u003e3) Pick ‘Sports’ under the Classification section and you can submit the classification batch. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eSave high-impact searches\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1029\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/08/Screenshot-2023-08-24-at-3.03.42-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can save any combination of searches as a \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslice\u003c/a\u003e in Catalog. For example, saving the natural language search of ‘Sporty apparel’ as a slice called ‘Sporty apparel’, creates a dynamic slice of data that can easily be revisited or edited as project needs evolve. Any future data that gets uploaded to Quantumworks Lab will automatically populate in any relevant slices based on its filters, creating an automatic data curation pipeline as your product catalog grows.\u003c/p\u003e\u003ch2 id=\"part-2-prepare-data-and-evaluate-model-performance\"\u003ePart 2: Prepare data and evaluate model performance\u003c/h2\u003e\u003cp\u003e\u003cbr\u003eFollow along with the below with the tutorial and walkthrough in this \u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eColab Notebook\u003c/a\u003e. If you are following along, \u003cstrong\u003eplease make a copy of the notebook.\u003c/strong\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\" class=\"kg-btn kg-btn-accent\"\u003ePart 2: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"prepare-a-training-dataset-for-model-diagnosis\"\u003ePrepare a training dataset for model diagnosis\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eModel diagnosis can play a pivotal role when training a model for personalized shopping experiences. The success of personalized recommendation systems hinge on the accuracy of a model’s understanding of a retailer’s product catalog or individual customer preferences. A properly curated and organized training dataset serves as the foundation for accurate model performance evaluation and fine-tuning.\u003c/p\u003e\u003cp\u003eSend the curated training dataset from Quantumworks Lab Annotate to Model in a few clicks to efficiently diagnose model performance of the training dataset.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate a training dataset for evaluation\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/zo945lphbi\" title=\"[Personalized Experiences Demo] Prepare a training dataset for model diagnosis Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreating a new model\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1866\" height=\"1408\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.51-PM.png 1866w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Navigate to the Model tab, select ‘Experiments’, and create a new model.\u003c/p\u003e\u003cp\u003e2) Name your model (e.g ‘Occasions’) and select a model thumbnail.\u003c/p\u003e\u003cp\u003e3) Select the same ontology that was used to bulk classify the data rows in the previous step.\u003c/p\u003e\u003cp\u003e4) Select the project that the classifications were sent to in the previous step. After selecting both the correct ontology and project, you should see the number of data rows that were bulk classified and ready to be added to the new model.\u003c/p\u003e\u003cp\u003e5) Hit ‘Create model’.\u003c/p\u003e\u003cp\u003e\u003cem\u003eCreating a new model run\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"938\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.02.34-PM-1.png 2306w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Once you’ve created your model, you can navigate back to the ‘Experiments’ tab and find the newly created model.\u003c/p\u003e\u003cp\u003e2) Create a ‘new model run.’ \u003ca href=\"https://docs.labelbox.com/docs/model-runs?ref=labelbox-guides.ghost.io\"\u003eA model run\u003c/a\u003e is a model training experiment within a model, providing a versioned data snapshot of all data rows, annotations, and data splits for that model run.\u003c/p\u003e\u003cp\u003e3) To create a model run, you’ll need to give it a name (e.g ‘dataset version 1’) and can adjust the balance of the data split. For this demo, we will leave them in the default setting (80% train, 10% validate, 10% test).\u003c/p\u003e\u003cp\u003e4) After creating the model run, you’ll be able to see the populated training data classifications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTrain a model on a provided training dataset\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/ab1phltynu\" title=\"[Personalized Experiences] Train a model on the provided training dataset Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eModel training occurs outside of Labelbox. Quantumworks Lab Model works with any model training and inference framework, major cloud providers (AWS, Azure, GCS), and any data lake (Databricks, Snowflake).\u003c/p\u003e\u003cp\u003eWe’ll be using the \u003ca href=\"https://colab.research.google.com/drive/1CSyAE9DhwGTl7bLaSoo7QSyMuoEqJpCj?ref=labelbox-guides.ghost.io#scrollTo=eZnixGEAkscW\"\u003eColab notebook\u003c/a\u003e to train a model on the training dataset and bring back inferences from the trained model for evaluation and diagnosis.\u003c/p\u003e\u003cp\u003eFor this step, you will need:\u003c/p\u003e\u003cul\u003e\u003cli\u003eYour Ontology ID — found in the Settings tab on the model run page\u003c/li\u003e\u003cli\u003eYour Model Run ID — found in the gear icon on the top-right of the model run page\u003c/li\u003e\u003cli\u003eYour API key\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e1) Enter your API key, Ontology ID, and Model Run ID in the Colab Notebook.\u003c/p\u003e\u003cp\u003e2)  Once those are inputted, you can select ‘Runtime’ in the navigation bar and hit ‘Run all’ – this will take the classifications from your model run and train a provided image classification model. After training, the notebook will also take the trained model and use it to run inference on the data.\u003c/p\u003e\u003cp\u003e3)  If you want to adjust your data splits, you can leverage search filters in Model to surface any data rows and move them to the train, test, and validation splits.\u003c/p\u003e\u003ch3 id=\"evaluate-and-diagnose-model-effectiveness-for-retail\"\u003eEvaluate and diagnose model effectiveness for retail\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eA well-performing model can accurately predict consumer behavior or recommend products based on past preferences. Effective model diagnosis helps fine-tune recommendation algorithms, resulting in more accurate and appealing product suggestions. \u003c/p\u003e\u003cp\u003eModel diagnosis and evaluation are not one-time tasks. By leveraging effective diagnostic tools and an active learning workflow, retailers can continuously identify areas of improvement and adapt to changing customer behavior or an evolving product catalog. This iterative approach keeps personalized experiences relevant and effective for driving business outcomes over time.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/qwqdx21ml2\" title=\"[Personalized Experiences Demo] Diagnose model performance and fix model errors Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eDiagnose model performance with model metrics\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"692\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.00.44-PM.png 2330w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) After running the notebook, you’ll be able to visually compare ground truth labels (in green) to the model predictions (in red).\u003c/p\u003e\u003cp\u003e2) Use the ‘Metrics view’ to drill into crucial model metrics, such as confusion matrix, precision, recall, F1 score, and more, to surface model errors.\u003c/p\u003e\u003cp\u003e3) Model metrics are auto-populated and interactive. You can click on any chart or metric to open up the gallery view of the model run and see corresponding examples.\u003c/p\u003e\u003cp\u003e4) Detect and visualize corner-cases where the model is underperforming. For example, in the demo above, we notice that the model is classifying this type of white shoe as a ‘Sports’ shoe when in fact it is a ‘Casual’ shoe.\u003c/p\u003e\u003cp\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCurate high-impact data to drastically improve model performance\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1172\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/08/Screenshot-2023-08-24-at-3.01.05-PM.png 2324w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e1) Select any corner-cases and select ‘Find similar in Catalog’ from the Manage Selection dropdown. This will bring you back into Catalog and will automatically surface all similar data rows to the selected example.\u003c/p\u003e\u003cp\u003e2) In addition to the similarity search, you can filter on ‘Annotation’ \u0026gt; ‘is none’ to surface only unlabeled data rows that you can retrain the model on to boost model performance.\u003c/p\u003e\u003cp\u003e3) Select any relevant examples and ‘Manage selection’ \u0026gt; ‘Add classifications’. In this case, we’d want to bulk classify these examples to reinforce to the model that these images are ‘casual’ shoes.\u003c/p\u003e\u003cp\u003e4) This step is similar to the bulk classification step in part 1. Select the labeling project that you made in the previous step and determine a step of the project’s review workflow that you would like to send the classifications to. We can send these to the ‘Done’ stage because we want to tell the model these white shoes fall under the ‘Casual’ category and want to automatically create ground truth labels.\u003c/p\u003e\u003cp\u003e5) Create a new model run (within the same model) and have the newly added classifications as a part of the training dataset.\u003c/p\u003e\u003cp\u003e6) Run the notebook again to train the model on this new training dataset and evaluate model performance with model metrics. You can compare results from the initial model run with the new model run to evaluate how the adjustment influenced model performance.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eAs consumer businesses strive to distinguish themselves in a competitive market, the power of AI-driven product recommendation systems cannot be underestimated. Companies can tap into their vast data stores and harness the capabilities of advanced algorithms to forge deeper connections with their customers.\u003c/p\u003e\u003cp\u003eLabelbox is a data-centric AI platform that empowers teams to iteratively build powerful product recommendation engines to fuel lasting customer relationships. To get started, \u003ca href=\"https://app.labelbox.com/signup?_gl=1*p9sldc*_ga*MTIxOTY2MjYxMy4xNjkwNDg1NjI5*_ga_WS2TB2GPYE*MTY5MjkwMjk0OC40LjAuMTY5MjkwMzQ1Ni4wLjAuMA..\u0026ref=labelbox-guides.ghost.io\"\u003esign up for a free Quantumworks Lab account\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003erequest a demo\u003c/a\u003e. \u003c/p\u003e","comment_id":"64e7a2c3b0c09f000179dbed","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1-.png","featured":false,"visibility":"public","created_at":"2023-08-24T18:34:43.000+00:00","updated_at":"2023-11-20T19:39:23.000+00:00","published_at":"2023-08-24T19:15:09.000+00:00","custom_excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-build-a-powerful-product-recommendation-system-for-retail","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-build-a-powerful-product-recommendation-system-for-retail/","excerpt":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","reading_time":10,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1--2.png","og_title":"How to build a powerful product recommendation system for retail","og_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/08/Group-3078--1--1.png","twitter_title":"How to build a powerful product recommendation system for retail","twitter_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","meta_title":"How to build a powerful product recommendation system for retail","meta_description":"Learn how to leverage Quantumworks Lab's data-centric AI platform to build a robust AI-powered product recommendation system to power personalized experiences for retail. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"646f88789568720001240642","uuid":"b8289ca0-7d94-41c4-84df-a5e0541ba9bb","title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","slug":"leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content","html":"\u003cp\u003eVideo data can offer a wealth of information for AI use cases, but because of their dense and dynamic nature, manually extracting insights can be a tedious task. To accelerate this process, leading AI teams often use off-the-shelf, pre-trained models like \u003ca href=\"https://ultralytics.com/yolov8?ref=labelbox-guides.ghost.io\"\u003eYOLO\u003c/a\u003e (short for You Only Look Once) to take a quick first pass at detecting the contents of a video dataset. \u003c/p\u003e\u003cp\u003eYOLO is a real-time object detection model. Unlike traditional models, which scan an image multiple times at different scales, YOLO looks at the entire image only once, making it particularly well-suited for video object detection. It can detect various objects and provide a bounding box for each detected object. Using this model to enrich video data can make it easier for AI teams to understand their data.\u003c/p\u003e\u003cp\u003eHowever, the real magic lies in going a step further by organizing and categorizing this information, making the video content searchable. In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.\u003c/p\u003e\u003ch2 id=\"how-to-make-videos-queryable\"\u003eHow to make videos queryable\u003c/h2\u003e\u003cp\u003eTo make a video queryable, the first step is to run the YOLO model on the video to detect the objects in each frame. Once objects are detected, they are classified, and a bounding box is added to the objects in Labelbox. You can then search your video content based on these annotations with Catalog. Want to find all instances where a \"bowl\" appears in your video? Simply search for \"bowl\" in the Quantumworks Lab UI. Catalog will return all the videos that contain this annotation.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"633\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_1.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_1.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOnce YOLO has added annotations to your video data, you can simply search for specific content within that dataset using Quantumworks Lab Catalog.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou can also create a custom workflow in Quantumworks Lab to create a bespoke review process, where you can create tasks that only have assets containing a specific annotation in the video, such as vehicles or other objects of interest. You can let YOLO take the first pass at labeling your video data, and then have human labelers review and/or add annotations in frames that contain specific objects of interest, reducing the time and costs required to label high-quality training data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"961\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_2.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_2.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_2.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eYou can create a custom labeling workflow that targets specific data in Quantumworks Lab to save labeling time and costs while ensuring high labeling quality.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRead on for step-by-step instructions on using YOLO and Quantumworks Lab to make your videos queryable.\u003c/p\u003e\u003ch2 id=\"part-1-create-project-and-ontology\"\u003ePart 1: Create project and ontology\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eproject = client.create_project(name=\"Video project with YOLO\",\n                                   media_type=lb.MediaType.Video)\n\n\n#connect ontology to your project\nproject.setup_editor(ontology)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-2-queue-assets-to-project-based-on-global-keys\"\u003ePart 2: Queue assets to project based on global keys\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003ebatch = project.create_batch(\n \"first-batch-video\"+str(uuid.uuid4()), # Each batch in a project must have a unique name\n global_keys= global_keys, # A paginated collection of data row objects, a list of data rows or global keys\n priority=5 # priority between 1(Highest) - 5(lowest)\n)\nprint(\"Batch: \", batch)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-3-load-yolo-model\"\u003ePart 3: Load YOLO model\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel = YOLO(f'{HOME}/yolov8n.pt')\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"part-4-create-predictions-and-upload-them-to-labelbox\"\u003ePart 4: Create predictions and upload them to Quantumworks Lab\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Export queued data rows from the project\nqueued_data_rows = project.export_queued_data_rows()\n\n\n# Initialize an empty list to store labels\nlabels = []\n\n\n# Loop over each data row. Here, it's only looping over the first data row.\nfor data_row in queued_data_rows[:1]:\n\n\n # Extract the URL of the video from the data row.\n video_url = data_row[\"rowData\"]\n\n\n # Extract the global key from the data row.\n global_key = data_row[\"globalKey\"]\n\n\n # Make a GET request to the video URL.\n response = requests.get(video_url)\n\n\n # Open a file in write-binary mode and write the content of the response to it.\n # This is downloading the video and saving it as 'sample_video.mp4'.\n with open('sample_video.mp4', 'wb') as f:\n     f.write(response.content)\n\n\n # Create a VideoCapture object to read frames from the downloaded video.\n cap = cv2.VideoCapture(\"sample_video.mp4\")\n\n\n # Set up the VideoWriter for the output video. The 'mp4v' argument specifies the codec to be used.\n fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n\n\n # Initialize a counter for the frame number.\n frame_number = 0\n\n\n # Start a loop to read frames from the video.\n while True:\n     # Read the next frame from the video.\n     ret, frame = cap.read()\n\n\n     # If the frame could not be read (i.e., we're at the end of the video), break the loop.\n     if not ret:\n         break\n\n\n     # Increment the frame number.\n     frame_number += 1\n\n\n     # Use the model to predict objects in the current frame. The confidence threshold is set to 0.5.\n     results = model.predict(frame, conf=0.50)\n\n\n     # Loop over each predicted class.\n     for c in results[0].boxes.cls:\n       # Loop over each bounding box predicted for the current class.\n       for idx, box in enumerate(results[0].boxes.xyxy):\n         # Get the class number from the model's class names.\n         class_number = model.names[int(c)]\n\n\n         # Get the coordinates of the bounding box.\n         xmin, ymin, xmax, ymax  = float(box[0]), float(box[1]), float(box[2]), float(box[3])\n\n\n         # Create an annotation for the bounding box.\n         bbox_annotation = [\n           lb_types.VideoObjectAnnotation(\n             name = class_number,\n             keyframe= True,\n             frame=frame_number,\n             segment_index=0,\n            \n             # Define the bounding box as a rectangle with a start and end point.\n             value = lb_types.Rectangle(\n                   start=lb_types.Point(x=xmin, y=ymin), # x = left, y = top\n                   end=lb_types.Point(x= xmax, y=ymax)))] # x= left + width , y = top + height\n        \n         # Append a new Label object to the labels list. Each Label represents one detected object in one frame.\n         labels.append(\n             Label(\n                 data=lb_types.VideoData(global_key=global_key),\n                 annotations = bbox_annotation\n             )\n         )\n\n\n # Release the VideoCapture object.\n cap.release()\u003c/code\u003e\u003c/pre\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"923\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_3.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_3.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_3.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample of Quantumworks Lab video editor with YOLO predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1182\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/YOLOGuide_4.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/YOLOGuide_4.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/YOLOGuide_4.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eAnalytics view of a dataset with YOLO predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/Large-GIF--1466x882-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1466\" height=\"882\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/Large-GIF--1466x882-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/Large-GIF--1466x882-.gif 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/Large-GIF--1466x882-.gif 1466w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eVideo is enriched with annotations from YOLO, and the contents can be queried in Quantumworks Lab Catalog.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eCombining the power of the YOLO — or any off-the-shelf AI model that suits your needs — with Quantumworks Lab opens up exciting possibilities for video content. It not only makes the video content queryable, but also helps bring a new level of understanding to what's inside the videos. This combination can be especially beneficial for use cases like surveillance, content creation, content moderation, and advertising, where insights from video content are crucial.\u003c/p\u003e\u003cp\u003eUsing an AI model as a first pass enables users to search videos based on their content, enabling AI teams to learn how many annotations of each object exist within their dataset and what types of annotations the training dataset might lack. This further reduces friction when it comes to finding the next set of assets that will improve the model's performance by doing active learning. Try enriching your videos using YOLO or any other AI model using this \u003ca href=\"https://colab.research.google.com/drive/1vOVo4MtsoUxNJ-tIdmI-GKWjVFo9RrQe?ref=labelbox-guides.ghost.io#scrollTo=rJXXOJdpWD48\"\u003escript\u003c/a\u003e to discover exactly what content already exists in your troves of unstructured videos and find specific videos quickly and easily.\u003c/p\u003e","comment_id":"646f88789568720001240642","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Screen-Shot-2023-05-24-at-1.45.31-PM.png","featured":false,"visibility":"public","created_at":"2023-05-25T16:10:32.000+00:00","updated_at":"2023-10-27T16:58:02.000+00:00","published_at":"2023-05-25T16:33:51.000+00:00","custom_excerpt":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/leveraging-yolo-and-labelbox-to-make-videos-queryable-by-content/","excerpt":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","og_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","twitter_image":null,"twitter_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","twitter_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","meta_title":"Leveraging YOLO and Quantumworks Lab to make videos queryable by content","meta_description":"In this guide, we'll explore how to use YOLO and Quantumworks Lab Catalog together to make a dataset of unlabeled videos searchable.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6452689090e75e0001b3546c","uuid":"5a55750c-5b23-4ce7-b075-117a24a4f392","title":"Automatically label images with 99% accuracy using foundation models","slug":"automatically-label-images-with-99-accuracy-using-foundation-models","html":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\u003cp\u003eIn this guide, you’ll learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab and foundation models. We will be walking through a sample \u003ca href=\"https://labelbox.com/guides/image-annotation/?ref=labelbox-guides.ghost.io\"\u003eimage classification task\u003c/a\u003e: figuring out if images contain cats or dogs.\u003c/p\u003e\u003cp\u003eHere's a high-level summary of the process that we'll be walking through step-by-step below:\u003c/p\u003e\u003cul\u003e\u003cli\u003eConnect your data to Quantumworks Lab with just a few lines of code.\u003c/li\u003e\u003cli\u003eLabelbox leverages foundation models to magically enrich your data.\u003c/li\u003e\u003cli\u003eUse the powerful search capabilities of Quantumworks Lab to quickly find data with similar traits and classify them in one click. With the help of foundation models, you can instantaneously label large amounts of data. \u003cem\u003ePro tip: Combine a variety of search techniques, such as a similarity search, natural language search, and investigate clusters of similar data, to boost your results.\u003c/em\u003e\u003c/li\u003e\u003cli\u003eWhile foundation models are a helpful starting point, they might not always correctly classify data, especially on challenging or rare data points. In this case, utilize human-in-the-loop labeling and QA by pre-labeling data using foundation models and sending it for your internal or external labeling team to review.\u003c/li\u003e\u003cli\u003eAutomatically apply these rules to all new incoming data by creating a \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslice\u003c/a\u003e in Labelbox.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, let’s take a look at how we can do the above in Labelbox. As a sneak peek into the process, by leveraging foundation models, we managed to \u003cstrong\u003eclassify 86% of our images in minutes with a 99.9% accuracy rate\u003c/strong\u003e. An additional 13.5% of our images were successfully pre-labeled using foundation models, with 98% accuracy, and were sent for human review. This left us with less than 0.5% of images to manually label – a massive efficiency gain for any labeling team.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"step-1-connect-your-data-to-labelbox-with-a-few-lines-of-code\"\u003eStep 1: Connect your data to Quantumworks Lab with a few lines of code\u003c/h2\u003e\u003cp\u003eSince this is a classification task, our goal is to correctly have the model identify cats and dogs in images. We will be using the following Hugging Face dataset - \u003ca href=\"https://huggingface.co/datasets/cats_vs_dogs?ref=labelbox-guides.ghost.io\"\u003ecats_vs_dogs\u003c/a\u003e, containing 18,699 images for our analysis.\u003c/p\u003e\u003cp\u003eTo begin, let's connect this data to Labelbox. Simply retrieve the dataset from Hugging Face and integrate it with Quantumworks Lab in just a few lines of code.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom datasets import load_dataset\ndataset = load_dataset(\"cats_vs_dogs\",split='train')\n\n# iterate over the data\npayload_imgs = []\ncounter = 0\n\nfor data in dataset:\n  image = data['image']\n  label = data['labels'] # 0 is cat, 1 is dog\n  global_key = \"cat_vs_dog_\" + str(counter)\n\n  # save image locally\n  path = \"/content/images/\"+global_key+\".jpg\"\n  image.save(path) \n\n  # create payload for images\n  payload_imgs.append({\"row_data\": path, \"global_key\": global_key})\n  counter += 1\n\n# create dataset in Quantumworks Lab\nlb_dataset = client.create_dataset(name=\"Cat_vs_dog\") \n\n\n# add data in Quantumworks Lab\ntask = lb_dataset.create_data_rows(payload_imgs[i:i+1000])  task.wait_till_done() # async\nprint(task.errors) # check errors \u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-2-leverage-foundation-models-to-instantly-enhance-your-data\"\u003eStep 2: Leverage foundation models to instantly enhance your data\u003c/h2\u003e\u003cp\u003eLabelbox will automatically compute and store CLIP embeddings for your data. Our CLIP model leverages \u003ca href=\"https://openai.com/research/clip?ref=labelbox-guides.ghost.io\"\u003eOpenAI\u003c/a\u003e and we are using \u003ca href=\"https://huggingface.co/sentence-transformers/clip-ViT-B-32?ref=labelbox-guides.ghost.io\"\u003ethis implementation\u003c/a\u003e available through Hugging Face. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"922\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-1141e64d-4de4-4a81-b6b2-9f4faf059871.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOnce your data has been uploaded, you can enrich your data with foundation model embeddings. These embeddings are powerful in that they can be harnessed to automatically label, or pre-label, your data.  \u003c/p\u003e\u003cp\u003eIf you don’t want to use the default embeddings by Quantumworks Lab, you can also \u003ca href=\"https://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/?ref=labelbox-guides.ghost.io\"\u003eupload custom embeddings\u003c/a\u003e from any other foundation model, with up to 100 custom embeddings for each data point. \u003c/p\u003e\u003cp\u003eWhether you’re using the default or custom embeddings, embeddings are helpful in curating and finding subsets of data that share similar characteristics. For instance, embeddings power Quantumworks Lab’s \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003esimilarity search\u003c/a\u003e, natural language search, and 2D projector view. You can search and explore all of your data with tools that help you powerfully surface specific subsets of data.\u003c/p\u003e\u003ch2 id=\"step-3-use-powerful-search-capabilities-to-quickly-find-data\"\u003eStep 3: Use powerful search capabilities to quickly find data\u003c/h2\u003e\u003cp\u003eWith \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003epowerful search capabilities\u003c/a\u003e in Quantumworks Lab, you can easily find and classify data that share similar characteristics. This is a special case of \u003ca href=\"https://labelbox.com/blog/few-shot-learning-and-zero-shot-learning-with-openai-embeddings/?ref=labelbox-guides.ghost.io\"\u003ezero-shot and few-shot learning\u003c/a\u003e: the challenge is to find all examples of cats and dogs, based on zero (or a few) examples from each class. \u003c/p\u003e\u003cp\u003eWith the help of foundation models, and minimal human signal, you can quickly label a lot of data in just a few clicks. The following are tools in Quantumworks Lab that help provide labeling signal to make it easy to automatically classify your data:\u003c/p\u003e\u003ch3 id=\"zero-shot-labeling-projector-view-for-classification\"\u003eZero-shot Labeling: Projector View for classification\u003c/h3\u003e\u003cp\u003eLabelbox allows you to visualize data clusters in 2D. For this example, we can see two distinct clusters: one for cats and another for dogs. By inspecting a few examples, we can ensure the data clustering is accurate. We then manually select each cluster and tag it with \"UMAP: cats: high confidence\" and \"UMAP: dogs: high confidence\". We intentionally left out data points situated between clusters, as these represent challenging data points. This is expected since each labeling function won’t be perfect in isolation and some data points are difficult and challenging.\u003c/p\u003e\u003cp\u003eWe then repeat the process with t-SNE, instead of UMAP, and tag each cluster with \"t-SNE: cats: high confidence\" and \"t-SNE: dogs: high confidence\".\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"924\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-6a50c54a-5528-475c-ba6f-95478cb3d84c.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUMAP: a cluster of cats with high confidence\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"923\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d8eca6af-f97b-4cd3-b61f-a9b457327695.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUMAP: a sub-cluster of images with two cats\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"926\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-efcbe4a2-78b9-46e8-a9ce-008614b29057.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003et-SNE: the same sub-cluster of images with two cats\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"zero-shot-labeling-natural-language-search-for-classification\"\u003eZero-shot Labeling: Natural language search for classification\u003c/h3\u003e\u003cp\u003eLabelbox enables you to conduct \u003ca href=\"https://docs.labelbox.com/docs/natural-language-search?ref=labelbox-guides.ghost.io\"\u003enatural language searches\u003c/a\u003e, for example you can type in “photos of cats” to surface all cat images. Adjusting the similarity threshold will narrow the search parameters to show only the images that contain cats. For this use case, we can filter for a similarity score higher than 0.61 and tag all of the 7,125 images as “Natural language search: Cats (high confidence)”. If we adjust the similarity score to be between 0.6 and 0.61, we can tag the 1,299 images as “Natural language search: Cats (low confidence)”. \u003c/p\u003e\u003cp\u003eWe take the same approach for images containing dogs. Using the same technique above, we tag 7,738 images of dogs as “Natural language search: Dogs (high confidence)” and surface and tag 2,750 images as “Natural language search: Dogs (low confidence)”.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"926\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-fba57f44-9231-45b0-91ad-693c9ba4a092.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eA natural language search will surface thousands of images of cats. By adjusting the similarity score, we can keep the most confident zero-shot predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"few-shot-labeling-similarity-search-for-classification\"\u003eFew-shot Labeling: Similarity search for classification\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eLabelbox also streamlines few-shot labeling. Quickly browse all your data in Catalog to surface 5 images of cats and 5 images of dogs. Perform a similarity search in one click using these 10 images as anchors. For each anchor image, run a similarity search and tag the top results (e.g  with a similarity score of higher than 0.895) as “Labeling function: similarity search (cats: high confidence)”. This provides us with 10 new labeling functions that surface images similar to the anchor images.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"925\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-78d77476-30e5-4f45-8445-c68a49192fe4.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eA similarity search example with anchor images of dogs. We can filter to keep the most confident few-shot predictions.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"weak-labeling-combining-different-sources-of-signal\"\u003eWeak Labeling: Combining different sources of signal\u003cbr\u003e\u003c/h3\u003e\u003cp\u003eWhile each of these labeling signals is powerful on its own, you can combine multiple sources in Labelbox. This allows you to apply simple rules in a weak supervision fashion to further enhance your results. Integrate different labeling signals, such as similarity searches, natural language searches, and data clusters, to boost your outcomes. You can \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003ecombine various filters\u003c/a\u003e by using the AND and OR functions.\u003c/p\u003e\u003ch2 id=\"step-4-automatically-classify-data-with-foundation-models-and-use-human-in-the-loop-qa-for-challenging-cases\"\u003eStep 4: Automatically classify data with foundation models and use human-in-the-loop QA for challenging cases\u003c/h2\u003e\u003ch3 id=\"high-confidence-data-points-direct-classification\"\u003eHigh confidence data points: direct classification\u003c/h3\u003e\u003cp\u003eFoundation models are highly confident about most data points. So much so that we can directly classify data points leveraging Quantumworks Lab’s \u003ca href=\"https://labelbox.com/blog/pre-label-and-enrich-your-data-with-bulk-classifications/?ref=labelbox-guides.ghost.io\"\u003ebulk classification feature\u003c/a\u003e. With this new feature, you can specify and send your data rows to a specific step of the \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox.ghost.io#how-it-works\"\u003elabeling and review workflow\u003c/a\u003e. We can directly move these high-confidence data points straight to the “Done” task.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"927\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-71fdc0c1-5398-4205-ac97-8e7e839b6a17.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWe can classify thousands of data points in bulk, and send them to the “Done” task of our labeling project, in just a click, since foundation models are confident on those.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn practice, these high-confident data points are those that belong to the cat or dog cluster, both with UMAP and t-SNE, and where the natural language score is higher than 0.61. This results in 7,627 dog classifications. But just how accurate are these classification predictions? \u003c/p\u003e\u003cp\u003eTo answer this question, we looked at the Hugging Face ground truths. On the surface, 10 out of the 7,627 dog predictions are incorrect (0.13%). However, upon closer inspection, it turns out that the Hugging Face dataset contains a few labeling mistakes and only 6 out of the 7,627 predictions (0.078%) of the foundation model’s predictions are actually incorrect. Similarly, there were 6,587 cat classifications. Only 6 out of the 6,587 cat predictions (0.09%) of the foundation model’s predictions are incorrect. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"761\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-d5d8573f-0102-4600-a61f-433bb79b78a7.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOut of 7,627 images, foundation models failed on these 10 by predicting dogs instead of cats.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eHigh-confident data points are also those that are found with a similarity search proximity to 2 or more anchors with a 0.895 or higher score. There were 907 dog classifications that fit this criteria, all of which were accurate except 1, and 1,022 cat classifications, all of which were accurate except 6. \u003c/p\u003e\u003cp\u003eBy leveraging the above methods, we were able to classify 16,143 data rows - with only 19 errors - achieving an \u003cstrong\u003eaccuracy of 99.9%. \u003c/strong\u003eSince 16,143 out of 18,699 data rows have been classified directly by foundation models, the \u003cstrong\u003ecoverage is 86%.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eNow, let’s move on to classify the remaining 14% of data rows, on which the foundation model appears to be less confident.\u003c/p\u003e\u003ch3 id=\"medium-confidence-data-points-human-in-the-loop-labeling\"\u003eMedium confidence data points: Human-in-the-Loop labeling\u003c/h3\u003e\u003cp\u003eFor some data points, foundation models exhibit moderate confidence. We can bulk classify these data points in Quantumworks Lab, but move them to the “To Review” task. This will ensure a human is looped in and will review the classifications coming from foundation models.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"922\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-8e8a1006-ec9e-452f-9712-8fa2a081aa97.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWe can pre-label thousands of data points in bulk and send them to “Review” in our labeling project, since foundation models are moderately confident on these images.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn practice, these data points are those that belong to the cat or dog cluster, with UMAP or t-SNE, and that we hadn’t classified before:\u003c/p\u003e\u003cul\u003e\u003cli\u003e1,622 dogs classifications, which turn out to be all accurate except 10.\u003c/li\u003e\u003cli\u003e907 cat classifications, which turn out to be all accurate except 38. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eUsing this approach, we manage to classify 2,529 data rows, with an \u003cstrong\u003eaccuracy of 98%\u003c/strong\u003e (48 errors). Good that we send them to humans for review! So far, we’ve classified all data rows except 27, so the coverage is \u003cstrong\u003e99.85%\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eNow, let’s move on to classify the remaining 27 images.\u003c/p\u003e\u003ch3 id=\"low-confidence-data-points-manual-labeling\"\u003eLow confidence data points: Manual labeling\u003c/h3\u003e\u003cp\u003eAfter applying these rules, 18,672 data rows out of 18,699 (99.85%) have been labeled, leaving only 27 data rows unclassified. Foundation models lack the confidence to label these remaining data points.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1135\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-08106dea-7c38-497e-afdf-da718ed520d9.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSome data rows, 27 in our case, were not classified through foundation models. This includes images that are blurry, where animals are turning their backs or are barely visible behind a cage.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThese 27 data points will require manual labeling by humans, which represents only 0.14% of data rows - a massive efficiency gain in labeling effort and speed!\u003c/p\u003e\u003ch3 id=\"results\"\u003eResults\u003c/h3\u003e\n\u003c!--kg-card-begin: html--\u003e\n\u003ctable style=\"border:none;border-collapse:collapse;table-layout:fixed;width:468pt\"\u003e\u003ccolgroup\u003e\u003ccol\u003e\u003ccol\u003e\u003ccol\u003e\u003ccol\u003e\u003c/colgroup\u003e\u003ctbody\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eDirect classification with foundation models\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eHuman in the loop with foundation models\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eManual classification\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e# of data rows classified\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e16,143\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e2,529\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e27\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e# of errors\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e19\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e48\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e0\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eAccuracy\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e99.9%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e98%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e100%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCoverage\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e86%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e13.5%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e0.15%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCumulative coverage\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e86%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e99.8%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003e100%\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003c!--kg-card-end: html--\u003e\n\u003cp\u003e\u003c/p\u003e\u003cp\u003eWith powerful search capabilities and the bulk classification feature, we managed to classify 16,143 images (86%) in minutes, with \u003cstrong\u003e99.9% accuracy\u003c/strong\u003e thanks to foundation models. An additional 2,529 data points (13.5%) have been pre-labeled with foundation models, with \u003cstrong\u003e98% accuracy\u003c/strong\u003e, and sent for human review. This leaves with only 27 very challenging images to label manually!\u003c/p\u003e\u003ch2 id=\"step-5-set-it-and-forget-it-%E2%80%93-automatically-apply-these-rules-to-fresh-incoming-data\"\u003eStep 5: Set it and forget it – automatically apply these rules to fresh, incoming data\u003c/h2\u003e\u003cp\u003eWith Quantumworks Lab \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslices\u003c/a\u003e, we can automatically classify fresh, incoming data as cats or dogs. \u003c/p\u003e\u003cp\u003eFor example, we can set up a slice that automatically surfaces all new images that have been connected to Quantumworks Lab in the past week, that haven’t been classified yet. We can set the slice’s criteria to include only images where the natural language search for the prompt “photo of a cat” is higher than 0.61 (since we know that these images are very likely to contain cats). \u003c/p\u003e\u003cp\u003eWith slices, you can easily surface and inspect any new and high-impact data that gets added to your data lake. \u003c/p\u003e\u003cp\u003eFrom there, it only takes one click to classify all of these images as cats.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"1216\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/05/data-src-image-a4cde4e1-6b94-4380-a322-3d14c9917d69.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWith slices and the ability to automatically surface high-impact data, we surfaced 7,000+ new images of cats that were connected to Quantumworks Lab in the past week. We can easily add a cat classification to all these images in one click.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eYou can learn more about how to bulk classify data in our \u003ca href=\"https://docs.labelbox.com/docs/bulk-classification?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e or in our \u003ca href=\"https://labelbox.com/blog/pre-label-and-enrich-your-data-with-bulk-classifications/?ref=labelbox-guides.ghost.io\"\u003erecent blog post\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eWith powerful search capabilities, the bulk classification feature, and foundation models, we managed to classify 16,143 images (86%) in minutes, with \u003cstrong\u003e99.9% accuracy\u003c/strong\u003e. An additional 2,529 data points (13.5%) have been pre-labeled with \u003cstrong\u003e98% accuracy\u003c/strong\u003e and sent for human review. This only left us with 27 very challenging images that we needed to label manually. \u003c/p\u003e\u003chr\u003e\u003cp\u003eIf you’re a current Quantumworks Lab user who wants to leverage any foundation model to supercharge your data labeling process in just a few clicks,\u003ca href=\"https://app.labelbox.com/catalog?ref=labelbox-guides.ghost.io\"\u003e try our bulk classification feature today\u003c/a\u003e or \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003eget started with a free Quantumworks Lab account\u003c/a\u003e.\u003c/p\u003e","comment_id":"6452689090e75e0001b3546c","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Group-3058--2-.png","featured":false,"visibility":"public","created_at":"2023-05-03T13:58:40.000+00:00","updated_at":"2023-10-27T17:01:07.000+00:00","published_at":"2023-05-03T17:28:24.000+00:00","custom_excerpt":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/automatically-label-images-with-99-accuracy-using-foundation-models","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa513375d13000123d7ea","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/automatically-label-images-with-99-accuracy-using-foundation-models/","excerpt":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","reading_time":10,"access":true,"comments":false,"og_image":null,"og_title":"Automatically label images with 99% accuracy using foundation models","og_description":"Learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","twitter_image":null,"twitter_title":"Automatically label images with 99% accuracy using foundation models","twitter_description":"Learn how to exponentially increase your labeling speed and efficiency by leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models. ","meta_title":"Automatically label images with 99% accuracy using foundation models","meta_description":"Automatically label images with 99% accuracy leveraging Quantumworks Lab's search capabilities, bulk classification, and foundation models.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"645007f474911d003db0cb11","uuid":"3d216637-f0d9-4995-bfd5-d289ba48b7d0","title":"Introducing Export V2: How to export data with more granular control","slug":"how-to-export-your-data-with-more-granular-control","html":"\u003cp\u003eIf you already leverage Quantumworks Lab to enrich and label your unstructured data, you know how important it is to export your data insights in the right format and connect it with your downstream data workflow. Whether you want to store your data in a database, a cloud-hosted table, an ML training pipeline, or a production environment, you need a flexible and powerful export system that can handle your specific needs.\u003c/p\u003e\u003cp\u003eThat’s why \u003cstrong\u003ewe’re excited to introduce a new way to export your data\u003c/strong\u003e. This new system gives you more granular control over your data exports across the Quantumworks Lab platform and SDK. With this new way to export, you can:\u003c/p\u003e\u003cul\u003e\u003cli\u003eExport the exact Data Rows you are interested in. You can use various filters in the Catalog and Data row tabs, or hand-select the data rows to export. For example, you can grab only the data rows that have received new labels, metadata, or issues updates within the last 24 hours.\u003c/li\u003e\u003cli\u003eConfigure the export to include exactly the right information you need. You can build a custom export payload that meets your specific data workflow needs with much faster performance. Learn more about these improvements \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#required--optional-fields\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eOrganize your assets into a data-row-centric framework that’s easy to structure and analyze.\u003c/li\u003e\u003cli\u003eLeverage\u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io\"\u003e improved annotation formats\u003c/a\u003e to rapidly export annotations.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhile we will continue supporting the Export v1 system until December 31, 2023, we encourage you to gradually start migrating all of your export workflows to this updated export workflow (Export v2). The Export v1 and Export v2 workflows may be used in tandem until Export v1 is sunset on December 31st.\u003c/strong\u003e \u003c/p\u003e\u003cp\u003ePlease refer to our documentation to learn more about export specifications and compare the old Export v1 and new Export v2 systems: \u003ca href=\"https://docs.labelbox.com/reference/export-image-annotations?ref=labelbox-guides.ghost.io\"\u003eimage\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-video-annotations?ref=labelbox-guides.ghost.io\"\u003evideo\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-text-annotations?ref=labelbox-guides.ghost.io\"\u003etext\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-document-annotations?ref=labelbox-guides.ghost.io\"\u003edocuments\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-geospatial-annotations?ref=labelbox-guides.ghost.io\"\u003egeospatial/tiled imagery\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-audio-annotations?ref=labelbox-guides.ghost.io\"\u003eaudio\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-conversational-text-annotations?ref=labelbox-guides.ghost.io\"\u003econversational text\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-html-annotations?ref=labelbox-guides.ghost.io\"\u003eHTML\u003c/a\u003e | \u003ca href=\"https://docs.labelbox.com/reference/export-dicom-annotations?ref=labelbox-guides.ghost.io\"\u003eDICOM\u003c/a\u003e\u003cbr\u003e\u003c/p\u003e\u003ch2 id=\"what%E2%80%99s-new-in-export-v2\"\u003eWhat’s new in Export v2\u003c/h2\u003e\u003ch3 id=\"data-row-centric-asynchronous-exports\"\u003eData row-centric asynchronous exports\u003c/h3\u003e\u003cp\u003eThe previous export system (Export v1) relied upon a less flexible label-centric export that limited access to all the information you might need about a Data Row. Within Export v2’s Data Row-centric context, you can access much more information — including fields like:\u003c/p\u003e\u003cul\u003e\u003cli\u003emetadata,\u003c/li\u003e\u003cli\u003eattachment,\u003c/li\u003e\u003cli\u003eworkflow history,\u003c/li\u003e\u003cli\u003emodel predictions,\u003c/li\u003e\u003cli\u003emedia attributes\u003c/li\u003e\u003cli\u003ebatch id,\u003c/li\u003e\u003cli\u003eand issues, alongside with the labels.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy reframing exports based on Data Rows, we’ve made it much more intuitive for you to integrate with your data tables that are organized around your team’s unique assets and data rows. \u003c/p\u003e\u003cul\u003e\u003cli\u003eAdditionally , now when you trigger an export job, it will occur asynchronously in the background, unblocking your workflow so you can avoid waiting. \u003c/li\u003e\u003cli\u003eIf you are using the Quantumworks Lab UI, you can access the task status in the notification center. \u003c/li\u003e\u003cli\u003eIf you are using SDK, you can query the task for status and results. \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"export-from-a-dataset-or-a-slice-with-the-option-to-grab-labels-from-multiple-projects-and-model-runs\"\u003eExport from a dataset or a slice, with the option to grab labels from multiple projects and model runs.\u003c/h3\u003e\u003cp\u003eA data row can have labels from multiple projects, or have predictions from multiple model runs. Using this new way to export through Catalog, or through the SDK, you can easily grab all the information about a Data Row. \u003c/p\u003e\u003cp\u003eUse data row filters to select a subset of data rows for export:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn the UI, you can build your \u003ca href=\"https://docs.labelbox.com/docs/data-rows-activity?ref=labelbox-guides.ghost.io#filter-data-rows\"\u003efilters within a project in the Data Rows tab\u003c/a\u003e, build \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003efilters in a dataset / slice in Catalog\u003c/a\u003e, or build \u003ca href=\"https://docs.labelbox.com/docs/filtering-and-sorting?ref=labelbox-guides.ghost.io\"\u003efilters in Model using model run filters\u003c/a\u003e. You can then choose to export only the filtered data rows. \u003c/li\u003e\u003cli\u003eIn the UI and SDK, you can use the \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'last_activity_at' filter\u003c/a\u003e to export only the data rows that have the creation and modification of labels, metadata, status, comments and reviews in a user-specified time range. This applies to a project in Annotate and a dataset or slice export. \u003c/li\u003e\u003cli\u003eIn the UI and SDK, we added a support for a \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'label_created_at' filter\u003c/a\u003e for you to export only the data rows that have the creation of labels in a user-specified time range. This applies to a project in Annotate and a dataset or slice export.\u003c/li\u003e\u003cli\u003eIn the UI, you can hand-pick data rows for export. Similarly in SDK, we added support for \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#filters\"\u003e'data_row_ids'\u003c/a\u003e filter to export only the data rows that you are interested in.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"configure-exports-to-selectively-include-or-exclude-certain-information-on-a-data-row\"\u003eConfigure exports to selectively include or exclude certain information on a data row\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWe recognize different teams have unique needs around what they need from exports. For example, labeling team would love to understand the performance and consensus scores of a labeling project, whereas a developer would like to know the metadata and media attributes on a data row.\u003c/li\u003e\u003cli\u003eExport v2 now not only covers all possible fields on a data row, but also makes it configurable so that you can grab only the necessary payload of export information with faster performance. See \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io#required--optional-fields\"\u003ethis table\u003c/a\u003e to check all available option fields that you can include/exclude in your exports. \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"remove-the-caching-for-exports\"\u003eRemove the caching for exports\u003c/h3\u003e\u003cp\u003eExport v1 used to cache exports for 30 minutes. In Export v2, you will always get a fresh export and you can run one export asynchronous task on a project at a time. \u003c/p\u003e\u003ch3 id=\"simplified-and-improved-export-payloads\"\u003eSimplified and improved export payloads\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWe've converted all fields in the export payload into snake case.\u003c/li\u003e\u003cli\u003eRather than isolating them into another JSON file, we've improved the video and DICOM exports to contain all frame annotations in the export ndjson file. and Export v2 provides three representations of objects in frames: “frames”, “segments”, and “key_frame_feature_map” to facilitate your different needs of downstream workflows. See examples in \u003ca href=\"https://docs.labelbox.com/reference/export-video-annotations?ref=labelbox-guides.ghost.io#annotation-export-formats\"\u003eVideo\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/reference/export-dicom-annotations?ref=labelbox-guides.ghost.io#annotation-export-formats\"\u003eDICOM\u003c/a\u003e exports.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"exporting-via-ui\"\u003eExporting via UI\u003c/h2\u003e\u003cp\u003eFrom Quantumworks Lab's UI, you can access the export function through the drop-down menu after selecting a subset of data rows. You can export the entire project, model, dataset, or slice from a set of filters or a selection of data rows within them. \u003c/p\u003e\u003cp\u003eBelow are some examples of Export v2 in action. For more detailed information, please refer to our \u003ca href=\"https://docs.labelbox.com/docs/export-labels?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"annotate-a-labeling-project\"\u003eAnnotate (A labeling project)\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-5691075b-e1cf-448b-9fa1-fa21e739f71f.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"884\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSelect data rows from filteres in the Data Rows tab.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-9e91c4d6-8d20-49fa-a1fb-739a4247487a.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"882\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eHand-select specific data rows.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"model-a-model-run\"\u003eModel (A model run)\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-be94fe0b-4fe4-40ba-a93d-a8268afcfe70.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"787\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSelect from metrics filters.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003c/p\u003e\u003ch3 id=\"catalog-a-dataset-and-slices\"\u003eCatalog (A dataset and slices)\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-51102232-fd36-41f0-a343-0f063d17c719.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"850\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExport a slice with labels from multiple projects.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"exporting-data-via-sdk\"\u003eExporting data via SDK\u003c/h2\u003e\u003cp\u003eFor developers that would like to programmatically feed exports directly into downstream data workflows or build automatic workflows to retrieve fresh data exports on a regular basis, we recommend Export v2 SDK. It provides flexibility to control what data you want to export. \u003c/p\u003e\u003ch3 id=\"project-export-v2\"\u003eProject Export v2\u003c/h3\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Set the export params to include/exclude certain fields. Make sure each of these fields are correctly grabbed \nexport_params= {\n  \"attachments\": True,\n  \"metadata_fields\": True,\n  \"data_row_details\": True,\n  \"project_details\": True,\n  \"performance_details\": True\n}\n\n# You can set the range for last_activity_at and label_created_at. You can also set a list of data \n# row ids to export. \n# For context, last_activity_at captures the creation and modification of labels, metadata, status, comments and reviews.\n\n# Note: This is an AND logic between the filters, so usually using one filter is sufficient.\nfilters= {\n  \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n  \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n  \"data_row_ids\": [\"data_row_id_1\", \"data_row_id_2\"] \n}\n\nexport_task = project.export_v2(params=export_params, filters=filters)\nexport_task.wait_till_done()\n\nif export_task.errors:\n  print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can check out SDK examples of exporting from datasets, slices, and model runs in this \u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"receiving-updates-via-webhooks\"\u003eReceiving updates via Webhooks\u003cbr\u003e\u003c/h2\u003e\u003cp\u003eFor teams that would like to get near real-time updates for each change on a data row, we recommend webhooks as a better option. Export v2 format can now be used for webhooks to receive the following events from project:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLABEL_CREATED\u003c/li\u003e\u003cli\u003eLABEL_UPDATED\u003c/li\u003e\u003cli\u003eLABEL_DELETED\u003c/li\u003e\u003cli\u003eREVIEW_CREATED\u003c/li\u003e\u003cli\u003eREVIEW_UPDATED\u003c/li\u003e\u003cli\u003eREVIEW_DELETED\u003c/li\u003e\u003cli\u003eWORKFLOW\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can configure a webhook that returns Export v2 in Project whenever an event is triggered. See more details in this \u003ca href=\"https://docs.labelbox.com/reference/webhook?ref=labelbox-guides.ghost.io\"\u003eWebhook Guide\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFor example, you can use ngrok to expose a local port.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003engrok http 3001\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis will generate an address that looks like ` \u003ca href=\"https://887d-2601-645-8000-3a90-9cb4-7d1b-d9b4-6714.ngrok.io/?ref=labelbox-guides.ghost.io\"\u003ehttps://887d-2601-645-8000-3a90-9cb4-7d1b-d9b4-6714.ngrok.io\u003c/a\u003e` and it will forward all requests to your localhost:3001. \u003c/p\u003e\u003cp\u003eIn your terminal, create a python file that contains the following code to receive webhook payload. Make sure to change your secret.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom flask import Flask, request\nimport hmac, hashlib\nimport json\nimport threading\nfrom werkzeug.serving import run_simple\n\n\n# This can be any secret that matches your webhook config (we will set later)\nsecret = b\"CHANGE-ME\"\n\n\n# Example for server-side code to receive webhook events\napp = Flask(__name__)\n\n\n@app.route(\"/webhook-endpoint\", methods=[\"POST\"])\ndef print_webhook_info():\n   payload = request.data\n   computed_signature = hmac.new(secret, msg=payload,\n                                 digestmod=hashlib.sha1).hexdigest()\n   if request.headers[\"X-Hub-Signature\"] != \"sha1=\" + computed_signature:\n       print(\n           \"Error: computed_signature does not match signature provided in the headers\"\n       )\n       return \"Error\", 500, 200\n\n\n   print(\"=========== New Webhook Delivery ============\")\n   print(\"Delivery ID: %s\" % request.headers[\"X-Labelbox-Id\"])\n   print(\"Event: %s\" % request.headers[\"X-Labelbox-Event\"])\n   print(\"Payload: %s\" %\n         json.dumps(json.loads(payload.decode(\"utf8\")), indent=4))\n   return \"Success\"\n\n\n\n\nthread = threading.Thread(target=lambda: run_simple(\"0.0.0.0\", 3001, app))\nthread.start()\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen run this script to start receiving requests from the ngrok address:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003engrok http 3001\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow, you can configure a webhook in Quantumworks Lab's Project setting. \u003c/p\u003e\u003cul\u003e\u003cli\u003eClick \u003cem\u003eSet up webhook\u003c/em\u003e\u003c/li\u003e\u003cli\u003eChoose V2 as the version of the webhook\u003c/li\u003e\u003cli\u003ePaste in the ngrok address plus /webhook-endpoint. You will need to write the secret to match the secret you specified in your app.py script \u003c/li\u003e\u003cli\u003eFinally, select the topics you want to subscribe to\u003cbr\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-122ef535-e118-494c-b065-4981a49f313d.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"876\" height=\"1110\"\u003e\u003c/figure\u003e\u003cp\u003eNow that you've created a webhook, everytime there is a new event triggered (such as updating a label), you will receieve the payload at / webhook-endpoint. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2023/05/data-src-image-bfd67059-8a6a-4e42-a232-ab9621d473a1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"927\"\u003e\u003c/figure\u003e\u003chr\u003e\u003cp\u003eThe improved and datarow-centric format of Export v2 empowers you to export with more granularity by including or excluding variables based on your project’s unique needs. Offering a more seamless user experience, the new export format more consistently mirrors our import format and aligns with annotation schema available in the platform.\u003c/p\u003e\u003cp\u003eAs you migrate from Export v1 to Export v2 workflows, please refer to our \u003ca href=\"https://docs.labelbox.com/reference/export-v2-glossary?ref=labelbox-guides.ghost.io\"\u003edocumentation \u003c/a\u003efor more detailed instructions on how to export your data through the UI or through the Python SDK.\u003c/p\u003e","comment_id":"645007f474911d003db0cb11","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/05/Frame-2299--3-.png","featured":false,"visibility":"public","created_at":"2023-05-01T18:41:56.000+00:00","updated_at":"2023-10-27T17:01:36.000+00:00","published_at":"2023-05-01T23:08:32.000+00:00","custom_excerpt":"With Export V2, you can export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-export-your-data-with-more-granular-control","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"url":"https://labelbox-guides.ghost.io/how-to-export-your-data-with-more-granular-control/","excerpt":"With Export V2, you can export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":"Introducing Export V2: How to export data with more granular control","og_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","twitter_image":null,"twitter_title":"Introducing Export V2: How to export data with more granular control","twitter_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","meta_title":"Introducing Export V2: How to export data with more granular control","meta_description":"Learn how to export your data with more granular control. Filter for specific data rows to export, configure the export to include or exclude information, and more. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6406883577b361003d3619d5","uuid":"4ab62fd8-b9da-474e-a833-f24758c230db","title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","slug":"using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data","html":"\u003cp\u003eOne of the biggest challenges that ML teams face is how difficult it is to select the right data to improve their ML models. From working with hundreds of teams, we’ve seen that ML teams possess a vast amount of unlabeled data, but lack a structured process for effectively finding and prioritizing \u003cem\u003especific data\u003c/em\u003e that can dramatically improve model performance. \u003c/p\u003e\u003cp\u003eThis manifests itself in the form of trying to find specific examples of an edge case where your model is struggling, or in the case of wanting to surface all occurrences of a rare data point that needs to be labeled in priority. In these cases, what is the best way for your team to efficiently surface this high-impact data?\u003c/p\u003e\u003ch2 id=\"what-will-you-learn-in-this-guide\"\u003eWhat will you learn in this guide? \u003c/h2\u003e\u003cp\u003eIn this guide, we'll show you how you can use a foundation model, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data. This technique will help your team quickly enrich your data with the latest advances in off-the-shelf models and embeddings.\u003c/p\u003e\u003cp\u003eBy the end of this guide, you’ll know how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGenerate custom embeddings with Hugging Face using a single line of code and upload your data to Quantumworks Lab in order to better explore and visualize your data.\u003c/li\u003e\u003cli\u003eBetter understand the distribution of your data and quickly find similar high-impact data.\u003c/li\u003e\u003cli\u003eUse Quantumworks Lab as a native similarity search engine, where you can leverage both off-the-shelf embeddings computed by Quantumworks Lab (for image, text, and documents) and upload your own custom embeddings to quickly find all instances of similar data.\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"what-are-embeddings\"\u003eWhat are embeddings? \u003c/h2\u003e\u003cp\u003eIn machine learning, an embedding, or feature vector, is an array of numbers assigned to an asset by a neural net. Assets that have similar content will also have similar embeddings. \u003c/p\u003e\u003cp\u003eFor example, in a dataset comprising images of apples and oranges, an appropriate embedding used for image similarity will show that all the vectors corresponding to apples have similar values. The vectors for all images of oranges will also be grouped together. \u003c/p\u003e\u003cp\u003eIn other words, the neural network acts as a feature extractor: it extracts an embedding vector that contains rich information about the data.\u003c/p\u003e\u003ch3 id=\"off-the-shelf-embeddings-vs-custom-embeddings\"\u003eOff-the-shelf embeddings vs custom embeddings\u003c/h3\u003e\u003cp\u003eWhen you connect your data to Quantumworks Lab, we automatically compute \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#supported-embeddings\"\u003eoff-the-shelf\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003eembeddings on your data – this includes CLIP embeddings for images and PDFs and All-mpnet-base-v2 embeddings for text. These off-the-shelf embeddings are a useful starting point for you to explore your data and conduct similarity searches. \u003c/p\u003e\u003cp\u003eHowever, in some cases where your data has unique attributes, you may want to use your own \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#how-to-upload-custom-embeddings\"\u003ecustom embeddings\u003c/a\u003e to power your data selection. Quantumworks Lab allows you to upload up to 100 custom embeddings in addition to the off-the-shelf embeddings that are automatically computed. \u003c/p\u003e\u003cp\u003eYou can easily compare the results of these custom and provided off-the-shelf embeddings in Quantumworks Lab to discover the best embeddings to use for data selection.\u003c/p\u003e\u003ch2 id=\"how-to-upload-custom-embeddings\"\u003eHow to upload custom embeddings\u003c/h2\u003e\u003cp\u003eFirst, connect your data with Labelbox. You can integrate your cloud storage bucket with Quantumworks Lab via IAM delegated access:\u003c/p\u003e\u003cp\u003e\u003cem\u003eHow to set up a delegated access integration with Quantumworks Lab\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-amazons3-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eAmazon S3\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-gcp-storage-labelbox/?ref=labelbox-guides.ghost.io\"\u003eGCP Storage\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-azure-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eMicrosoft Azure Blob Storage\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve successfully uploaded your data, Quantumworks Lab will automatically compute off-the-shelf embeddings on your data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1013\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can then compute and upload custom embeddings from Hugging Face on your data:\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eGoogle Colab notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003cem\u003eFollow along in this \u003c/em\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eColab notebook \u003c/em\u003e\u003c/a\u003e\u003cem\u003ewith examples shown using ResNet-50 embeddings from Hugging Face.\u003c/em\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003eImport Quantumworks Lab into your notebook\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for Quantumworks Lab\n!pip3 install -q Quantumworks Lab[data]\nimport Quantumworks Lab as lb\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e2. Import the \u003ca href=\"https://github.com/Quantumworks Lab/advlib/tree/main/pylib/advlib?ref=labelbox-guides.ghost.io\"\u003eADVLib\u003c/a\u003e. This is a library built by Quantumworks Lab for you to upload custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for custom embeddings in Quantumworks Lab\n!pip3 install -q 'git+https://github.com/Quantumworks Lab/advlib.git'\n#ndjson\n!pip3 install -q ndjson\nimport ndjson\nimport time\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e3. Select the data rows (images or text) in Quantumworks Lab on which you want to add custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# get images from a Quantumworks Lab dataset\ndataset = client.get_dataset(\"clemr01l42uil07y36qkq7ygn\")\ndrs = list(dataset.export_data_rows(timeout_seconds=9999))\ndata_row_ids = [dr.uid for dr in drs]\ndata_row_urls = [dr.row_data for dr in drs]\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e4. Use Hugging Face to generate your custom embeddings by loading a specific neural network (e.g. Resnet50).\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# import HuggingFace\n!pip3 install -q transformers\n!pip3 install -q timm\n\n# load a neural network from HuggingFace \nimport transformers\ntransformers.logging.set_verbosity(50)\nimport torch\nimport torch.nn.functional as F\nimport PIL, requests\nfrom tqdm import tqdm\n\n# get ResNet-50\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nmodel = transformers.ResNetModel.from_pretrained(\"microsoft/resnet-50\")\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cbr\u003e5. Generate custom embeddings by iterating over your image or text data. \u003c/p\u003e\u003cp\u003e\u003cem\u003eNote: \u003c/em\u003eThis should take approximately ~2 minutes for 512 images. For the similarity search function to work in Quantumworks Lab, you must upload at least 1,000 embeddings. \u003c/p\u003e\u003cul\u003e\u003cli\u003eRetrieve your images/text and run model inference \u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# process images\nimg_hf = image_processor(imgs, return_tensors=\"pt\")\n\n# generate resnet embeddings, thanks to inference\nwith torch.no_grad():\n\tlast_layer = model(**img_hf, output_hidden_states=True).last_hidden_state\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\u003cli\u003eRemember to do global pooling on the last layer of your embedding to reduce dimensionality\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e6. Create the payload to upload custom embeddings to Quantumworks Lab in the form of an NDJSON file.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# create the payload\npayload = []\nfor (dr_id,resnet_embedding) in zip(dr_ids, resnet_embeddings):\n\tpayload.append({\"id\": dr_id, \"vector\": resnet_embedding})\n\n# write to NDJson file\nwith open('payload.ndjson', 'w') as f:\n\tndjson.dump(payload, f)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e7. Pick an existing custom embedding or create a custom embedding.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# max pool to reduce dimensionality\nresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\n\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e8. Upload your payload of custom embeddings into Labelbox.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!advtool embeddings import \u0026lt;EMB ID\u0026gt; ./payload.ndjson\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e9. Use Quantumworks Lab Catalog UI to start conducting similarity searches.\u003c/p\u003e\u003ch2 id=\"how-to-quickly-find-instances-of-similar-data\"\u003eHow to quickly find instances of similar data\u003c/h2\u003e\u003cp\u003eOnce you have uploaded your custom embeddings to Quantumworks Lab, you can focus on curating data in Catalog that will dramatically improve your model’s performance.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eIdentify an edge case or rare example image/text you want to use to find similar data.\u003c/strong\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThis can include examples of data on which your model might be struggling. For example, let’s say the model is incorrectly classifying images with sparse patches of grass as having been affected by a wildfire. \u003c/p\u003e\u003cp\u003eIn the example below, the model appears to struggle on recognizing images with ‘no wildfire'\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1530\" height=\"736\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1530w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e2. Surface all instances of similar data.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1775\" height=\"959\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-16-47--1--1.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-16-47--1--1.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-16-47--1--1.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif 1775w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can run \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io\"\u003esimilarity searches\u003c/a\u003e to find all instances of similar data. A similarity search will automatically surface all similar data rows – you can select multiple data rows as anchors to continue to refine your similarity search. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Combine a similarity search with other search filters.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo filter the dataset even further, you can combine a similarity search with other \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003esearch filters\u003c/a\u003e. This includes filtering on metadata, media attribute, annotation, and more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1516\" height=\"824\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1516w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e4. Compare similarity search results.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1772\" height=\"964\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-23-53--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-23-53--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-23-53--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif 1772w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can compare the results of the similarity search on different embeddings (across off-the-shelf and custom embeddings). This gives you an understanding of which embeddings are most effective towards providing your desired results. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e5. Add all instances of similar data to a labeling project or save it as a slice.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve found additional examples of similar data rows on which your model is struggling, you can queue them to your labeling project in priority or save the filters as a slice. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1774\" height=\"954\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-29-38--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-29-38--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-29-38--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif 1774w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cbr\u003eBy saving your similarity search as a slice, any new incoming data that matches the search criteria will automatically show up in the slice. This enables automatic data curation.\u003c/p\u003e\u003cp\u003eLearn more about other key ML workflows that you can perform using similarity search \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003ein this guide\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eLeveraging embeddings as a powerful similarity search technique can help you find specific data points within an ocean of data. With a similarity search, you can easily query and curate specific data that will dramatically improve your model performance. If you’re interested in learning more, please check out the additional resources below.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdditional resources:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-kickstart-and-scale-your-data-labeling-efforts/?ref=labelbox-guides.ghost.io\"\u003eHow to kickstart and scale your data labeling efforts\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eHow to filter and sort your data\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003eHow to find similar data in one click\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"6406883577b361003d3619d5","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3012--4-.png","featured":false,"visibility":"public","created_at":"2023-03-07T00:41:25.000+00:00","updated_at":"2024-02-02T18:28:44.000+00:00","published_at":"2023-03-08T19:31:53.000+00:00","custom_excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-imapctful-data","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa513375d13000123d7ea","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/","excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","reading_time":6,"access":true,"comments":false,"og_image":null,"og_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","og_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","twitter_image":null,"twitter_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","twitter_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","meta_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","meta_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}],"tag":{"slug":"explore-manage-data","id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","count":{"posts":19},"url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},"slug":"explore-manage-data","currentPage":1},"__N_SSG":true},"page":"/guides/tag/[id]","query":{"id":"explore-manage-data"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script>
    

    

    <footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>

                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><span style="color: inherit; cursor: default;">Docs</span></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="/static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <span style="color: inherit; cursor: default;">Terms of Service</span>
                    <div class="footer-divider"></div>
                    <span style="color: inherit; cursor: default;">Privacy Notice</span>
                    <div class="footer-divider"></div>
                    <span style="color: inherit; cursor: default;">Copyright Dispute Policy</span>
                </div>
            </div>
        </div>
    </footer>
</body>
<!-- Mirrored from labelbox.com/guides/tag/explore-manage-data/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 11:32:13 GMT -->
</html>