<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/guides/tag/label-data-for-ai/page/5/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:28:27 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Guides | Quantumworks Lab</title><meta name="description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><link rel="preconnect" href="../../../../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta property="og:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta property="og:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="og:image" content="/static/images/guides-social.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta name="twitter:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="twitter:image" content="/static/images/guides-social.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../../../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../../../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../../../../static/scripts/munchkin.js"></script><script src="../../../../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../../../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../../../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../../../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../../../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../../../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../../../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../../../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../../../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../../../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../../../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../../../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../../../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../../../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../../../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../../../../_next/static/chunks/5008-6b2f21a0ee7e9705.js" defer=""></script><script src="../../../../../_next/static/chunks/pages/guides/tag/%5bid%5d/page/%5bpagenum%5d-da4e9ee1c105845a.js" defer=""></script><script src="../../../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../../../../index.html"><img width="106" height="24" alt="logo" src="../../../../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><div class="py-12 md:py-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3"><div class="sticky top-24"><img src="../../../../../static/images/guide.svg" class="h-10"/><h1 class="font-future text-2xl md:text-4xl font-bold my-5">Guides</h1><p class="text-base max-w-xs text-neutral-500  pr-6">Covering everything you need to know in order to build AI products faster.</p><div class="pb-4 md:pb-0"><div class="flex relative  md:max-w-xs my-10  md:pr-6"><input type="text" class="bg-transparent border-[1px] border-solid border-black w-full rounded-md pl-10 p-2 focus-visible:outline-none" placeholder="Search..."/><img class="absolute top-3 left-0 ml-2 w-6" src="../../../../../static/images/library/large_search_icon.svg"/></div></div><div class="hidden md:flex md:flex-col"><a href="../../../../index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Latest</a><a href="../../../build-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Build AI</a><a href="../../../use-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Use AI</a><a href="../../../explore-manage-data/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Explore &amp; manage data</a><a href="../../index.html" class="text-base text-neutral-900 font-medium hover:text-neutral-800 mb-4">Label data for AI</a><a href="../../../train-fine-tune-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Train &amp; fine-tune AI</a><a href="../../../mlops/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">MLOps</a></div></div></div><div class="col-span-12 md:col-span-9"><div class="grid grid-cols-12 gap-6"><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-annotate-conversational-text-for-chatbot-use-cases/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/index34a1.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2792.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-annotate-conversational-text-for-chatbot-use-cases/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to annotate conversational text for chatbot use cases</p><p class="text-base max-w-2xl undefined line-clamp-3">Teams can easily train an open-source model on their own data and use Quantumworks Lab&#x27;s suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexdf6b.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2760.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to run model-assisted labeling and active learning on NER data with a 🤗Hugging Face model</p><p class="text-base max-w-2xl undefined line-clamp-3">Efficiently improve models in development and production by using a third-party model, such as HuggingFace, to guide and identify targeted improvements in your training data to boost model performance. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../fundamental-elements-of-the-labelbox-editor/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexfa31.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F09%2FGroup-2710.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../fundamental-elements-of-the-labelbox-editor/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Fundamental elements of the Quantumworks Lab editor</p><p class="text-base max-w-2xl undefined line-clamp-3">Aligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab Editor.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-create-and-manage-ontologies/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexf982.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FGroup-2791--9-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-create-and-manage-ontologies/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to create and manage ontologies and features</p><p class="text-base max-w-2xl undefined line-clamp-3">Ontologies are an essential part of Quantumworks Lab&#x27;s platform. You&#x27;ll need to select an ontology when you create a new project or model. Learn how to create, reuse, and manage your ontologies and features. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../data-labeling/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexf0fe.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../data-labeling/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Data labeling for AI</p><p class="text-base max-w-2xl undefined line-clamp-3">Get a primer on data labeling, defined as the task of detecting and tagging data with labels, most commonly in the form of images, videos, audio and text assets.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../image-segmentation/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexb959.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FSocial-Card_Image-annotation-1.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../image-segmentation/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to create high-quality image segmentation masks quickly and easily</p><p class="text-base max-w-2xl undefined line-clamp-3">Image segmentation is used to label images for applications that require high accuracy and is manually intensive.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../image-annotation/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/index84d6.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F10%2FScreen-Shot-2022-10-03-at-10.17.25-AM.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../image-annotation/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Best practices for successful image annotation</p><p class="text-base max-w-2xl undefined line-clamp-3">Image annotation is defined as the task of annotating an image with labels. Discover how an AI data engine supports image annotation at scale.</p></a></div></div></div></div></div><div class="col-span-12"><div class="flex align-items-center justify-content-center mx-auto mt-8"><a class="mr-9 text-neutral-700 mb-1" href="../4/index.html">&lt;</a>Page 5 of 5</div></div></div></div></div></div><footer class="Footer__StyledFooter-sc-u68pnv-0 eJChXt"><div class="undefined lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="py-24"><div class=" w-full h-[1px] bg-neutral-200"></div></div><div class="hidden md:block"><img src="../../../../../static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36"/></div><section class="hidden md:grid footer-grid"></section><section class="social-media"></section><div class="text-center "><p class="font-normal text-base text-neutral-900 dark:text-neutral-50" style="font-family:&quot;IBM Plex Mono&quot;, sans-serif;font-size:14px;font-feature-settings:unset">© Quantumworks Lab, Inc <br/>We enable breakthroughs</p><div class="flex flex-row flex-wrap justify-content-center gap-4 mt-4"><a href="https://docs.labelbox.com/page/terms-of-service" class=" " target="_blank"><p class="font-normal text-base text-neutral-900 dark:text-neutral-50" style="font-family:&quot;IBM Plex Mono&quot;, sans-serif;font-size:14px;font-feature-settings:unset">Terms of Service</p></a><div class="mx-1 border"></div><a href="https://docs.labelbox.com/page/privacy-notice" target="_blank"><p class="font-normal text-base text-neutral-900 dark:text-neutral-50" style="font-family:&quot;IBM Plex Mono&quot;, sans-serif;font-size:14px;font-feature-settings:unset">Privacy Notice</p></a><div class="mx-1 border hidden sm:block"></div><a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank"><p class="font-normal text-base text-neutral-900 dark:text-neutral-50" style="font-family:&quot;IBM Plex Mono&quot;, sans-serif;font-size:14px;font-feature-settings:unset">Copyright Dispute Policy</p></a></div></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"id":"633629c01beec0003d38bdf3","uuid":"b2f4bcf2-b0bf-4906-a6bd-2571ed491fea","title":"How to annotate conversational text for chatbot use cases","slug":"how-to-annotate-conversational-text-for-chatbot-use-cases","html":"\u003cp\u003eAs AI continues to grow, there's been a rapid adoption in the industrial application of language-based models. Teams interested in training chatbots or other language models can now use Quantumworks Lab's Conversational Text editor. \u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/7b3knr04l0\" title=\"How to annotate conversational text for chatbot use cases Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eOur Conversational Text editor allows teams to create unique message-based classifications that can identify user intent or sentiment. Teams can easily train an open-source model on their own data and use Quantumworks Lab's suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWith our Conversational Text editor, teams can:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eNatively \u003ca href=\"https://docs.labelbox.com/reference/text-conversational?ref=labelbox-guides.ghost.io\"\u003eimport\u003c/a\u003e conversational text or thread-based messages\u003c/li\u003e\u003cli\u003eCreate \u003ca href=\"https://docs.labelbox.com/docs/conversational-annotations?ref=labelbox-guides.ghost.io#entity\"\u003eentities\u003c/a\u003e for NER \u003c/li\u003e\u003cli\u003eCreate \u003ca href=\"https://docs.labelbox.com/docs/conversational-annotations?ref=labelbox-guides.ghost.io#message-based-classifications---radio\"\u003emessage-based classifications\u003c/a\u003e to identify user intent or sentiment \u003c/li\u003e\u003cli\u003eCreate radio, checklist, or free-form text classifications\u003c/li\u003e\u003cli\u003eCreate \u003ca href=\"https://docs.labelbox.com/docs/conversational-annotations?ref=labelbox-guides.ghost.io#relationship\"\u003eannotation relationships\u003c/a\u003e between entities\u003c/li\u003e\u003cli\u003eUse \u003ca href=\"https://docs.labelbox.com/docs/conversational-annotations?ref=labelbox-guides.ghost.io#text-specific-hotkeys\"\u003ehotkeys\u003c/a\u003e to speed up labeling\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo learn more about our Conversational Text editor, refer to our \u003ca href=\"https://docs.labelbox.com/docs/conversational-annotations?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e","comment_id":"633629c01beec0003d38bdf3","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2792.png","featured":false,"visibility":"public","created_at":"2022-09-29T23:26:56.000+00:00","updated_at":"2023-10-26T18:19:27.000+00:00","published_at":"2022-09-30T21:17:29.000+00:00","custom_excerpt":"Teams can easily train an open-source model on their own data and use Quantumworks Lab's suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/how-to-annotate-conversational-text-for-chatbot-use-cases/","tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5fc375d13000123d7f8","name":"Industry: Retail \u0026 e-commerce","slug":"industry-retail-e-commerce","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-retail-e-commerce/"},{"id":"653aa630375d13000123d800","name":"Industry: Manufacturing","slug":"industry-manufacturing","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-manufacturing/"},{"id":"653aa623375d13000123d7fe","name":"Industry: Internet \u0026 media","slug":"industry-internet-media","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-internet-media/"},{"id":"653aa608375d13000123d7fa","name":"Industry: Finance \u0026 insurance","slug":"industry-finance-insurance","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-finance-insurance/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-annotate-conversational-text-for-chatbot-use-cases/","excerpt":"Teams can easily train an open-source model on their own data and use Quantumworks Lab's suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.","reading_time":1,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2792-2.png","og_title":"How to annotate conversational text for chatbot use cases","og_description":"Teams can easily train an open-source model on their own data and use Quantumworks Lab's suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.","twitter_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2792-1.png","twitter_title":"How to annotate conversational text for chatbot use cases","twitter_description":"Teams can easily train an open-source model on their own data and use Quantumworks Lab's suite of tools across Annotate, Catalog, and Model to quickly tailor their language model to meet their specific business needs.","meta_title":"How to annotate conversational text for chatbot use cases | Quantumworks Lab","meta_description":"Teams can easily train an open-source model and use Quantumworks Lab to quickly tailor their language model to meet their specific business needs.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"632e177f16e912003d39b2bb","uuid":"3a1d718f-8dba-46ed-a8a3-d45ed71360b3","title":"How to run model-assisted labeling and active learning on NER data with a 🤗Hugging Face model","slug":"how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model","html":"\u003cp\u003eNot all data impacts model performance equally. In fact, a huge roadblock many teams face is being able to leverage automation to speed up labeling to go through even faster data-centric iterations. \u003c/p\u003e\u003cp\u003eIn this guide, we'll be showing you how you can efficiently improve models in development and production by using a third-party model, such as 🤗Hugging Face, to guide and identify targeted improvements in your training data to boost model performance. \u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/bn1is51w76\" title=\"How to run model-assisted labeling and active learning on NER data with a HuggingFace model Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTry the Colab: \u003ca href=\"https://colab.research.google.com/drive/1ovL6BiLqh81KXoSC1CYdOKuaOF6lAG3X?ref=labelbox-guides.ghost.io#scrollTo=-ZW42JeD22fq\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eLearn more about \u003ca href=\"https://docs.labelbox.com/docs/upload-model-predictions?ref=labelbox-guides.ghost.io\"\u003eActive Learning\u003c/a\u003e and the benefits of prioritizing high-value data\u003c/li\u003e\u003cli\u003eLearn more about \u003ca href=\"https://docs.labelbox.com/docs/upload-model-predictions?ref=labelbox-guides.ghost.io\"\u003ehow to import your model predictions \u0026amp; metrics\u003c/a\u003e in Quantumworks Lab\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://colab.research.google.com/drive/1ovL6BiLqh81KXoSC1CYdOKuaOF6lAG3X?ref=labelbox-guides.ghost.io#scrollTo=-ZW42JeD22fq\"\u003eGoogle Colab Notebook\u003c/a\u003e (used in the video) to run MAL and active learning on NER data with the Hugging Face model \u003c/li\u003e\u003c/ul\u003e","comment_id":"632e177f16e912003d39b2bb","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2760.png","featured":false,"visibility":"public","created_at":"2022-09-23T20:30:55.000+00:00","updated_at":"2023-10-26T18:16:11.000+00:00","published_at":"2022-09-23T22:47:09.000+00:00","custom_excerpt":"Efficiently improve models in development and production by using a third-party model, such as HuggingFace, to guide and identify targeted improvements in your training data to boost model performance. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model/","tags":[{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model/","excerpt":"Efficiently improve models in development and production by using a third-party model, such as HuggingFace, to guide and identify targeted improvements in your training data to boost model performance. ","reading_time":1,"access":true,"comments":false,"og_image":null,"og_title":"How to run model-assisted labeling and active learning on NER data with a HuggingFace model","og_description":"Efficiently improve models in development and production by using a third-party model, such as HuggingFace, to guide and identify targeted improvements in your training data to boost model performance. ","twitter_image":null,"twitter_title":"How to run model-assisted labeling and active learning on NER data with a HuggingFace model","twitter_description":"Efficiently improve models in development and production by using a third-party model, such as HuggingFace, to guide and identify targeted improvements in your training data to boost model performance. ","meta_title":"how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model | Quantumworks Lab","meta_description":"Efficiently improve models in development and production by using a third-party model, such as HuggingFace to boost model performance. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"632b4fb516e912003d39b1b6","uuid":"7e2371f4-daa6-4da2-a67a-6130f8fed8e6","title":"Fundamental elements of the Quantumworks Lab editor","slug":"fundamental-elements-of-the-labelbox-editor","html":"\u003cp\u003eAligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab editor.\u003c/p\u003e\u003cp\u003eFor a complete list of key definitions, check out our documentation \u003ca href=\"https://docs.labelbox.com/docs/key-definitions?ref=labelbox-guides.ghost.io\" rel=\"noopener noreferrer\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/fkluhsbns2\" title=\"Fundamental elements of the Quantumworks Lab Editor Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/annotation?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eAnnotation\u003c/strong\u003e\u003c/a\u003e: An instance of a Feature. Annotations can be imported as ground truth, model predictions, or can be created in the Quantumworks Lab editor. Annotations are categorized as \u003cem\u003eObjects\u003c/em\u003e (e.g. bounding box, polygon, etc) or \u003cem\u003eClassifications\u003c/em\u003e (e.g. radio, checklist, etc).\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/data-import-format-overview?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eAsset\u003c/strong\u003e\u003c/a\u003e: A single cloud-hosted file to be labeled (e.g., an image, a video, or a text file).\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/data-row?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eData Row\u003c/strong\u003e\u003c/a\u003e: The container that houses all of the following information for a single Asset:\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\t\u003cem\u003e\tURL to your cloud-hosted file\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e\t\tMetadata\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e\t\tMedia attributes (e.g data type, size, etc.)       \u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e\t\tAttachments (files that provide context for your labelers) \u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eEditor\u003c/strong\u003e\u003c/a\u003e: The labeling interface you can use to create, review, and edit annotations. When you create a project, you will be prompted to configure your editor (i.e., select an ontology, add labeling instructions, etc).\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/working-with-features?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eFeature\u003c/strong\u003e\u003c/a\u003e: A feature is the master definition of what you want the model to predict. It is also the blueprint for your ground truth. An ontology is made up of a set of features. There are two kinds of features: objects (e.g., Bounding box) and classifications (e.g., Radio). A feature can have multiple deeply nested sub-classifications.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/reference/label-export?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eLabel\u003c/strong\u003e\u003c/a\u003e: A collection of all annotations on a Data Row. For example, all Bounding boxes, Polylines, and Radio classifications on an image would be considered the “Label”.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eOntology\u003c/strong\u003e\u003c/a\u003e: A collection of Features and their relationships (also known as a taxonomy). Ontologies can be reused across different projects. It is essential for data labeling, model training, and evaluation. When you are in the editor, the ontology is what appears in the “Tools” panel.\u003c/li\u003e\u003c/ul\u003e","comment_id":"632b4fb516e912003d39b1b6","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2710.png","featured":false,"visibility":"public","created_at":"2022-09-21T17:53:57.000+00:00","updated_at":"2023-10-26T18:02:56.000+00:00","published_at":"2022-09-22T15:33:25.000+00:00","custom_excerpt":"Aligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab Editor.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/fundamental-elements-of-the-labelbox-editor/","tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/fundamental-elements-of-the-labelbox-editor/","excerpt":"Aligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab Editor.","reading_time":1,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2710-2.png","og_title":"Fundamental elements of the Quantumworks Lab editor","og_description":"Aligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab Editor.","twitter_image":"https://labelbox-guides.ghost.io/content/images/2022/09/Group-2710-1.png","twitter_title":"Fundamental elements of the Quantumworks Lab editor","twitter_description":"Aligning with your team on key terms used in Quantumworks Lab will serve to greatly enhance collaboration and cohesiveness throughout your work in the platform. In this brief video, we introduce the fundamental elements of the Quantumworks Lab Editor.","meta_title":"Fundamental elements of the Quantumworks Lab editor | Quantumworks Lab","meta_description":"Aligning with your team on key terms used in Quantumworks Lab will  greatly enhance collaboration and cohesiveness throughout your work in the platform","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6344b98cb75421003d6e6019","uuid":"5a7fea79-24bd-4241-a5cd-841e07066f08","title":"How to create and manage ontologies and features","slug":"how-to-create-and-manage-ontologies","html":"\u003cp\u003eA clean, thoughtful ontology is critical for creating high-quality labeled data with minimal errors and inconsistencies. Ontologies are an essential part of the Quantumworks Lab labeling platform. Every time you create a project or a model in Quantumworks Lab, you will need to select an ontology.\u003c/p\u003e\u003cp\u003eOntologies and features should be created and managed with the goals of proper labeling, efficiency, and reusability in mind.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/nuxpfgxd6x\" title=\"How to create and manage ontologies \u0026amp; features Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003eWhen creating and implementing an ontology, here are some helpful tips to consider:\u003c/p\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThoroughly understand the task and the tools at your disposal.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReview the basic documentation for \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eOntologies\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/working-with-features?ref=labelbox-guides.ghost.io\"\u003eFeatures\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eCheck the \u003ca href=\"https://docs.labelbox.com/docs/image-annotations?ref=labelbox-guides.ghost.io\"\u003esupported annotation types\u003c/a\u003e for different editors.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCreate an ontology that follows the most logical workflow for a labeler.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eChoose tools that will allow labelers to reach the highest speed and quality possible.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCreate and upload detailed \u003ca href=\"https://docs.labelbox.com/docs/labeling-instructions?ref=labelbox-guides.ghost.io\"\u003einstructions\u003c/a\u003e, considering known edge cases that labelers will encounter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTest your ontology in a brief trial run before sending the project to the labeling team.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"python-sdk\"\u003ePython SDK\u003c/h3\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/develop/examples/basics/ontologies.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eTry the Google Colab\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003cbr\u003e\u003cstrong\u003eCreate features and ontologies:\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\n# Import packages\nfrom Quantumworks Lab import OntologyBuilder, Tool, Classification, Option, Client\n\n# Establish client\nclient = Client()\n\n# Create a bounding box tool with a nested radio subclass\nobject_features = [\n    Tool(\n        tool=Tool.Type.BBOX,\n        name=\"regulatory-sign\",\n        color=\"#ff0000\",\n        classifications=[\n            Classification(\n                class_type=Classification.Type.RADIO,\n                instructions=\"Sign type\",\n                options=[\n                    Option(value=\"stop\", label=\"Stop\"),\n                    Option(value=\"one_way\", label=\"One way\")\n                ]\n            )\n        ]\n    )\n]\n\n# Create a global checklist classification\nclassification_features = [\n    Classification(\n        class_type=Classification.Type.CHECKLIST,\n        instructions=\"Quality Issues\",\n        options=[\n            Option(value=\"blurry\", label=\"Blurry\"),\n            Option(value=\"distorted\", label=\"Distorted\")\n        ]\n    )\n\n]\n\n# Use the above features to create an ontology\nontology_builder = OntologyBuilder(\n    tools=object_features,\n    classifications=classification_features\n)\n\nontology = client.create_ontology(\n    \"SDK Demo\",\n    ontology_builder.asdict()\n)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eCreate an ontology from existing features:\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Search for feature by name in your org\nfeature_1 = next(client.get_feature_schemas(\"\u0026lt;TOOL_NAME\u0026gt;\"))\nfeature_2 = next(client.get_feature_schemas(\"\u0026lt;TOOL_NAME\u0026gt;\"))\n\n# Get feature by feature schema ID (you can find this in the UI)\nfeature_3 = client.get_feature_schema(\"\u0026lt;FEATURE_SCHEMA_ID\u0026gt;\")\n\n# View the features\nprint(feature_1)\nprint(feature_2)\nprint(feature_3)\n\nontology = client.create_ontology_from_feature_schemas(\n    \"Ontology of shared features\", \n    [feature_1.uid, feature_2.uid, feature_3.uid]\n)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo view more common SDK methods for ontology management, check out our documentation \u003ca href=\"https://docs.labelbox.com/reference/ontology?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","comment_id":"6344b98cb75421003d6e6019","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Group-2791--9-.png","featured":false,"visibility":"public","created_at":"2022-10-11T00:32:12.000+00:00","updated_at":"2024-11-21T18:10:27.000+00:00","published_at":"2022-09-02T14:54:00.000+00:00","custom_excerpt":"Ontologies are an essential part of Quantumworks Lab's platform. You'll need to select an ontology when you create a new project or model. Learn how to create, reuse, and manage your ontologies and features. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/how-to-create-and-manage-ontologies/","tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-create-and-manage-ontologies/","excerpt":"Ontologies are an essential part of Quantumworks Lab's platform. You'll need to select an ontology when you create a new project or model. Learn how to create, reuse, and manage your ontologies and features. ","reading_time":1,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Group-2791--9--2.png","og_title":"How to create and manage ontologies and features","og_description":"Ontologies are an essential part of Quantumworks Lab's platform. You'll need to select an ontology when you create a new project or model. Learn how to create and manage your ontologies and features. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Group-2791--9--1.png","twitter_title":"How to create and manage ontologies and features","twitter_description":"Ontologies are an essential part of Quantumworks Lab's platform. You'll need to select an ontology when you create a new project or model. Learn how to create and manage your ontologies and features. ","meta_title":"How to create and manage ontologies and features | Quantumworks Lab","meta_description":"Ontologies are an essential part of Quantumworks Lab's platform. Learn how to create and manage your ontologies and features. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"635768d8a31ffb004d18ff6b","uuid":"48399a28-049e-4e5f-8556-5c654373a659","title":"Data labeling for AI","slug":"data-labeling","html":"\u003cp\u003eHaving an efficient data labeling and model evaluation process is an important foundation for any successful AI product. Your model is only as good as the data it's trained with, and part of the training process includes getting your data labeled quickly and accurately by highly skilled experts.\u003c/p\u003e\u003cp\u003eHowever, many companies typically approach this process by gathering and quickly labeling as much data as they possibly can to train their model. In reality, AI teams today need to focus more on the quality of their data in order to add advanced capabilities and reasoning to their frontier and task-specific\u0026nbsp; models.\u003c/p\u003e\u003cp\u003eHaving larger, low-quality datasets prolong the data labeling process and makes getting to production AI harder. Wading through a vast amount of unstructured data to get accurately labeled data requires a tremendous amount of patience, organization, and time. Ensuring that you have high quality data will save you time and money from decreased labeling costs.\u003c/p\u003e\u003ch2 id=\"what-is-data-labeling\"\u003eWhat is data labeling?\u003c/h2\u003e\u003cp\u003eData labeling has become a broad term that can apply to everything from annotating specific data types to providing feedback and ratings on complex responses from generative AI (GenAI) and LLMs. \u003c/p\u003e\u003cp\u003eHistorically, it has referred to the task of annotating data such as images, PDFs, text, videos or audio with the purpose of helping to teach a machine learning model to make similar annotations. Labels can include bounding boxes and \u003ca href=\"https://labelbox.com/guides/image-segmentation/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003esegmentation masks for image\u003c/u\u003e\u003c/a\u003e and text data, for example.\u003c/p\u003e\u003cp\u003eWith the rapid rise of GenAI, data labeling tools now often include powerful solutions for \u003ca href=\"https://labelbox.com/product/evals/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eevaluating and rating multimodal AI models\u003c/u\u003e\u003c/a\u003e in a chat arena style experience, \u003ca href=\"https://labelbox.com/solutions/response-generation/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003egenerating prompt/response pairs\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://labelbox.com/blog/multi-step-reasoning-teach-llms-to-think-critically/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eevaluating step-by-step reasoning\u003c/u\u003e\u003c/a\u003e, and more. These advanced rating tasks are often performed by highly skilled experts in a specific topic, such as coding, math, physics, medicine, and finance. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcmewYa8dZy5fqgwzjazBpu-8RytD6u34P9KlBdZuyCvzMsq3XiX08C3NzpUjhNviNJOpBRc4hELzoYvOKl9eHiDZAShb37hMMciMjEJKLZoL6WusnSAXXKsdCkrp62NrqN3d95mg?key=ggURVl5ZMBIeZKbEDFF3wmqE\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"377\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample of advanced data labeling of a complex, multi-step response \u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe data labeling process typically involves human-powered work in order to manually curate datasets or create new responses, and in some cases, computer-assisted help. The types of labels are predetermined by a machine learning engineer and are chosen to give a machine learning model specific information to train and improve the model from these examples. Labels can be as simple as deciding whether a photo contains a human all the way down to determining if the fifth step in a multi-step response is incorrect or unclear.\u003c/p\u003e\u003cp\u003eThe process of data labeling also helps machine learning engineers hone in on important factors that determine the overall precision and accuracy of their model. Example considerations include possible naming and categorization issues, how to represent occluded objects, how a model reasoned through an answer for a given prompt, etc. \u003c/p\u003e\u003ch2 id=\"how-does-data-labeling-work-and-why-is-it-important\"\u003eHow does data labeling work and why is it important?\u003c/h2\u003e\u003cp\u003eData labeling is a central part of the data pre-processing workflow for machine learning. Data labeling structures data to make it meaningful.\u003c/p\u003e\u003cp\u003eThis labeled data is then used to train a machine learning model to find “meaning” in new, relevantly similar data. Throughout this process, machine learning practitioners strive for both quality and quantity. Accurately labeled data coupled with a larger quantity creates more useful deep learning models, as the resulting machine learning model bases their decisions on all the labeled data.\u003c/p\u003e\u003cp\u003eTo illustrate from the example below, a human labeler applies a series of labels on an image asset by applying bounding boxes to the relevant objects, otherwise known as image labeling or \u003ca href=\"https://labelbox.com/guides/image-annotation/?ref=labelbox-guides.ghost.io\"\u003eimage annotation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn the example below, pedestrians are marked in blue and taxis are marked in yellow, while trucks are marked in yellow. Accurately identifying the cars from the pedestrians will yield a more successful model, which is defined as a model that can make accurate predictions when presented with new data (which in this case, are images of objects in a street view).\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/KGoZKy4JrIcD-B6COxYVIYksQ-yNkK-D7c6kNKmgIWds8xcOyJbWYf1HjR4aUTjmWmruyvM9ZUw79T6zko2uJjYTR7yBde1AUkNezqg6LMN1J1tAv-tGUsVo0rwFQiNYsR2_zCiLHh5I1rf7KJf8AYIeR7SCz6lYo6ljf9RoOwvPj-Jmt21OYVmTUg\" class=\"kg-image\" alt=\"In the example below, pedestrians are marked in blue and taxis are marked in yellow, while trucks are marked in yellow.\" loading=\"lazy\" width=\"728\" height=\"538\"\u003e\u003c/figure\u003e\u003cp\u003eThis process is then repeated, and depending on the business use case and project, the quantity of labels on each image can vary. Some projects will require only one label to represent the content of an entire image (e.g. \u003ca href=\"https://labelbox.com/usecases/computer-vision/image-classification/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eimage classification\u003c/a\u003e). Other projects could require multiple objects to be tagged within a single image, each with a different label (e.g., bounding boxes).\u003c/p\u003e\u003ch2 id=\"what-are-the-different-types-of-data-labeling\"\u003eWhat are the different types of data labeling?\u003c/h2\u003e\u003cp\u003eThere are many fields of AI, each working with a different type of data and requiring different data labeling types. The most common fields are \u003ca href=\"https://labelbox.com/solutions/generative-ai/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003egenerative AI\u003c/a\u003e, \u003ca href=\"https://labelbox.com/usecases/computer-vision/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ecomputer vision for image and video\u003c/a\u003e, \u003ca href=\"https://labelbox.com/usecases/natural-language-processing/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003enatural language processing\u003c/a\u003e (NLP) for text, and audio processing for speech recognition.\u003c/p\u003e\u003ch3 id=\"data-labeling-for-generative-ai\"\u003eData labeling for generative AI\u003c/h3\u003e\u003cp\u003eWith its potential to revolutionize industries and its impressive capabilities in content generation and problem-solving, generative AI has gained significant popularity in the AI space. By learning from existing data patterns, it creates original content, such as code, text, or images. To ensure optimal performance, generative AI models require high-quality, diverse data and human expertise for tasks like\u003ca href=\"https://labelbox.com/product/evals/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003e model evaluation\u003c/a\u003e,\u003ca href=\"https://labelbox.com/solutions/supervised-fine-tuning/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003e supervised fine-tuning (SFT)\u003c/a\u003e, \u003ca href=\"https://labelbox.com/solutions/rlhf/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eRLHF\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/solutions/red-teaming/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ered teaming\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eThese post-training tasks rely on quality data to expand the capabilities of frontier and task-specific models in areas like coding, text-to-image, text-to-audio, multilingual understanding, complex \u0026amp; agentic reasoning, and multimodal reasoning.  \u003c/p\u003e\u003ch3 id=\"data-labeling-for-computer-vision-with-image-and-video\"\u003eData labeling for computer vision with image and video\u003c/h3\u003e\u003cp\u003eA \u003ca href=\"https://labelbox.com/guides/computer-vision/?ref=labelbox-guides.ghost.io\"\u003ecomputer vision model\u003c/a\u003e is built to interpret visual data from images and videos to identify, classify, and extract further information about objects that appear in the data. The data labeling process for this type of model includes labeling images, much like in the example above. The computer vision model would then be trained with the labeled data to categorize images, recognize the position of objects, or identify objects of importance in an image. A real-world use case for this type of model includes helping retailers manage inventory by identifying different products on a shelf and the quantity of their stock.\u003c/p\u003e\u003ch3 id=\"data-labeling-for-nlp\"\u003eData labeling for NLP\u003c/h3\u003e\u003cp\u003eNatural language processing (NLP) is a branch of AI that gives models the ability to understand natural language as it is spoken or written. This form of data labeling requires labelers to identify important sections of text or tag text with specific labels to train the model. The model would then develop the ability to understand and interpret the text, even when it's worded slightly differently. \u003c/p\u003e\u003cp\u003eA common real-world use case for this model is a chatbot built for customer support. Using this model, a \u003ca href=\"https://labelbox.com/guides/how-to-train-a-chatbot/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003echatbot\u003c/a\u003e would be able to understand the question, “When is my package being delivered?” even when phrased differently by different customers, such as “When will my package be delivered?” or “What is the delivery date of my package?” and answer accordingly.\u003c/p\u003e\u003ch3 id=\"audio-processing-for-speech-recognition\"\u003eAudio processing for speech recognition\u003c/h3\u003e\u003cp\u003eAudio processing converts sounds into structured data so it can be used for model training and improvement. This data labeling process actually goes hand-in-hand with NLP, as it typically requires the audio to first be transcribed into text before it is labeled.\u003c/p\u003e\u003cp\u003eA common real-world use case for this is any type of virtual assistant commands. When you ask your phone, “What is the weather like today?” and receive an answer, this interaction is enabled by the data labeling process for audio.\u003c/p\u003e\u003ch2 id=\"how-does-labelbox-support-data-labeling\"\u003eHow does Quantumworks Lab support data labeling?\u003c/h2\u003e\u003cp\u003eData labeling projects begin by identifying and instructing human labelers (otherwise known as annotators or raters) to perform labeling tasks. Annotators must be thoroughly trained on the specifications and guidelines of each annotation project, as every use case, team, and organization will have different requirements.\u003c/p\u003e\u003cp\u003eIn the specific case of images and videos, once the annotators are trained on how to annotate or label the data, they will begin labeling hundreds or thousands of images or videos, often using home-grown or open-source labeling tools. \u003c/p\u003e\u003cp\u003eLabelbox’s AI data factory offers three key components necessary to delivering high-quality labeled data: highly-skilled humans, best-in-class software, and operational excellence. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox’s Labeling Services\u003c/u\u003e\u003c/a\u003e, powered by Alignerrs, offers a proven community of subject matter experts in a wide range of domains and languages to help align and improve your AI models by generating high-quality data. If you are looking to quickly onboard and customize your own team of experts, use \u003ca href=\"https://labelbox.com/services/alignerr-connect/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eAlignerr Connect\u003c/u\u003e\u003c/a\u003e to directly discover, select, and recruit qualified AI trainers to connect these experts directly with your internal processes.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOur data-centric AI platform is software that is designed to have all the necessary tools for labeling any data modality. This type of software also promotes an iterative approach to data labeling. Instead of using one large dataset to train your model, Quantumworks Lab equips AI teams with the tools they need to label data in smaller batches. This approach means AI teams give more supervision and feedback at the beginning of the project and create a more agile process. This type of approach prioritizes two-way collaboration between the labelers and AI teams to ensure that the data labeling process is efficient and accurate.\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, you can achieve operational excellence while maintaining total transparency. Our services and platform offers customizable workflows, multi-step review and rework, and \u003ca href=\"https://labelbox.com/blog/ai-code-and-grammar-critic-improve-quality/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLLM as a judge\u003c/u\u003e\u003c/a\u003e, all accessible through a user-friendly interface to help you continuously generate the highest quality data.\u003c/p\u003e\u003cp\u003eLabelbox sets itself apart by combining a scientific approach to data quality with large-scale operations. Last month alone, we facilitated the creation of over 50 million annotations, requiring over 200,000 human hours. By continuously monitoring and analyzing data quality, we ensure immediate improvements and optimize your data labeling projects.\u003c/p\u003e\u003cp\u003e\u0026nbsp;To further enhance data quality and efficiency, we offer a range of features to optimize your data labeling projects.\u003c/p\u003e\u003ch3 id=\"high-performance-data-labeling-tools\"\u003e\u003cstrong\u003eHigh-performance data labeling tools\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWhen looking for the right AI platform for your team, it’s important to ensure that the software supports enough labels and annotations per asset without sacrificing loading times. This way, you’ll be able to use the AI platform for both simple and complex use cases, which may be a requirement in the future for your team.\u003c/p\u003e\u003ch3 id=\"customization-based-on-ontology-requirements\"\u003e\u003cstrong\u003eCustomization based on ontology requirements\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe ability to configure an AI platform to your exact data structure (ontology) requirements enables you to ensure consistency and scalability in the data labeling process as your use cases expand. Quantumworks Lab provides a convenient way to copy your ontology across multiple projects so that you can make cascading changes or use an existing ontology as a starting point rather than starting from scratch.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/yi9z-000uuamEgNcR1Rx6Zv7dNaGKi_KARwDF5L11YTMVeILEcTw-EKue0lz5QsYLc6waBK-xoVIDH5WLCOGlB7Ui8ECPWNcxBIpl1KPpZ9deWNNZSsbKB36SAKpKQgC3Uxx26mmmNXIoZ2ZnCNvcK3ymBfducw_HEASEqIrXqjsVIABWiHGWwaj8A\" class=\"kg-image\" alt=\"Quantumworks Lab allows you to configure the label editor to your ontology requirements. Bring additional attachments such as text, videos, images, overlays, or even custom widgets to aid data labelers to create perfect labels.\" loading=\"lazy\" width=\"1444\" height=\"1174\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eLabelbox allows you to configure the label editor to your ontology requirements. Bring additional attachments such as text, videos, images, overlays, or even custom widgets to aid data labelers to create perfect labels.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"an-emphasis-on-performance-for-a-wide-array-of-devices\"\u003e\u003cstrong\u003eAn emphasis on performance for a wide array of devices\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eA data-centric AI platform includes an intuitive user interface, which helps lower the cognitive load on labelers and enables fast data labeling. Even on lower spec PCs and laptops, high performance is critical for professional annotators who are working in an editor all day.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/TLqBOVgb-6XCHSr3BE42mhNlOm5MZUSSvGYbIWEi7JHek6tREPFQYH6Vb_G_AitECjDCy-iZngI4Sck3xSfFhphCxnP1PvR-Ivd-pOiKtMVu1SgoN2R9PYsmR13rPvj8NMDJYTSXa9swmSa2MOcELgwDNha71jTf6w52UfBmybbEK3fhywCobZgl8A\" class=\"kg-image\" alt=\"A simple, intuitive UI reduces friction in the data labeling process.\" loading=\"lazy\" width=\"1600\" height=\"936\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA simple, intuitive UI reduces friction in the data labeling process.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"seamlessly-connect-your-data-via-python-sdk-or-api-for-easy-data-labeling\"\u003e\u003cstrong\u003eSeamlessly connect your data via Python SDK or API for easy data labeling\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eStream data into an AI platform and push labeled data into training environments like TensorFlow and PyTorch. Quantumworks Lab was built to be developer friendly and API-first, so you can use it as infrastructure to scale up and connect your ML models to accelerate data labeling productivity and orchestrate active learning.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/A7Kv8_sI8c0PaU8KobZPqI38H4rHFByIUHRPSxMf8NgCbB7aqoYZosGNlzanv2HiRHoN3_mw5s_aV201P12sC87ezaP7FciE5K-YgN4HXnZFk7y7vmxBqxriOPBpJzdBje3F6isYITYtekx6Djsd_un3d2i7-TqkBj0h2vm_EDpBIq7qZe0QEHotxA\" class=\"kg-image\" alt=\"Simplified data import without writing and maintaining your own scripts.\" loading=\"lazy\" width=\"1600\" height=\"1000\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSimplified data import without writing and maintaining your own scripts.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"benchmarks-consensus-for-data-labeling\"\u003e\u003cstrong\u003eBenchmarks \u0026amp; consensus for data labeling\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eQuality is measured by both the consistency and the accuracy of labeled data. The industry standard methods for calculating data quality are benchmarks (aka gold standard), consensus, and review.\u003c/p\u003e\u003cp\u003eFiguring out what combination of these quality assurance procedures is right for your machine learning project is an essential part of an AI data scientist’s job.\u0026nbsp;In a recent blog post, we \u003ca href=\"https://labelbox.com/blog/inside-the-data-factory-how-labelbox-produces-the-highest-quality-data-at-scale/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003elook deep inside the Quantumworks Lab AI data factory\u003c/u\u003e\u003c/a\u003e, revealing important tools, techniques and processes that are the bedrock for producing the highest-grade data at scale.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cp\u003eQuality assurance is an automated process that operates continuously throughout your training data development and improvement processes. \u003ca href=\"https://docs.labelbox.com/docs/benchmarks?ref=labelbox-guides.ghost.io#:~:text=The%20Benchmarks%20tool%20allows%20you,Benchmark%20Label%20on%20the%20asset.\"\u003eWith Quantumworks Lab consensus and benchmark features\u003c/a\u003e, you can automate consistency and accuracy tests. These tests allow you to customize the percentage of your data to test and the number of labelers that will annotate the test data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/10/Untitled-removebg-preview-1.png\" class=\"kg-image\" alt=\"Benchmarks in action, highlighting the example labeled asset with a gold star.\" loading=\"lazy\" width=\"678\" height=\"368\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/10/Untitled-removebg-preview-1.png 600w, https://labelbox-guides.ghost.io/content/images/2022/10/Untitled-removebg-preview-1.png 678w\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eBenchmarks in action, highlighting the example labeled asset with a gold star.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eLabelbox also offers private, human-centric evaluations to complement traditional benchmarks with what we believe is a more accurate assessment of AI models. By incorporating expert human judgement, addressing challenges around current benchmarks, and providing comprehensive metrics for various AI modalities, \u003ca href=\"https://labelbox.com/blog/labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox Leaderboards\u003c/u\u003e\u003c/a\u003e aims to offer a more accurate, innovative evaluation of genAI models. \u003c/p\u003e\u003ch3 id=\"collaboration-and-performance-monitoring\"\u003e\u003cstrong\u003eCollaboration and performance monitoring\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eHaving an organized system to invite and supervise all your labelers during the data labeling process is important for both scalability and security. A data-centric AI platform should include granular options to invite users and review the work of each one.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh3.googleusercontent.com/t6RnaBQEsZjkXnXK3IKe-AhfvcSW-SH79XxpjXjweMkFa6swQg2KMEUo07Gj0NuHi2Qn_ZCWhaAJQtllLPeSjyDjeoMqBvtoi0_87xlU9EaLS4tWW0gLcDKGyapTOwWBQVas9g6n6zyblSPbKe7-vPB2o7p0tWBfaNimEfsQEy0tWJ3GCHRRKJw3SQ\" class=\"kg-image\" alt=\"Seamless collaboration between data science teams, domain experts, and dedicated internal \u0026amp; external labeling teams.\" loading=\"lazy\" width=\"1344\" height=\"1024\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSeamless collaboration between data science teams, domain experts, and dedicated internal \u0026amp; external labeling teams.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eTo ensure top-tier data quality, we also offer Quantumworks Lab Monitor, a powerful tool for granular performance monitoring. Quantumworks Lab Monitor provides a centralized dashboard to visualize and analyze data labeling operations, enabling users to enhance data quality, monitor performance, make data-driven decisions, and streamline management all in one simple click.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTake a quick tour of Monitor in this \u003ca href=\"https://demo.arcade.software/fQYL8I9rMzAi7vuigL8k?embed=\u0026ref=labelbox-guides.ghost.io\"\u003equick, click-through demo t\u003c/a\u003eo learn a bit more. \u003c/p\u003e\u003ch2 id=\"final-thoughts-on-data-labeling\"\u003eFinal thoughts on data labeling\u003c/h2\u003e\u003cp\u003eThe traditional method of training your model with one large training dataset is no longer effective. Machine learning and AI training has moved past this approach to be more agile: carefully curating datasets to accelerate the data labeling process and train the model, examining its performance, and modifying the next dataset accordingly.\u003c/p\u003e\u003cp\u003eThe Quantumworks Lab data factory promotes this iterative process and enables AI teams with the tools needed to accelerate their data labeling and model evaluation process — empowering teams to create powerful training datasets. As such, investing in the right platform and services is key for deploying successful AI products. \u003ca href=\"https://app.labelbox.com/signup?_r=https://www.google.com/?utm_keyword=Quantumworks Lab\u0026utm_source=google\u0026utm_medium=paid-search\u0026utm_campaign=20490363302\u0026gclid=CjwKCAiArva5BhBiEiwA-oTnXdVg1Vj42KRQMjKvBPOVflRG3KbY0t6f-ns2DQADGe_vyVPXN_k0ARoC-jAQAvD_BwE\u0026attr=arcade\u0026landingPageAnonymousId=%22ce322bab-56ea-43b8-a113-000851a3ebaf%22\u0026referrer_url=https://www.google.com/\"\u003eTry Quantumworks Lab for free\u003c/a\u003e.\u003c/p\u003e","comment_id":"635768d8a31ffb004d18ff6b","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Social-Card_Image-annotation--1-.png","featured":false,"visibility":"public","created_at":"2022-10-25T04:40:56.000+00:00","updated_at":"2024-11-27T19:31:15.000+00:00","published_at":"2022-08-19T04:41:00.000+00:00","custom_excerpt":"Get a primer on data labeling, defined as the task of detecting and tagging data with labels, most commonly in the form of images, videos, audio and text assets.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/data-labeling/","tags":[{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},"url":"https://labelbox-guides.ghost.io/data-labeling/","excerpt":"Get a primer on data labeling, defined as the task of detecting and tagging data with labels, most commonly in the form of images, videos, audio and text assets.","reading_time":10,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Introduction to Data Labeling for Machine Learning and AI","meta_description":"Data labeling is the task of detecting and tagging data with labels, most commonly in the form of images, videos, audio and text assets","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6345d52db75421003d6e6197","uuid":"b3e5add7-62f4-4aea-9a09-b610a3705cf2","title":"How to create high-quality image segmentation masks quickly and easily","slug":"image-segmentation","html":"\u003cp\u003eEnterprise AI teams often spend an enormous amount of time and energy on the development and curation of datasets. This is because, unlike academic machine learning models, the use of open source datasets for a commercial application is unlikely to yield an accurate representation of the real world. Instead, teams need to create a new labeled dataset tailored for their specific project.\u003c/p\u003e\u003cp\u003eIn order to create this novel labeled dataset, data scientists and ML engineers have the choice between a variety of annotation types. In \u003ca href=\"https://labelbox.com/guides/computer-vision/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003ecomputer vision\u003c/a\u003e, the frequent choice for differentiating between objects with the highest degree of accuracy is image segmentation.\u003c/p\u003e\u003cp\u003eIt’s important to stress that without the right tooling, however, image segmentation can be prohibitive for many projects, as it becomes very costly to label the amount of training data necessary to achieve performant model results.\u003c/p\u003e\u003ch2 id=\"what-is-image-segmentation\"\u003eWhat is image segmentation?\u003c/h2\u003e\u003cp\u003eImage segmentation is one of the most labor intensive annotation tasks because it requires pixel level accuracy. Labeling a single image can take up to 30 minutes. With image segmentation, each annotated pixel in an image belongs to a single class. The output is a mask that outlines the shape of the object in the image.\u003c/p\u003e\u003cp\u003eAlthough image segmentation annotations come in a lot of different types (such as semantic segmentation, instance segmentation, and panoptic segmentation), the practice of image segmentation generally describes the need to annotate every pixel of the image with a class.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/ACJ2PcVw1AaqlIWoxZNCTUGS9j3EsF1-0cqn4A0u9xlERfpnmsfJdEff-Vmt0lW1IqOHULdHzpC18or_19GFUwKKZnljTrlfsZ8Gr-Bx-cMOJGhZug2H-D_2Gj0Js6Lbn2-4sSDCfxvf_UPYCgCoIaqJ0xxn6o7W-JThV3A33gSuFHWT7Jfv_t3NAA\" class=\"kg-image\" alt=\"Image segmentation masks used to annotate every pixel and distinguish between items such as sky, ground, and vehicle.\" loading=\"lazy\" width=\"732\" height=\"376\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eImage segmentation masks used to annotate every pixel and distinguish between items such as sky, ground, and vehicle.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"what-are-the-benefits-of-using-image-segmentation-for-my-machine-learning-model\"\u003eWhat are the benefits of using image segmentation for my machine learning model?\u003c/h2\u003e\u003cp\u003eThe primary benefit of image segmentation can be best understood by comparing the three most common annotation types within computer vision.\u003c/p\u003e\u003cul\u003e\u003cli\u003eImage classification: The goal is to simply identify which objects and other properties exist in an image.\u003c/li\u003e\u003cli\u003eImage object detection: This goes one step beyond classification to find the position (using bounding boxes) of individual objects.\u003c/li\u003e\u003cli\u003eImage segmentation: The goal is to recognize and understand what's in the image at the pixel level. Every pixel in an image belongs to a single class, as opposed to object detection where the bounding boxes of objects can overlap.\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/-MwGV8z6bBoJIK8pCjzyanHVH21aYa6BJRxqK6VbD2oN3tthDBp76k8tcEcGk8RdGCpPZXbkaGxg3UrDeifRAdKWszU10QcfERG9Ph2mHiFwmj20gQEw3UNGT2u3D582N1tyOYsw0h6bdVK_YlBCFJ6dEcmyYKT0AumHb_Akgu9dq_xYr9Rs1AHlWA\" class=\"kg-image\" alt=\"One image labeled in four ways for four separate computer vision tasks: classification, object detection, image segmentation, and image segmentation with instances.\" loading=\"lazy\" width=\"1600\" height=\"551\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eOne image labeled in four ways for four separate computer vision tasks: classification, object detection, image segmentation, and image segmentation with instances.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eFor a point of comparison, employing image segmentation is particularly useful when dealing with use cases in a model where you need to definitively know whether or not an image contains the object of interest — and also what \u003cem\u003eisn’t\u003c/em\u003e an object of interest.\u003c/p\u003e\u003cp\u003eThis is in contrast to other annotation types such as image classification or bounding boxes, which may be faster to label, but less accurate. In short, annotations generated from image segmentation tend to end up with the most widely applicable and versatile models, because they are the most focused on what is in the contents of an image.\u003c/p\u003e\u003ch2 id=\"how-does-an-ai-data-factory-support-complex-image-segmentation\"\u003eHow does an AI data factory support complex image segmentation?\u003c/h2\u003e\u003cp\u003eAI data factories are commonly equipped with tools which allow labelers to outline complex shapes for image segmentation. The Quantumworks Lab pen tool allows you to draw freehand as well as straight lines. Having fast and ergonomic drawing tools help reduce the time-consuming nature of creating consistent, pixel-perfect labels.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh3.googleusercontent.com/xFTJLKe1HRXJTSGm3fi3V7aPOvI4jxeTq5mlOJtxcFWSp7QKGMJnRUIXOOslCzniw7nrxwp47x4QyB58l_HrtfEhH5G8cXet6zJGR16olzEjX_7UyLNsGYzozsAY7QHs5VBktG8qla16hsTlcXzRYToqW7IwXHO-DT4lzBvCtrbTcFKmA3XL5KMURg\" class=\"kg-image\" alt=\"The Quantumworks Lab pen tool makes image segmentation quick and easy.\" loading=\"lazy\" width=\"900\" height=\"532\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eThe Quantumworks Lab pen tool makes image segmentation quick and easy.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn addition, AI data factories typically include additional features that specifically help optimize your image segmentation project.\u003c/p\u003e\u003ch3 id=\"automating-the-image-segmentation-labeling-task\"\u003eAutomating the image segmentation labeling task\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/10/My-Movie-35--1--1.gif\" class=\"kg-image\" alt=\"A best-in-class AI data engine helps accelerate the image segmentation process through automation\" loading=\"lazy\" width=\"1280\" height=\"720\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/10/My-Movie-35--1--1.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/10/My-Movie-35--1--1.gif 1000w, https://labelbox-guides.ghost.io/content/images/2022/10/My-Movie-35--1--1.gif 1280w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA best-in-class AI data factory helps accelerate the image segmentation process through automation\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eA best-in-class AI data factory helps users automate parts of the image segmentation process to accelerate efforts without diminishing the quality of annotations. One crucial part of this automation includes the incorporation of auto-segmentation tools that enable labelers to complete the  complex image segmentation drawing tasks in seconds.\u003c/p\u003e\u003cp\u003eAnother labeling automation technique, called pre-labeling or model-assisted labeling, has been proven to reduce labeling time and costs by up to 50% for AI teams. Model-assisted labeling involves the use of a model — whether it’s a generic off-the-shelf model, your own model in training, or a model built specifically to generate labels. The model’s output is used as pre-labels, enabling labelers to simply correct or edit them instead of labeling data from scratch.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/10/2022-10-14_16-13-28--1--2.gif\" class=\"kg-image\" alt=\"Model-assisted labeling, or pre-labeling, helps accelerating model training by eliminating the need to label data from scratch\" loading=\"lazy\" width=\"1778\" height=\"884\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/10/2022-10-14_16-13-28--1--2.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/10/2022-10-14_16-13-28--1--2.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2022/10/2022-10-14_16-13-28--1--2.gif 1600w, https://labelbox-guides.ghost.io/content/images/2022/10/2022-10-14_16-13-28--1--2.gif 1778w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eModel-assisted labeling, or pre-labeling, helps accelerating model training by eliminating the need to label data from scratch\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003ePre-labeling decreases labeling costs as the model gets smarter with every iteration, leaving teams more time to focus on manually labeling edge cases or areas where the model might not be performing as well. It’s not only faster and less expensive, but delivers better model performance.\u003c/p\u003e\u003ch3 id=\"customization-based-on-ontology-for-image-segmentation\"\u003e\u003cstrong\u003eCustomization based on ontology for image segmentation\u003c/strong\u003e\u003cbr\u003e\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/lztPGENgnYbTrWp-jfg19tsQyeWeOvRZY0aXZ2Q7qXPIKn3s6pXwD0aXT-cDA5mgtN6q2Z-9-g347uyDnJqGYeoGSN5-wZGLSM3PlQsgvMnRujDaJp8O77UzPk5_7VdNfw469frXI0GM0_IUxTyu5l9NMR35R7CVoqnGq_0VRPIyIUr_TmORUJt_Ug\" class=\"kg-image\" alt=\"Configure the label editor to your ontology requirements. Bring additional attachments such as text, videos, images, overlays, or even custom widgets to aid data labelers to create perfect labels.\" loading=\"lazy\" width=\"1444\" height=\"1174\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eConfigure the label editor to your ontology requirements. Bring additional attachments such as text, videos, images, overlays, or even custom widgets to aid data labelers to create perfect labels.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBeing able to configure the label editor to your exact data structure (ontology) requirements, with the ability to further classify instances that you have segmented, is important for accurate and easy image segmentation. Quantumworks Lab’s ontology management feature includes classifications, custom attributes, hierarchical relationships, and more.\u003c/p\u003e\u003ch3 id=\"an-emphasis-on-performance-for-a-wide-array-of-devices\"\u003e\u003cstrong\u003eAn emphasis on performance for a wide array of devices\u003c/strong\u003e\u003cbr\u003e\u003cbr\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/M67Xt9O5E6AM7y9vUFeOLsUVeBNyp8zqKBkJAe_BFE1n32qdcq0nVrfu5-HhbwlIvwknEL7GzhpVJSLNW1gLJ_fpKTo5WtRQ9gitkiKGYu5Ir4UQ-Vihubw2sGe5WTl6AzKtQR3H2P9C6v-R52tVUILOJblI4E_UXKJlQfE1RhZWzB7yWhI5Ding4A\" class=\"kg-image\" alt=\"A simple, intuitive UI reduces friction in the image segmentation process.\" loading=\"lazy\" width=\"1600\" height=\"936\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA simple, intuitive UI reduces friction in the image segmentation process.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAs previously mentioned, image segmentation can be a time consuming process, taking up to 30 minutes to complete a single image. A focus on intuitive UI across multiple devices (even on lower-spec PCs or laptops) is important to reduce fatigue for professional labelers who are working on image segmentation labeling tasks for hours on end.\u003c/p\u003e\u003ch3 id=\"dynamic-queuing-for-large-scale-image-segmentation-projects\"\u003e\u003cstrong\u003eDynamic queuing for large scale image segmentation projects\u003c/strong\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/yIz5zll3BvFXsk-kqFn7-fL3vvbqjsCiz0ESTeCulEb0GLH0w_h3J8-sjOpSb6mI3W_A_SlPxoD8ydkdXh06KMPAVPos7pUbM0Z5yky1YCYc35TKVn64D8JHrqG84suq7QyJwHfvs9kycFWJwvGlZTNeFYe5vGfC2MjtOsEy3lAxuV9gFqDYK8HHrw\" class=\"kg-image\" alt=\"Dynamic queuing helps cut down on time spent on image segmentation tasks\" loading=\"lazy\" width=\"940\" height=\"581\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eDynamic queuing helps cut down on time spent on image segmentation tasks\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eStandard queuing methods have image segmentation tasks distributed equally to active annotators. These equal distribution methods typically lead to inefficient workflows as not all annotators work at the same speeds and not all image segmentation tasks are created equal. With large scale projects, this also potentially leads to longer delays as annotators sit idle, waiting for new tasks.\u003c/p\u003e\u003cp\u003eAn AI data factory supports more efficient labeling queues for image segmentation tasks by enabling a continuous workflow for annotators. With this method, new tasks will automatically be distributed at the rate of completion to eliminate idle time and help get your image segmentation project finished faster.\u003c/p\u003e\u003ch3 id=\"software-first-approach-to-image-segmentation\"\u003e\u003cstrong\u003eSoftware-first approach to image segmentation\u003c/strong\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/2aLRRrCSJUbvVKcLwvDRC0r6dPTlkYL24pE1Ta2PPWAOHYk2EsNK9ceOrFp1VX3FNcaW8lduNfeoMCr3YuALeMezMMmjNWTy_CtOtGnUpVDan_5mEXIZMQbJFoA3Kl4dDY3or7nErq5z47uQLkDtOOfkz7ulwLcsWKIzPu1gGpe7bIFgM-ntaa4yHA\" class=\"kg-image\" alt=\"With a software-first approach, you pay only for productive screen activity time from your human image segmentation labeling service\" loading=\"lazy\" width=\"1600\" height=\"1080\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eWith a software-first approach, you pay only for productive screen activity time from your human image segmentation labeling service\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eA best-in-class data factory gives you options when it comes to labeling configuration for image segmentation tasks, adopting a software-first approach.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/blog/how-a-software-first-approach-to-labeling-ai-data-gets-you-a-better-roi-than-tech-enabled-bpos/?ref=labelbox-guides.ghost.io\"\u003eThis software-first approach\u003c/a\u003e allows AI teams with image segmentation projects to use any labeling service or vendor with full transparency, collaborate easily with all stakeholders throughout the labeling process, and train their own models to automate labeling thereby significantly reducing their unit costs for image segmentation tasks.\u003c/p\u003e\u003cp\u003eThis includes using an in-house image segmentation team, a BPO (business process outsourcing), or on-demand labeling services from \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"enabling-the-creation-of-synthetic-data\"\u003e\u003cstrong\u003eEnabling the creation of synthetic data\u003c/strong\u003e \u003c/h3\u003e\u003cp\u003eAI teams are increasingly turning to synthetic data to meet their needs when real data is thin, or when handling sensitive information as the dataset won’t contain any real information during the model training process.\u003c/p\u003e\u003cp\u003eSynthetic data can also simulate edge cases and conditions that aren’t represented in real data or mitigate issues caused by potential changes in the camera sensor or lighting conditions, helping teams fill in the gaps in their dataset.\u003c/p\u003e\u003cp\u003eAI data factory enables teams to build a VAE(variational auto-encoder) or GAN (Generative Adversarial Networks) model to generate image data.\u003c/p\u003e\u003cp\u003eSynthetic data generation can be used for preserving privacy, and overcoming some imbalanced dataset problems (for example, if you are training on a cancer diagnosis dataset from patient records but there are only 2% of positive cases, you would want to generate a few synthetic positive examples that are anonymous).\u003c/p\u003e\u003cp\u003eWhile it can be helpful to bootstrap a model training with a larger dataset,  synthetic data will inherit biases from the data it is modeling from, and the model might still struggle when facing with production data it has not learned about before.  Thus, it is often recommended to collect diverse real-world data for training (and use active learning techniques to curate more efficiently), rather than relying on synthetic data.\u003c/p\u003e\u003ch3 id=\"support-for-shared-borders-when-creating-image-segmentation-masks\"\u003e\u003cstrong\u003eSupport for shared borders when creating image segmentation masks\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003cbr\u003eWhen creating image segmentation masks, it’s important to be able to share borders between objects. With the Quantumworks Lab editor, it’s simple. Whenever you draw a new object, if you overlap the border of an already existing object, the new border you’re drawing will be shared.\u003c/p\u003e\u003cp\u003eThis method works well when you are labeling objects from the background first. Sometimes, though, you want to be able to draw foreground objects first, and then be able to draw an object behind without messing up the masks you’ve already created. A best-in-class AI data factory will support shared borders to help you accelerate the image segmentation process.\u003c/p\u003e\u003ch2 id=\"what-are-some-example-real-world-image-segmentation-use-cases\"\u003eWhat are some example real world image segmentation use cases?\u003c/h2\u003e\u003cp\u003eImage segmentation is popular for real world machine learning models when high accuracy is required of the computer vision application being built.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/usecases/computer-vision/image-segmentation/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eUse cases employing image segmentation\u003c/a\u003e can be found as follows:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAutonomous vehicles\u003c/li\u003e\u003cli\u003eMedical imagery\u003c/li\u003e\u003cli\u003eRetail applications\u003c/li\u003e\u003cli\u003eFace recognition and analysis\u003c/li\u003e\u003cli\u003eVideo surveillance\u003c/li\u003e\u003cli\u003eSatellite image analysis\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/ukjoguzCSt8X_qtZ9GKD04C1dYp-hNXTa9CCnU5lcUtjv2Lic0bq96gJZ6i9EEiDPRiH-LL3BOg0bGgE70qqVParJsHRfDpEaHvfTIiJn0mnpysc5hPiVLjbWiGtxPrQRdwUYWDr4Pu2sc0wi4S_PpcVlboXGK_5h7ki4yePRdiUjIMVX3nAusiOjw\" class=\"kg-image\" alt=\"Machine learning models built to help retailers better manage inventory might use image segmentation masks to identify and count products on shelves.\" loading=\"lazy\" width=\"1280\" height=\"720\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMachine learning models built to help retailers better manage inventory might use image segmentation masks to identify and count products on shelves.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"final-thoughts-on-image-segmentation-with-an-ai-data-factory\"\u003eFinal thoughts on image segmentation with an AI data factory\u003c/h2\u003e\u003cp\u003eHistorically, image segmentation has been prohibitive for many projects, despite the benefits of pin-point accuracy, because the costs associated with labeling the amount of training data necessary to achieve performant model results can become astronomical.\u003c/p\u003e\u003cp\u003eHowever, an AI data factory can rewrite this precedent. With the features included in a best-in-class AI data such as a flexible pen tool, auto-segmentation, and model-assisted labeling techniques, image segmentation becomes a fast and accurate process — thus also becoming a more accessible technology to AI teams.\u003c/p\u003e\u003cp\u003eInvesting in an AI data factory like Quantumworks Lab empowers teams with the tools to quickly build better image segmentation AI products. \u003c/p\u003e","comment_id":"6345d52db75421003d6e6197","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Social-Card_Image-annotation-1.png","featured":false,"visibility":"public","created_at":"2022-10-11T20:42:21.000+00:00","updated_at":"2024-11-20T21:34:50.000+00:00","published_at":"2022-08-17T20:55:00.000+00:00","custom_excerpt":"Image segmentation is used to label images for applications that require high accuracy and is manually intensive.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/image-segmentation/","tags":[{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},"url":"https://labelbox-guides.ghost.io/image-segmentation/","excerpt":"Image segmentation is used to label images for applications that require high accuracy and is manually intensive.","reading_time":8,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Introduction to Image Segmentation for Machine Learning \u0026 AI","meta_description":"Image segmentation is used to label images for applications that require high accuracy and is manually intensive.","email_subject":null,"frontmatter":null,"feature_image_alt":"How to create high-quality image segmentation masks quickly and easily","feature_image_caption":null},{"id":"6336244e1beec0003d38bdcc","uuid":"9183edaf-81ca-46b5-a0d7-d4d5c1d56cf0","title":"Best practices for successful image annotation","slug":"image-annotation","html":"\u003ch2 id=\"what-is-image-annotation\"\u003eWhat is image annotation?\u003c/h2\u003e\u003cp\u003eImage annotation is the task of labeling digital images, typically involving human input and, in some cases, computer-assisted help. Labels are predetermined by a machine learning (ML) engineer and are chosen to give the \u003ca href=\"https://labelbox.com/guides/computer-vision/?ref=labelbox-guides.ghost.io\"\u003ecomputer vision model\u003c/a\u003e information about the objects present in the image. The process of labeling images also helps machine learning engineers hone in on important factors in the image data that determine the overall precision and accuracy of their model.\u003c/p\u003e\u003cp\u003eExample considerations include possible naming and categorization issues, how to represent occluded objects (objects hidden by other objects in the image), how to deal with parts of the image that are unrecognizable, etc.\u003c/p\u003e\u003ch2 id=\"how-do-you-annotate-an-image\"\u003eHow do you annotate an image?\u003c/h2\u003e\u003cp\u003eFrom the example image below, a person has used an image annotation tool to apply a series of labels by placing bounding boxes around the relevant objects, thereby annotating the image. In this case, pedestrians are marked in blue and taxis are marked in yellow, while trucks are marked in yellow.\u003c/p\u003e\u003cp\u003eDepending on the business use case and project, the number of image annotations on each image can vary. Some projects will require only one label to represent the content of an entire image (e.g. image classification). Other projects could require multiple objects to be tagged within a single image, each with a different label (e.g. a bounding box).\u003c/p\u003e\u003cp\u003eImage annotation software is designed to make image labeling as easy as possible. A good image annotation app will include features like a bounding box annotation tool and a pen tool for freehand \u003ca href=\"https://labelbox.com/guides/image-segmentation/?ref=labelbox-guides.ghost.io\"\u003eimage segmentation\u003c/a\u003e.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/fSf1jZJOJk9eRfx9AIsU4jqg9TriNm0nOfNU8u0ibv5r1c_2iAptWQjpNUMY_KDBjiYI-Z6ldPujqKtNGjxMJDyHd8cKEoUq47rLTpD_ISkhPxd-rXxVnNGHd8ITlQwl5xDZ-SmbVaZrJYQZuIHkN99RSgsqCPMZQmif5g4cxepWYwXj8pDRcxg0iA\" class=\"kg-image\" alt=\"Bounding boxes applied to identify vehicle types and pedestrians.\" loading=\"lazy\" width=\"728\" height=\"538\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eBounding boxes applied to identify vehicle types and pedestrians.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"what-are-the-different-types-of-image-annotation\"\u003eWhat are the different types of image annotation?\u003c/h2\u003e\u003cp\u003eTo create a novel labeled dataset for use in computer vision projects, data scientists and ML engineers have the choice between a variety of annotation types they can apply to images. Researchers will use an image markup tool to help with the actual labeling. The three most common image annotation types within computer vision are:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eClassification:\u003c/strong\u003e With whole-image classification, the goal is to simply identify which objects and other properties exist in an image without localizing them within the image\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eObject detection:\u003c/strong\u003e With image object detection, the goal is to find the location (established by using bounding boxes) of individual objects within the image\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/image-segmentation/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eImage segmentation\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003eWith image segmentation, the goal is to recognize and understand what's in the image at the pixel level. Every pixel in an image is assigned to at least one class, as opposed to object detection, where the bounding boxes of objects can overlap. This is also known as semantic segmentation.\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/bnfgDITr0oB6E_CybfiAyOPjvXNe5L_cbjTykcjXEXxBlnwzyKE4F0ZTWkcWcFjdwNoLQBI8Iqk-e5pp-7FO3ZNrwpFtFIH61oxbRQJXNv2tQm4hpKDFKSQyUE5B3IEjZexd7-4fTg3S2ya_ksa1w2KtkFizfNfuMb5C7etXkbkBqU2D9eUIC4OjoA\" class=\"kg-image\" alt=\"Different types of image annotation\" loading=\"lazy\" width=\"1600\" height=\"551\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eDifferent types of image annotation\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhole image classification provides a broad categorization of an image and is a step up from unsupervised learning as it associates an entire image with just one label. It is by far the easiest and quickest to annotate out of the other common options. Whole-image classification is also a good option for abstract information such as scene detection or time of day.\u003c/p\u003e\u003cp\u003eBounding boxes, on the other hand, are the standard for most object detection use cases and require a higher level of granularity than whole-image classification. They provide a balance between annotation speed and targeting items of interest.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/guides/image-segmentation/?ref=labelbox-guides.ghost.io\"\u003eImage segmentation\u003c/a\u003e is usually chosen to support use cases in a model where you need to definitively know whether or not an image contains the object of interest as well as what isn’t an object of interest. This is in contrast to other annotation types such as classification or bounding boxes, which may be faster but usually convey less information.\u003c/p\u003e\u003ch2 id=\"why-is-image-annotation-useful\"\u003eWhy is image annotation useful?\u003c/h2\u003e\u003cp\u003eImage annotation is a vital part of training computer vision models that process image data for object detection, classification, segmentation, and more. A dataset of images that have been labeled and annotated to identify and classify specific objects, for example, is required to train an object detection model.\u003c/p\u003e\u003cp\u003eThis kind of computer vision model is an increasingly important technology. For example, a self-driving vehicle relies on a sophisticated computer vision image annotation algorithm. This model labels all the objects in the vehicle's environment, such as cars, pedestrians, bicycles, trees, etc. This data is then processed by the vehicle's computer and used to navigate traffic successfully and safely.\u003c/p\u003e\u003cp\u003eThere are many off-the-shelf image annotation models available. One such model is YOLO, an object detection model that generates bounding box annotations in real time. YOLO stands for \"You only look once,\" indicating that the algorithm analyzes the image and applies image annotations in one pass, prioritizing speed.\u003c/p\u003e\u003ch2 id=\"how-does-an-ai-data-engine-support-complex-image-annotation\"\u003eHow does an AI data engine support complex image annotation?\u003c/h2\u003e\u003cp\u003eImage annotation projects begin by determining what should be labeled in the images and then instructing annotators to perform the annotation tasks using an image annotation tool.\u003c/p\u003e\u003cp\u003eAnnotators must be thoroughly trained on the specifications and guidelines of each image annotation project, as every company will have different image labeling requirements. The annotation process will also differ depending upon the image annotation tool used.\u003c/p\u003e\u003cp\u003eOnce the annotators are trained on proper data annotation procedures for the project, they will begin annotating hundreds or thousands of images on an image annotation tool.\u003c/p\u003e\u003cp\u003eData engine software like Quantumworks Lab is not only equipped with an image annotation tool, but also allows AI teams to organize and store their structured and unstructured data while providing a model training framework.\u003c/p\u003e\u003cp\u003eThis scalable and flexible image annotation tool allows you to perform all the tasks mentioned above, from image classification to advanced semantic segmentation.\u003c/p\u003e\u003cp\u003eIn addition, a best-in-class data engine will typically include additional features that specifically help optimize your image annotation projects.\u003c/p\u003e\u003ch3 id=\"model-assisted-labeling\"\u003e\u003cstrong\u003eModel-assisted labeling\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAn AI data engine helps users automate several parts of their image annotation process to accelerate efforts without diminishing the quality of annotations.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/10/doc-hero.png\" class=\"kg-image\" alt=\"Quantumworks Lab enables AI teams to quickly and easily annotate images with powerful, flexible, and configurable labeling editors.\" loading=\"lazy\" width=\"1824\" height=\"1140\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/10/doc-hero.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/10/doc-hero.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2022/10/doc-hero.png 1600w, https://labelbox-guides.ghost.io/content/images/2022/10/doc-hero.png 1824w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eLabelbox enables AI teams to quickly and easily annotate images with powerful, flexible, and configurable labeling editors.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e1. Automated queuing enables labelers to work continuously, eliminating the delays that occur as they wait to receive datasets, instructions, and other materials \u003c/p\u003e\u003cp\u003e2. Auto-segmentation tools that cut complex image segmentation drawing tasks down to seconds \u003c/p\u003e\u003cp\u003e3. Automate data operations and workflows programmatically with a Python SDK \u003c/p\u003e\u003cp\u003e4. AI teams can import model predictions as pre-labels, so that labelers can review and correct them instead of labeling data from scratch \u003c/p\u003e\u003cp\u003eThis final labeling automation technique, called pre-labeling or model-assisted labeling, has been proven to reduce labeling time and costs by up to 50% for AI teams. \u003c/p\u003e\u003cp\u003ePre-labeling decreases labeling costs as the model gets smarter with every iteration, leaving teams more time to focus on manually labeling edge cases or areas where the model might not be performing as well. It’s not only faster and less expensive, but delivers better model performance.\u003c/p\u003e\u003ch3 id=\"high-performance-image-annotation-tools\"\u003e\u003cstrong\u003eHigh-performance image annotation tools\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe image annotation tool on the AI data engine you are testing can support a high number of objects and labels per image without sacrificing loading times.\u003c/p\u003e\u003cp\u003eLabelbox’s fast and ergonomic drawing tools provide efficiency to help reduce the time-consuming nature of creating consistent, pixel-perfect labels. A vector pen tool, for instance, allows users to draw freehand as well as generate straight lines. When you have the right tool for the job, image annotation is much easier.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/tsRLs-Hvh8Hk4l_RihmDxalaObPvHw9DlgLfuwYr38lH9aMamuQL98ZmUistHlSBDt0d1HbrE-7qaxE4FIDZbNUiuuF40rE96sKR8z6J4uYDAb5cSx1ZOfFcmiv_DSyRuV4Ppro5A9ZXQXGgW2l4C4c4DOwFXIaiwzSN7FllMqrZHfJwDxNKHLXZtw\" class=\"kg-image\" alt=\"The Quantumworks Lab segmentation pen tool makes image annotation quick and easy.\" loading=\"lazy\" width=\"1600\" height=\"1056\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eThe Quantumworks Lab segmentation pen tool makes image annotation quick and easy.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"customization-based-on-ontology-requirements\"\u003e\u003cstrong\u003eCustomization based on ontology requirements\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/product/annotate/image/?ref=labelbox-guides.ghost.io\"\u003eLabelbox’s suite of image annotation tools\u003c/a\u003e gives you the ability to configure the label editor to your exact data structure (ontology) requirements, with the ability to further classify instances that you have segmented.\u003c/p\u003e\u003cp\u003eOntology management includes classifications, custom attributes, hierarchical relationships, and more. You'll be able to quickly annotate images with the labels that matter to you, without the clutter of irrelevant options.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/Eo5Nk92kyinI-jRWdHIi50Yn-yuWMHhDrhARjTprS56BUUoqBLtosk0ic9XRjV1SmEBBP1E6-PByGZWkE1YCKE4w5rNYNcHT2R5V6PaaMAkV9Kd85PyyPPNnu_Gh-aXzsdZM4eymU_FOlMVAidc1wm2zAqKTmE3khVTtYfbz7MIjhucekyQ4QVZSDw\" class=\"kg-image\" alt=\"Configure the label editor to your exact data structure (ontology) requirements. Bring additional attachments such as text, videos, images, overlays or even custom  widgets to aid data labelers to create perfect labels.\" loading=\"lazy\" width=\"1444\" height=\"1174\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eConfigure the label editor to your exact data structure (ontology) requirements. Bring additional attachments such as text, videos, images, overlays or even custom widgets to aid data labelers to create perfect labels.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"a-streamlined-user-interface-that-emphasizes-performance-for-a-wide-array-of-devices\"\u003e\u003cstrong\u003eA streamlined user interface that emphasizes performance for a wide array of devices\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAn intuitive design helps lower the cognitive load on image labelers which enables faster image annotation. Moreover, an uncluttered online image annotation tool is built to run quickly, even on lower spec PCs and laptops. Both are critical for professional labelers who are working in an annotation editor all day.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh5.googleusercontent.com/wdXPZTvdOxnK78h7aB5ALH89zRK4Ag2RZsoGX0DPN3u14TCwFgFqmjE97e6SPgqd7sepjlZU4EEUfcDowJ1qRmFTgYvz9nO_036oLdk3xVe94uAsiQtY4HRCJrQdYrf7mgZa1PPKbbpRrRe69BDKKlpJ8Rrg9-I3jmulZif52YCJCLX6BA_fW9URSA\" class=\"kg-image\" alt=\"A simple, intuitive UI reduces friction.\" loading=\"lazy\" width=\"1600\" height=\"936\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA simple, intuitive UI reduces friction.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"seamlessly-connect-your-data-via-python-sdk-or-api\"\u003e\u003cstrong\u003eSeamlessly connect your data via Python SDK or API\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eStream data into your AI data engine and push labeled data into training environments like \u003ca href=\"https://labelbox.com/blog/tensorflow-launch-partners/?ref=labelbox-guides.ghost.io\"\u003eTensorFlow\u003c/a\u003e and PyTorch. Quantumworks Lab was built to be developer-friendly and API first, so you can use it as infrastructure to scale up and connect your computer vision models to accelerate labeling productivity and orchestrate active learning.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh4.googleusercontent.com/3hP2i26_j9k7FomFavaQnvOQSFiQo5KXW3GSj1OyPLT0LWFI22ENYRvQ01N_kjnJTrfJvn1YrFYOrOM5qnDwMCBzMJiDb8SNqNBWHWVz6nW8peW2TP2Yr_lGsgOiSw22zebxhpK1ooOaIJ1GTWi-SyjawwXoKEI7bAQe7cWqdeATWx2jbPcSZT0xgA\" class=\"kg-image\" alt=\"Simplified data import without writing and maintaining your own scripts.\" loading=\"lazy\" width=\"1600\" height=\"1000\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSimplified data import without writing and maintaining your own scripts.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"benchmarks-and-consensus\"\u003e\u003cstrong\u003eBenchmarks and consensus\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eData quality is measured by both the consistency and the accuracy of labeled data. The industry-standard methods for calculating data quality are benchmarks (aka gold standard), consensus, and review.\u003c/p\u003e\u003cp\u003eAn essential part of an AI data scientist’s job is figuring out what combination of these quality assurance procedures is right for annotated images used in your ML project. Quality assurance is an automated process that operates continuously throughout your training data development and improvement processes. \u003ca href=\"https://docs.labelbox.com/docs/benchmarks?ref=labelbox-guides.ghost.io#:~:text=The%20Benchmarks%20tool%20allows%20you,Benchmark%20Label%20on%20the%20asset.\"\u003eWith Quantumworks Lab consensus and benchmark features\u003c/a\u003e, you can automate consistency and accuracy tests. These tests allow you to customize the percentage of your data to test and the number of labelers that will annotate the test data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/zeTWFetAKuzB57EcIrdcnzJEMDOi_ZgfnN0xeCfK6rz5Ahdnj9rk4NXqKrIYSg7DgoYHJaLgqfP6aZpTj3KADi1wniVnFyloPWHOnnUbmdZbrW9TCoErBfNY95WRSyrRpDiv24hVxMo0mjUdZzvHbD2bMaZWuDq1kGJjSoDqfHO-hz3I5F967_aLAQ\" class=\"kg-image\" alt=\"Benchmarks in action, highlighting the example labeled asset with a gold star.\" loading=\"lazy\" width=\"1514\" height=\"822\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eBenchmarks in action, highlighting the example labeled asset with a gold star.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"collaboration-and-performance-monitoring\"\u003e\u003cstrong\u003eCollaboration and performance monitoring\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eHaving an organized system to invite and supervise all your labelers during an image annotation project is important for both scalability and security. An AI data engine should include granular options to invite users and review the work of each one.\u003c/p\u003e\u003cp\u003eWith Quantumworks Lab, setting up a project and inviting new members is extremely easy, and there are many options for \u003ca href=\"https://docs.labelbox.com/docs/performance-dashboard?ref=labelbox-guides.ghost.io\"\u003emonitoring their performance\u003c/a\u003e, including statistics on seconds needed to label an image. You can implement several quality control mechanisms, including activating automatic consensus between different labelers or setting gold standard benchmarks.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/wQieRUTWPY1MIuy-QJu2btbCzmw5Arm-ZR42vAIFe8ZmvHMGQNqJU7XyhDxhVgoxYD6hXR7dspTEUCm-e1zMH5DvlcfN9ys0wRgFE2JXfTokHgdqt26MHFvS4WFaBCvD_S3qKwD-iTMWCwqfGn2FjCSM0pLcHqXKchs-95raW5oCCg01QWWmrs9yjA\" class=\"kg-image\" alt=\"Seamless collaboration between data science teams, domain experts, and dedicated external labeling teams.\" loading=\"lazy\" width=\"1344\" height=\"1024\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eSeamless collaboration between data science teams, domain experts, and dedicated external labeling teams.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"automatic-annotation-tool\"\u003e\u003cstrong\u003eAutomatic annotation tool\u003c/strong\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh6.googleusercontent.com/xvu89pZOSbVC5_EPrM2ZRi56xwCvF_tS-KECnDwXOE2ReGprVoEQZzd8Mee-m5e3CZFu4KVcoBsSVLK52hMnWwsjJb-Cvyfj1OArbozIgwxNMkeFjdkYIeS8MFcHMFji-YaMOrKZnLyGrn1rkYgzSTuZQorjL-Viw9-0Gt3Q3Sc5EEjrn7p_Al_D1Q\" class=\"kg-image\" alt=\"Automatic annotation tools help you save time\" loading=\"lazy\" width=\"1600\" height=\"990\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eAutomatic annotation tools help you save time\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIf you are using image annotation to train a machine learning model, Quantumworks Lab allows you to use your model to create pre-labeled images for your labeling team using an \u003ca href=\"https://labelbox.com/blog/use-automation-to-reduce-your-labeling-time-and-spend/?ref=labelbox-guides.ghost.io\"\u003eautomatic image segmentation tool\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eLabelers can then review the output of the computer vision annotation tool and make any necessary corrections or adjustments. Instead of starting from scratch, much of the work is already done, resulting in significant time savings.\u003c/p\u003e\u003ch2 id=\"final-thoughts-on-image-annotation-with-an-ai-data-engine\"\u003eFinal thoughts on image annotation with an AI data engine\u003c/h2\u003e\u003cp\u003eThe real-world applications for image annotation are endless, from content moderation to self-driving cars to security and surveillance. And, while there are many components to image annotation (classification, detection, segmentation), ultimately the annotation process itself is just a way to produce high quality data for model training. \u003c/p\u003e\u003cp\u003eWhen engineers at Tesla developed their Full Self Driving (FSD) vehicle technology in 2020, a key part of their success was an AI data engine. OpenAI currently uses their own proprietary AI data engine to train, deploy and maintain popular successful models such as GPT-3 and DALL-E 2.\u003c/p\u003e\u003cp\u003eFrom these examples, we can see how an AI data engine is key to deploying successful AI products, as it is the foundational infrastructure for how team members interface with data and models. Unfortunately, not all teams have the time and resources to architect an intricate and complex data engine for every use case.\u003c/p\u003e\u003cp\u003eLuckily, AI teams today don’t have to build and maintain data engines for their projects like Tesla and OpenAI did — they can invest in one instead. A best-in-class AI data engine gives you the ability to visualize, curate, organize, label data to improve model performance. Quantumworks Lab can help you get there.\u003c/p\u003e\u003cp\u003e\u003cbr\u003eDownload the \u003ca href=\"https://labelbox.com/learn/library/complete-guide-data-engines-for-ai/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003eComplete guide to data engines for AI\u003c/strong\u003e\u003c/a\u003e to learn how investing in a data engine can help your team build transformative AI products fast.\u003c/p\u003e","comment_id":"6336244e1beec0003d38bdcc","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/10/Screen-Shot-2022-10-03-at-10.17.25-AM.png","featured":false,"visibility":"public","created_at":"2022-09-29T23:03:42.000+00:00","updated_at":"2024-05-29T23:56:57.000+00:00","published_at":"2022-08-01T23:07:00.000+00:00","custom_excerpt":"Image annotation is defined as the task of annotating an image with labels. Discover how an AI data engine supports image annotation at scale.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/image-annotation/","tags":[{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"authors":[{"id":"6336232f1beec0003d38bdc9","name":"Lisa Dimyadi","slug":"lisa","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/lisa/"}],"primary_author":{"id":"6336232f1beec0003d38bdc9","name":"Lisa Dimyadi","slug":"lisa","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/lisa/"},"primary_tag":{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},"url":"https://labelbox-guides.ghost.io/image-annotation/","excerpt":"Image annotation is defined as the task of annotating an image with labels. Discover how an AI data engine supports image annotation at scale.","reading_time":9,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Image Annotation Best Practices \u0026 How to Annotate Images","meta_description":"Image annotation is defined as the task of annotating an image with labels. Discover how an AI data engine supports image annotation at scale.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}],"total":48,"tag":{"slug":"label-data-for-ai","id":"653aa53f375d13000123d7ec","name":"Label data for AI","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","count":{"posts":48},"url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"},"slug":"label-data-for-ai","currentPage":"5"},"__N_SSG":true},"page":"/guides/tag/[id]/page/[pagenum]","query":{"id":"label-data-for-ai","pagenum":"5"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/guides/tag/label-data-for-ai/page/5/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:28:33 GMT -->
</html>