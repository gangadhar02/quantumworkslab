<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/guides/tag/build-ai/page/5/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:28:07 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Guides | Quantumworks Lab</title><meta name="description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><link rel="preconnect" href="../../../../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta property="og:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta property="og:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="og:image" content="/static/images/guides-social.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Guides | Quantumworks Lab" data-next-head=""/><meta name="twitter:description" content="Covering everything you need to know in order to build AI products faster." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.com/guides/" data-next-head=""/><meta property="twitter:image" content="/static/images/guides-social.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../../../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../../../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../../../../static/scripts/munchkin.js"></script><script src="../../../../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../../../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../../../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../../../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../../../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../../../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../../../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../../../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../../../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../../../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../../../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../../../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../../../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../../../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../../../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../../../../_next/static/chunks/5008-6b2f21a0ee7e9705.js" defer=""></script><script src="../../../../../_next/static/chunks/pages/guides/tag/%5bid%5d/page/%5bpagenum%5d-da4e9ee1c105845a.js" defer=""></script><script src="../../../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../../../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../../../../index.html"><img width="106" height="24" alt="logo" src="../../../../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><div class="py-12 md:py-24 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3"><div class="sticky top-24"><img src="../../../../../static/images/guide.svg" class="h-10"/><h1 class="font-future text-2xl md:text-4xl font-bold my-5">Guides</h1><p class="text-base max-w-xs text-neutral-500  pr-6">Covering everything you need to know in order to build AI products faster.</p><div class="pb-4 md:pb-0"><div class="flex relative  md:max-w-xs my-10  md:pr-6"><input type="text" class="bg-transparent border-[1px] border-solid border-black w-full rounded-md pl-10 p-2 focus-visible:outline-none" placeholder="Search..."/><img class="absolute top-3 left-0 ml-2 w-6" src="../../../../../static/images/library/large_search_icon.svg"/></div></div><div class="hidden md:flex md:flex-col"><a href="../../../../index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Latest</a><a href="../../index.html" class="text-base text-neutral-900 font-medium hover:text-neutral-800 mb-4">Build AI</a><a href="../../../use-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Use AI</a><a href="../../../explore-manage-data/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Explore &amp; manage data</a><a href="../../../label-data-for-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Label data for AI</a><a href="../../../train-fine-tune-ai/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">Train &amp; fine-tune AI</a><a href="../../../mlops/index.html" class="text-base text-neutral-500 hover:text-neutral-800 mb-4">MLOps</a></div></div></div><div class="col-span-12 md:col-span-9"><div class="grid grid-cols-12 gap-6"><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-fine-tune-large-language-models-with-labelbox/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/index528e.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FFrame-2299--2-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-fine-tune-large-language-models-with-labelbox/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to fine-tune large language models (LLMs) with Quantumworks Lab</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-use-the-labelbox-connector-to-prepare-unstructured-data-for-ai-and-analytics-in-databricks/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexf0a8.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3013--3-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-use-the-labelbox-connector-to-prepare-unstructured-data-for-ai-and-analytics-in-databricks/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to prepare unstructured data for AI and analytics in Databricks</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/index4b8a.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-3012--4-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data</p><p class="text-base max-w-2xl undefined line-clamp-3">In this guide, we&#x27;ll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../intro-to-model-metrics/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexebef.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F03%2FGroup-2721--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../intro-to-model-metrics/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">An introduction to model metrics</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-train-evaluate-and-improve-your-ml-models/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexcf8d.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2966--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-train-evaluate-and-improve-your-ml-models/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to ship better models faster by leveraging Quantumworks Lab Model. In this guide, we&#x27;ll walk you through a COCO object detection example to get you onboarded in Model with your first project, model, and model run. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-kickstart-and-scale-your-data-labeling-efforts/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexc47c.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2973--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-kickstart-and-scale-your-data-labeling-efforts/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to kickstart and scale your data labeling efforts</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-evaluate-and-optimize-your-data-labeling-projects-results/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/index2f15.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2977--3-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-evaluate-and-optimize-your-data-labeling-projects-results/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to evaluate and optimize your data labeling project&#x27;s results</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-define-a-task-for-your-data-labeling-project/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexf18b.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2023%2F01%2FGroup-2974--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-define-a-task-for-your-data-labeling-project/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to define a task for your data labeling project</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to align on key components of your project: define a task, create an ontology, and determine timelines for your labeling project.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-find-similar-data-in-one-click/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexe3f3.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2965.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-find-similar-data-in-one-click/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to find similar data in one click</p><p class="text-base max-w-2xl undefined line-clamp-3">Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Learn more about how to find similar data in one click with Labelbox. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 h-100"><div class="h-100"><div class="bg-transparent rounded-lg h-100 flex flex-col"><a href="../../../../how-to-train-a-chatbot/index.html" target="_self" class="relative aspect-video  false border border-neutral-200 rounded-lg"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=3840&amp;q=70 3840w" src="../../../../../_next/image/indexd51d.html?url=https%3A%2F%2Flabelbox-guides.ghost.io%2Fcontent%2Fimages%2F2022%2F12%2FGroup-2962--1-.png&amp;w=3840&amp;q=70"/></a><div class="py-6 px-1 flex flex-col flex-grow justify-content-between"><div><a href="../../../../how-to-train-a-chatbot/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to train a chatbot</p><p class="text-base max-w-2xl undefined line-clamp-3">The rise in natural language processing (NLP) language models have given machine learning (ML) teams the opportunity to build custom, tailored experiences for their customers. Learn how to train a domain-specific chatbot.</p></a></div></div></div></div></div><div class="col-span-12"><div class="flex align-items-center justify-content-center mx-auto mt-8"><a class="mr-9 text-neutral-700 mb-1" href="../4/index.html">&lt;</a>Page 5 of 8<a class="ml-9 text-neutral-700 mb-1" href="../6/index.html">&gt;</a></div></div></div></div></div></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"id":"64134c4235aad5003db6f2b2","uuid":"72160526-3ea8-42ee-ab34-75b7b0fa3878","title":"How to fine-tune large language models (LLMs) with Quantumworks Lab","slug":"how-to-fine-tune-large-language-models-with-labelbox","html":"\u003ch2 id=\"what-are-large-language-models-llms\"\u003eWhat are large language models (LLMs)?\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/usecases/large-language-models/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eLarge language models\u003c/a\u003e leverage deep learning techniques to recognize, classify, analyze, generate and even predict text. Critical in \u003ca href=\"https://labelbox.com/usecases/natural-language-processing/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003enatural language processing (NLP)\u003c/a\u003e applications like AI voice assistants, chatbots, translation, and sentiment analysis — large language models rely upon large volumes of data to consistently comprehend, capture and convey the nuances of human language.\u003c/p\u003e\u003ch2 id=\"why-should-you-consider-using-one\"\u003eWhy should you consider using one?\u003c/h2\u003e\u003cp\u003eRecent advancements and accessibility of large language models can serve as a powerful starting point for your machine learning team. Although you’ll still need to retrain these base models on data that is contextually-relevant to your use case, leveraging a foundational model saves significant times and costs. Large language models significantly improve with Reinforcement Learning from Human Preferences (RLHP). This guide provides a framework for using Quantumworks Lab to fine-tune OpenAI 's popular GPT-3 large language model for your use case. \u003c/p\u003e\u003ch2 id=\"getting-started\"\u003e\u003cstrong\u003eGetting Started\u003c/strong\u003e \u003c/h2\u003e\u003cp\u003eThis guide and Colab notebook will walk you through how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eSelect your own relevant classification ontology to use with foundational large language models like GPT-3.\u003c/li\u003e\u003cli\u003eCreate a Project in Quantumworks Lab Annotate to generate labeled training data.\u003c/li\u003e\u003cli\u003eLeverage iterative model runs to rapidly tune OpenAI large language models.\u003c/li\u003e\u003cli\u003eUse Quantumworks Lab Model to diagnose performance, find high impact data, get the data labeled, and create another model run for the next iteration of fine tuning.\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/deya57pbun\" title=\"How to fine-tune large language models (LLMs) with Quantumworks Lab Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003ch3 id=\"1-import-colab-notebook-packages\"\u003e1. Import Colab notebook packages\u003c/h3\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1p3nwxBHUpnUMP4B3mWAACwL-g4uOpjzw?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eGoogle Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003eTo help you get started, for this workflow, we’ve created a \u003ca href=\"https://colab.research.google.com/drive/1p3nwxBHUpnUMP4B3mWAACwL-g4uOpjzw?ref=labelbox-guides.ghost.io\"\u003eColab notebook\u003c/a\u003e which has installed Open AI and Quantumworks Lab packages within the same python notebook. Import all of the packages and use the corresponding Open AI and Quantumworks Lab API keys to connect to your instances. \u003c/p\u003e\u003cp\u003e\u003ccode\u003e!pip install Quantumworks Lab[data] --upgrade -q !pip install openai -q \u003c/code\u003e\u003c/p\u003e\n\u003ch3 id=\"2-create-a-project-based-on-your-desired-data-ontology\"\u003e\u003cstrong\u003e2\u003c/strong\u003e.\u003cstrong\u003e Create a Project based on your desired data ontology\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eNext, \u003ca href=\"https://docs.labelbox.com/docs/create-a-project?ref=labelbox-guides.ghost.io\"\u003ecreate a Project\u003c/a\u003e in the platform that matches the defined ontology for the data you want to classify using Open AI’s GPT-3 model. Add this ontology to a Project. Our Colab notebook example focuses on classifying e-commerce assets into the following four categories that comprise 80% of all e-commerce assets sold:\u003c/p\u003e\u003cul\u003e\u003cli\u003e“Electronics”\u003c/li\u003e\u003cli\u003e“Household”\u003c/li\u003e\u003cli\u003e“Books”\u003c/li\u003e\u003cli\u003e“Clothing \u0026amp; Accessories” up  common e-commerce use case.  \u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e``import os \nimport openai\nfrom labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\nfrom Quantumworks Lab import Client, LabelingFrontend, LabelImport, MALPredictionImport``\n\n``from labelbox.data.annotation_types import (\n    Label, ImageData, ObjectAnnotation, MaskData,\n    Rectangle, Point, Line, Mask, Polygon,\n    Radio, Checklist, Text,\n    ClassificationAnnotation, ClassificationAnswer\n    )``\n\n``from labelbox.data.serialization import NDJsonConverter\nimport pandas as pd\nimport shutil\nimport labelbox.data\nimport json\nimport uuid ``\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3-generate-training-data\"\u003e3. Generate training data\u003c/h3\u003e\u003cp\u003eOnce you’ve determined the ontology and added it to your Quantumworks Lab Project, you can begin curating the training data that supports your requirements. This will ultimately play a critical role towards adapting GPT-3 to support your use case. Once you add your ontology to a project, you have multiple options for creating training data, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eUsing Quantumworks Lab Annotate to label the data yourself\u003c/li\u003e\u003cli\u003eImporting existing annotations you have in your data lake\u003c/li\u003e\u003cli\u003eLeveraging our experts from \u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003edata labeling services\u003c/a\u003e for support rapidly curating training-quality data \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"4-push-the-batch-of-training-data-labels-to-model-runs\"\u003e4. Push the batch of training data labels to model runs\u003c/h3\u003e\u003cp\u003eOnce you've created the training data, select the appropriate, corresponding data rows and export them to \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003eLabelbox Model\u003c/a\u003e for model training. Note that you'll need to implement model training settings that connect your model training environment and cloud service provider (CSP) to Labelbox. Our Colab Notebook demo uses Google Cloud Platform (GCP) but this same workflow and Quantumworks Lab’s cloud-agnostic platform works well with any model training environment. \u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-17-at-8.47.42-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1148\" height=\"586\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-17-at-8.47.42-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/Screen-Shot-2023-03-17-at-8.47.42-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-17-at-8.47.42-PM.png 1148w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eYou will iteratively run the last section of this notebook as you build momentum fine-tuning your model and improving performance.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"5-iteratively-improve-and-fine-tune-the-model\"\u003e5. Iteratively improve and fine-tune the model\u003c/h3\u003e\u003cp\u003eNext the Colab notebook features a list of prompts to iteratively train the Open AI GPT-3 model based on the annotations that fit your unique use case. As you review the model predictions in Quantumworks Lab Model, the platform will help you easily identify mis-predictions and target areas where the model consistently performs poorly. \u003c/p\u003e\u003cp\u003eIn Quantumworks Lab Catalog, you can leverage embeddings and similarity search features to find training data samples that exhibit similar characteristics to data where your model is consistently performing poorly – then queue that data for labeling so it can be incorporated during your next retraining iteration. You'll do this by iteratively \u003ca href=\"https://docs.labelbox.com/docs/batches?ref=labelbox-guides.ghost.io\"\u003esubmitting a batch\u003c/a\u003e – featuring these newly-curated Data Rows – to the same Project you created earlier (in step two) for fine-tuning your LLM. Ultimately, this iterative loop of exposing the model to new prompts will allow you to continuously fine-tune the GPT-3 model to perform based on your own data priorities.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-17-at-8.40.57-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1656\" height=\"834\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-17-at-8.40.57-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/Screen-Shot-2023-03-17-at-8.40.57-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/Screen-Shot-2023-03-17-at-8.40.57-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-17-at-8.40.57-PM.png 1656w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eFind and prioritize data from Catalog most likely to have the highest impact on your next training iteration.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe notebook feeds the output results from Open AI back into the Quantumworks Lab Model tab. This iterative back and forth workflow empowers you to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLeverage Quantumworks Lab Model to measure model performance \u003c/li\u003e\u003cli\u003eEvaluate model output predictions and identify areas where the model performs poorly\u003c/li\u003e\u003cli\u003eLeverage Catalog to prioritize data from your Catalog that will have the most maximal impact towards addressing your edge cases\u003c/li\u003e\u003cli\u003eFine-tune the Open AI large language model by iteratively feeding it relevant data addressing your ontology, finding erroneous model predictions and fixing areas where the model performs poorly.\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eGet started today by following the prompts in this \u003ca href=\"https://colab.research.google.com/drive/1p3nwxBHUpnUMP4B3mWAACwL-g4uOpjzw?ref=labelbox-guides.ghost.io#scrollTo=KSsXvqbaeLXs\"\u003eColab notebook\u003c/a\u003e. To learn more about Quantumworks Lab Model, check out the following guides below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-train-evaluate-and-improve-your-ml-models/?ref=labelbox-guides.ghost.io\"\u003eHow to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-run-model-assisted-labeling-with-active-learning-on-ner-data-with-a-hugging-face-model/?ref=labelbox-guides.ghost.io\"\u003eHow to run model-assisted labeling and active learning on NER data with a Hugging Face model\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"64134c4235aad5003db6f2b2","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Frame-2299--2-.png","featured":false,"visibility":"public","created_at":"2023-03-16T17:05:06.000+00:00","updated_at":"2024-10-02T22:30:29.000+00:00","published_at":"2023-03-22T23:00:29.000+00:00","custom_excerpt":"Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-fine-tune-large-language-models-with-Labelbox","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa506375d13000123d7e8","name":"Using LLMs","slug":"using-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-llms/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-fine-tune-large-language-models-with-labelbox/","excerpt":"Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. ","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":"How to fine-tune large language models (LLMs) with Quantumworks Lab","og_description":"Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. ","twitter_image":null,"twitter_title":"How to fine-tune large language models (LLMs) with Quantumworks Lab","twitter_description":"Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. ","meta_title":"How to fine-tune large language models (LLMs) with Quantumworks Lab","meta_description":"Learn how to iterate and rapidly fine-tune OpenAI large language models with Quantumworks Lab Model. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6418777a35aad5003db6f4d6","uuid":"7958bb69-5b16-4a54-b471-76f9db6354cc","title":"How to prepare unstructured data for AI and analytics in Databricks","slug":"how-to-use-the-labelbox-connector-to-prepare-unstructured-data-for-ai-and-analytics-in-databricks","html":"\u003cp\u003eLarge data lakes typically house a combination of structured and unstructured data. As the amount of unstructured data grows, you need a way to effectively prepare and analyze your unstructured datasets. \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://labelbox.com/blog/announcing-labelbox-on-databricks-partner-connect/?ref=labelbox-guides.ghost.io\"\u003eDatabricks and Quantumworks Lab partnership\u003c/a\u003e gives you an end-to-end environment for unstructured data workflows – a query engine built around Delta Lake, fast annotation tools, and a powerful machine learning compute environment. With the Quantumworks Lab Connector for Databricks and the LabelSpark API, you can easily integrate the two platforms and add structure to your data. \u003c/p\u003e\u003cp\u003eStart with unstructured data in your data lake, pass it to Quantumworks Lab for annotation, and load your annotations into Databricks for analysis.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.16.23-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1604\" height=\"980\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.16.23-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.16.23-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2024/02/Screenshot-2024-02-02-at-10.16.23-AM.png 1600w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.16.23-AM.png 1604w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eLabelbox empowers you to quickly explore, organize, and annotate a variety of unstructured data from your data lake. You can apply insights to modalities such as \u003ca href=\"https://labelbox.com/product/image?ref=labelbox-guides.ghost.io\"\u003eimages\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/video?ref=labelbox-guides.ghost.io\"\u003evideo\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/text?ref=labelbox-guides.ghost.io\"\u003etext\u003c/a\u003e, and \u003ca href=\"https://docs.labelbox.com/docs/tiled-imagery-editor?ref=labelbox-guides.ghost.io\"\u003egeospatial tiled imagery\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"what-will-you-learn-in-this-guide\"\u003eWhat will you learn in this guide?\u003c/h2\u003e\u003cp\u003eIn this guide, you’ll learn how you can access the Quantumworks Lab Connector for Databricks to prepare unstructured data for AI and analytics. This includes:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRequirements to get started\u003c/li\u003e\u003cli\u003eHow to create data rows with the Quantumworks Lab Connector for Databricks\u003c/li\u003e\u003cli\u003eHow to create data rows with metadata, annotations, and attachments \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eCheck out \u003ca href=\"https://www.databricks.com/session_na21/productionizing-unstructured-data-for-ai-and-analytics?ref=labelbox-guides.ghost.io\"\u003ethis end-to-end video demo\u003c/a\u003e of this workflow.\u003c/p\u003e\u003ch3 id=\"requirements-to-get-started\"\u003eRequirements to get started:\u003c/h3\u003e\u003cp\u003eYou can find the necessary requirements for all data rows \u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/intro.ipynb?ref=labelbox-guides.ghost.io\"\u003ein this notebook\u003c/a\u003e. \u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/intro.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eView notebook\u003c/a\u003e\u003c/div\u003e\u003ch3 id=\"requirements\"\u003eRequirements:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eA \u003ccode\u003erow_data\u003c/code\u003e column — This column must be URLs that point to the asset to-be-uploaded\u003c/li\u003e\u003cli\u003eEither a \u003ccode\u003edataset_id\u003c/code\u003e column or an input argument for \u003ccode\u003edataset_id\u003c/code\u003e\u003c/li\u003e\u003cli\u003eIf uploading to multiple datasets, provide a \u003ccode\u003edataset_id\u003c/code\u003e column\u003c/li\u003e\u003cli\u003eIf uploading to one dataset, provide a \u003ccode\u003edataset_id\u003c/code\u003e input argument (\u003cem\u003eThis can still be a column if it's already in your dataframe) \u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"recommended\"\u003eRecommended:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eA \u003ccode\u003eglobal_key\u003c/code\u003e column\u003c/li\u003e\u003cli\u003eThis column contains unique identifiers for your data rows\u003c/li\u003e\u003cli\u003eIf none is provided, will default to your \u003ccode\u003erow_data\u003c/code\u003e column\u003c/li\u003e\u003cli\u003eAn \u003ccode\u003eexternal_id\u003c/code\u003e column\u003c/li\u003e\u003cli\u003eThis column contains non-unique identifiers for your data rows\u003c/li\u003e\u003cli\u003eIf none is provided, will default to your \u003ccode\u003eglobal_key\u003c/code\u003e column\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"optional\"\u003eOptional:\u003c/h3\u003e\u003cul\u003e\u003cli\u003eA \u003ccode\u003eproject_id\u003c/code\u003e column or an input argument for \u003ccode\u003eproject_id\u003c/code\u003e\u003c/li\u003e\u003cli\u003eIf batching to multiple projects, provide a \u003ccode\u003eproject_id\u003c/code\u003e column\u003c/li\u003e\u003cli\u003eIf batching to one project, provide a \u003ccode\u003eproject_id\u003c/code\u003e input argument (\u003cem\u003eThis can still be a column if it's already in your dataframe)\u003c/em\u003e\u003c/li\u003e\u003cli\u003eA row_data column - this column must be URLs that point to the asset to-be-uploaded\u003c/li\u003e\u003cli\u003eA dataset_id column or an input argument for dataset_id\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eIf uploading to multiple datasets, provide a dataset_id column\u003c/strong\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eIf uploading to one dataset, provide a dataset_id input argument\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"creating-data-rows-with-the-labelbox-connector-for-databricks\"\u003eCreating data rows with the Quantumworks Lab Connector for Databricks\u003c/h2\u003e\u003cp\u003eOnce you have set up the above requirements, you can create data rows with the Quantumworks Lab Connector for Databricks. \u003c/p\u003e\u003cp\u003eFollow the steps outlined \u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/intro.ipynb?ref=labelbox-guides.ghost.io\"\u003ein this notebook\u003c/a\u003e to create data rows in Labelbox. \u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/intro.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eView notebook\u003c/a\u003e\u003c/div\u003e\u003ch2 id=\"an-end-to-end-demo-creating-data-rows-with-metadata-annotations-and-attachments-with-the-labelbox-connector-for-databricks\"\u003eAn end-to-end demo: Creating data rows with metadata, annotations, and attachments with the Quantumworks Lab Connector for Databricks\u003c/h2\u003e\u003cp\u003eIn addition to being able to create data rows with this connector, you can create data rows with attributes such as metadata, annotations, and attachments. \u003c/p\u003e\u003cp\u003eFollow the steps \u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/full-demo.ipynb?ref=labelbox-guides.ghost.io\"\u003ein this notebook\u003c/a\u003e to learn more about the requirements for creating metadata, annotations, and attachments and the steps needed to create data rows with all three attributes in Labelbox. \u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/full-demo.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eView notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003eYou can also refer to the below links for specific instructions on how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/metadata.ipynb?ref=labelbox-guides.ghost.io\"\u003eCreate a data row with metadata\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/annotations.ipynb?ref=labelbox-guides.ghost.io\"\u003eCreate a data row with annotations\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/Quantumworks Lab/labelspark/blob/master/notebooks/attachments.ipynb?ref=labelbox-guides.ghost.io\"\u003eCreate a data row with attachments\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003cp\u003eIf you have questions or encounter issues with the Quantumworks Lab Connector for Databricks, please reach out to \u003ca href=\"https://labelbox.atlassian.net/servicedesk/customer/portal/2?ref=labelbox-guides.ghost.io\"\u003eLabelbox Support\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eIn the meantime, you can learn more about \u003ca href=\"https://labelbox.com/customers/burberry-customer-story/?ref=labelbox-guides.ghost.io\"\u003ehow Burberry is harnessing the power of Quantumworks Lab and Databricks\u003c/a\u003e to curate their strategic marketing assets. \u003c/p\u003e","comment_id":"6418777a35aad5003db6f4d6","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3013--3-.png","featured":false,"visibility":"public","created_at":"2023-03-20T15:10:50.000+00:00","updated_at":"2024-02-02T18:16:59.000+00:00","published_at":"2023-03-20T17:17:50.000+00:00","custom_excerpt":"Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/prepare-unstructured-data-for-AI-and-analytics-in-Databricks","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-use-the-labelbox-connector-to-prepare-unstructured-data-for-ai-and-analytics-in-databricks/","excerpt":"Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. ","reading_time":3,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3013--3--2.png","og_title":"How to prepare unstructured data for AI and analytics in Databricks","og_description":"Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3013--3--1.png","twitter_title":"How to prepare unstructured data for AI and analytics in Databricks","twitter_description":"Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. ","meta_title":"How to prepare unstructured data for AI and analytics in Databricks","meta_description":"Learn how to use the Quantumworks Lab Connector to quickly explore, organize, and annotate a variety of unstructured data from your Data Lake. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6406883577b361003d3619d5","uuid":"4ab62fd8-b9da-474e-a833-f24758c230db","title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","slug":"using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data","html":"\u003cp\u003eOne of the biggest challenges that ML teams face is how difficult it is to select the right data to improve their ML models. From working with hundreds of teams, we’ve seen that ML teams possess a vast amount of unlabeled data, but lack a structured process for effectively finding and prioritizing \u003cem\u003especific data\u003c/em\u003e that can dramatically improve model performance. \u003c/p\u003e\u003cp\u003eThis manifests itself in the form of trying to find specific examples of an edge case where your model is struggling, or in the case of wanting to surface all occurrences of a rare data point that needs to be labeled in priority. In these cases, what is the best way for your team to efficiently surface this high-impact data?\u003c/p\u003e\u003ch2 id=\"what-will-you-learn-in-this-guide\"\u003eWhat will you learn in this guide? \u003c/h2\u003e\u003cp\u003eIn this guide, we'll show you how you can use a foundation model, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data. This technique will help your team quickly enrich your data with the latest advances in off-the-shelf models and embeddings.\u003c/p\u003e\u003cp\u003eBy the end of this guide, you’ll know how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGenerate custom embeddings with Hugging Face using a single line of code and upload your data to Quantumworks Lab in order to better explore and visualize your data.\u003c/li\u003e\u003cli\u003eBetter understand the distribution of your data and quickly find similar high-impact data.\u003c/li\u003e\u003cli\u003eUse Quantumworks Lab as a native similarity search engine, where you can leverage both off-the-shelf embeddings computed by Quantumworks Lab (for image, text, and documents) and upload your own custom embeddings to quickly find all instances of similar data.\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"what-are-embeddings\"\u003eWhat are embeddings? \u003c/h2\u003e\u003cp\u003eIn machine learning, an embedding, or feature vector, is an array of numbers assigned to an asset by a neural net. Assets that have similar content will also have similar embeddings. \u003c/p\u003e\u003cp\u003eFor example, in a dataset comprising images of apples and oranges, an appropriate embedding used for image similarity will show that all the vectors corresponding to apples have similar values. The vectors for all images of oranges will also be grouped together. \u003c/p\u003e\u003cp\u003eIn other words, the neural network acts as a feature extractor: it extracts an embedding vector that contains rich information about the data.\u003c/p\u003e\u003ch3 id=\"off-the-shelf-embeddings-vs-custom-embeddings\"\u003eOff-the-shelf embeddings vs custom embeddings\u003c/h3\u003e\u003cp\u003eWhen you connect your data to Quantumworks Lab, we automatically compute \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#supported-embeddings\"\u003eoff-the-shelf\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003eembeddings on your data – this includes CLIP embeddings for images and PDFs and All-mpnet-base-v2 embeddings for text. These off-the-shelf embeddings are a useful starting point for you to explore your data and conduct similarity searches. \u003c/p\u003e\u003cp\u003eHowever, in some cases where your data has unique attributes, you may want to use your own \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io#how-to-upload-custom-embeddings\"\u003ecustom embeddings\u003c/a\u003e to power your data selection. Quantumworks Lab allows you to upload up to 100 custom embeddings in addition to the off-the-shelf embeddings that are automatically computed. \u003c/p\u003e\u003cp\u003eYou can easily compare the results of these custom and provided off-the-shelf embeddings in Quantumworks Lab to discover the best embeddings to use for data selection.\u003c/p\u003e\u003ch2 id=\"how-to-upload-custom-embeddings\"\u003eHow to upload custom embeddings\u003c/h2\u003e\u003cp\u003eFirst, connect your data with Labelbox. You can integrate your cloud storage bucket with Quantumworks Lab via IAM delegated access:\u003c/p\u003e\u003cp\u003e\u003cem\u003eHow to set up a delegated access integration with Quantumworks Lab\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-amazons3-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eAmazon S3\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-gcp-storage-labelbox/?ref=labelbox-guides.ghost.io\"\u003eGCP Storage\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-set-up-a-delegated-access-integration-between-azure-and-labelbox/?ref=labelbox-guides.ghost.io\"\u003eMicrosoft Azure Blob Storage\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOnce you’ve successfully uploaded your data, Quantumworks Lab will automatically compute off-the-shelf embeddings on your data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1013\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-06-at-7.57.54-PM.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can then compute and upload custom embeddings from Hugging Face on your data:\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\" class=\"kg-btn kg-btn-accent\"\u003eGoogle Colab notebook\u003c/a\u003e\u003c/div\u003e\u003cp\u003e\u003cem\u003eFollow along in this \u003c/em\u003e\u003ca href=\"https://colab.research.google.com/github/Quantumworks Lab/labelbox-python/blob/master/examples/integrations/huggingface/huggingface.ipynb?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003eColab notebook \u003c/em\u003e\u003c/a\u003e\u003cem\u003ewith examples shown using ResNet-50 embeddings from Hugging Face.\u003c/em\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003eImport Quantumworks Lab into your notebook\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for Quantumworks Lab\n!pip3 install -q Quantumworks Lab[data]\nimport Quantumworks Lab as lb\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e2. Import the \u003ca href=\"https://github.com/Quantumworks Lab/advlib/tree/main/pylib/advlib?ref=labelbox-guides.ghost.io\"\u003eADVLib\u003c/a\u003e. This is a library built by Quantumworks Lab for you to upload custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# for custom embeddings in Quantumworks Lab\n!pip3 install -q 'git+https://github.com/Quantumworks Lab/advlib.git'\n#ndjson\n!pip3 install -q ndjson\nimport ndjson\nimport time\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e3. Select the data rows (images or text) in Quantumworks Lab on which you want to add custom embeddings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# get images from a Quantumworks Lab dataset\ndataset = client.get_dataset(\"clemr01l42uil07y36qkq7ygn\")\ndrs = list(dataset.export_data_rows(timeout_seconds=9999))\ndata_row_ids = [dr.uid for dr in drs]\ndata_row_urls = [dr.row_data for dr in drs]\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e4. Use Hugging Face to generate your custom embeddings by loading a specific neural network (e.g. Resnet50).\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# import HuggingFace\n!pip3 install -q transformers\n!pip3 install -q timm\n\n# load a neural network from HuggingFace \nimport transformers\ntransformers.logging.set_verbosity(50)\nimport torch\nimport torch.nn.functional as F\nimport PIL, requests\nfrom tqdm import tqdm\n\n# get ResNet-50\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\nmodel = transformers.ResNetModel.from_pretrained(\"microsoft/resnet-50\")\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cbr\u003e5. Generate custom embeddings by iterating over your image or text data. \u003c/p\u003e\u003cp\u003e\u003cem\u003eNote: \u003c/em\u003eThis should take approximately ~2 minutes for 512 images. For the similarity search function to work in Quantumworks Lab, you must upload at least 1,000 embeddings. \u003c/p\u003e\u003cul\u003e\u003cli\u003eRetrieve your images/text and run model inference \u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# process images\nimg_hf = image_processor(imgs, return_tensors=\"pt\")\n\n# generate resnet embeddings, thanks to inference\nwith torch.no_grad():\n\tlast_layer = model(**img_hf, output_hidden_states=True).last_hidden_state\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\u003cli\u003eRemember to do global pooling on the last layer of your embedding to reduce dimensionality\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e6. Create the payload to upload custom embeddings to Quantumworks Lab in the form of an NDJSON file.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# create the payload\npayload = []\nfor (dr_id,resnet_embedding) in zip(dr_ids, resnet_embeddings):\n\tpayload.append({\"id\": dr_id, \"vector\": resnet_embedding})\n\n# write to NDJson file\nwith open('payload.ndjson', 'w') as f:\n\tndjson.dump(payload, f)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e7. Pick an existing custom embedding or create a custom embedding.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# max pool to reduce dimensionality\nresnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\nresnet_embeddings = torch.flatten(resnet_embeddings, start_dim=1, end_dim=3)\n\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e8. Upload your payload of custom embeddings into Labelbox.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!advtool embeddings import \u0026lt;EMB ID\u0026gt; ./payload.ndjson\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e9. Use Quantumworks Lab Catalog UI to start conducting similarity searches.\u003c/p\u003e\u003ch2 id=\"how-to-quickly-find-instances-of-similar-data\"\u003eHow to quickly find instances of similar data\u003c/h2\u003e\u003cp\u003eOnce you have uploaded your custom embeddings to Quantumworks Lab, you can focus on curating data in Catalog that will dramatically improve your model’s performance.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eIdentify an edge case or rare example image/text you want to use to find similar data.\u003c/strong\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThis can include examples of data on which your model might be struggling. For example, let’s say the model is incorrectly classifying images with sparse patches of grass as having been affected by a wildfire. \u003c/p\u003e\u003cp\u003eIn the example below, the model appears to struggle on recognizing images with ‘no wildfire'\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1530\" height=\"736\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.12-AM.png 1530w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e2. Surface all instances of similar data.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1775\" height=\"959\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-16-47--1--1.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-16-47--1--1.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-16-47--1--1.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-16-47--1--1.gif 1775w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can run \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io\"\u003esimilarity searches\u003c/a\u003e to find all instances of similar data. A similarity search will automatically surface all similar data rows – you can select multiple data rows as anchors to continue to refine your similarity search. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Combine a similarity search with other search filters.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo filter the dataset even further, you can combine a similarity search with other \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003esearch filters\u003c/a\u003e. This includes filtering on metadata, media attribute, annotation, and more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1516\" height=\"824\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1000w, https://labelbox-guides.ghost.io/content/images/2024/02/Screenshot-2024-02-02-at-10.28.28-AM.png 1516w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003e4. Compare similarity search results.\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1772\" height=\"964\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-23-53--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-23-53--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-23-53--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-23-53--1-.gif 1772w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eYou can compare the results of the similarity search on different embeddings (across off-the-shelf and custom embeddings). This gives you an understanding of which embeddings are most effective towards providing your desired results. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e5. Add all instances of similar data to a labeling project or save it as a slice.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve found additional examples of similar data rows on which your model is struggling, you can queue them to your labeling project in priority or save the filters as a slice. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1774\" height=\"954\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/2023-03-06_17-29-38--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/03/2023-03-06_17-29-38--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/03/2023-03-06_17-29-38--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/03/2023-03-06_17-29-38--1-.gif 1774w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cbr\u003eBy saving your similarity search as a slice, any new incoming data that matches the search criteria will automatically show up in the slice. This enables automatic data curation.\u003c/p\u003e\u003cp\u003eLearn more about other key ML workflows that you can perform using similarity search \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003ein this guide\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eLeveraging embeddings as a powerful similarity search technique can help you find specific data points within an ocean of data. With a similarity search, you can easily query and curate specific data that will dramatically improve your model performance. If you’re interested in learning more, please check out the additional resources below.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdditional resources:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-kickstart-and-scale-your-data-labeling-efforts/?ref=labelbox-guides.ghost.io\"\u003eHow to kickstart and scale your data labeling efforts\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003eHow to filter and sort your data\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003eHow to find similar data in one click\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"6406883577b361003d3619d5","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-3012--4-.png","featured":false,"visibility":"public","created_at":"2023-03-07T00:41:25.000+00:00","updated_at":"2024-02-02T18:28:44.000+00:00","published_at":"2023-03-08T19:31:53.000+00:00","custom_excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-imapctful-data","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa4fb375d13000123d7e6","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/use-ai/"},{"id":"653aa513375d13000123d7ea","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/using-computer-vision/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/using-labelbox-and-foundation-models-to-generate-custom-embeddings-and-curate-impactful-data/","excerpt":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","reading_time":6,"access":true,"comments":false,"og_image":null,"og_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","og_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","twitter_image":null,"twitter_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","twitter_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","meta_title":"Using Quantumworks Lab and foundation models to generate custom embeddings and curate impactful data","meta_description":"In this guide, we'll show you how you can use foundation models, such as Hugging Face’s embedding extractors, combined with Quantumworks Lab’s search capabilities to select impactful data.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6375c52617f6c9003d7b0fd9","uuid":"5f8b37d4-a683-4515-a584-0116c30aa131","title":"An introduction to model metrics","slug":"intro-to-model-metrics","html":"\u003cp\u003eModel metrics help you evaluate the performance of a model and allows you to qualitatively compare different models. You can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. \u003c/p\u003e\u003ch3 id=\"why-does-model-accuracy-not-give-a-complete-picture-of-the-models-performance\"\u003eWhy does model accuracy not give a complete picture of the model's performance?\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.23.08-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1600\" height=\"392\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/12/Screen-Shot-2022-12-08-at-4.23.08-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/12/Screen-Shot-2022-12-08-at-4.23.08-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.23.08-PM.png 1600w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eAccuracy tells us the model's overall performance, but this metric doesn't provide all the information needed to accurately assess a model's performance. For a more holistic picture, we'll need to consider other metrics, based on the specific context that the model is used in.\u003c/p\u003e\u003cp\u003eGenerally, accuracy tends to be high in situations where a class has a very low probability of occurring, so a model can achieve high accuracy by simply predicting the most common class. For instance, the probability of finding cancer in computed topography scans or of finding swimming pools from satellite images of homes is low, so the model's accuracy can be high even if the model's ability to detect true positives is very poor.\u003c/p\u003e\u003ch3 id=\"precision\"\u003ePrecision\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.36.39-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1522\" height=\"702\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/12/Screen-Shot-2022-12-08-at-4.36.39-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/12/Screen-Shot-2022-12-08-at-4.36.39-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.36.39-PM.png 1522w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003ePrecision metrics focus on consistency and agreement among labelers, which are primarily derived from Quantumworks Lab's built-in consensus capability. Quantumworks Lab uses and tests the effectiveness of over 15 similar metrics for a wide range of supported annotations.\u003c/p\u003e\u003cp\u003ePrecision is a valuable metric when the negative cost of a false positive is high. For example, in spam detection models, a false positive would cause a vital email to be hidden and marked as spam when in fact, it is non-spam. A false positive in this case would negatively impact the user experience for seeing essential and urgent emails on time.\u003c/p\u003e\u003cp\u003ePopular precision metrics include:\u003c/p\u003e\u003cul\u003e\u003cli\u003eKrippendorff's Alpha is a popular metric used to assess the agreement among raters because it works well for two or more raters, can handle missing data, and supports nominal, ordinal, and ranking data types.\u003c/li\u003e\u003cli\u003eStandard deviation measures the dispersion of a set of ratings from their mean (average) value. In the context of AI data quality, it quantifies how much variation or spread exists in the ratings given by different AI trainers for the same item or task.\u003c/li\u003e\u003cli\u003ePercent agreement is a straightforward measure of inter-rater reliability that calculates the proportion of times different raters agree in their judgments. This is particularly useful in classification tasks (enums).\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"\"\u003e\u003c/h3\u003e\u003ch3 id=\"recall\"\u003eRecall\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.38.13-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1616\" height=\"774\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/12/Screen-Shot-2022-12-08-at-4.38.13-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/12/Screen-Shot-2022-12-08-at-4.38.13-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2022/12/Screen-Shot-2022-12-08-at-4.38.13-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-08-at-4.38.13-PM.png 1616w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eRecall is a helpful metric to use when the cost of false negative is high, and you want to minimize it. For example, in fraud detection models, a false negative would cause a fraudulent transaction to be successfully processed when it should have been flagged as fraudulent. This would obviously have a negative impact on the finances of the user. Recall is also helpful for most medical condition predictions, where you would minimize false negatives to increase recall.\u003c/p\u003e\u003ch3 id=\"f-1\"\u003eF-1\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-03-at-12.47.58-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"938\" height=\"316\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/03/Screen-Shot-2023-03-03-at-12.47.58-PM.png 600w, https://labelbox-guides.ghost.io/content/images/2023/03/Screen-Shot-2023-03-03-at-12.47.58-PM.png 938w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eIn some cases with imbalanced data problems, both precision and recall are important – we can consider the F1 score as an evaluation metric. An F1 score helps in the detection of skewed datasets and rare classes. Generally, it is best to have high precision and recall so that your F1 score is high. \u003c/p\u003e\u003cp\u003eTo demonstrate how accuracy only provides a partial assessment of a model's performance, we can compare the model metrics of two models below: \u003c/p\u003e\u003cfigure class=\"kg-card kg-gallery-card kg-width-wide\"\u003e\u003cdiv class=\"kg-gallery-container\"\u003e\u003cdiv class=\"kg-gallery-row\"\u003e\u003cdiv class=\"kg-gallery-image\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-01-at-6.20.45-PM.png\" width=\"1142\" height=\"808\" loading=\"lazy\" alt=\"\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/12/Screen-Shot-2022-12-01-at-6.20.45-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/12/Screen-Shot-2022-12-01-at-6.20.45-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-01-at-6.20.45-PM.png 1142w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/div\u003e\u003cdiv class=\"kg-gallery-image\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-01-at-6.20.59-PM.png\" width=\"1142\" height=\"792\" loading=\"lazy\" alt=\"\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/12/Screen-Shot-2022-12-01-at-6.20.59-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/12/Screen-Shot-2022-12-01-at-6.20.59-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2022/12/Screen-Shot-2022-12-01-at-6.20.59-PM.png 1142w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/figure\u003e\u003cp\u003eThe accuracy in model A is 73.65%, and model B is 83.69%. Based on accuracy alone, model B seems to perform better. However, if you compare their recall scores, then model A has a better recall of 87.38% vs model B's 82.97% recall. Taking this into account, model A performs better since the cost of a false negative is high. \u003c/p\u003e\u003ch3 id=\"what-do-model-metrics-look-like-in-labelbox\"\u003eWhat do model metrics look like in Quantumworks Lab? \u003c/h3\u003e\u003cp\u003eRather than having you manually compute and upload metrics, \u003ca href=\"https://docs.labelbox.com/docs/models-overview?ref=labelbox-guides.ghost.io\"\u003eLabelbox Model\u003c/a\u003e auto-computes metrics such as precision, recall, F-1, confusion matrix, etc. on individual predictions for you. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/2022-12-19_22-08-24--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1773\" height=\"884\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/2022-12-19_22-08-24--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/2022-12-19_22-08-24--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/2022-12-19_22-08-24--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/01/2022-12-19_22-08-24--1-.gif 1773w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eLabelbox Model will auto-generate metrics on individual predictions\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eYou can simply upload your model predictions and ground truths to receive auto-generated metrics on model precision, recall, F1-score, TP/TN/FP/FN, and confusion matrix.\u003c/li\u003e\u003cli\u003eIf the auto-generated metrics aren’t sufficient for your use case, you can upload your own custom metrics as well.\u003c/li\u003e\u003cli\u003eVisualize, filter, sort, and drill into your metrics, confidence scores, predictions, and annotations. This allows you to easily surface mispredictions, mislabeled data, and allows you to quickly identify improvements to your training data.\u003c/li\u003e\u003cli\u003eYou can interact and click into the NxN confusion matrix or click into the IOU / Precision / Recall histograms to surface and view specific data rows in “gallery view.” For instance, you can understand where your model is not performing well, where your labels are off, or where your model is the least confident.\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/Screenshot-2022-12-21-at-18.09.09-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1031\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/Screenshot-2022-12-21-at-18.09.09-1.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/Screenshot-2022-12-21-at-18.09.09-1.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/Screenshot-2022-12-21-at-18.09.09-1.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/01/Screenshot-2022-12-21-at-18.09.09-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eAuto-computed confusion matrix\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eUpload confidence scores alongside every prediction and tune the confidence and IOU thresholds in the Quantumworks Lab Model UI to see how model metrics change as the thresholds change.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eFind the distribution of annotations and predictions in every model run via histograms\u003c/strong\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/histogram-1.jpeg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1980\" height=\"1337\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/histogram-1.jpeg 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/histogram-1.jpeg 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/histogram-1.jpeg 1600w, https://labelbox-guides.ghost.io/content/images/2023/01/histogram-1.jpeg 1980w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eUse the prediction and annotation distribution histogram to surface important information about your model runs\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn addition, you can easily understand the distribution of your annotations and predictions via histograms. This makes curating datasets for labeling and analyzing model performance easier than ever. You can now use distributions to find the most predicted or least-predicted class and surface classes represented in training data, but rarely predicted by the model. \u003c/p\u003e\u003ch3 id=\"labelbox-leaderboards-a-new-era-of-evaluation-for-generative-ai\"\u003e\u003cstrong\u003eLabelbox leaderboards: A new era of evaluation for generative AI\u0026nbsp;\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eIn the rapidly evolving landscape of artificial intelligence, traditional benchmarks are no longer sufficient to capture the full capabilities of AI models. As AI grows increasingly complex, challenges like data contamination, overfitting to public benchmarks, scalability issues, and the absence of standardized evaluation criteria necessitate a more advanced approach to model metrics. \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://labelbox.com/leaderboards/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox leaderboards\u003c/u\u003e\u003c/a\u003e are the first to tackle these challenges by conducting structured evaluations on subjective AI model outputs using human experts and a scientific process that provides detailed feature-level metrics and multiple ratings. Leaderboards are available for \u003ca href=\"https://labelbox.com/leaderboards/image-generation/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eImage Generation\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://labelbox.com/leaderboards/speech-generation?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eSpeech Generation\u003c/u\u003e\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/leaderboards/video-generation?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eVideo Generation\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eBy combining expert human evaluations with our \u003ca href=\"https://www.alignerr.com/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eAlignerr\u003c/u\u003e\u003c/a\u003e workforce, reliable methodology, and continuous updates, Quantumworks Lab is redefining AI evaluation. Our approach complements traditional leaderboards by offering a  comprehensive and human-based assessment of AI models. \u003c/p\u003e\u003cp\u003eRead more about Quantumworks Lab leaderboards on our blog \u003ca href=\"https://labelbox.com/blog/labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"get-started-today\"\u003e\u003cstrong\u003eGet started today\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003e\u003cstrong\u003e \u003c/strong\u003eLabelbox offers a robust platform coupled with expert human evaluation services to efficiently generate and visualize these metrics, empowering you to make informed decisions and improve your models.\u0026nbsp;\u003c/p\u003e\u003cp\u003eYou can learn more about Quantumworks Lab auto-metrics in our \u003ca href=\"https://docs.labelbox.com/docs/evaluate-model-performance?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e or by reviewing \u003ca href=\"https://docs.labelbox.com/reference/upload-image-predictions?ref=labelbox-guides.ghost.io\"\u003ehow to upload image predictions in Quantumworks Lab\u003c/a\u003e.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cp\u003eIf you're interested in implementing this evaluation approach or leveraging Quantumworks Lab's tools for your model evaluation, \u003ca href=\"https://app.labelbox.com/signup?utm_source=google\u0026utm_medium=paid-search\u0026utm_campaign=20490363302\u0026utm_keyword=Quantumworks Lab%2520pricing\u0026gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_HaRJu-zYfq545Dxl9HUqyPBNDpQAHecf-NxYsnKueRGjicsKGXfRoCzlsQAvD_BwE\u0026landingPageAnonymousId=%22a83b92ec-b8b4-41cd-9622-4e3725a530bf%22\u0026referrer_url=https://www.google.com/\u0026_r=https://www.google.com/\"\u003e\u003cu\u003esign up for a free\u003c/u\u003e\u003c/a\u003e Quantumworks Lab account to try it out, or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003econtact us\u003c/u\u003e\u003c/a\u003e to learn more.\u003c/p\u003e","comment_id":"6375c52617f6c9003d7b0fd9","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-2721--1-.png","featured":false,"visibility":"public","created_at":"2022-11-17T05:22:46.000+00:00","updated_at":"2024-11-27T03:03:43.000+00:00","published_at":"2023-03-03T17:53:39.000+00:00","custom_excerpt":"Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/intro-to-model-metrics","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"},{"id":"653aa598375d13000123d7f2","name":"MLOps","slug":"mlops","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/mlops/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/intro-to-model-metrics/","excerpt":"Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. ","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":"An introduction to model metrics","og_description":"Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/03/Group-2721--1--2.png","twitter_title":"An introduction to model metrics","twitter_description":"Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. ","meta_title":"An introduction to model metrics","meta_description":"Learn how you can use model metrics to surface low-performing classes, find and fix labeling errors, and improve the overall performance of the model before it hits production on real-world data. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6348256660b562003d250b50","uuid":"f78ce8ff-29aa-4034-9953-1b6b50823eea","title":"How to get started in Quantumworks Lab Model: Train, evaluate, and improve your ML models","slug":"how-to-train-evaluate-and-improve-your-ml-models","html":"\u003cp\u003eThe quality of your data will dictate your model’s performance. ML teams have historically had to rely on manual methods of curating data and debugging model errors. For teams who are looking to go through fast, data-centric iterations, this is not an ideal way to quickly scale and reach production AI. \u003c/p\u003e\u003cp\u003eIn order to ship performant models, you need to be able to quickly train models with collaborative data-centric tools. Quantumworks Lab Model can help you ship better models faster by leveraging collaborative tools to curate, debug, diagnose, and optimize your machine learning data and models.\u003c/p\u003e\u003cp\u003eThis guide will walk you through how to get started with \u003ca href=\"https://app.labelbox.com/models?ref=labelbox-guides.ghost.io\"\u003eModel in the Quantumworks Lab platform\u003c/a\u003e. We’ll walk through a COCO object detection example and show you how to get onboarded in Model with your first project, model, and model run. \u003c/p\u003e\u003cp\u003eBy the end of the tutorial, you will have learned how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eUpload and version a dataset in a Quantumworks Lab Model run\u003c/li\u003e\u003cli\u003eExport and train an object detection model from a pre-trained model\u003c/li\u003e\u003cli\u003eVisualize model predictions against ground truth annotations\u003c/li\u003e\u003cli\u003eView auto-generated metrics (F1, precision, recall, IOU, confusion matrix, etc.) and the distribution of annotations and predictions\u003c/li\u003e\u003cli\u003eEvaluate model performance and improve your model and data with error analysis and active learning\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eKey definitions in Quantumworks Lab Model:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eA \u003ca href=\"https://docs.labelbox.com/docs/create-a-model?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003emodel\u003c/em\u003e\u003c/a\u003e\u0026nbsp;is a large language model (LLM) integrated into Quantumworks Lab Model or your custom configuration specified by an ontology of data.\u003c/li\u003e\u003cli\u003eAn \u003ca href=\"https://docs.labelbox.com/docs/experiments?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003e\u003cem\u003eexperiment\u003c/em\u003e \u003c/u\u003e\u003c/a\u003eis a directory where you can create, manage, and compare a set of \u003cem\u003emodel runs\u003c/em\u003e related to the same machine learning task (e.g object detection on COCO). \u003c/li\u003e\u003cli\u003eA \u003ca href=\"https://docs.labelbox.com/docs/create-a-model-run?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003emodel run\u003c/em\u003e\u003c/a\u003e is a model training experiment within a model directory. Each model run provides a versioned data snapshot of the data rows, annotations, and training/validation/test splits for that model run\u003c/li\u003e\u003cli\u003eYou can specify \u003ca href=\"https://docs.labelbox.com/docs/add-model-run-config-to-track-hyperparameters?ref=labelbox-guides.ghost.io\"\u003e\u003cem\u003emodel run configuratio\u003c/em\u003ens\u003c/a\u003e to create, version, and track your hyperparameters and any training-related configurations for a model run\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"part-1-seed-a-coco-dataset-and-create-a-project-and-model-run\"\u003ePart 1: Seed a COCO dataset and create a project and model run\u003c/h2\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/174ebhOCA8XeQ-WavIDZw3U1EeUHh8MaV?ref=labelbox-guides.ghost.io#scrollTo=UxrfeTs6fint\" class=\"kg-btn kg-btn-accent\"\u003ePart 1: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/74ypf3u3ba\" title=\"How to get started in Quantumworks Lab Model (Part 1) Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"640\" height=\"360\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eFor this onboarding tutorial, we’ll be working with a COCO dataset example. You can follow along by using the \u003c/em\u003e\u003ca href=\"https://colab.research.google.com/drive/174ebhOCA8XeQ-WavIDZw3U1EeUHh8MaV?ref=labelbox-guides.ghost.io#scrollTo=UxrfeTs6fint\"\u003e\u003cem\u003eGoogle Colab Notebook\u003c/em\u003e\u003c/a\u003e\u003cem\u003e and the accompanying video tutorials, but feel free to also bring your own dataset into Quantumworks Lab Model to create a Quantumworks Lab project, model and model run for your use case.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBefore you begin this tutorial, you’ll need to sign into your Quantumworks Lab account or \u003c/strong\u003e\u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003ecreate a free account\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e.\u003c/strong\u003e\u003c/p\u003e\u003ch3 id=\"step-1-upload-the-coco-dataset-to-labelbox\"\u003eStep 1: Upload the COCO dataset to Quantumworks Lab\u003c/h3\u003e\u003cul\u003e\u003cli\u003eUse the provided helper functions in the Colab Notebook to upload the provided COCO dataset to Quantumworks Lab\u003c/li\u003e\u003cli\u003eOnce you’ve successfully run the helper function, you should be able to see the COCO dataset appear in \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/Screen-Shot-2023-01-18-at-4.41.01-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1068\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/Screen-Shot-2023-01-18-at-4.41.01-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/Screen-Shot-2023-01-18-at-4.41.01-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/Screen-Shot-2023-01-18-at-4.41.01-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/01/Screen-Shot-2023-01-18-at-4.41.01-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch3 id=\"step-2-upload-the-coco-dataset%E2%80%99s-bounding-box-labels-to-labelbox\"\u003eStep 2: Upload the COCO dataset’s bounding box labels to Quantumworks Lab\u003c/h3\u003e\u003cul\u003e\u003cli\u003eWhile labels are typically created by an internal or external team of labelers, we are going to use an already labeled public dataset for this tutorial\u003c/li\u003e\u003cli\u003eUse the provided helper function to directly upload the dataset’s labels to Quantumworks Lab\u003c/li\u003e\u003cli\u003eSimilarly to the step above, you should be able to see your COCO data rows and the appropriate labels in \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"step-3-populate-a-model-run-version-model-run-data-and-model-hyperparameters\"\u003eStep 3: Populate a model run: Version model run data and model hyperparameters\u003c/h3\u003e\u003cul\u003e\u003cli\u003eNow, we’re ready to populate the above data (dataset + labels) in a model run\u003c/li\u003e\u003cli\u003eFollow the steps in the Colab Notebook to configure the ontology (containing classes of objects that we want to detect in the image dataset)\u003c/li\u003e\u003cli\u003eYou can also specify your model run’s hyperparameters\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"step-4-view-your-populated-model-run-in-the-model-tab\"\u003eStep 4: View your populated model run in the Model tab\u003c/h3\u003e\u003cul\u003e\u003cli\u003eOnce you’ve completed these steps, you should be able to see your versioned data in the Model tab\u003c/li\u003e\u003cli\u003eYou can view your data rows, labels, and inspect your model run configuration (hyperparameters) in the Quantumworks Lab app \u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/Screen-Shot-2023-01-18-at-4.41.26-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1052\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/Screen-Shot-2023-01-18-at-4.41.26-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/Screen-Shot-2023-01-18-at-4.41.26-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/Screen-Shot-2023-01-18-at-4.41.26-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/01/Screen-Shot-2023-01-18-at-4.41.26-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eNext, we’re going to use the model run data that we’ve uploaded in Quantumworks Lab to train a model.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"part-2-fine-tune-a-faster-r-cnn-model-upload-predictions-to-model-and-run-error-analysis\"\u003ePart 2: Fine-tune a Faster R-CNN model, upload predictions to Model, and run error analysis\u003c/h2\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"kg-card kg-button-card kg-align-left\"\u003e\u003ca href=\"https://colab.research.google.com/drive/1mSl3RU8tz2NMQUbE5RZC9rjsmXCTjgjT?ref=labelbox-guides.ghost.io#scrollTo=kvrRY4pJk1ul\" class=\"kg-btn kg-btn-accent\"\u003ePart 2: Google Colab Notebook\u003c/a\u003e\u003c/div\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/yxk8wmgpmg\" title=\"How to get started in Quantumworks Lab Model (Part 2) Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003ch3 id=\"step-1-train-an-object-detection-model-from-a-pre-trained-faster-r-cnn-model\"\u003eStep 1: Train an object detection model from a pre-trained Faster R-CNN model\u003c/h3\u003e\u003cul\u003e\u003cli\u003eExport the labels from the model run you created – the labels will be versioned by the model run\u003c/li\u003e\u003cli\u003eUse the provided helper function to transform the labels into a format that the Pytorch model can accept\u003c/li\u003e\u003cli\u003eWe’ve provided a Faster R-CNN model for fine-tuning – this replaces the last box prediction head with a new layer so that it can predict the model ontology and classes that we are concerned with\u003c/li\u003e\u003cli\u003eTrain the Faster R-CNN model for 1 epoch (4 minutes) – after this, you’ll have a model that performs decently well for this use case\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"step-2-generate-predictions-with-the-trained-model\"\u003eStep 2: Generate predictions with the trained model \u003c/h3\u003e\u003cul\u003e\u003cli\u003eGenerating predictions will help us visualize model performance in Quantumworks Lab Model and can help identify model errors\u003c/li\u003e\u003cli\u003eAssemble predictions and results of the model into a format that can be ingested back into Quantumworks Lab\u003c/li\u003e\u003cli\u003eTurn predictions into NumPy arrays and create annotation payloads for each object \u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWant to upload a \u003c/strong\u003e\u003ca href=\"https://labelbox.com/blog/bring-your-own-models-to-labelbox-with-new-custom-model-integration/?ref=labelbox-guides.ghost.io\"\u003e\u003cstrong\u003e\u003cu\u003ecustom model\u003c/u\u003e\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e instead?\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAt Quantumworks Lab, we want to ensure you are able to upload your own models quickly and easily, with no manual onboarding. With just a few clicks, you can seamlessly integrate your own custom models into our platform to enhance prediction, accelerate model evaluation, and improve data enrichment.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdlv2idAhfmVrY-LfZhsvYcU2L7e9a5gJ-9XLJW_f98QwSSm6SlOvKk36PC-8parhUQmEc02JMpOhffaz9IjfDYGNOzfzGZNsHb9qCRDqi3r4_KUoVr2KvLV6Tgo8PHbHL1DtUM?key=d5f31BHEZOcEnpQg1zrr_5zJ\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"339\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003e\u0026nbsp;Import a Custom Model from the Model homepage\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"step-3-upload-predictions-back-into-your-labelbox-model-run\"\u003eStep 3: Upload predictions back into your Quantumworks Lab model run \u003c/h3\u003e\u003cul\u003e\u003cli\u003eUpload the model predictions to the Quantumworks Lab app in order to visualize how the model is performing\u003c/li\u003e\u003cli\u003eOther than confidence scores, you don’t have to worry about computing metrics. Quantumworks Lab Model will auto-compute model metrics such as F1 scores, precision, IOU,  confusion matrix, false positives/false negatives/true positives/true negatives, etc\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"step-4-visualize-model-predictions-and-auto-generated-metrics-in-labelbox-model\"\u003eStep 4: Visualize model predictions and auto-generated metrics in Quantumworks Lab Model \u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/GIF--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/GIF--1-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/GIF--1-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/GIF--1-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2023/01/GIF--1-.gif 1920w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eAfter you’ve completed the steps above, you should now be able to go to the Models tab to visualize model predictions and model metrics\u003c/li\u003e\u003cli\u003eClick on “Metrics View” to inspect model metrics and the model’s performance on each class\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can run \u003ca href=\"https://docs.labelbox.com/docs/find-model-errors?ref=labelbox-guides.ghost.io\"\u003eerror analysis\u003c/a\u003e on specific classes or data rows of interest:\u003c/p\u003e\u003cul\u003e\u003cli\u003eStart by inspecting how the model is doing on each class\u003c/li\u003e\u003cli\u003eIf you notice the model is struggling on a specific class, you can click into the histogram to view data rows on which the model is struggling. You can refine the search query to further drill into and inspect model performance\u003c/li\u003e\u003cli\u003eLeverage “detailed view” to better inspect disagreements and find patterns of model failures on images\u003c/li\u003e\u003cli\u003eAfter running error analysis, you can make more informed decisions on how to iterate and improve your model’s performance with corrective action or targeted data selection\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"learn-more\"\u003eLearn More \u003c/h2\u003e\u003cp\u003eBy following this step-by-step tutorial, you’ve now successfully created a model, a model run, and have uploaded model predictions into Quantumworks Lab for further analysis. \u003c/p\u003e\u003cp\u003eYou can also refer to the below guides for a more in-depth walkthrough on how to improve data selection and model performance:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-search-surface-and-prioritize-data-within-a-project/?ref=labelbox-guides.ghost.io\"\u003eHow to search, surface, and prioritize data within a project\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/active-learning?ref=labelbox-guides.ghost.io\"\u003eHow to prioritize high-value data\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-and-fix-label-errors/?ref=labelbox-guides.ghost.io\"\u003eHow to find and fix label errors\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-and-fix-model-errors/?ref=labelbox-guides.ghost.io\"\u003eHow to find and fix model errors\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003eHow to find similar data in one click\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’re happy to help answer any questions. Reach out to us anytime on our \u003ca href=\"https://labelbox.com/sales?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003econtact us\u003c/u\u003e\u003c/a\u003e page. \u003c/p\u003e","comment_id":"6348256660b562003d250b50","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2966--1-.png","featured":false,"visibility":"public","created_at":"2022-10-13T14:49:10.000+00:00","updated_at":"2024-11-27T02:19:06.000+00:00","published_at":"2023-01-25T23:49:15.000+00:00","custom_excerpt":"Learn how to ship better models faster by leveraging Quantumworks Lab Model. In this guide, we'll walk you through a COCO object detection example to get you onboarded in Model with your first project, model, and model run. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-train-evaluate-and-improve-your-ML-models","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa5be375d13000123d7f4","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox-guides.ghost.io/tag/train-fine-tune-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-train-evaluate-and-improve-your-ml-models/","excerpt":"Learn how to ship better models faster by leveraging Quantumworks Lab Model. In this guide, we'll walk you through a COCO object detection example to get you onboarded in Model with your first project, model, and model run. ","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":"How to get started in Quantumworks Lab Model: train, evaluate, and improve your ML models","og_description":"Learn how to ship better models faster by leveraging Quantumworks Lab Model. In this guide, we'll walk you through a COCO object detection example to get you onboarded in Model with your first project, model, and model run. ","twitter_image":null,"twitter_title":"How to get started in Quantumworks Lab Model: train, evaluate, and improve your ML models","twitter_description":"Learn how to ship better models faster by leveraging Quantumworks Lab Model. In this guide, we'll walk you through a COCO object detection example to get you onboarded in Model with your first project, model, and model run. ","meta_title":"How to get started in Quantumworks Lab Mode: Train evaluate, and improve your ML models","meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"63bdef75be228d003d1e9ce3","uuid":"abe288c8-c70e-407b-b727-da6a90605cb3","title":"How to kickstart and scale your data labeling efforts","slug":"how-to-kickstart-and-scale-your-data-labeling-efforts","html":"\u003cp\u003eYour model performance will only ever be as strong as the quality of your training data. A common bottleneck for many AI teams is how to obtain vast amounts of high-quality training data for their use case at scale in the most time efficient and cost-effective way possible. \u003c/p\u003e\u003cp\u003eWhen it comes to deciding how to label your data, you might consider one of the following options:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCompletely outsource this task to a labeling service — these external teams often receive training on the specific labeling tasks required and quickly proceed to label large datasets\u003c/li\u003e\u003cli\u003eLeverage AI-powered solutions from a labeling platform to speed up the labeling process\u003c/li\u003e\u003cli\u003eManage homegrown or open source tools and rely on your own internal team of labelers to label your dataset\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOn the surface, the above options may seem sufficient, but they have their disadvantages. The labeling process itself is opaque, so by relying on completely outsourcing your task, you risk having little insight into metrics such as labeling quality, throughput, and efficiency. If you’re working with sensitive data, outsourcing labeling can be a greater challenge regarding security concerns. Many service providers also don’t provide access to a labeling platform, hindering AI teams from experimenting within the labeling process and taking advantage of techniques like automation and active learning. In addition, utilizing in-house or open source tools can quickly become hard to manage, resulting in an exorbitant amount of time and resources in maintenance and scale. This can lead to delays from quality management and labeling iteration, poor ontology creation and management, miscommunication between stakeholders, SMEs, labelers, and more.\u003c/p\u003e\u003cp\u003eTo appropriately scale and maintain the quality required for your production use case, you’ll need to leverage a \u003ca href=\"https://labelbox.com/learn/library/complete-guide-data-engines-for-ai/?ref=labelbox-guides.ghost.io\"\u003edata engine\u003c/a\u003e. An effective data engine combines data management, quality and performance monitoring, and advanced techniques and labeling services to help improve the speed and efficiency of your labeling operations.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/Frame_2963.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1368\" height=\"1010\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/Frame_2963.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/Frame_2963.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/01/Frame_2963.png 1368w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eLabelbox provides \u003c/em\u003e\u003c/i\u003e\u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\" rel=\"noreferrer\"\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003elabeling services\u003c/em\u003e\u003c/i\u003e\u003c/a\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e and AI expertise, on-demand. You can outsource labeling work and partner with ML experts to fine-tune the above workflows to ensure clarity on tasks and achieve your quality targets.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRegardless of your use case, if you’re working with an external labeling team or partnering with a service provider, you’ll want to make sure that you’re set up for success. Carefully outlining your labeling project and task, defining your project’s success criteria, measuring and maintaining quality, scaling your labeling operations, and evaluating your project’s results are all key steps to ensuring that you are producing high-quality training data.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"step-1-define-a-task-for-your-labeling-project\"\u003eStep 1: Define a task for your labeling project\u003c/h2\u003e\u003col\u003e\u003cli\u003eAlign on the key components of your labeling task so that it can be effectively communicated to your labeling team\u003c/li\u003e\u003cli\u003eDetermine the \u003ca href=\"https://docs.labelbox.com/docs/datasets-datarows?ref=labelbox-guides.ghost.io#supported-data-types\"\u003edata type\u003c/a\u003e or industry vertical — this allows your Labeling Team Manager to appropriately match you with a team of labelers well-suited for your task\u003c/li\u003e\u003cli\u003eOutline any specific labeling or compliance requirements for this task — this will often require a specialized workforce that is trained in your specific industry or task\u003c/li\u003e\u003cli\u003eDefine your data volume and agree on a project timeline — this will help allocate resources for your project and set expectations upon project start\u003c/li\u003e\u003cli\u003eCreate \u003ca href=\"https://labelbox.com/guides/how-to-create-and-manage-ontologies/?ref=labelbox-guides.ghost.io\"\u003ean ontology\u003c/a\u003e with the goals of proper labeling, efficiency, and reusability in mind\u003c/li\u003e\u003cli\u003eProvide labeling instructions for the labeling team to use — instructions should provide context to the task, explain what the task entails, describe the labeling steps, and be treated as a “living document”\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eTo learn more, read our guide, \u003ca href=\"https://labelbox.com/guides/how-to-define-a-task-for-your-data-labeling-project/?ref=labelbox-guides.ghost.io\"\u003eHow to define a task for your data labeling project\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"step-2-define-your-labeling-project%E2%80%99s-success-criteria\"\u003e\u003cbr\u003eStep 2: Define your labeling project’s success criteria \u003c/h2\u003e\u003col\u003e\u003cli\u003eUnderstand your project’s timeline and scope — this includes any deadlines, projected data volume, and the  average time per label\u003c/li\u003e\u003cli\u003eSelect the grading requirements for your project — this will help determine what is a “good” or “bad” quality label.\u003c/li\u003e\u003cli\u003eDecide if you want to implement a \u003ca href=\"https://labelbox.com/guides/how-to-define-your-data-labeling-projects-success-criteria/?ref=labelbox-guides.ghost.io#slas-quality-speed-throughput\"\u003equality SLA\u003c/a\u003e with your labeling team — this is a bidirectional commitment with your labeling team that is built on throughput and quality calculations \u003c/li\u003e\u003c/ol\u003e\u003cp\u003eTo learn more, read our guide,\u003cstrong\u003e \u003c/strong\u003e\u003ca href=\"https://labelbox.com/guides/how-to-define-your-data-labeling-projects-success-criteria/?ref=labelbox-guides.ghost.io\"\u003eHow to define your data labeling project’s success criteria.\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"step-3-create-a-quality-strategy-for-your-labeling-project\"\u003eStep 3: Create a quality strategy for your labeling project\u003c/h2\u003e\u003cp\u003eAfter defining and setting expectations on how quality is defined, you'll want to spend some time developing a quality strategy.\u003c/p\u003e\u003col\u003e\u003cli\u003eMake sure you have quality monitoring tools in place — Quantumworks Lab’s \u003ca href=\"https://docs.labelbox.com/docs/benchmarks?ref=labelbox-guides.ghost.io\"\u003ebenchmark\u003c/a\u003e or \u003ca href=\"https://docs.labelbox.com/docs/consensus?ref=labelbox-guides.ghost.io\"\u003econsensus\u003c/a\u003e tools help measure labeling accuracy and labeling consistency so you can gauge your project’s labeling efficiency\u003c/li\u003e\u003cli\u003eIncorporate manual review and feedback throughout your projects’ duration, as labeling data is a collaborative process. Quantumworks Lab’s \u003ca href=\"https://labelbox.com/guides/how-to-customize-your-annotation-review-process/?ref=labelbox-guides.ghost.io\"\u003eworkflow feature\u003c/a\u003e allows you to set up customized review steps based on your quality strategy\u003c/li\u003e\u003cli\u003eIf you have a quality SLA, regularly monitor and review your data to determine whether the SLA has been met\u003c/li\u003e\u003cli\u003eEnsure that there is an open two-way communication channel between your labeling team and key stakeholders — this can resemble Quantumworks Lab platform features such as \u003ca href=\"https://docs.labelbox.com/docs/issues-comments?ref=labelbox-guides.ghost.io\"\u003eissues \u0026amp; comments\u003c/a\u003e or \u003ca href=\"https://docs.labelbox.com/docs/boost-workforce-notifications?ref=labelbox-guides.ghost.io\"\u003eupdates\u003c/a\u003e, Slack, Google Docs, etc.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eTo learn more, read our guide, \u003ca href=\"https://labelbox.com/guides/how-to-create-a-quality-strategy-for-your-data-labeling-project/?ref=labelbox-guides.ghost.io\"\u003eHow to create a quality strategy for your data labeling project\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"step-4-scale-your-labeling-operations-while-maintaining-quality\"\u003e\u003cbr\u003e\u003cstrong\u003eStep 4:\u003c/strong\u003e \u003cstrong\u003eScale your labeling operations while maintaining quality\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eOnce a desired quality strategy has been implemented, a key question becomes how to maintain consistency and quality as team size or data volume grows.\u003c/p\u003e\u003col\u003e\u003cli\u003eManage your labeling workflow by making use of iteration with small batches and an initial calibration phase\u003c/li\u003e\u003cli\u003eThe \u003ca href=\"https://labelbox.com/guides/how-to-scale-up-your-labeling-operations-while-maintaining-quality/?ref=labelbox-guides.ghost.io#calibration-phase\"\u003ecalibration phase\u003c/a\u003e is often a smaller subset of your task — it is used to train the labeling team on labeling instructions, the ontology, and to help them become familiar with the data in the project\u003c/li\u003e\u003cli\u003eProvide feedback and work with your labeling team to iterate on the data until the desired quality threshold is reached\u003c/li\u003e\u003cli\u003eMonitor overall quality and speed of your labeling operations as you enter the \u003ca href=\"https://labelbox.com/guides/how-to-scale-up-your-labeling-operations-while-maintaining-quality/?ref=labelbox-guides.ghost.io#production-phase\"\u003eproduction phase\u003c/a\u003e of your project\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eTo learn more, read our guide, \u003ca href=\"https://labelbox.com/guides/how-to-scale-up-your-labeling-operations-while-maintaining-quality/?ref=labelbox-guides.ghost.io\"\u003eHow to scale up your labeling operations while maintaining quality\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"step-5-evaluate-and-optimize-your-labeling-project%E2%80%99s-results\"\u003eStep 5: Evaluate and optimize your labeling project’s results\u003c/h2\u003e\u003cp\u003eAfter a task is completed and you have entered the production phase, it’s important to evaluate and consider factors that can guide you toward greater optimization of future batches.\u003c/p\u003e\u003cp\u003eAfter a task is completed and you have entered the production phase, it’s important to evaluate and consider factors that can guide you toward greater optimization of future batches. \u003c/p\u003e\u003col\u003e\u003cli\u003eCrowdsource feedback from your labelers — understanding their challenges with the given task can help clarify future labeling instructions, discover edge cases, and suggest ways to improve efficiency\u003c/li\u003e\u003cli\u003eReview project results and labeler performance against your existing ontology and labeling instructions — see if project results reveal an opportunity to improve ontology structure or guidance\u003c/li\u003e\u003cli\u003eSave labeling time and cost by leveraging active learning techniques to prioritize high-impact data — Quantumworks Lab \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/models-overview?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e can help you quickly identify label and model errors, find all instances of similar data to edge cases or mislabeled data rows, and more\u003c/li\u003e\u003cli\u003eDetermine how well your project’s results aligned with your quality strategy outlined in step 3 — see if you notice areas for improvement or if further customization to improve review efficiency is needed with \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox-guides.ghost.io\"\u003eworkflows\u003c/a\u003e\u003c/li\u003e\u003cli\u003eEvaluate whether the labeling team size and skillset was appropriate for your use case and the desired production capability \u003c/li\u003e\u003c/ol\u003e\u003cp\u003eTo learn more, read our guide, \u003ca href=\"https://labelbox.com/guides/how-to-evaluate-and-optimize-your-data-labeling-projects-results/?ref=labelbox-guides.ghost.io\"\u003eHow to evaluate and optimize your data labeling project’s results\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003ePowered by Quantumworks Lab’s data engine, experience the next level of data labeling service with direct access to curated data labeling teams for your projects in any expert domain or popular languages. Set new standards in quality and throughput at half the cost.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003eContact us\u003c/a\u003e today to access the best data labeling services with specialized labeling teams that match your use case. You can also sign up and \u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003eget started with Quantumworks Lab for free\u003c/a\u003e. \u003c/p\u003e","comment_id":"63bdef75be228d003d1e9ce3","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2973--1-.png","featured":false,"visibility":"public","created_at":"2023-01-10T23:06:29.000+00:00","updated_at":"2024-09-12T23:47:29.000+00:00","published_at":"2023-01-12T21:31:12.000+00:00","custom_excerpt":"Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-kickstart-and-scale-your-data-labeling-efforts","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-kickstart-and-scale-your-data-labeling-efforts/","excerpt":"Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. ","reading_time":5,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2973--1--3.png","og_title":"How to kickstart and scale your data labeling efforts","og_description":"Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2973--1--1.png","twitter_title":"How to kickstart and scale your data labeling efforts","twitter_description":"Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. ","meta_title":"How to kickstart and scale your data labeling efforts","meta_description":"Learn how to effectively kickstart and scale your data labeling efforts to reduce cost, while maintaining the desired quality required for your use case. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"63b5df77f94604003d092822","uuid":"2b424b77-c04e-4b37-8b3e-e9343aa9c81e","title":"How to evaluate and optimize your data labeling project's results","slug":"how-to-evaluate-and-optimize-your-data-labeling-projects-results","html":"\u003cp\u003eLeading machine learning teams establish high quality labeling workflows by starting with \u003ca href=\"https://labelbox.com/guides/how-to-scale-up-your-labeling-operations-while-maintaining-quality/?ref=labelbox-guides.ghost.io\"\u003esmall iterative batches\u003c/a\u003e to develop an effective feedback loop with labeling teams early on in the process. This approach allows ML teams to quickly identify issues and make necessary changes to their labeling instructions and ontologies, enabling labeling teams to become more proficient with the task before large volumes of data are labeled. Following this waterfall approach, teams are able to generate higher quality labeled data quickly and at scale. \u003c/p\u003e\u003cp\u003eAfter a task has been completed and an ML team has entered into the production phase, it's important to evaluate and consider several factors that can guide you toward greater optimization of future batches. \u003c/p\u003e\u003chr\u003e\u003ch2 id=\"what-should-ml-teams-consider-once-a-labeling-project-is-complete\"\u003eWhat should ML teams consider once a labeling project is complete? \u003c/h2\u003e\u003ch3 id=\"feedback-from-labelers\"\u003eFeedback from labelers\u003c/h3\u003e\u003cp\u003eAfter project completion, you should consider sourcing feedback from your labelers. Machine learning teams often benefit from asking labelers to share their thoughts on the given labeling task to better understand what was challenging, to discover edge cases, and receive suggestions on how to improve efficiency. \u003c/p\u003e\u003cp\u003eA great way to crowdsource this feedback is through Quantumworks Lab's \u003ca href=\"https://docs.labelbox.com/docs/issues-comments?ref=labelbox-guides.ghost.io\"\u003eissues \u0026amp; comments\u003c/a\u003e feature that can be used on individual data rows. This allows the labeling team and your ML team to collaborate and provide feedback on specific examples or assets. \u003ca href=\"https://docs.labelbox.com/docs/boost-workforce-notifications?ref=labelbox-guides.ghost.io\"\u003eUpdates\u003c/a\u003e within a project can also be used to provide more holistic feedback on the project – enabling three-way communication between you, the Quantumworks Lab Boost admin, and the labeling workforce. Lastly, you can also rely on shared Google Docs and team syncs to collect feedback from the labeling team. \u003c/p\u003e\u003ch3 id=\"labeling-instructions-and-ontology-changes\"\u003eLabeling instructions and ontology changes\u003c/h3\u003e\u003cp\u003eAfter a project has been completed, you can review project results and labeler performance to pinpoint areas for improving your labeling instructions or ontology. \u003c/p\u003e\u003cp\u003eQuestions that you can consider during review include: \u003c/p\u003e\u003cul\u003e\u003cli\u003eDo the results of the project show any areas of labeling uncertainty that can be improved by editing the task's instructions?\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003cem\u003e \u003c/em\u003e\u003c/strong\u003eCreating category definitions that are mutually exclusive can improve labeling team alignment and reduce the chance of confusion between object types. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003cem\u003e \u003c/em\u003e\u003c/strong\u003eAdding numbered steps can be a great way to organize complex labeling tasks. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003cem\u003e \u003c/em\u003e\u003c/strong\u003eIncluding decision trees and rule of thumb guidance can be helpful for subjective tasks that require critical thinking. \u003c/p\u003e\u003cul\u003e\u003cli\u003eDo project results reveal opportunities for improving ontology structure? \u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003c/strong\u003e Think about if the ontology is organized in the most efficient manner. For instance, can the labeling time can be improved using nested classifications vs having a list of single objects?\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip: \u003c/em\u003e\u003c/strong\u003eReview whether the ontology includes too many objects or too few objects to achieve project goals.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003c/strong\u003e If warranted, share the \"why\" behind your ontology requirements or provide additional project context to help labelers better contextualize tasks. \u003c/p\u003e\u003ch3 id=\"improve-your-data-selection\"\u003eImprove your data selection \u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/catalog-06--1-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1344\" height=\"1024\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/catalog-06--1-.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/catalog-06--1-.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/01/catalog-06--1-.png 1344w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eAfter the successful completion of a labeling project, it can be tempting to proceed by creating projects or batches of even larger datasets to label. However, to make sure that you're training your model on the most impactful examples, you can leverage Quantumworks Lab's \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/models-overview?ref=labelbox-guides.ghost.io\"\u003eModel\u003c/a\u003e to curate and prioritize future batches. \u003c/p\u003e\u003cp\u003eWith Catalog and Model, you can quickly identify label and model errors, find all instances of similar data to edge cases or mislabeled data rows and send them to Annotate in order to retrain your model on specific slices of data. Smartly selecting high value data to label in priority is key to maximizing labeling efficiency and reduce project costs. \u003c/p\u003e\u003cp\u003eRefer to the below guides and resources to learn more about how to improve data selection with Quantumworks Lab: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-search-surface-and-prioritize-data-within-a-project/?ref=labelbox-guides.ghost.io\"\u003eHow to search, surface, and prioritize data within a project\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/active-learning?ref=labelbox-guides.ghost.io\"\u003eHow to prioritize high-value data\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-and-fix-label-errors/?ref=labelbox-guides.ghost.io\"\u003eHow to find and fix label errors\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-and-fix-model-errors/?ref=labelbox-guides.ghost.io\"\u003eHow to find and fix model errors\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003eHow to find similar data in one click\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"review-your-quality-strategy\"\u003eReview your quality strategy\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/workflow--3-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1360\" height=\"1024\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/workflow--3-.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/workflow--3-.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/01/workflow--3-.png 1360w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOne key area to review after the completion of a project is how well your \u003ca href=\"http://labelbox.com/guides/how-to-create-a-quality-strategy-for-your-data-labeling-project?ref=labelbox-guides.ghost.io\"\u003equality assurance strategy\u003c/a\u003e performed. ML teams will benefit from asking the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf \u003ca href=\"https://docs.labelbox.com/docs/consensus?ref=labelbox-guides.ghost.io\"\u003econsensus\u003c/a\u003e was used on the project, were there enough votes to provide sufficient insights?\u003c/li\u003e\u003cli\u003eWas the number of \u003ca href=\"https://docs.labelbox.com/docs/benchmarks?ref=labelbox-guides.ghost.io\"\u003ebenchmarks\u003c/a\u003e used or was the percentage of consensus coverage applied sufficient to assess performance across the dataset?\u003c/li\u003e\u003cli\u003eWere the benchmark or consensus agreement results as expected, or lower than anticipated?\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTip:\u003c/em\u003e\u003c/strong\u003e If consensus scores are consistently high or do not provide additional valuable insights, consider lowering the number of votes, coverage percentage, or removing altogether to reduce labeling time.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIf using SLAs, how well were expectations and requirements met?\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYour team should also assess how well the labeling review process was. If you notice areas for improvement or the need for customization to improve review efficiency, you can customize your review step with \u003ca href=\"https://docs.labelbox.com/docs/workflows?ref=labelbox-guides.ghost.io\"\u003eworkflows\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eTo learn more about workflows, read our guide, \u003ca href=\"https://labelbox.com/guides/how-to-customize-your-annotation-review-process?ref=labelbox-guides.ghost.io\"\u003eHow to customize your annotation review process\u003c/a\u003e\u003c/p\u003e\u003ch3 id=\"labeling-team-size-and-skillset\"\u003eLabeling team size and skillset\u003c/h3\u003e\u003cp\u003eEvaluating the size and makeup of the labeling team is important at every phase of your labeling operations. At the end of a project, it's recommended that you review whether the labeling team size was too small to meet the desired production capability or too large for the required volume. Additionally, it is key for teams to consider whether future batches of data will require labelers with specialized training (such as having industry-specific or language experience). \u003c/p\u003e\u003cp\u003eKeeping communication open with the labeling team is also crucial during these considerations. This is especially important when working with external labeling teams, who often benefit from having advance notice of any new batches or changing requirements so that they can effectively allocate or maintain their resources. \u003c/p\u003e\u003cp\u003eClear and timely communication of future project needs, such as the anticipated readiness of the next project or batch, the expected size of the dataset, changes to the instructions or labeling requirements, and ideal completion dates, should be communicated to help ensure a smooth ramp up on the next project. \u003c/p\u003e\u003cp\u003eYou can easily access data labeling services with specialized expertise that are fit for your specific use case through \u003ca href=\"https://labelbox.com/product/boost/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost\u003c/a\u003e. Collaborate with the workforce in real-time to monitor high-quality data,, all while managing and keeping human labeling costs to a minimum using AI-assisted tools and automation techniques. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/sales/?ref=labelbox-guides.ghost.io\"\u003eContact our Boost team\u003c/a\u003e to get paired with a specialized workforce team or learn more about how one of our customers, NASA's Jet Propulsion Laboratory, used \u003ca href=\"https://labelbox.com/customers/nasa-jpl/?ref=labelbox-guides.ghost.io\"\u003eLabelbox Boost to deliver quality labels at 5x their previous speed\u003c/a\u003e. \u003c/p\u003e","comment_id":"63b5df77f94604003d092822","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2977--3-.png","featured":false,"visibility":"public","created_at":"2023-01-04T20:20:07.000+00:00","updated_at":"2023-10-26T18:15:02.000+00:00","published_at":"2023-01-12T21:31:07.000+00:00","custom_excerpt":"Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-evaluate-and-optimize-your-data-labeling-project's-results","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-evaluate-and-optimize-your-data-labeling-projects-results/","excerpt":"Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. ","reading_time":4,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2977--3--2.png","og_title":"How to evaluate and optimize your data labeling project's results","og_description":"Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2977--3--1.png","twitter_title":"How to evaluate and optimize your data labeling project's results","twitter_description":"Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. ","meta_title":"How to evaluate and optimize your data labeling project's results","meta_description":"Learn how to evaluate the results of your labeling project in order to further optimize and improve future iterations and batches of data. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"63b34450f94604003d092366","uuid":"32b97a0e-237d-4690-8906-19aa50b4a3fd","title":"How to define a task for your data labeling project","slug":"how-to-define-a-task-for-your-data-labeling-project","html":"\u003cp\u003eLarge volumes of high-quality training data are crucial to the success of any machine learning model. A labeling project is where you orchestrate and manage all of your labeling operations within Labelbox.\u003c/p\u003e\u003cp\u003eThe first step in the labeling process is to align on the key components of the labeling task within a project. This sets the tone of the project and allows Quantumworks Lab to make labeling more efficient down the line.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"defining-the-data\"\u003eDefining the data\u003c/h2\u003e\u003ch3 id=\"data-type\"\u003eData type \u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/annotate-one-platform--1-.svg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"672\" height=\"512\"\u003e\u003c/figure\u003e\u003cp\u003e\u003ca href=\"https://docs.labelbox.com/docs/create-a-project?ref=labelbox-guides.ghost.io\"\u003eCreating a project\u003c/a\u003e and configuring your labeling task on the Quantumworks Lab platform begins alignment on which type of data needs to be labeled.\u003c/p\u003e\u003cp\u003eLabelbox supports the following \u003ca href=\"https://docs.labelbox.com/docs/datasets-datarows?ref=labelbox-guides.ghost.io#supported-data-types\"\u003edata types\u003c/a\u003e:\u003c/p\u003e\u003cul\u003e\u003cli\u003eImages\u003c/li\u003e\u003cli\u003eVideos\u003c/li\u003e\u003cli\u003eText\u003c/li\u003e\u003cli\u003eConversational text\u003c/li\u003e\u003cli\u003ePDF documents\u003c/li\u003e\u003cli\u003eGeospatial / Tiled imagery\u003c/li\u003e\u003cli\u003eAudio\u003c/li\u003e\u003cli\u003eHTML\u003c/li\u003e\u003cli\u003eDICOM (medical imagery)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBased on your chosen data modality, the Labeling Team Manager can leverage prior knowledge and the existing experience of different teams of labelers to work on your projects.\u003c/p\u003e\u003cp\u003eFor instance, some workforce teams have an excellent track record of successfully labeling projects with a specific type of imagery, while others have extended experience in working with the video editor or in specialized text projects. By curating labeling teams who are already well-versed in your use case and match your project needs, they can get started quicker with little friction.\u003c/p\u003e\u003ch3 id=\"industry-verticals\"\u003e\u003cstrong\u003eIndustry verticals\u003c/strong\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/catalog-hero--1-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1011\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/catalog-hero--1-.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/catalog-hero--1-.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/catalog-hero--1-.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/01/catalog-hero--1-.png 2089w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eSimilarly, our labeling partners are experienced in various industries such as:\u003c/p\u003e\u003cul\u003e\u003cli\u003eManufacturing\u003c/li\u003e\u003cli\u003eReal estate\u003c/li\u003e\u003cli\u003eFood service\u003c/li\u003e\u003cli\u003eAgrotech\u003c/li\u003e\u003cli\u003eHealthcare\u003c/li\u003e\u003cli\u003eInsurance\u003c/li\u003e\u003cli\u003eRetail\u003c/li\u003e\u003cli\u003eand many more\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLeveraging labelers who have experience in the industry of interest for your task should be discussed, as it allows the Labeling Team Manager to allocate the best workforce who meets your needs.\u003c/p\u003e\u003cp\u003eSome teams have large experience in aerial roof tagging for insurance companies, while others have been working on long-term microscopy pictures in the medical field, and many more variations of all kinds of tasks. Understanding the scope and frame of the task allows Quantumworks Lab to set your team up for success with the right workforce.\u003c/p\u003e\u003cp\u003eA workforce team who is well-versed in your industry or use case will need less time to get calibrated on your task. This means they'll be able to label more data in less time, which results in cheaper labeling costs as you only pay for the time when labeling screen-time occurs.\u003c/p\u003e\u003cp\u003eThere might be some use cases where general experience in a specific industry or data type might not be sufficient enough to meet your requirements. Quantumworks Lab also offers the option for you to onboard expert labelers for your project needs. You can learn more below under the \"Specific labeling requirements\" section.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"leveraging-labelboxs-suite-of-tools\"\u003eLeveraging Quantumworks Lab's suite of tools \u003c/h2\u003e\u003ch3 id=\"annotate\"\u003eAnnotate\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/annotate-header-image--3-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1170\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/annotate-header-image--3-.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/annotate-header-image--3-.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/annotate-header-image--3-.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/01/annotate-header-image--3-.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eLabelbox's \u003ca href=\"https://labelbox.com/product/annotate/?ref=labelbox-guides.ghost.io\"\u003eAnnotate\u003c/a\u003e is designed to give you complete visibility and control over every aspect of your labeling operations across data modalities.\u003c/p\u003e\u003cp\u003eWhile setting up your labeling project, you'll need to acknowledge the supported file formats and annotation types in order to prevent issues down the line.\u003c/p\u003e\u003cp\u003eSimilarly, it is important to understand how to use Annotate to set up your project and labeling task, collaborate with your internal or external teams, and how to ensure that you're minimizing labeling time and spend. \u003c/p\u003e\u003cp\u003eFor instance, only one labeler can work per data row. If you have long videos to annotate, we might recommend splitting them into multiple files so more annotators can work on the data. Ultimately this will depend on your own speed and time requirements, however the Labeling Team Manager is available to work with you to determine what will work best for your team's use case.\u003c/p\u003e\u003cp\u003eYou can learn more about Annotate in our \u003ca href=\"https://docs.labelbox.com/docs/annotate-overview?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"catalog\"\u003eCatalog\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/catalog-hero--2-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1250\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/catalog-hero--2-.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/catalog-hero--2-.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/catalog-hero--2-.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2023/01/catalog-hero--2-.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eLabelbox's \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox-guides.ghost.io\"\u003eCatalog\u003c/a\u003e is a data curation tool for you to organize, search, visualize, and explore your unstructured data. \u003c/p\u003e\u003cp\u003eUtilizing Catalog for data selection is a huge advantage in having a quality batch of data to label, according to specific parameters required for your task. You can leverage Catalog's features, such as \u003ca href=\"https://docs.labelbox.com/docs/search?ref=labelbox-guides.ghost.io\"\u003efilters\u003c/a\u003e, a one-click \u003ca href=\"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/?ref=labelbox-guides.ghost.io\"\u003esimilarity search\u003c/a\u003e, \u003ca href=\"https://docs.labelbox.com/docs/adding-metadata?ref=labelbox-guides.ghost.io\"\u003emetadata\u003c/a\u003e, and more, to ensure that the data you're queueing to your project is well-structured for your business requirements. \u003c/p\u003e\u003cp\u003eYou can learn more about Catalog in our \u003ca href=\"https://docs.labelbox.com/docs/catalog-overview?ref=labelbox-guides.ghost.io\"\u003edocumentation\u003c/a\u003e. \u003c/p\u003e\u003chr\u003e\u003ch2 id=\"specific-labeling-requirements\"\u003eSpecific labeling requirements \u003c/h2\u003e\u003ch3 id=\"expert-workforce\"\u003eExpert workforce\u003c/h3\u003e\u003cp\u003eFor more specific and specialized tasks, Quantumworks Lab has the ability to onboard labelers who are qualified in particular domains:\u003c/p\u003e\u003cul\u003e\u003cli\u003eTechnical labelers with determined skills, such as people with software programming certifications\u003c/li\u003e\u003cli\u003eMedical labelers like nurses, clinicians, dermatologists, neurologists, and surgeons\u003c/li\u003e\u003cli\u003eLabelers fluent in one of 20+ languages covered by our partners\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYour Labeling Team Manager can source a specialist, based on the expertise needed, who can get started on your task. Since experts can take longer to source, it is essential to determine and request this requirement along with additional information needed prior to the start of labeling. \u003c/p\u003e\u003ch3 id=\"compliance\"\u003eCompliance\u003c/h3\u003e\u003cp\u003eAs Quantumworks Lab partners are spread out across different countries, it's important that geographical location is acknowledged and discussed so your business requirements are met. Depending on your discussed compliance and project needs, the Labeling Team Manager will ensure that the right workforce is onboarded accordingly. \u003c/p\u003e\u003cp\u003eLabelbox partners are compliant with the following certifications:\u003c/p\u003e\u003cul\u003e\u003cli\u003eSOC2 Type I\u003c/li\u003e\u003cli\u003eSOC2 Type II\u003c/li\u003e\u003cli\u003eGDPR\u003c/li\u003e\u003cli\u003eHIPAA\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"labeling-forecast\"\u003eLabeling forecast  \u003c/h2\u003e\u003ch3 id=\"volume\"\u003eVolume\u003c/h3\u003e\u003cp\u003eDefining your data volume is a key element to consider when outlining your labeling task. This allows early expectations to be set in context of throughput and subsequently helps the Labeling Team Manager and the workforce to organize the labeling in the most efficient manner.\u003c/p\u003e\u003cp\u003eFor instance, the following aspects should be considered and discussed when defining your task:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLarge volumes of data\u003c/li\u003e\u003cli\u003eLong-term projects\u003c/li\u003e\u003cli\u003eShort projects\u003c/li\u003e\u003cli\u003eTurnarounds\u003c/li\u003e\u003cli\u003eUploads frequency\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBased on the above, the Labeling Team Manager can allocate the task to the team most appropriate to meet the volume demands in terms of resources and availability.\u003c/p\u003e\u003ch3 id=\"timeline\"\u003eTimeline\u003c/h3\u003e\u003cp\u003eUnderstanding the timeline of your task is also crucial in effectively ramping up and scaling labeling activity. A rough outline of when you want the project to start and the target completion data helps define a structured labeling process and makes resource management easier. \u003c/p\u003e\u003cp\u003eA task that is set up for success will consider the following: \u003c/p\u003e\u003cul\u003e\u003cli\u003eHow many data rows do you plan to upload to your project? At which frequency?\u003c/li\u003e\u003cli\u003eWhat are the expectations in terms of speed?\u003c/li\u003e\u003cli\u003eDo you have a deadline?\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eQuick turnarounds on high volumes of data and tight deadlines can be delicate to navigate, so planning ahead and understanding timelines in advance can help maximize the resources available and the workforce's time can be used efficiently. \u003c/p\u003e\u003chr\u003e\u003ch2 id=\"creating-an-ontology\"\u003eCreating an ontology\u003c/h2\u003e\u003cp\u003eAnother important aspect of a well-defined labeling task is the \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox-guides.ghost.io\"\u003eontology\u003c/a\u003e. It needs to be built in a way that will work for the task at hand, and that follows the most logical workflow for a labeler. Ontologies and features should be created and managed with the goals of proper labeling, efficiency, and reusability in mind.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/2acf976-Screen_Shot_2021-12-09_at_12.28.01_PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1840\" height=\"1404\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/2acf976-Screen_Shot_2021-12-09_at_12.28.01_PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/2acf976-Screen_Shot_2021-12-09_at_12.28.01_PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2023/01/2acf976-Screen_Shot_2021-12-09_at_12.28.01_PM.png 1600w, https://labelbox-guides.ghost.io/content/images/2023/01/2acf976-Screen_Shot_2021-12-09_at_12.28.01_PM.png 1840w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch3 id=\"components\"\u003eComponents\u003c/h3\u003e\u003cp\u003eWithin an ontology, the three kinds of features are: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eObjects\u003c/strong\u003e (bounding boxes, polygons, segmentation masks, points, polylines, etc)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eClassifications\u003c/strong\u003e (radio, checklist, etc), that can be global or nested\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRelationships \u003c/strong\u003e(these are approached differently in Quantumworks Lab depending on the data type): With text data, you can define relationships between entity annotations as part of the objects. With image data, you can set relationship items in the ontology \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA good ontology should define and answer the following: \u003c/p\u003e\u003cul\u003e\u003cli\u003eWhat should the labeling team be labeling? \u003c/li\u003e\u003cli\u003eHow should objects and/or classifications be labeled? \u003c/li\u003e\u003cli\u003eWhat additional information is helpful for your model? \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eReusing ontologies can be useful if you're planning on having multiple projects for the same or a very similar use case. Elements can be added to an existing ontology without affecting labels, so an ontology is not set in stone and you're encouraged to test and fine-tune your ontology. \u003c/p\u003e\u003cp\u003eYou can learn more about how to create and manage your ontologies in \u003ca href=\"https://labelbox.com/guides/how-to-create-and-manage-ontologies/?ref=labelbox-guides.ghost.io\"\u003ethis guide\u003c/a\u003e. \u003c/p\u003e\u003ch3 id=\"speed\"\u003eSpeed\u003c/h3\u003e\u003cp\u003eYou should choose tools that will allow labelers to label as fast as possible while maintaining the output needed for your model.\u003c/p\u003e\u003cp\u003eSample questions to consider when selecting tools would be: \u003c/p\u003e\u003cul\u003e\u003cli\u003eWould separate bounding boxes per class be better than one bounding box with a nested classification? \u003c/li\u003e\u003cli\u003eIs a segmentation mask necessary or would a polygon do? \u003c/li\u003e\u003cli\u003eDo you need every frame to be annotated? \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"quality\"\u003eQuality\u003c/h3\u003e\u003cp\u003eHigh-quality training data is critical to the success of your model. Ensure quality by designing a clear and efficient ontology that makes it easier for you to organize the output.\u003c/p\u003e\u003cp\u003eSample questions to consider include: \u003c/p\u003e\u003cul\u003e\u003cli\u003eDoes the ontology need to be extremely complex, or can you consider separate projects to label different things on the same data?\u003c/li\u003e\u003cli\u003eIs the free text field necessary? Avoid options that can lead to inconsistencies, typos and misspellings.\u003c/li\u003e\u003cli\u003eIs it best to skip or should there be an annotation denoting that the answer is unknown, that there was nothing to label? Do you want to understand why some assets do not meet the criteria, or is it fine to have a bucket of unlabeled assets?\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003ch2 id=\"creating-labeling-instructions\"\u003eCreating labeling instructions \u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/01/Screen-Shot-2023-01-12-at-4.10.49-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1450\" height=\"1208\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2023/01/Screen-Shot-2023-01-12-at-4.10.49-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2023/01/Screen-Shot-2023-01-12-at-4.10.49-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/2023/01/Screen-Shot-2023-01-12-at-4.10.49-PM.png 1450w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eOnce all the modalities of the task have been properly defined, you have to provide \u003ca href=\"https://docs.labelbox.com/docs/labeling-instructions?ref=labelbox-guides.ghost.io\"\u003elabeling instructions\u003c/a\u003e to the workforce. Even with an extremely simple ontology, it is necessary to offer additional information related to the labeling task. \u003c/p\u003e\u003cp\u003eLabeling instructions compliment the ontology and can be in the form of a document or a video demo. You can include anything that you deem useful and relevant to explaining the rules of your labeling task in a way that is easy for labelers to follow. \u003c/p\u003e\u003cp\u003eGood instructions will go into detail with specific examples and clearly lay out major labeling rules. Labeling instructions should provide context to the task, explain what the task entails, describe the labeling steps, and serve as a \"living document\".\u003c/p\u003e\u003cp\u003eInstructions can be altered depending on task progress and any changes in your requirements. Since changes can be made, it is advised for you to keep track of what made a label meet your success criteria so you can tailor the instructions to help the team understand important criteria of what makes a \"good label\". \u003c/p\u003e\u003chr\u003e\u003ch2 id=\"defining-labeling-rules\"\u003eDefining labeling rules\u003c/h2\u003e\u003ch3 id=\"definition-of-all-ontology-items\"\u003eDefinition of all ontology items\u003c/h3\u003e\u003cp\u003eIt is important that you make sure to list and define the items that you want labeled. As mentioned in the \"Creating an ontology\" section above, you should be clear on the features and rules behind each expected annotation: \u003c/p\u003e\u003cul\u003e\u003cli\u003eObjects\u003c/li\u003e\u003cli\u003eClassifications\u003c/li\u003e\u003cli\u003eRelationships\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor example, if the project contains several entities/objects to be labeled with multiple classifications to choose from, explain each entity/object and each classification in sufficient detail: \u003c/p\u003e\u003cul\u003e\u003cli\u003eHow tight around the object does the bounding box need to be? \u003c/li\u003e\u003cli\u003eHow do labelers pinpoint a precise point on a blurry image with shapes that are not sharp? \u003c/li\u003e\u003cli\u003eIs there a maximum number of points a polygon can have before it becomes excessive for your model? \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhen defining your labeling rules, you should aim to: \u003c/p\u003e\u003cul\u003e\u003cli\u003eProvide clear definitions of all concepts for text projects to prevent ambiguities in the labeling\u003c/li\u003e\u003cli\u003eTry to format your instructions in a way that is easy to read, and make sure the golden rules pop out in a clear and distinguishable manner to minimize any chance that these could be missed\u003c/li\u003e\u003cli\u003eDefine your approach on a frame basis for video projects\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"step-by-step-labeling-workflow\"\u003eStep-by-step labeling workflow\u003c/h3\u003e\u003cp\u003eMake sure to describe each step in the labeling workflow so that your labelers are not lost in the ontology:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor projects with multiple objects per asset, is there a specific order in which you need the annotations to be added?\u003c/li\u003e\u003cli\u003eDescribe your expectations for the review process\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"examples\"\u003eExamples\u003c/h3\u003e\u003cp\u003eThe best way to convey the results you want is by providing clear examples of the data to the labelers in the form of screenshots in your instructions. There are several approaches to this:\u003c/p\u003e\u003cul\u003e\u003cli\u003eProvide screenshots of unlabeled and labeled data for the labelers to have an overview of the assets they will be working on and what the outcome should be. Try to include several images that represent the variations of the full set.\u003c/li\u003e\u003cli\u003eClarify the variability of the data by sharing “edge cases” in your guidelines. An asset that would stand out from the rest of the set should be explained in detail, so the labelers know how to approach these types of cases.\u003c/li\u003e\u003cli\u003eInclude incorrectly labeled (negative) examples as well. This helps the team to identify mistakes to avoid. Common mistakes can be mentioned to prevent making them in this task.\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003cp\u003eAll of these key components contribute to defining a task that is set for success on the Quantumworks Lab platform. These aspects also help the Labeling Team Manager ensure that your project outcomes are successful. \u003c/p\u003e\u003cp\u003eAfter the initial task setup, the next step in your labeling journey is to define your success criteria. Along with your volumes and deadlines, learn more about how to get a notion of the average time per label, describe how a \"good label\" is measured, and learn about SLAs in our next guide: How to define your data labeling project's success criteria. \u003c/p\u003e","comment_id":"63b34450f94604003d092366","feature_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2974--1-.png","featured":false,"visibility":"public","created_at":"2023-01-02T20:53:36.000+00:00","updated_at":"2024-10-02T22:27:59.000+00:00","published_at":"2023-01-12T21:30:52.000+00:00","custom_excerpt":"Learn how to align on key components of your project: define a task, create an ontology, and determine timelines for your labeling project.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/guides/how-to-define-a-task-for-your-data-labeling-project","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-define-a-task-for-your-data-labeling-project/","excerpt":"Learn how to align on key components of your project: define a task, create an ontology, and determine timelines for your labeling project.","reading_time":9,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2974--1--2.png","og_title":"How to define a task for your labeling project","og_description":"A crucial first step in the labeling process is to align on key components of the labeling task. Learn how to define a task, create an ontology, and determine timelines for your labeling project.","twitter_image":"https://labelbox-guides.ghost.io/content/images/2023/01/Group-2974--1--1.png","twitter_title":"How to define a task for your labeling project","twitter_description":"A crucial first step in the labeling process is to align on key components of the labeling task. Learn how to define a task, create an ontology, and determine timelines for your labeling project.","meta_title":"How to define a task for your labeling project","meta_description":"A key first step in the labeling process is to align on components of the labeling task. Learn how to define a task, create an ontology, and determine timelines for your labeling project. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"638e795d26221b003dd3cb95","uuid":"2d10380a-0764-4d34-b1b5-4b2e576b7be5","title":"How to find similar data in one click","slug":"how-to-find-similar-data-in-one-click","html":"\u003cp\u003eThe most successful training datasets are carefully visualized, curated, and debugged to increase model performance at each iteration.\u003c/p\u003e\u003cp\u003eML teams mine data by looking for all examples of rare assets or edge cases that will dramatically improve model performance. Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Building a similarity search engine that scales to hundreds of millions of data points and generates instant results is difficult for even the most advanced ML teams. \u003c/p\u003e\u003cp\u003eWith similarity search, you can easily query and explore your unstructured data and develop a holistic understanding of your training data. Plus, it helps break down silos across datasets, so teams can focus on curating and labeling the data that will dramatically improve model performance.\u003c/p\u003e\u003cp\u003eLabelbox provides a native similarity search engine, where you can leverage both off-the-shelf embeddings (for image, text, and documents)\u003cstrong\u003e \u003c/strong\u003eor upload your own custom embeddings to quickly find all instances of similar data.\u003c/p\u003e\u003ch2 id=\"how-to-conduct-a-similarity-search-query\"\u003eHow to conduct a similarity search query\u003c/h2\u003e\u003cfigure class=\"kg-card kg-embed-card\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/mz9zvhw4mo\" title=\"Instantly find ​similar data in one click [Catalog] Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"540\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003c/figure\u003e\u003cp\u003e1) Hover and click on the bottom right icon of any data row OR select all data rows of interest and click \"Similar to selection\" \u003c/p\u003e\u003cp\u003e2) This will automatically surface similar data rows – you can select multiple data rows as anchors to refine your similarity search \u003c/p\u003e\u003cp\u003e3) Combine similarity search with other filters and save these searches as \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslices\u003c/a\u003e. This will allow you to revisit all current and incoming data rows that match the specific search criteria.\u003c/p\u003e\u003chr\u003e\u003cp\u003eWith Quantumworks Lab' similarity search, you can unlock the following workflows: \u003c/p\u003e\u003ch2 id=\"explore-visualize-and-understand-your-data-in-one-click\"\u003eExplore, visualize, and understand your data in one click\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/2022-11-28_08-44-21--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1756\" height=\"967\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eBefore you train your ML model, you can explore all of your data in Catalog\u003c/li\u003e\u003cli\u003eIn just a few clicks, you can surface all examples of data rows of interest, and either save them as a slice of data of interest, or send them to a labeling project as a batch\u003c/li\u003e\u003cli\u003eIn the example above, we can filter all images of a single flower from almost five million data rows in Catalog with just one click\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"quickly-mine-edge-cases-or-rare-examples\"\u003eQuickly mine edge cases or rare examples \u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/2022-11-28_09-03-44--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1764\" height=\"975\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eAfter training your model, you might find an edge case where your model is struggling\u003c/li\u003e\u003cli\u003eYou can use similarity search in Catalog to easily confirm whether this is a pattern of model failures, or simply a one-off mistake\u003c/li\u003e\u003cli\u003eIn the above example, the model appears to struggle with images with many flowers, so we can quickly mine edge cases to find all images containing many flowers\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"find-all-labeling-mistakes-in-your-project-and-send-them-to-re-labeling\"\u003eFind all labeling mistakes in your project and send them to re-labeling\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/bleh--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1080\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eWithin a labeling project, you might identify data rows with problems – such as labeling quality issues or mislabeled data\u003c/li\u003e\u003cli\u003eYou can leverage similarity search to find all similar labeled data (which might contain labeling errors and need additional review) and submit them to a specific review step \u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"select-even-more-high-impact-data-to-label\"\u003e\u003cbr\u003eSelect even more high-impact data to label \u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/2022-11-28_09-18-49--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1764\" height=\"972\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eOnce you’ve identified data rows on which your model is struggling, you can find all similar unlabeled data in your datasets, label that data, and retrain the model to improve performance\u003c/li\u003e\u003cli\u003eIn this example, the model has low confidence with green bananas, so we used a similarity search and filter to show only unlabeled images of green bananas —\u0026nbsp;which can then be labeled and used to train the model\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"automatically-curate-data\"\u003e\u003cbr\u003eAutomatically curate data \u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/My-Movie-47--4-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1080\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eBy saving your similarity search as a slice, any new incoming data point uploaded to Quantumworks Lab — and that matches the similarity search — will show up in the slice\u003c/li\u003e\u003cli\u003eWith data curation pipelines that update even when you're offline, you can continuously upload data from production, and data points that look similar to data of interest will show up in the corresponding slice\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"find-duplicate-data\"\u003eFind duplicate data \u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/2022-11-28_09-24-41--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1765\" height=\"964\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eEasily find all instances of duplicate data that you don't want to appear in your labeling project by leveraging similarity search\u003c/li\u003e\u003cli\u003eOnce you've found all similar duplicate data, you can save this search as a slice and this will automatically filter and all similar images, including past and incoming data that gets added to Catalog\u003c/li\u003e\u003cli\u003eYou can then take action on duplicate data, such as deleting them from your Quantumworks Lab instance\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"automatically-label-data-from-catalog\"\u003eAutomatically label data from Catalog\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/11/My-Movie-47--2-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1080\"\u003e\u003c/figure\u003e\u003cul\u003e\u003cli\u003eLeverage similarity search and metadata to automatically identify and label data in bulk without sending data to a labeling project\u003c/li\u003e\u003cli\u003eSave search criteria for a cluster of similar data as a data slice, so that all new and old data that matches that criteria will automatically get added to that slice\u003c/li\u003e\u003cli\u003eYou can then select data rows of interest within the slice, or select the entire slice and tag these data rows with metadata\u003c/li\u003e\u003cli\u003eIn the above example, we surfaced a cluster of data rows containing green stamps using similarity search, selected the data rows of interest, and added a metadata tag called 'green stamps'\u003c/li\u003e\u003c/ul\u003e\u003chr\u003e\u003cp\u003eYou can learn more about \u003ca href=\"https://docs.labelbox.com/docs/similarity?ref=labelbox-guides.ghost.io\"\u003esimilarity search\u003c/a\u003e and \u003ca href=\"https://docs.labelbox.com/docs/slices?ref=labelbox-guides.ghost.io\"\u003eslices\u003c/a\u003e in our documentation. \u003c/p\u003e","comment_id":"638e795d26221b003dd3cb95","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/12/Group-2965.png","featured":false,"visibility":"public","created_at":"2022-12-05T23:06:05.000+00:00","updated_at":"2023-10-27T17:06:03.000+00:00","published_at":"2022-12-19T14:46:22.000+00:00","custom_excerpt":"Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Learn more about how to find similar data in one click with Labelbox. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/how-to-find-similar-data-in-one-click/","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa484375d13000123d7e2","name":"Building computer vision","slug":"building-computer-vision","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-computer-vision/"},{"id":"653aa4e3375d13000123d7e4","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox-guides.ghost.io/tag/explore-manage-data/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"},{"id":"653aa53f375d13000123d7ec","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/label-data-for-ai/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"url":"https://labelbox-guides.ghost.io/how-to-find-similar-data-in-one-click/","excerpt":"Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Learn more about how to find similar data in one click with Labelbox. ","reading_time":4,"access":true,"comments":false,"og_image":"https://labelbox-guides.ghost.io/content/images/2022/12/Group-2965-2.png","og_title":"How to find similar data in one click","og_description":"Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Learn more about how to find similar data in one click with Labelbox. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2022/12/Group-2965-1.png","twitter_title":"How to find similar data in one click","twitter_description":"Powerful similarity search capabilities can give your team an edge by helping find specific data points in an ocean of data. Learn more about how to find similar data in one click with Labelbox. ","meta_title":"How to find similar data in one click | Quantumworks Lab","meta_description":"Find examples of edge cases that will improve model performance. Learn more about how to find similar data in one click with Labelbox. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6383ebc240fdcb003d956de5","uuid":"b5555a52-fdfc-4dcc-9521-39b7981ee85c","title":"How to train a chatbot","slug":"how-to-train-a-chatbot","html":"\u003cp\u003eThe rise in natural language processing (NLP) language models have given machine learning (ML) teams the opportunity to build custom, tailored experiences. Common use cases include improving customer support metrics, creating delightful customer experiences, and preserving brand identity and loyalty. \u003c/p\u003e\u003cp\u003eAs a result, companies are able to drive tangible business results such as reducing support costs by routing customer support chats to relevant channels or increasing the conversion rate of upsell opportunities through AI augmented sales conversations. As we’ve seen with the success of OpenAI's ChatGPT, we’ll likely continue to see AI powered language experiences penetrate all major industries.\u003c/p\u003e\u003ch3 id=\"building-a-domain-specific-chatbot-on-question-and-answer-data\"\u003eBuilding a domain-specific chatbot on question and answer data\u003c/h3\u003e\u003cp\u003eYou can harness the potential of the most powerful language models, such as ChatGPT, Gemini, Llama, etc., and tailor them to your unique business application. Domain-specific chatbots will need to be trained on quality annotated data that relates to your specific use case. \u003c/p\u003e\u003cp\u003eIn this guide, we’ll walk you through how you can use Quantumworks Lab to create and train a chatbot. For the particular use case below, we wanted to train our chatbot to identify and answer specific customer questions with the appropriate answer. \u003c/p\u003e\u003chr\u003e\u003ch2 id=\"step-1-gather-and-label-data-needed-to-build-a-chatbot\"\u003eStep 1: Gather and label data needed to build a chatbot\u003c/h2\u003e\u003cp\u003eAfter gathering your data, the first step will be to identify the main components that are needed to build your chatbot. In this case, the two main components are: questions and answers.\u003c/p\u003e\u003cp\u003eOnce you’ve identified the data that you want to label and have determined the components, you’ll need to create an ontology and label your data.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/11/My-Movie-47--8-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/11/My-Movie-47--8-.gif 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/11/My-Movie-47--8-.gif 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2022/11/My-Movie-47--8-.gif 1600w, https://labelbox-guides.ghost.io/content/images/2022/11/My-Movie-47--8-.gif 1920w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eDepending on the amount of data you're labeling, this step can be particularly challenging and time consuming. However, it can be drastically sped up with the use of a labeling service, such as \u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox labeling services\u003c/u\u003e\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eWe used Quantumworks Lab labeling services to annotate our examples of conversations. The labeling workforce annotated whether the message is a question or an answer as well as classified intent tags for each pair of questions and answers. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/11/Screen-Shot-2022-11-28-at-4.57.41-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1078\" srcset=\"https://labelbox-guides.ghost.io/content/images/size/w600/2022/11/Screen-Shot-2022-11-28-at-4.57.41-PM.png 600w, https://labelbox-guides.ghost.io/content/images/size/w1000/2022/11/Screen-Shot-2022-11-28-at-4.57.41-PM.png 1000w, https://labelbox-guides.ghost.io/content/images/size/w1600/2022/11/Screen-Shot-2022-11-28-at-4.57.41-PM.png 1600w, https://labelbox-guides.ghost.io/content/images/size/w2400/2022/11/Screen-Shot-2022-11-28-at-4.57.41-PM.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eNow, we have a group of intents and the aim of our chatbot will be to receive a message and figure out what the intent behind it is. \u003c/p\u003e\u003cp\u003eIf a chatbot is trained on unsupervised ML, it may misclassify intent and can end up saying things that don’t make sense. Since we are working with annotated datasets, we are hardcoding the output, so we can ensure that our NLP chatbot is always replying with a sensible response. For all unexpected scenarios, you can have an intent that says something along the lines of “I don’t understand, please try again”.\u003c/p\u003e\u003ch2 id=\"step-2-download-and-import-modules\"\u003eStep 2: Download and import modules\u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport nltk\nfrom nltk.stem.lancaster import LancasterStemmer\nstemmer = LancasterStemmer()\nnltk.download ('punkt')\nfrom nltk.tokenize import word_tokenize\nimport numpy as np\nimport tflearn\nimport tensorflow as tf\nimport random\nimport json\nimport urllib3\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSince this is a python tutorial for building a chatbot, we’ll be using a python notebook as well as the following:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://www.nltk.org/?ref=labelbox-guides.ghost.io\"\u003eNLTK\u003c/a\u003e (Natural Language Toolkit) - considered the Swiss-knife of NLP, this will help us trim down our words and help with some pre-processing steps\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://numpy.org/?ref=labelbox-guides.ghost.io\"\u003eNumPy\u003c/a\u003e - for array management \u003c/li\u003e\u003cli\u003e\u003ca href=\"http://tflearn.org/?ref=labelbox-guides.ghost.io\"\u003eTFLearn\u003c/a\u003e and \u003ca href=\"https://www.tensorflow.org/?ref=labelbox-guides.ghost.io\"\u003eTensorFlow\u003c/a\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003cstrong\u003eModules for data:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe’ll need our data as well as the annotations exported from Quantumworks Lab in a JSON file. \u003c/p\u003e\u003cp\u003e\u003cem\u003eUrllib3\u003c/em\u003e - this is relevant when working with Quantumworks Lab, we accept a URL of your file so your data can live in your own cloud storage. In the below code snippet, the URL refers to our data: \u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e[ ] http = urllib3.PoolManager()\n\tr = http.request ('GET', url)\n    data = json.loads (r.data.decode('utf-8'))\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eOnce the data has been imported, you can start playing around with it. We recommend printing your data to confirm that you’ve imported it correctly.\u003c/p\u003e\u003cp\u003eThe next step in building our chatbot will be to loop in the data by creating lists for intents, questions, and their answers.\u003c/p\u003e\u003ch2 id=\"step-3-pre-processing-the-data\"\u003eStep 3: Pre-processing the data\u003c/h2\u003e\u003cp\u003eWe need to pre-process the data in order to reduce the size of vocabulary and to allow the model to read the data faster and more efficiently. This allows the model to get to the meaningful words faster and in turn will lead to more accurate predictions.\u003c/p\u003e\u003cp\u003eIn addition to tokenization and stemming (discussed below), we’ll need to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRemove punctuation\u003c/li\u003e\u003cli\u003eTransform all of our text to lowercase\u003c/li\u003e\u003cli\u003eRemove all duplicates\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"step-4-tokenization\"\u003eStep 4: Tokenization\u003c/h2\u003e\u003cp\u003eTokenization is the process of dividing text into a set of meaningful pieces, such as words or letters, and these pieces are called tokens. A token is essentially the smallest meaningful unit of your data. This is an important step in building a chatbot as it ensures that the chatbot is able to recognize meaningful tokens.\u003c/p\u003e\u003cp\u003eThe first thing we’ll need to do in order to get our data ready to be ingested into the model is to tokenize this data.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e[ ] for intent in data[\"intents\"]:\n\t\tfor question in intent[\"questions\"]:\n          tokens = nltk.word_tokenize(question)\n          words.extend(tokens)\n          docs_questions.append(tokens)\n          docs_intents.append(intent['tag'])\n          \n        if intent[\"tag\"] not in labels:\n        \tlabels.append(intent[\"tag\"])\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-5-stemming\"\u003e\u003cbr\u003eStep 5: Stemming\u003c/h2\u003e\u003cp\u003eStemming is a process where words are reduced to a root by removing inflection through dropping unnecessary characters.\u003c/p\u003e\u003cp\u003eFor example, reducing words with suffixes such as ‘smarter’, ‘smartest’, etc. to their stem, which is simply ‘smart’.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003ewords = [stemmer.stem(token.lower()) for token in words if token != ['\u0026gt;', '\u0026lt;', '\\\\', ':', '-', ',', '#','[' , ']', '/', '//', '_', '(', ')']]\n                                                                     \nwords = sorted(list(set(words)))\nlabels = sorted(labels)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-6-set-up-training-and-test-the-output\"\u003e\u003cbr\u003eStep 6: Set up training and test the output \u003c/h2\u003e\u003cp\u003eSo far, we’ve successfully pre-processed the data and have defined lists of intents, questions, and answers. \u003c/p\u003e\u003cp\u003eHowever, these are ‘strings’ and in order for a neural network model to be able to ingest this data, we have to convert them into \u003ca href=\"https://numpy.org/doc/stable/user/absolute_beginners.html?ref=labelbox-guides.ghost.io#what-is-an-array\"\u003enumPy arrays\u003c/a\u003e. In order to do this, we will create \u003ca href=\"https://scikit-learn.org/stable/modules/feature_extraction.html?ref=labelbox-guides.ghost.io#the-bag-of-words-representation\"\u003ebag-of-words\u003c/a\u003e (BoW) and convert those into numPy arrays.\u003c/p\u003e\u003ch2 id=\"step-7-create-a-bag-of-words-bow\"\u003eStep 7: Create a bag-of-words (BoW)\u003c/h2\u003e\u003cp\u003eA bag-of-words are one-hot encoded (categorical representations of binary vectors) and are extracted features from text for use in modeling. They serve as an excellent vector representation input into our neural network. \u003c/p\u003e\u003cp\u003eFor our chatbot and use case, the bag-of-words will be used to help the model determine whether the words asked by the user are present in our dataset or not.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2022/11/Screen-Shot-2022-11-28-at-5.38.15-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"548\" height=\"298\"\u003e\u003c/figure\u003e\u003cp\u003eTo create a bag-of-words, simply append a 1 to an already existent list of 0s, where there are as many 0s as there are intents.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e[ ] for intent in data[\"intents\"]:\n\t\tfor question in intent[\"questions\"]:\n          tokens = nltk.word_tokenize(question)\n          words.extend(tokens)\n          docs_questions.append(tokens)\n          docs_intents.append(intent['tag'])\n          \n        if intent[\"tag\"] not in labels:\n        \tlabels.append(intent[\"tag\"])\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-8-convert-bows-into-numpy-arrays\"\u003eStep 8: Convert BoWs into numPy arrays \u003c/h2\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003einput = np.array(input)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAfter creating a bag-of-words, the array should look like the below:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003ebag_of_words(\"Hey how are you\", words)\n\narray([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWe recommend storing the pre-processed lists and/or numPy arrays into a pickle file so that you don’t have to run the pre-processing pipeline every time.\u003c/p\u003e\u003ch2 id=\"step-9-build-the-model-for-the-chatbot\"\u003eStep 9: Build the model for the chatbot \u003c/h2\u003e\u003cp\u003eAfter the bag-of-words have been converted into numPy arrays, they are ready to be ingested by the model and the next step will be to start building the model that will be used as the basis for the chatbot. \u003c/p\u003e\u003cp\u003eSince this is a classification task, where we will assign a class (intent) to any given input, a neural network model of two hidden layers is sufficient. \u003c/p\u003e\u003cp\u003eFor this step, we’ll be using \u003ca href=\"http://tflearn.org/?ref=labelbox-guides.ghost.io\"\u003eTFLearn\u003c/a\u003e and will start by resetting the default graph data to get rid of the previous graph settings.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e#resetting default settings\ntf.compat.v1.reset_default_graph()\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWe can then proceed with defining the input shape for our model. For our use case, we can set the length of training as ‘0’, because each training input will be the same length. The below code snippet tells the model to expect a certain length on input arrays. \u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003enet = tflearn.input_data(shape=[None, len(training[0])])\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe next step will be to define the hidden layers of our neural network. The below code snippet allows us to add two fully connected hidden layers, each with 8 neurons. \u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003enet_h1 = tflearn.fully_connected(net, 8)\nnet_h2 = tflearn.fully_connected(net, 8)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSimilar to the input hidden layers, we will need to define our output layer. We’ll use the softmax activation function, which allows us to extract probabilities for each output. Lastly, we’ll apply regression to our neural network. \u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003enet = tflearn.fully_connected(net, len(output[0], activation=\"softmax\")\nnet = tflearn.regression(net)\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAfter these steps have been completed, we are finally ready to build our deep neural network model by calling ‘tflearn.DNN’ on our neural network. \u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel = tflearn.DNN(net)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-10-model-fitting-for-the-chatbot\"\u003e\u003cbr\u003eStep 10: Model fitting for the chatbot\u003c/h2\u003e\u003cp\u003eModel fitting is the calculation of how well a model generalizes data on which it hasn’t been trained on. A well-fitted model is able to more accurately predict outcomes. This is an important step as your customers may ask your NLP chatbot questions in different ways that it has not been trained on.\u003c/p\u003e\u003cp\u003eOnce our model is built, we’re ready to pass it our training data by calling ‘the.fit()’ function. The ‘n_epochs’ represents how many times the model is going to see our data. In this case, our epoch is 1000, so our model will look at our data 1000 times. \u003c/p\u003e\u003cp\u003eWhen our model is done going through all of the epochs, it will output an accuracy score.\u003c/p\u003e\u003ch2 id=\"step-11-model-predictions-for-the-chatbot\"\u003eStep 11: Model predictions for the chatbot\u003c/h2\u003e\u003cp\u003eSince our model was trained on a bag-of-words, it is expecting a bag-of-words as the input from the user. \u003c/p\u003e\u003cp\u003eIn order for us to train our model to make predictions on new data, questions that a customer might ask will have to be converted to B.O.Ws, we’ll need to create a function that will allow us to convert incoming questions into bag-of-words.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef bag_of_words(sentence, words):\n\tbag = np.zeros(len(words))\n    sentence_words = nltk.word_tokenize(sentence)\n    sentence_words = [stemmer.stem(wod.lower)) for word in sentence_words]\n    \n\tfor sw in sentence_words:\n    \tfor i,word in enumerate(words):\n        \tif word==sw:\n            \tbag[i] +=1\n              \n   \treturn np.array(bag)\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-12-create-a-chat-function-for-the-chatbot\"\u003eStep 12: Create a chat function for the chatbot \u003c/h2\u003e\u003cp\u003eThe next step will be to create a chat function that allows the user to interact with our chatbot. We’ll likely want to include an initial message alongside instructions to exit the chat when they are done with the chatbot. \u003c/p\u003e\u003cp\u003eThe user can simply ask questions by using the input() method as follows:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003einput = input(\"You: \")\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-13-classifying-incoming-questions-for-the-chatbot\"\u003e\u003cbr\u003eStep 13: Classifying incoming questions for the chatbot\u003c/h2\u003e\u003cp\u003eWhen a customer asks our chatbot a question, the input from the user will be converted into a bag-of-words using the above function (in step 10) and will run through the model using ‘model.predict()’, where the model will then try to classify the input into the various classes (intent) by predicting their probabilities. \u003c/p\u003e\u003cp\u003eThe arg max function will then locate the highest probability intent and choose a response from that class.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresults_index = np.argmax(results) \u003c/code\u003e\u003c/pre\u003e\u003cp\u003eA safe measure is to always define a confidence threshold for cases where the input from the user is out of vocabulary (OOV) for the chatbot. In this case, if the chatbot comes across vocabulary that is not in its vocabulary, it will respond with “I don’t quite understand. Try again or ask a different question”.\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e#adding a confidence threshold \n\tif results[results_index] \u0026gt; 0.7:\n    \tprint(random.choice(responses))\n    else:\n    \tprint(\"I don't quite understand. Try again or ask a different question.\")\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"step-14-customize-your-chatbot\"\u003e\u003cbr\u003eStep 14: Customize your chatbot\u003c/h2\u003e\u003cp\u003eYou can customize your chatbot to make it specific to your use case or business needs. \u003c/p\u003e\u003cp\u003eIn order to do so, you’ll need to:\u003c/p\u003e\u003col\u003e\u003cli\u003eCreate your own domain specific dataset\u003c/li\u003e\u003cli\u003eCreate an ontology that would be your tags\u003c/li\u003e\u003cli\u003eHave your data labeled by AI experts with \u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox labeling services\u003c/u\u003e\u003c/a\u003e,\u0026nbsp; \u003ca href=\"https://labelbox.com/services/alignerr-connect/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox Alignerr Connect\u003c/u\u003e\u003c/a\u003e, or an internal labeling team using the \u003ca href=\"https://labelbox.com/product/platform/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLabelbox Platform\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eYou can now reference the tags to specific questions and answers in your data and train the model to use those tags to narrow down the best response to a user’s question.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"get-started-today\"\u003e\u003cstrong\u003eGet started today\u0026nbsp;\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eDomain specific chatbots can be tailored from powerful language models for your specific use case or unique business application.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo start training your own AI chat bot, check out the solutions Quantumworks Lab offers here:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eExplore our on-demand labeling services: \u003c/u\u003e\u003c/a\u003eUtilize and build your own team of SMEs to create specialized, high-quality conversational data.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://app.labelbox.com/signup?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eTry out the conversational text editor for free:\u003c/u\u003e\u003c/a\u003e Ready to experiment with building your own chatbots? Easily sign up and get started.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/guides/how-to-annotate-conversational-text-for-chatbot-use-cases/?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003eLearn more:\u003c/u\u003e\u003c/a\u003e See in action how to annotate conversational text for chatbot use cases. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’re happy to help answer any questions. Reach out to us anytime on our \u003ca href=\"https://labelbox.com/sales?ref=labelbox-guides.ghost.io\"\u003e\u003cu\u003econtact us\u003c/u\u003e\u003c/a\u003e page.\u003c/p\u003e","comment_id":"6383ebc240fdcb003d956de5","feature_image":"https://labelbox-guides.ghost.io/content/images/2022/12/Group-2962--1-.png","featured":false,"visibility":"public","created_at":"2022-11-27T22:59:14.000+00:00","updated_at":"2024-11-27T02:59:54.000+00:00","published_at":"2022-12-14T23:11:39.000+00:00","custom_excerpt":"The rise in natural language processing (NLP) language models have given machine learning (ML) teams the opportunity to build custom, tailored experiences for their customers. Learn how to train a domain-specific chatbot.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/guides/how-to-train-a-chatbot/","authors":[{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"}],"tags":[{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},{"id":"653aa45d375d13000123d7de","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/build-ai/"},{"id":"653aa474375d13000123d7e0","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox-guides.ghost.io/tag/building-llms/"},{"id":"653aa5ec375d13000123d7f6","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox-guides.ghost.io/tag/industry-any/"}],"primary_author":{"id":"6328cbf816e912003d39b1a4","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox-guides.ghost.io/author/Quantumworks Lab/"},"primary_tag":{"id":"6323919944f246003d341ab8","name":"Labeling automation","slug":"labeling-automation","description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Guides | Labeling operations","meta_description":"Leverage an end-to-end system that features the full set of capabilities needed to improve your model’s performance.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox-guides.ghost.io/tag/labeling-automation/"},"url":"https://labelbox-guides.ghost.io/how-to-train-a-chatbot/","excerpt":"The rise in natural language processing (NLP) language models have given machine learning (ML) teams the opportunity to build custom, tailored experiences for their customers. Learn how to train a domain-specific chatbot.","reading_time":9,"access":true,"comments":false,"og_image":null,"og_title":"How to train a chatbot","og_description":"Learn how to train a domain-specific chatbot to create custom, tailored experiences for your customers. ","twitter_image":"https://labelbox-guides.ghost.io/content/images/2022/12/Group-2962--1--1.png","twitter_title":"How to train a chatbot","twitter_description":"Learn how to train a domain-specific chatbot to create custom, tailored experiences for your customers. ","meta_title":"How to train a chatbot | Quantumworks Lab","meta_description":"Learn how to train a domain-specific chatbot to create custom, tailored experiences for your customers. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}],"total":74,"tag":{"slug":"build-ai","id":"653aa45d375d13000123d7de","name":"Build AI","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","count":{"posts":74},"url":"https://labelbox-guides.ghost.io/tag/build-ai/"},"slug":"build-ai","currentPage":"5"},"__N_SSG":true},"page":"/guides/tag/[id]/page/[pagenum]","query":{"id":"build-ai","pagenum":"5"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/guides/tag/build-ai/page/5/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:28:08 GMT -->
</html>