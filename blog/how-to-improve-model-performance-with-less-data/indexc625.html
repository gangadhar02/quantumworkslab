<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/how-to-improve-model-performance-with-less-data/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:53:42 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">How to improve model performance with less data</title><meta name="description" content="This data-centric ML method can reduce the required amount of training data by 10% to 50%." data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="How to improve model performance with less data" data-next-head=""/><meta property="og:description" content="This data-centric ML method can reduce the required amount of training data by 10% to 50%." data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/how-to-improve-model-performance-with-less-data/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_Header.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="How to improve model performance with less data" data-next-head=""/><meta name="twitter:description" content="This data-centric ML method can reduce the required amount of training data by 10% to 50%." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/how-to-improve-model-performance-with-less-data/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_Header.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
<link rel="stylesheet" href="fix-footer-visibility.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>January 20, 2022</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">How to improve model performance with less data</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_Header.png"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><p>Machine learning has evolved past the traditional method of iterating on the model with a single large training dataset. Today, advanced ML teams extend their focus to carefully selecting their training data, training the model, examining its performance, and modifying the next training dataset accordingly. This data-centric ML method can, according to a <a href="https://arxiv.org/abs/2007.00077?ref=labelbox.ghost.io">recent study from Stanford University researchers</a>, result in anywhere from a 10% to 50% reduction in the amount of training data, depending on the ML task at hand. This can translate into significant time and cost savings for ML teams. </p><p>In this post, we’re going to walk through the details of model error analysis and data curation, both of which are vital to data-centric ML.</p><h2 id="model-diagnosis">Model diagnosis</h2><p>Model performance metrics are generally grouped into two categories: training metrics and summary metrics. Training metrics are evaluated for every epoch while a model is training, and often include measures of loss and accuracy. Usually, these metrics will tell the ML team how well the model is training and whether there are issues with the model itself. Tools like TensorBoard make it easy to view and interact with this data at a high level and improve a model given a specific architecture and dataset. </p><p>Summary metrics are measured when the model has finished training to evaluate its performance. Often, teams will use aggregate metrics to measure loss and accuracy, but it’s important to more closely examine these measurements to build a nuanced understanding of the model’s performance and curate your next set of training data accordingly.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../../../labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png" class="kg-image" alt="" loading="lazy" width="710" height="430" srcset="https://labelbox.ghost.io/blog/content/images/size/w600/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png 600w, https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png 710w"><figcaption><span style="white-space: pre-wrap;">The basic iterative cycle when training an ML model with a data-centric approach.</span></figcaption></figure><h3 id="digging-deeper-into-performance-metrics">Digging deeper into performance metrics</h3><p>For most computer vision and text models, teams typically use localization and classification error metrics to measure performance. Though errors of both types can have the same root cause, they are worth examining separately to better plan your next steps. One of the most common metrics that measures localization error is intersection over union (IOU) — measuring how well the model prediction covered an object. An IOU score of .5 or .6 is often considered an acceptable level of accuracy, depending on the application.</p><p>Another commonly used category of summary metric is precision or recall. These measure any misclassifications and help ML teams identify the level of confidence required to score an example or class. </p><p>With aggregate summary metrics, ML engineers might be able to monitor a model’s loss decreasing and its accuracy increasing over iterations, but they are likely to miss other patterns in performance that are vital to the model’s success in a production environment, such as biases that have been inadvertently been “taught.” When teams dig deeper into performance data to look at IOU scores and precision/recall metrics, they’ll usually see that performance is quite varied across the dataset and can address specific issues with the next set of training data.</p><p>The process of digging into data can be a challenge with the traditional Jupyter Notebook approach to iteration, where predictions and ground truth can be densely packed and hard to sort through. Having an interactive tool (such as Quantumworks Lab’s <a href="../../product/platform/diagnose/indexc625.html?ref=labelbox.ghost.io">Model Diagnostics</a>) can be invaluable for this data-centric approach to ML.</p><h2 id="curating-training-data">Curating training data</h2><p>Data-centric ML requires two key considerations with respect to training data:</p><ol><li>How well it’s labeled for your specific use case</li><li>Which labeled assets are in the dataset for each iteration</li></ol><p>Curating a dataset based on the performance metrics discussed above is vital if an ML team wants to reduce the overall amount of training data required to get a model to production-level accuracy. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../../../labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_DataCuration.png" class="kg-image" alt="" loading="lazy" width="512" height="329"><figcaption><span style="white-space: pre-wrap;">Typically, the amount of labeled data required increases over each iteration, as model performance sees diminishing returns. By curating their training datasets, ML teams can significantly reduce the required amount of training data.</span></figcaption></figure><p>When deciding what to add to the next training dataset, there are three key objectives to keep in mind:</p><ol><li><strong>Rarity.</strong> Ensuring that each class is appropriately represented within the dataset.</li><li><strong>Redundancy.</strong> If two assets are too similar, they won’t be as informative for the model. For example, a computer vision model training on images of vehicles will need images of each vehicle in various environments and conditions to accurately identify vehicles in a real-world setting.</li><li><strong>Complexity.</strong> In computer vision, if objects are difficult to find due to environment, occlusion, camera focus, or other issues, including examples of those objects in a more easily identifiable image or video in the dataset will help the model train faster.</li></ol><h3 id="sampling-methods">Sampling methods</h3><p>Many ML teams use random sampling (the assets chosen are completely random) or stratified sampling (the assets chosen are random, but include equal examples of every class based on metadata) methods to produce their dataset for each iteration. While random sampling might work well for the first couple iteration cycles, where the model only needs to develop a basic understanding of the task at hand, it becomes inefficient over time. When teams employ random sampling for further iterations, performance gains are generally small. Stratified sampling doesn’t consistently show results either, mostly because metadata doesn’t always capture the right information for the team's specific use case. </p><p>The sampling method that typically works best with a data-centric approach to ML is weak supervision via labeling functions. Labeling functions can be created to group assets by a weak classifier — for example, in a computer vision use case, a labeling function can sort through a dataset and loosely label all images likely to have a specific class or object. This tool is not perfectly accurate, but it can help ML teams quickly sort their data based on the categories they’ve identified during model diagnosis.</p><p>Combining this weak supervision method with stratified and/or random sampling will help teams curate a dataset most likely to significantly improve model performance.</p><p>Quantumworks Lab makes it easy for ML teams to create labeling functions and visually sort their data with <a href="../../product/platform/prioritize/indexc625.html?ref=labelbox.ghost.io">Catalog</a>. Check out our other posts on <a href="https://labelbox.ghost.io/blog/stop-labeling-data-blindly/">data-driven labeling</a> and <a href="https://labelbox.ghost.io/blog/youre-probably-doing-data-discovery-wrong/">data discovery</a> to learn more about our data curation and model diagnosis tools. You can also watch our on demand webinar, <a href="https://learn.labelbox.com/mlunboxed-diagnose-improve-model-performance/?ref=labelbox.ghost.io">How to diagnose and improve model performance</a>, for more details and a demo.</p></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index632b.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Esther Na<span class="mx-2">•</span>March 6, 2025</p></div><a href="../the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">The power of human expertise: Transforming audio and multimodal STEM models with Quantumworks Lab Services</p><p class="text-base max-w-2xl undefined line-clamp-3">In this blog, learn about two AI lab customers who utilized Quantumworks Lab&#x27;s top-tier AI trainers to drive innovation in their audio and multimodal STEM models. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../how-to-generate-industry-specific-data-for-ai-training-with-labelbox/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index49ca.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>February 25, 2025</p></div><a href="../how-to-generate-industry-specific-data-for-ai-training-with-labelbox/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to generate industry-specific data for AI training with Quantumworks Lab</p><p class="text-base max-w-2xl undefined line-clamp-3">This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index4144.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Dmytro Apollonin<span class="mx-2">•</span>December 20, 2024</p></div><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Code Runner: Secure, scalable code execution for model evaluation</p><p class="text-base max-w-2xl undefined line-clamp-3">Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer>
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"how-to-improve-model-performance-with-less-data","id":"61e8e48a6ff46e003bb842f1","uuid":"b3fefd2b-af2c-4e1a-bdfc-f093def70728","title":"How to improve model performance with less data","html":"\u003cp\u003eMachine learning has evolved past the traditional method of iterating on the model with a single large training dataset. Today, advanced ML teams extend their focus to carefully selecting their training data, training the model, examining its performance, and modifying the next training dataset accordingly. This data-centric ML method can, according to a \u003ca href=\"https://arxiv.org/abs/2007.00077?ref=labelbox.ghost.io\"\u003erecent study from Stanford University researchers\u003c/a\u003e, result in anywhere from a 10% to 50% reduction in the amount of training data, depending on the ML task at hand. This can translate into significant time and cost savings for ML teams. \u003c/p\u003e\u003cp\u003eIn this post, we’re going to walk through the details of model error analysis and data curation, both of which are vital to data-centric ML.\u003c/p\u003e\u003ch2 id=\"model-diagnosis\"\u003eModel diagnosis\u003c/h2\u003e\u003cp\u003eModel performance metrics are generally grouped into two categories: training metrics and summary metrics. Training metrics are evaluated for every epoch while a model is training, and often include measures of loss and accuracy. Usually, these metrics will tell the ML team how well the model is training and whether there are issues with the model itself. Tools like TensorBoard make it easy to view and interact with this data at a high level and improve a model given a specific architecture and dataset. \u003c/p\u003e\u003cp\u003eSummary metrics are measured when the model has finished training to evaluate its performance. Often, teams will use aggregate metrics to measure loss and accuracy, but it’s important to more closely examine these measurements to build a nuanced understanding of the model’s performance and curate your next set of training data accordingly.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"710\" height=\"430\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png 600w, https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_IterativeCycle.png 710w\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eThe basic iterative cycle when training an ML model with a data-centric approach.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"digging-deeper-into-performance-metrics\"\u003eDigging deeper into performance metrics\u003c/h3\u003e\u003cp\u003eFor most computer vision and text models, teams typically use localization and classification error metrics to measure performance. Though errors of both types can have the same root cause, they are worth examining separately to better plan your next steps. One of the most common metrics that measures localization error is intersection over union (IOU) — measuring how well the model prediction covered an object. An IOU score of .5 or .6 is often considered an acceptable level of accuracy, depending on the application.\u003c/p\u003e\u003cp\u003eAnother commonly used category of summary metric is precision or recall. These measure any misclassifications and help ML teams identify the level of confidence required to score an example or class. \u003c/p\u003e\u003cp\u003eWith aggregate summary metrics, ML engineers might be able to monitor a model’s loss decreasing and its accuracy increasing over iterations, but they are likely to miss other patterns in performance that are vital to the model’s success in a production environment, such as biases that have been inadvertently been “taught.” When teams dig deeper into performance data to look at IOU scores and precision/recall metrics, they’ll usually see that performance is quite varied across the dataset and can address specific issues with the next set of training data.\u003c/p\u003e\u003cp\u003eThe process of digging into data can be a challenge with the traditional Jupyter Notebook approach to iteration, where predictions and ground truth can be densely packed and hard to sort through. Having an interactive tool (such as Quantumworks Lab’s \u003ca href=\"https://labelbox.com/product/platform/diagnose?ref=labelbox.ghost.io\"\u003eModel Diagnostics\u003c/a\u003e) can be invaluable for this data-centric approach to ML.\u003c/p\u003e\u003ch2 id=\"curating-training-data\"\u003eCurating training data\u003c/h2\u003e\u003cp\u003eData-centric ML requires two key considerations with respect to training data:\u003c/p\u003e\u003col\u003e\u003cli\u003eHow well it’s labeled for your specific use case\u003c/li\u003e\u003cli\u003eWhich labeled assets are in the dataset for each iteration\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eCurating a dataset based on the performance metrics discussed above is vital if an ML team wants to reduce the overall amount of training data required to get a model to production-level accuracy. \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_DataCuration.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"512\" height=\"329\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eTypically, the amount of labeled data required increases over each iteration, as model performance sees diminishing returns. By curating their training datasets, ML teams can significantly reduce the required amount of training data.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhen deciding what to add to the next training dataset, there are three key objectives to keep in mind:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eRarity.\u003c/strong\u003e Ensuring that each class is appropriately represented within the dataset.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRedundancy.\u003c/strong\u003e If two assets are too similar, they won’t be as informative for the model. For example, a computer vision model training on images of vehicles will need images of each vehicle in various environments and conditions to accurately identify vehicles in a real-world setting.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eComplexity.\u003c/strong\u003e In computer vision, if objects are difficult to find due to environment, occlusion, camera focus, or other issues, including examples of those objects in a more easily identifiable image or video in the dataset will help the model train faster.\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"sampling-methods\"\u003eSampling methods\u003c/h3\u003e\u003cp\u003eMany ML teams use random sampling (the assets chosen are completely random) or stratified sampling (the assets chosen are random, but include equal examples of every class based on metadata) methods to produce their dataset for each iteration. While random sampling might work well for the first couple iteration cycles, where the model only needs to develop a basic understanding of the task at hand, it becomes inefficient over time. When teams employ random sampling for further iterations, performance gains are generally small. Stratified sampling doesn’t consistently show results either, mostly because metadata doesn’t always capture the right information for the team's specific use case. \u003c/p\u003e\u003cp\u003eThe sampling method that typically works best with a data-centric approach to ML is weak supervision via labeling functions. Labeling functions can be created to group assets by a weak classifier — for example, in a computer vision use case, a labeling function can sort through a dataset and loosely label all images likely to have a specific class or object. This tool is not perfectly accurate, but it can help ML teams quickly sort their data based on the categories they’ve identified during model diagnosis.\u003c/p\u003e\u003cp\u003eCombining this weak supervision method with stratified and/or random sampling will help teams curate a dataset most likely to significantly improve model performance.\u003c/p\u003e\u003cp\u003eLabelbox makes it easy for ML teams to create labeling functions and visually sort their data with \u003ca href=\"https://labelbox.com/product/platform/prioritize?ref=labelbox.ghost.io\"\u003eCatalog\u003c/a\u003e. Check out our other posts on \u003ca href=\"https://labelbox.ghost.io/blog/stop-labeling-data-blindly/\"\u003edata-driven labeling\u003c/a\u003e and \u003ca href=\"https://labelbox.ghost.io/blog/youre-probably-doing-data-discovery-wrong/\"\u003edata discovery\u003c/a\u003e to learn more about our data curation and model diagnosis tools. You can also watch our on demand webinar, \u003ca href=\"https://learn.labelbox.com/mlunboxed-diagnose-improve-model-performance/?ref=labelbox.ghost.io\"\u003eHow to diagnose and improve model performance\u003c/a\u003e, for more details and a demo.\u003c/p\u003e","comment_id":"61e8e48a6ff46e003bb842f1","feature_image":"https://labelbox.ghost.io/blog/content/images/2022/01/MLUnboxed_Jan2022_RecapBlogPost_Header.png","featured":false,"visibility":"public","created_at":"2022-01-19T20:26:50.000-08:00","updated_at":"2023-10-18T13:58:18.000-07:00","published_at":"2022-01-20T08:22:36.000-08:00","custom_excerpt":"This data-centric ML method can reduce the required amount of training data by 10% to 50%.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"},{"id":"65302ef44e99900001fc0519","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox.ghost.io/blog/tag/industry-any/"},{"id":"653030324e99900001fc052b","name":"Explore \u0026 manage data","slug":"explore-manage-data","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#E7BF00","url":"https://labelbox.ghost.io/blog/tag/explore-manage-data/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},"url":"https://labelbox.ghost.io/blog/how-to-improve-model-performance-with-less-data/","excerpt":"This data-centric ML method can reduce the required amount of training data by 10% to 50%.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":"How to improve model performance with less data","og_description":"This data-centric ML method can reduce the required amount of training data by 10% to 50%.","twitter_image":null,"twitter_title":"How to improve model performance with less data","twitter_description":"This data-centric ML method can reduce the required amount of training data by 10% to 50%.","meta_title":"How to improve model performance with less data","meta_description":"This data-centric ML method can reduce the required amount of training data by 10% to 50%.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"recommended":[{"id":"67ca1d6cb890cf0001e11bef","uuid":"16aa9964-ac17-468a-bef9-f6dddf71c1a7","title":"The power of human expertise: Transforming audio and multimodal STEM models with Quantumworks Lab Services","slug":"the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services","html":"\u003cp\u003eLeading frontier AI builders leverage domain-and language-specific expertise to differentiate their models across data modalities—including audio, multimodal, image, text, and video—and to train them for more complex tasks. As the capabilities of AI expands, the need for post-training processes like SFT, RLHF, and human evaluation remain strong. These tasks depend on expert human knowledge to guide models toward higher performance.This is where we come in. Quantumworks Lab is the AI data factory that delivers high-quality data across all modalities, including specialized domains like STEM, finance, coding, and law—across a wide range of languages for each.\u0026nbsp; \u003c/p\u003e\u003cp\u003eWith \u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox Labeling Services\u003c/u\u003e\u003c/a\u003e, we harness our skilled talent network, \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr\u003c/u\u003e\u003c/a\u003e, to source, vet, and onboard custom teams of human experts who can align models and generate new training data with domain-specific knowledge. Quantumworks Lab can operate and fully-manage a project with Alignerrs and the Quantumworks Lab Platform that generates new training data for our customers, or through \u003ca href=\"https://labelbox.com/services/alignerr-connect/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr Connect\u003c/u\u003e\u003c/a\u003e, customers can browse and select top-tier experts to staff their existing projects and utilize their in-house tools and processes. In this blog, we highlight two recent customers who utilized our top-tier human experts to drive innovation in their cutting-edge audio and multimodal STEM models.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"driving-breakthroughs-in-the-ai-audio-landscape\"\u003eDriving breakthroughs in the AI audio landscape\u0026nbsp;\u003c/h2\u003e\u003cp\u003eA growing AI audio startup aimed to enhance its voice, speech, and sound models by training with expert-labeled data. They faced challenges due to the subjectivity of labeling large volumes of complex audio. Quantumworks Lab addressed this through our platform’s custom audio editor and building a team of trainers with expertise in voice acting and speech. Their background enabled them to label nuanced audio segments with greater accuracy than generalists.\u003c/p\u003e\u003cp\u003eOne of the Alignerrs on the project, Jeff K., has a PhD in Theater and Performance Studies. He shared this about his experience on the project:\u003c/p\u003e\u003cp\u003e\u003cem\u003e“Through years of performing and teaching the arts, I've developed a deep understanding of voice dynamics. I have mental checklists for how and where voices change, which makes it natural for me to identify the various emotions in speech and understand their impact on the listener.\" \u003c/em\u003e\u003cbr\u003e\u003cbr\u003eThis specialized level of human expertise was critical in enabling the startup to create high-quality audio datasets and enhance their AI models, driving the adoption of their advanced audio technology. \u003cbr\u003e\u003cbr\u003eWant to explore the full story behind this success? Read more \u003ca href=\"https://labelbox.com/customers/cutting-edge-audio-models-customer-story/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"improving-multimodal-reasoning-capabilities-with-stem-experts\"\u003eImproving multimodal reasoning capabilities with STEM experts\u003c/h2\u003e\u003cp\u003eA leading AI lab aimed to enhance its large language model (LLM) by identifying weaknesses in K-12 STEM education responses, but they needed a diverse team of STEM experts to create new training data.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox’s Labeling Services brought together a team of highly skilled experts with PhDs and Masters in STEM, who were tasked with reviewing multimodal prompts and responses spanning various domains, including natural science, physics, earth science, and language comprehension. Each task included reviewing the model’s response to a question that contained metadata such as question format, subject category, and an associated image URL.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe AI trainers then had to rate the answers across a number of different areas, including examining the model’s ability to read text, analyze image, and respond correctly. This collaboration helped the lab pinpoint areas for improvement and boost performance with high-quality, domain-specific STEM data.\u003c/p\u003e\u003cp\u003eIf you are interested in learning more about this work, read more \u003ca href=\"https://labelbox.com/customers/multimodal-STEM-customer-story/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"looking-to-leverage-labelbox%E2%80%99s-expert-ai-trainers\"\u003eLooking to leverage Quantumworks Lab’s expert AI trainers?\u003c/h2\u003e\u003cp\u003eThese two customer stories highlight a few examples of the groundbreaking work Quantumworks Lab is performing with frontier model builders.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIf you’d like to learn more about the expert teams we offer and are ready to discuss your data needs, \u003ca href=\"https://labelbox.com/sales/?ref=labelbox.ghost.io\"\u003e\u003cu\u003econtact our team\u003c/u\u003e\u003c/a\u003e anytime on how we can help. You can also directly explore profiles of some of our AI trainers \u003ca href=\"https://labelbox.com/services/alignerr-connect/trainers/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e","comment_id":"67ca1d6cb890cf0001e11bef","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/03/Blog_CustomerStories-1.png","featured":false,"visibility":"public","created_at":"2025-03-06T14:10:52.000-08:00","updated_at":"2025-03-31T14:44:29.000-07:00","published_at":"2025-03-06T14:19:30.000-08:00","custom_excerpt":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"671a9e7504d48b00016d39a3","name":"Esther Na","slug":"esther","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/esther/"}],"tags":[{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"66e9be59d0584c0001886b42","name":"Services","slug":"services","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/services/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"670018ec863cb90001f263e9","name":"Customers","slug":"customers","description":"Quantumworks Lab customer stories","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/customers/"}],"primary_author":{"id":"671a9e7504d48b00016d39a3","name":"Esther Na","slug":"esther","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/esther/"},"primary_tag":{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},"url":"https://labelbox.ghost.io/blog/the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/","excerpt":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","reading_time":3,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Customers transform audio and multimodal AI with Quantumworks Lab Services","meta_description":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"67bd005c3d2f94000130cf29","uuid":"3f09970f-5674-4723-9240-ac8ba605d717","title":"How to generate industry-specific data for AI training with Quantumworks Lab","slug":"how-to-generate-industry-specific-data-for-ai-training-with-labelbox","html":"\u003cp\u003eGenerative AI models are becoming increasingly sophisticated thanks to advances in post-training and model alignment tasks. As a result, the demand for models that not only understand language but also grasp the nuances of specific industries is skyrocketing.\u003c/p\u003e\u003cp\u003eWhile general-purpose large language models (LLMs) have made significant strides, they often fall short when faced with tasks requiring deep domain expertise. Many industries require AI systems capable of industry-specific reasoning that can navigate complex, domain-specific scenarios with expert-level understanding.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe journey to creating AI that truly \"gets\" a particular field goes beyond simply feeding it more data. It requires a targeted approach that focuses on enhancing the model's ability to understand and apply the unique language, concepts, and problem-solving frameworks inherent to a particular field. This is where industry-specific reasoning comes in, and it is the key to unlocking the true potential of AI across sectors like finance, law, medicine, and insurance. By building and using higher quality training data, companies are creating a competitive advantage and opening the door to new opportunities.\u003c/p\u003e\u003cp\u003eThis guide will walk you through the process of generating domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. We'll explore real-world examples in finance and law, delve into the intricacies of creating post-training datasets, and provide a step-by-step walkthrough of creating a project in the Quantumworks Lab platform. We will also discuss the importance of selecting the right AI trainers and crafting clear instructions and ontology.\u0026nbsp;\u003c/p\u003e\u003cp\u003eBy the end of this guide, you'll be equipped with the knowledge and tools to embark on your own journey toward creating powerful training data to help you build AI models that are not just intelligent, but industry-smart.\u003c/p\u003e\u003ch2 id=\"examples-of-how-industry-specific-reasoning-is-becoming-a-reality\"\u003eExamples of how industry-specific reasoning is becoming a reality\u003c/h2\u003e\u003cp\u003eThe power of industry-specific reasoning in AI is not merely theoretical; it's being realized today by forward-thinking companies leveraging advanced tools and expert human insights. Before explaining how to use the Quantumworks Lab platform to build a dataset for training models on industry-specific reasons, let's examine two real-world examples where Quantumworks Lab has helped clients in the finance and legal sectors expand the capabilities of foundational models.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThese examples showcase how targeted data labeling, guided by domain experts, can enhance an LLM's ability to support different industries. And while each example discusses a specific industry’s use case, we’ll later see how the process and usage of Quantumworks Lab can be extended to a much broader range of domains and uses, paving the way for a deeper dive into the practical steps involved in creating your own successful projects.\u003c/p\u003e\u003ch4 id=\"finance-training-models-on-financial-analysis\"\u003e\u003cstrong\u003eFinance: Training models on financial analysis\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA leading AI lab wanted to improve their LLM’s performance in financial analysis and argumentation. They hoped to train the LLM to provide meaningful insights on any public company when provided a ticker symbol and the latest financial reports of a company. In addition, they wanted the model trained and prepared to answer the most common questions financial analyst might ask.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo reach this level of financial expertise, they needed training on detailed, domain-specific datasets that were accurately labeled by a team of Chartered Financial Analysts (CFAs) and financial experts. The CFAs needed to have advanced industry knowledge and experience reviewing and analyzing financial models and details.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, they faced two major challenges: (1) sourcing financial experts who could accurately evaluate and rank responses through multi-step analyses, and (2) managing a complex process where each piece of data could take an hour or more to properly analyze and fully label.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe company turned to Quantumworks Lab to help source experts with financial expertise. Quantumworks Lab leveraged their Alignerr network of expert human labelers to quickly recruit and onboard a skilled team of financial experts with backgrounds in CFA, MBA, and Masters in Finance. The team built a customized project consisting of a complex ontology, detailed instructions, and numerous attachments per dataset to review and prepare hypothetical questions and scenarios around.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"legal-automating-case-evaluation-and-data-discovery\"\u003e\u003cstrong\u003eLegal: Automating case evaluation and data discovery\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA forward-thinking legal tech company wants to revolutionize how plaintiff firms operate. By using AI-driven tools with industry-specific reasoning, they want to significantly enhance their ability to evaluate cases, analyze key facts and claims, and ultimately deliver results for their clients more efficiently and transparently.\u003c/p\u003e\u003cp\u003eTo achieve this, they needed to imbue their foundational AI model with deep legal expertise, particularly in understanding long legal documents, interpreting insurance and medical bills, and assessing case value.\u003c/p\u003e\u003cp\u003eThe company partnered with Quantumworks Lab to create specialized datasets for post-training their model. Quantumworks Lab's network of legal experts reviewed a long list of example prompts that were each associated with many multi-page legal documents. They were tasked with identifying key information based on the prompt, crafting well-reasoned responses supported by evidence found in the documents, and evaluating the models responses for accuracy, safety, and reasoning. They were also used to build a dataset based on understanding insurance and medical billing details and learning how to extra the correct details.\u003c/p\u003e\u003cp\u003eSimilar to the finance example above, this project involved creating a custom ontology and using the flexibility of the Quantumworks Lab text editor to generate responses to sample prompts from industry experts, identify key data in attached documents, and use their own expertise to properly interpret complex documents.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"importance-of-high-quality-training-datasets\"\u003eImportance of high-quality training datasets\u0026nbsp;\u003c/h2\u003e\u003cp\u003eThe above finance and legal examples, while distinct in their domain-specific challenges, underscore a fundamental truth about building industry-specific reasoning into AI: the underlying approach remains consistent across industries, whether it's finance, medicine, insurance, or any other specialized field.\u0026nbsp;\u003c/p\u003e\u003cp\u003eAt its core, the process revolves around creating unique and differentiated datasets that capture the specific nuances, knowledge, and reasoning patterns of the target domain. These datasets serve as the bedrock for training models to perform the desired capabilities, enabling them to go beyond general understanding and develop true expertise.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"strategies-to-remember-when-planning-your-project\"\u003e\u003cstrong\u003eStrategies to remember when planning your project\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eBefore kicking off a project or starting the process of building a post-training dataset for industry-specific reasoning, organizations should take the time to think through the following steps:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIdentifying key domain-specific competencies required\u003c/li\u003e\u003cli\u003eDefining clear evaluation criteria for expert knowledge\u003c/li\u003e\u003cli\u003eGathering supporting documentation and examples to attach to the project\u003c/li\u003e\u003cli\u003eWriting hypothetical scenarios and questions you want the model to answer\u003c/li\u003e\u003cli\u003eEstablishing metrics for measuring improvement in domain understanding\u003c/li\u003e\u003cli\u003eSetting realistic scope and scale for the training dataset\u003c/li\u003e\u003cli\u003ePreparing a model evaluation process for side-by-side comparisons\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis list may be shortened by some users and for others there may be other key considerations to add; however, we’ve learned that the most successful projects involve advanced planning and often a fair amount of preparation to gather necessary documents, built prompt examples, and think through the key scenarios that require examples and labeled data to sufficiently train the model.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"selecting-the-right-ai-trainers\"\u003e\u003cstrong\u003eSelecting the right AI trainers\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe next big AI breakthroughs will be fueled by unique, high-quality data. The massive quantity of available data from the internet has been used to train all of the most popular AI models—meaning they all have similar core capabilities and areas of weakness.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo properly train these models on new domain-specific knowledge and reasoning it’s imperative that we tap into new information and capture data from domain experts. As a result, the focus must be on properly identifying and recruiting AI trainers with unique skills—like the \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr network\u003c/u\u003e\u003c/a\u003e of highly educated industry experts—to label data, generate new responses, evaluate models, and perform critical model post-training alignment tasks.\u003c/p\u003e\u003cp\u003eBased on our experience from leading the Alignerr network and working with AI labs and model builders to form teams of experts, it’s important to keep the following in mind:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDomain expertise:\u003c/strong\u003e Look for annotators with relevant qualifications, certifications, and experience in the target industry (e.g., CFA, JD, MD).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAnalytical skills:\u003c/strong\u003e Choose individuals who can demonstrate strong analytical and reasoning abilities.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAttention to detail:\u003c/strong\u003e Ensure the annotators are meticulous and capable of identifying subtle nuances in the data.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCommunication skills:\u003c/strong\u003e Select annotators who can clearly articulate their reasoning and provide constructive feedback.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePrevious success metrics:\u003c/strong\u003e For annotators that have worked on AI training before and used a complete AI platform, then you should be able to review past performance metrics to assist in the evaluations.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAI interviews: \u003c/strong\u003eAbilities can only be determined so much by reviewing resumes and profiles, so using interviews tailored to their specific background provides the most powerful data.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"key-labelbox-features-for-generating-industry-specific-training-data\"\u003eKey Quantumworks Lab features for generating industry-specific training data\u003c/h2\u003e\u003cp\u003eHaving outlined strategic considerations to review before starting a project as well as the keys to selecting the right domain experts, the next crucial step is understanding how to operationalize this process efficiently and effectively. This is where a robust and versatile platform like Quantumworks Lab becomes indispensable.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox Platform is an industry-leading software tool with the flexibility and advanced features needed to translate your vision into a concrete, well-structured labeling project tailored for industry-specific reasoning.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFrom selecting the appropriate editor—often the flexible text editor for tasks involving complex analysis and document reviews—to building a comprehensive ontology with a mix of selection tools and free-form text inputs, Quantumworks Lab can capture the nuances of your target domain. In addition, the built-in quality assurance and project management capabilities ensure that your project stays on track, maintains high accuracy, and ultimately delivers a dataset that enhances your AI model's performance.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLet's briefly explore the key components of the Quantumworks Lab platform that we see used most often in industry-specific reasoning tasks and discuss how they can be leveraged to build the foundation for your industry-specific AI.\u003c/p\u003e\u003ch4 id=\"data-types-editors\"\u003e\u003cstrong\u003eData types \u0026amp; editors\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox supports a range of data types, including text, video, image, audio, PDFs, multimodal, and more. For each data type, a customized editor exists to serve as the core interface for labeling that specific data type. While tailored to specific datatypes, the editors are extremely flexible and can be customized to help label and capture the specific data needed for a given industry.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor most industry-specific reasoning projects, we have seen the core \u003ca href=\"https://docs.labelbox.com/docs/text-editor?ref=labelbox.ghost.io\"\u003e\u003cu\u003etext editor\u003c/u\u003e\u003c/a\u003e serve as the key editor. It was the editor used in both the finance and legal examples shared earlier. The editor supports these annotation types: entity, relationships, radio classification, checklist classification, and free-form text classification. The latter is often used to capture detailed information and sample responses from domain experts on a given prompt or to provide detailed information on specific information found or extracted from an attached document.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"ontology\"\u003e\u003cstrong\u003eOntology\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox ontology\u003c/u\u003e\u003c/a\u003e defines the structure and categories for labeling data. Ontologies can be reused across different projects and they are required for data labeling, model training, and evaluation. When you are in the editor, the ontology appears in the Tools panel.\u003c/p\u003e\u003cp\u003eOntologies can be customized for any given project and supports classifications, object detection, segmentation, relationships, messaging ranking, prompt rating, step-by-step rating, and more. The available ontology tasks will vary based on the selected editor and data type.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOntologies also allow for hierarchical relationships between classes, allowing you to create complex labeling tasks with detailed information.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"quality-assurance\"\u003e\u003cstrong\u003eQuality assurance\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox offers a suite of quality assurance features to deliver high-quality labeled data, which is particularly crucial when dealing with complex, industry-specific reasoning tasks. Consensus allows you to measure the agreement between multiple labelers on the same data point, providing a statistical measure of confidence in the assigned labels. Benchmarks enable you to incorporate known ground-truth data into your project, allowing you to directly assess labeler accuracy against established standards.\u0026nbsp;\u003c/p\u003e\u003cp\u003eCalibration tools help identify and correct for systematic biases that individual labelers might exhibit, further refining the consistency of your dataset. Moreover, Quantumworks Lab Monitor provides real-time insights into your labeling operations, allowing you to track key metrics, identify trends, and quickly spot any outliers in labeler performance. With Monitor, you can proactively address issues and make adjustments as needed, ensuring that your project stays on course.\u003c/p\u003e\u003ch4 id=\"project-management\"\u003e\u003cstrong\u003eProject management\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox provides robust project management tools to manage and track your industry-specific reasoning projects from start to finish. Unlike many labeling services and solutions, the Quantumworks Lab platform offers transparency into project progress, allowing you to monitor the status of individual tasks, track labeler performance, and gain a clear overview of the entire project's health. Real-time communication features enable seamless interaction with your team of expert labelers, facilitating quick clarification of instructions, addressing questions, and providing feedback directly within the platform.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox also allows you to build customized workflows tailored to your specific review and quality control processes, ensuring that each piece of data undergoes the appropriate level of scrutiny before being incorporated into your training set. Furthermore, robust data versioning capabilities provide a comprehensive history of all changes made to your data and ontology, allowing for easy rollback if needed and providing a clear audit trail for maintaining data integrity.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"creating-an-industry-specific-reasoning-project-in-labelbox\"\u003eCreating an industry-specific reasoning project in Quantumworks Lab\u003c/h2\u003e\u003cp\u003eHaving explored the core features of the Quantumworks Lab platform, let’s examine the key steps to creating and executing on a project to generate new data for training your AI models and apps on industry-specific reasoning.\u003c/p\u003e\u003cp\u003eThis section provides a practical roadmap, walking you through each stage of the process, from crafting clear and comprehensive instructions for your expert labelers to setting up your project within the Quantumworks Lab environment, configuring the ideal ontology, managing the labeling operation, and conducting thorough reviews to ensure the highest level of data quality.\u0026nbsp;\u003c/p\u003e\u003cp\u003eUsing these steps as a framework for your project, you can start exploring how the Quantumworks Lab Platform can be used for your unique project. You’ll learn what it takes to build a new training dataset for your specific needs. \u003c/p\u003e\u003ch4 id=\"1-identify-desired-outcomes-and-goals\"\u003e\u003cstrong\u003e1. Identify desired outcomes and goals\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eBefore diving into the mechanics of using Quantumworks Lab, it's crucial to establish a clear understanding of your project's objectives. Training frontier models for industry-specific reasoning requires a well-defined target. What specific problem are you trying to solve? What capabilities do you want your model to possess? Answering these questions will guide your data collection and annotation strategy, ultimately determining the success of your project. For example, are you aiming to build a model that can summarize legal documents, predict financial market trends, or diagnose medical conditions? Each of these scenarios demands a different approach to data and annotation.\u003c/p\u003e\u003cp\u003eThis initial phase focuses on defining the desired outcomes and the key capabilities you want your model to achieve. Let's consider a practical example: building a model to assist legal experts in reviewing case files. The desired outcome might be to reduce the time spent on initial case review by automating the identification of key legal arguments and relevant precedents. This translates into key capabilities like: understanding legal terminology, identifying relationships between different parts of a case file, and summarizing complex legal arguments. We need to capture training data that reflects these capabilities. This might include labeled examples of legal arguments, summaries of past cases, and annotations highlighting the relationships between different legal concepts within a document.\u003c/p\u003e\u003ch4 id=\"2-write-clear-instructions\"\u003e\u003cstrong\u003e2. Write clear instructions\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe quality of your training data hinges on the clarity and completeness of the instructions provided to your AI trainers. Ambiguous guidelines lead to inconsistent annotations, which ultimately undermines the performance of your frontier model. This section outlines the key components of effective instruction design, ensuring your team can accurately and efficiently generate the high-quality data you need.\u003c/p\u003e\u003cp\u003eA comprehensive instruction set begins with a clear overview of the task. Explain the project's overall goal and how the annotations contribute to achieving that goal. Frame the task within the context of the larger project, emphasizing the importance of accurate labeling. For our legal case review example, this overview might explain how the labeled data will train a model to assist lawyers in quickly identifying key information within case files, ultimately saving time and resources.\u003c/p\u003e\u003cp\u003eNext, provide a detailed explanation of the ontology and all relevant terminology. Clearly define each label, category, or rating, avoiding jargon or technical terms that the labelers might not understand. Use simple language and provide real-world examples to illustrate each concept. For instance, instead of simply defining \"legal precedent,\" explain it with a concrete example: \"Legal precedent refers to a previous court decision that serves as a guide for similar cases in the future. For example, the 1954 Supreme Court case Brown v. Board of Education established a precedent for desegregating public schools.\" Provide multiple examples for each category to cover a range of scenarios. For financial analysis, this might include defining terms like \"bull market,\" \"bear market,\" and \"market volatility,\" each with illustrative examples from real-world financial news.\u003c/p\u003e\u003cp\u003eAddressing edge cases and exceptions is crucial. Anticipate situations where the correct label might be unclear or ambiguous. Provide specific guidance on how to handle these situations. And it’s important to provide guidance on what a trainer should do if they don’t feel qualified or confident in a given task. The instructions should clearly state: \"If you are unsure about the correct label, or if you encounter a situation not covered in these guidelines, do not guess. Instead, flag the case for review by a subject matter expert.\" This emphasis on accuracy over completeness is essential for maintaining data quality.\u003c/p\u003e\u003cp\u003eFinally, establish a clear process for feedback, questions, and clarification. Provide a designated channel for labelers to ask questions, report issues, or suggest improvements to the guidelines. Regularly review and incorporate feedback to refine the instructions and address any ambiguities that arise during the annotation process. This iterative approach ensures that the labeling process becomes more accurate and efficient over time. A well-defined communication channel also empowers labelers to contribute valuable insights based on their experience with the data.\u003c/p\u003e\u003ch4 id=\"3-create-a-new-project-and-select-the-right-editor\"\u003e\u003cstrong\u003e3. Create a new project and select the right editor\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eYou're ready to create your project within the Quantumworks Lab platform. Begin by logging into your \u003ca href=\"https://app.labelbox.com/home?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox account\u003c/u\u003e\u003c/a\u003e. Once logged in, click “Create project.”\u003c/p\u003e\u003cp\u003eThe first step is to select the appropriate data modality or task type for your project. This choice is crucial as it determines the tools and interface available to your labelers. For industry-specific reasoning projects involving long-form text analysis, such as reviewing legal documents or analyzing financial reports, the \u003cem\u003eText editor\u003c/em\u003e is often the most suitable option.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe6JVMOwP2YQkAGOA_b1BMZyK0LV3m9Q2h2XMLsFwDVxpjmwIOZS0RUTSfdijAF_LkaewSJmvA_Gh_-30qE8wTAxOawA4Eohobyp2izBk85Tl2f6w4BROD4ls1LVmuYKBy_J3-gQA?key=n3W5WytgaR_uk4G4uepV7qDG\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"379\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreate a new project in Quantumworks Lab by selecting the appropriate data modality or task type\u003c/em\u003e\u003c/p\u003e\u003cp\u003eLabelbox also supports other modalities like image, video, audio, and multimodal chat, allowing you to adapt to various data types. For example, if your project involves evaluating the quality of responses from a large language model in a live chat conversation, you may use the multimodal chat editor. If your project involves processing audio recordings of earnings calls, you may select audio. Select the modality that best reflects the nature of your data.\u003c/p\u003e\u003cp\u003eProvide your project with a descriptive and informative \u003cem\u003ename\u003c/em\u003e. This will help you easily identify and manage your project within Labelbox. For our legal case review example, a name like \"Legal Case Review - Contract Analysis\" would be appropriate. For financial analysis, it might be “Financial Report Analysis - Risk Assessment.”\u003c/p\u003e\u003cp\u003eFinally, \u003cem\u003eupload any existing data\u003c/em\u003e that you plan to use in the project. Quantumworks Lab supports various data formats, making it easy to import your data. This might include PDFs, plain text files, CSV files, or even connections to cloud storage. Consider organizing your data into logical batches or datasets before uploading to simplify project management. While uploading, ensure that your data is properly formatted and structured for optimal use within the Quantumworks Lab platform. For large datasets, consider using Quantumworks Lab's data import capabilities to streamline the process.\u003c/p\u003e\u003ch4 id=\"4-customize-your-ontology\"\u003e\u003cstrong\u003e4. Customize your ontology\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA well-defined ontology is the backbone of your labeling project. It provides the structure and vocabulary for your AI trainers, ensuring consistency and accuracy in their annotations.\u003c/p\u003e\u003cp\u003eNavigate to the \"Ontology\" tab within your newly created project. This is where you'll define the building blocks of your annotation schema.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf-803iyhcp4sokBV32MavTuHSP0jcDW7l72SZFdzMBoCiUcEnhz-qpo2cIw3qGSdA7Mh4ebaIH1WHQIikgzFJRus8lbpU6tGFtz5VrAdSQhWKz4e8suPlvKSI_cS2Z0qFMerEhig?key=n3W5WytgaR_uk4G4uepV7qDG\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"391\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eExample of an ontology configured to collect both ratings and free responses on a given datarow\u003c/em\u003e\u003c/p\u003e\u003cp\u003eClean, thoughtful ontologies help create high-quality labeled data with minimal errors and inconsistencies. Ontologies are an essential part of the Quantumworks Lab labeling platform. Every time you create a project or a model in Quantumworks Lab, you will need to select an ontology.\u003c/p\u003e\u003cp\u003eAlong with the core objects, classifications, and relationships that you’ll use in the text editor, you can also establish \u003cem\u003ehierarchical relationships\u003c/em\u003e between classes if it makes sense for your domain. This allows you to create a more structured and organized ontology. For instance, \"Breach of Contract\" could be a subclass of a more general class called \"Contractual Issue.\" Hierarchical relationships can help your model learn more general concepts from specific examples. They can also make the labeling process more efficient by allowing labelers to quickly navigate through related concepts. For complex ontologies, consider using Quantumworks Lab's hierarchical labeling features to simplify the annotation process.\u003c/p\u003e\u003cp\u003eFor most of today’s complex tasks for generative AI, consider incorporating \u003cem\u003efree text fields\u003c/em\u003e to capture richer insights from your AI trainers. These fields give the trainers the ability to rewrite prompts or responses, provide detailed feedback, and explain the rationale behind their ratings or labels. This qualitative information can be invaluable for understanding model behavior and improving its performance.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor instance, a free text field could allow a labeler to explain why they chose a particular label, highlight ambiguities in the data, or suggest improvements to the ontology. This feedback loop is crucial for refining your model and ensuring it aligns with your desired outcomes.\u003c/p\u003e\u003ch4 id=\"5-execute-the-project-label-rate-and-align\"\u003e\u003cstrong\u003e5. Execute the project: label, rate and align\u0026nbsp;\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eWith your project configured, data loaded, and a robust ontology in place, you're ready to invite your team to begin executing on the tasks and generating new training data.\u003c/p\u003e\u003cp\u003eFirst, invite your selected AI trainers to the project. Quantumworks Lab makes it easy to add team members and assign them specific roles. Ensure that each annotator has the necessary training and understands the project's goals, the ontology, and the annotation guidelines. Consider providing a brief onboarding session to familiarize annotators with the Quantumworks Lab platform and the specific requirements of your project.\u003c/p\u003e\u003cp\u003eNext, assign data batches to the annotators. Organize your data into manageable batches to streamline the annotation workflow. Quantumworks Lab provides tools for batch management, allowing you to distribute data evenly among your team members. Consider assigning smaller batches initially to allow for early feedback and adjustments to the annotation process. As annotators become more proficient, you can increase the batch size.\u003c/p\u003e\u003cp\u003eMonitor the labeling progress regularly. The \u003ca href=\"https://docs.labelbox.com/docs/monitor?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox workspace monitor\u003c/u\u003e\u003c/a\u003e provides dashboards and reporting tools that allow you to track the progress of each annotator and identify any potential bottlenecks or issues. Regular monitoring also allows you to provide timely feedback to annotators and address any questions or concerns they may have. This proactive approach helps maintain data quality and ensures that the project stays on track.\u003c/p\u003e\u003cp\u003eUtilize Consensus, Benchmarks, and Calibration to ensure data quality. These features are essential for maintaining consistency and accuracy in your annotations. Consensus involves having multiple annotators label the same data points and then comparing their annotations. Discrepancies can be discussed and resolved, leading to higher quality data.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cem\u003eBenchmarks\u003c/em\u003e are pre-labeled data points that serve as a gold standard for evaluating annotator performance. Regularly testing annotators on benchmarks can help identify areas where they may need additional training or guidance.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cem\u003eCalibration\u003c/em\u003e is the process of adjusting the annotation guidelines or training materials based on feedback from annotators and insights gained from consensus and benchmark analysis. This iterative approach ensures that your data quality continuously improves throughout the project lifecycle. By actively managing your team and implementing these quality control measures, you can generate the high-quality training data needed to power your frontier models.\u003c/p\u003e\u003ch4 id=\"6-review-and-perform-qa\"\u003e\u003cstrong\u003e6. Review and perform QA\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eEven with well-defined instructions and diligent annotators, a robust review process is essential for guaranteeing the highest quality training data.\u003c/p\u003e\u003cp\u003eEstablishing a strong review process within Quantumworks Lab allows you to implement multiple layers of quality control. You can configure reviews on a per-project basis, tailoring the process to the specific needs of your task. For example, you might require all annotations to be reviewed by a subject matter expert before being accepted into the training dataset. Alternatively, you could implement a tiered review system, where a subset of annotations are reviewed by a senior annotator, and only those that meet a certain quality threshold are then passed on to a subject matter expert for final review. Quantumworks Lab's review workflows can be customized to fit your specific requirements, allowing you to create a scalable and efficient quality control system. Consider implementing a system where annotations are reviewed by a different annotator than the one who originally labeled the data. This helps to catch potential biases or inconsistencies.\u003c/p\u003e\u003cp\u003eBeyond manual review, Quantumworks Lab offers AutoQA features that can significantly improve data quality. AutoQA leverages machine learning models to automatically identify potential errors or inconsistencies in your annotations. These features can flag annotations that deviate significantly from the consensus, highlight areas where annotators disagree, or identify annotations that are inconsistent with pre-defined rules or constraints. By proactively identifying potential issues, AutoQA allows you to focus your review efforts on the most critical areas, saving time and resources.\u0026nbsp;\u003c/p\u003e\u003cp\u003eBy combining manual review with AutoQA, you can create a comprehensive quality assurance system that ensures your training data is accurate, consistent, and reliable. This, in turn, will lead to better performing frontier models capable of industry-specific reasoning.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"disrupting-your-industry-with-advanced-ai-capabilities\"\u003eDisrupting your industry with advanced AI capabilities\u003c/h2\u003e\u003cp\u003eThe pursuit of AI excellence demands a shift from generic to specialized. As we've explored in this guide, building industry-specific reasoning into LLMs and AI models is not just a technical challenge, but a strategic imperative. By leveraging platforms like Quantumworks Lab and embracing a data-centric approach, companies can unlock the true potential of AI and create models that are not just intelligent, but also insightful, reliable, and tailored to the unique demands of their respective industries.\u003c/p\u003e\u003cp\u003eThis guide has provided a roadmap for embarking on this transformative journey. From crafting clear instructions and building robust ontologies to selecting the right AI trainers and leveraging the powerful features of the Quantumworks Lab platform, you now have the foundational knowledge to create your own industry-specific reasoning projects. Remember that the key to success lies in a meticulous, iterative approach, where continuous learning and improvement are paramount.\u003c/p\u003e\u003cp\u003eAs you venture forth, keep in mind that the landscape of AI is constantly evolving. Stay curious, embrace new challenges, and never stop refining your approach. The future of AI is not just about building smarter models, but about building models that truly understand the world in all its specialized complexity. And with Quantumworks Lab as your partner, you're well-equipped to lead the charge toward a future where AI is not just a tool, but a true industry expert.\u003c/p\u003e\u003ch2 id=\"additional-resources\"\u003eAdditional resources:\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox documentation\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/customers/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox customer stories\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"67bd005c3d2f94000130cf29","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/02/Blog_industry-specific.png","featured":false,"visibility":"public","created_at":"2025-02-24T15:27:24.000-08:00","updated_at":"2025-03-31T14:46:10.000-07:00","published_at":"2025-02-24T16:03:56.000-08:00","custom_excerpt":"This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/how-to-generate-industry-specific-data-for-ai-training-with-labelbox/","excerpt":"This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. ","reading_time":17,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Ultimate guide to generating industry-specific AI training data","meta_description":"This guide teaches you how to generate domain-specific data with the Quantumworks Lab data factory to train your AI models on industry-specific knowledge.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6765b8c06f63bf0001f1ca72","uuid":"9f912bc0-54da-4ac6-ab5f-78d8f926463c","title":"Code Runner: Secure, scalable code execution for model evaluation","slug":"code-runner-secure-scalable-code-execution-for-model-evaluation-2","html":"\u003cp\u003eIn the world of large language models (LLMs), evaluating their responses effectively is a fundamental aspect of improving model performance. We’re excited to announce the latest addition to the Quantumworks Lab platform: Code Runner.\u003cstrong\u003e \u003c/strong\u003eThis new capability pushes the boundaries of interactivity by allowing users to execute written code directly within the evaluation workflow.\u003c/p\u003e\u003cp\u003eCode Runner helps eliminate errors, optimizes functionality, and validates outputs, leading to higher-quality datasets. Today, we’ll introduce this new feature and then dive into the technical details of the infrastructure powering this feature, highlighting how it was designed with security, scalability, and\u003cstrong\u003e \u003c/strong\u003erobustness at its core.\u003c/p\u003e\u003ch2 id=\"what-is-code-runner\"\u003e\u003cstrong\u003eWhat is Code Runner?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner is a new built-in feature of the Quantumworks Lab platform designed to improve the quality of responses and labels generated in any coding-related projects. The new features enables users to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDirectly execute code found in either model responses or user-written responses \u003c/li\u003e\u003cli\u003eReceive precise outputs including:\u003cul\u003e\u003cli\u003eStandard output (stdout)\u003c/li\u003e\u003cli\u003eStandard error (stderr)\u003c/li\u003e\u003cli\u003eExecution time\u003c/li\u003e\u003cli\u003eWarnings or runtime errors\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy integrating Code Runner into the evaluation pipeline, we aim to simplify the process of verifying the accuracy, efficiency, and functionality of code responses, all without users needing to leave the platform.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBDN_1bnU_bTrPrWS59SWalVqw22Gxq3AIxNnbsOJmZGPap3weXHYFEgzrlPnEyhVK1GOjzCVClvQycomfMfhQsulqPk4wdQGqniZv8aIaHGP69wzgcFjdDdr5FgooITwNJCsp?key=GRyWmie9kDWaUfN6osDAF8J7\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"389\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOur system automatically detects the language in the text area and suggests the appropriate environment for execution, whether Python or JavaScript (and more to come).\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut what makes this feature stand out is the sophisticated infrastructure behind it, designed to ensure seamless execution while maintaining strict security and privacy standards.\u003c/p\u003e\u003ch2 id=\"code-runner-infrastructure-a-deep-dive\"\u003e\u003cstrong\u003eCode Runner infrastructure: A deep dive\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eAt the heart of Code Runner’s infrastructure lies Google Cloud Run, a fully managed compute platform that runs containerized applications in a secure, scalable manner. Here are the key components and principles driving the system:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1. Cloud Run for language-specific environments\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEvery code execution happens in a dedicated Cloud Run instance. Each instance is tailored to a specific programming language environment (e.g., Python, JavaScript, etc.) and is spun up dynamically based on the code type detected in the user response.\u003c/p\u003e\u003cp\u003eThis design includes the following characteristics to ensure security and speed:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eIsolation\u003c/strong\u003e: Each execution is fully containerized, completely isolating the runtime environment from others.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTemporary directories\u003c/strong\u003e: Code is executed in a temporary directory within the container, and it is deleted immediately after execution, leaving no trace behind.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage-specific tools\u003c/strong\u003e: Each environment comes preloaded with the necessary packages and libraries to ensure compatibility and speed.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e2. Enhanced security with separate GCP projects \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Cloud Run service is hosted in a separate Google Cloud Platform (GCP) project, distinct from our main infrastructure. This segmentation provides an additional layer of security by isolating code execution from our core services. Even in the unlikely event of a compromise, the blast radius is contained.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Communication via private service connect\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo ensure secure and controlled communication, all interactions between the main evaluation system and the Cloud Run service occur over Private Service Connect, which provides the following advantages: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eNo public exposure\u003c/strong\u003e: The Cloud Run endpoint is never exposed to the public internet, reducing the risk of unauthorized access.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOne-way communication\u003c/strong\u003e: The Private Service Connect setup restricts outbound networking from the Cloud Run service, ensuring that executed code cannot make arbitrary network requests. \u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGranular networking controls\u003c/strong\u003e: The private network allows for precise control over what resources the Cloud Run service can access.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e4. Automatic cleanup\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo maintain a lightweight and secure runtime, the system delivers:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEphemeral execution\u003c/strong\u003e: Each execution request is handled in a stateless, temporary environment.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAutomatic deletion\u003c/strong\u003e: Files, logs, and temporary directories are wiped as soon as execution completes, leaving no residual data.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"how-code-runner-works-a-step-by-step-overview\"\u003e\u003cstrong\u003eHow Code Runner works: A step-by-step overview\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow that you have an understanding of the powerful infrastructure underneath Code Runner, here is a summary of how the feature works from start to finish:\u0026nbsp;\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eCode submission\u003c/strong\u003e: A user requests code execution from the evaluation interface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage detection\u003c/strong\u003e: The system detects the programming language and forwards the request to the corresponding Cloud Run service.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e: The Cloud Run instance spins up a container, executes the code in a sandboxed environment, and collects the results.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResult delivery\u003c/strong\u003e: The system returns the output (stdout, stderr, execution time, and any warnings) to the user for analysis.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCleanup\u003c/strong\u003e: The container and all related resources are terminated and deleted.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"advantages-of-labelbox%E2%80%99s-built-in-code-execution\"\u003e\u003cstrong\u003eAdvantages of Quantumworks Lab’s built-in code execution\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner’s infrastructure was designed specifically to provide the previously discussed benefits and to address several key challenges that other solutions may face:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSecurity\u003c/strong\u003e: By isolating execution environments and ensuring no public exposure, we eliminate a significant attack surface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability\u003c/strong\u003e: Cloud Run’s serverless nature allows us to scale dynamically with demand, handling thousands of requests efficiently.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eReliability\u003c/strong\u003e: The use of ephemeral containers ensures that each execution starts in a clean slate, avoiding cross-contamination or resource conflicts.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"explore-it-yourself\"\u003e\u003cstrong\u003eExplore it yourself\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWith Code Runner, we’re empowering users to go beyond static evaluations, enabling dynamic, interactive testing that’s as secure as it is scalable. As always, we’re excited to hear your feedback and explore how we can push this feature even further.\u003c/p\u003e\u003cp\u003e If you want to explore Code Runner and other LLM evaluation tools, \u003ca href=\"https://app.labelbox.com/signup?_r=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/?utm_keyword=Quantumworks Lab\u0026utm_source=house\u0026utm_medium=email\u0026utm_campaign=1224%2520\u0026gclid=CjwKCAiA34S7BhAtEiwACZzv4a9veoKXnMnMvo2rWJvXkH46oHs4Lb5VFQi2ERBN_sQ5kgypV_zfBxoC0yMQAvD_BwE\u0026landingPageAnonymousId=%22e3f2f82f-be24-4045-b2b9-50a49cb801e8%22\u0026referrer_url=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/\"\u003e\u003cu\u003esign up\u003c/u\u003e\u003c/a\u003e for our platform today.\u0026nbsp;\u003c/p\u003e\u003cp\u003eStay tuned for updates, and happy coding!\u003c/p\u003e","comment_id":"6765b8c06f63bf0001f1ca72","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Labelbox-code-runner--1-.png","featured":false,"visibility":"public","created_at":"2024-12-20T10:34:40.000-08:00","updated_at":"2025-03-12T12:01:43.000-07:00","published_at":"2024-12-20T12:44:45.000-08:00","custom_excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"65303cb64e99900001fc05a5","name":"Labeling automation","slug":"labeling-automation","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/labeling-automation/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"}],"primary_author":{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/code-runner-secure-scalable-code-execution-for-model-evaluation-2/","excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"how-to-improve-model-performance-with-less-data"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/blog/how-to-improve-model-performance-with-less-data/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:53:42 GMT -->
</html>