<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/inside-the-matrix-a-look-into-the-math-behind-ai/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:46:50 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Inside the matrix: A look into the math behind AI</title><meta name="description" data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Inside the matrix: A look into the math behind AI" data-next-head=""/><meta property="og:description" data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/inside-the-matrix-a-look-into-the-math-behind-ai/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2024/12/Matrices.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Inside the matrix: A look into the math behind AI" data-next-head=""/><meta name="twitter:description" data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/inside-the-matrix-a-look-into-the-math-behind-ai/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2024/12/Matrices.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Michał Jóźwiak<span class="mx-2">•</span>December 11, 2024</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">Inside the matrix: A look into the math behind AI</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2024/12/Matrices.png"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><h2 id="introduction"><strong>Introduction</strong></h2><p>Matrices are omnipresent in math and computer science, both theoretical and applied. They are often used as data structures, such as in graph theory. They are a computational workhorse in many AI fields, such as deep learning, computer vision and natural language processing. Why is that? Why would a rectangular array of numbers, with famously unintuitive multiplication rules, be so prevalent in AI?</p><p>AI methods (with emphasis on machine learning) are all about processing multi-dimensional data. A lot of that processing is done in a linear way - input data points are multiplied by scalars and added together to create output data. While that sounds limiting, a lot can be achieved with just that, for example:</p><ul><li>Linear layers in neural networks (excluding possibly non-linear activations)</li><li>Principal component analysis</li><li>Word embeddings</li><li>Image processing</li></ul><p>This particular kind of processing data has a name in mathematics - linear map, which is a concept from linear algebra. I will formally define it later in this blog. For now it suffices to say that you can represent any linear map as a matrix, and matrix operations are intimately connected to operations on linear maps. This is the main reason why matrices are so ubiquitous in AI.</p><p>While you don't necessarily need to know linear algebra to do machine learning, it is very helpful to have a good intuition for the concepts. This blog is an attempt to demystify matrices and linear algebra surrounding them in a way that strikes a balance between mathematical rigor and intuitive understanding. Contrary to most introductory material on the subject, we won't restrict ourselves to the usual Rn spaces, but I'll still give examples in R2 and R3 for clarity. If you don't know what R<sup>2</sup>, R<sup>3</sup> and R<sup>n</sup> are, don't worry - we'll get to that.</p><p>I will start with formally defining what a matrix is. We will gradually build up to understanding matrix multiplication, and by the end of the article we will have covered all the necessary concepts.</p><h2 id="definition-of-a-matrix"><strong>Definition of a matrix</strong></h2><p>A matrix is a rectangular array of numbers. The numbers are called elements of the matrix. The horizontal lines of elements are called rows, the vertical lines are called columns.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_G7NDTYF5VXkLrCSA5bRJU7n6iW3pSmIh2zr_wIKnE4B0L9ZxC_heoW-d0Q8raR2GySqWwv4DRLQjzJFuklWk6ZUtoO71vhpGvwH_rLMhPyaGg-FEMlka2am4HR5ESk4DYX4DX4ihZoy48ZU9FgzvKGt4170gWoHZA2W-GfM3Rm8OPLuzNX2VOJHwj8vOAOmdBLLqfGtJsLIVn0v929K9bV5OO8NLHc80MbxPLJE6-D2IrE3syCl4uVGuUzmaSQ-dtorzfDSYUImt7gFrDRTvmm5UAyBPrhoPp9cdlszntMKIMR0WxCxy6KMjlggbN5IFkf2zjCrrHJUNiziJjWHeRpazrMFHcoj_E0m-1GTMABpCc60HXXXhLEDl-Qkwd2WIMoX5KdlcKlImogJozvgkBoJjEqDoV3aYJq0CKvFLx6OJTWzlrjtIJKCfcnOy-Oqvwrjmn7-lAXM-XcXGHdqAEqy__gNOv5_OX0FBL0OXhqwzIQBCg5OnBODmzesB814eCkugyt=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="306" height="215"><figcaption><i><em class="italic" style="white-space: pre-wrap;">&nbsp;A real-valued matrix with 2 rows and 3 columns.</em></i></figcaption></figure><p>There are many operations we can perform on matrices, but for the purpose of this article we only need to know three:</p><ul><li><strong>Addition:</strong> Element-wise addition, only matrices of the same dimensions can be added</li><li><strong>Scalar multiplication:</strong> Multiplying each element by a scalar</li><li><strong>Matrix multiplication:</strong> Multiplying two matrices, resulting in a matrix with dimensions equal to the number of rows in the second matrix and number of columns in the first matrix</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_HyUu9-_FOWdy8-NKTEeh23TSznSqaP4tkPAOPJf5baetR2CRvfOG5fUSwsX8nv4QjvS0Cab1uh9GexJtEA-t4IVXt3YUn9w2gsOBBjcnPo6NNxTP1mQfHZy-oHE-pxgauT06sKvfThyTxbCCJr8yZZjqIb2MeNqem-sOtkedunZ1ONaah-5w9cEvFNygBBv1FUAz48BcRIfkZNkrDHYEQBMszo_9HABDN6_WwXrfLE27PHWQksudBcX4Dlx5ghOLWa8Vn1Iz2_MNyRgRBWjB5b9bOoyXAA-57xArm3btL_HCX3LKzB569512GNFaPuAEx4YZTSEHTr20cFokVNjcjq9MiGHdui6LKZhDavi9NxAGKZmv4VuB09fKYeg4p0jM_U_ZOClU3fZ4OW0yPA1aHFYKgt1iJVZ_F4F6mh9GuS4RfnTXLB6dL9zpzvoJjGIEWuUQ9y8vCJHp5r9Kv-WesQEnGSTJqxz7KKlUFiY2JtdmBRWiowMTE9_0GuMXVG8eaub8Ws=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="624" height="257"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Matrix addition and scalar multiplication.</em></i></figcaption></figure><p>The first two operations are pretty straightforward, but matrix multiplication is a bit more complex. There are several algorithms to do it, all resulting in the same end product. </p><p>One of the most common algorithms is this: For element in j-th row and k-th column of the resulting matrix, take the element-wise product of j-th row of the first matrix and k-th column of the second matrix, and sum all the elements of the resulting vector.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_F2_7S90tcQGrRpAOmSr1n8UlTzIKtA-eoi_WNiSn4On_ZYjxwRhIVI445hsPgHa5knG6pizOdUd6gsIIrV-7DnWJgEkB5JODr1tu9W44nIRFeaFfnemWwAo5ZLlMcdf9lJzqQeF_ZjohAKFCzJhGEe3hg3j8BLLqjUEB_zcM7rkOA6W9vx8_VvKNC_pNpo4VM2YzOEPLUiiFnCu3mo2pU67iBkEtNmpVmSvTVaYQHolXGjbEEXigNkVAeITyNtzyEBzujZdmVWW3u5gr1V2ypoSliMBMlsBxpF4syjRRyQYV8ToJTriY13iV2s9S5QsFg0Yh3DdjkSbQjMnsTxofA1eY7wIF4QzhGOop8Pgs0MzNDbneUVIY38qJYrpU1AjY8YFU7vmD42sUOAYO2RoAmQJz9jEYRHsmRRNCIX3zC7s6vmbw9eZ8390KnPHdxiNqMYs2RprbOX5QFW648JIfM8zjHw6SiDBKmBTmk5eErkUBHShUdC8l-fO4mvZGyG4Dfzwtam=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="624" height="155"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Matrix multiplication. To compute the element in the first row and first column of the resulting matrix (10), take the first row of the first matrix (2, 3, 4) and the first column of the second matrix (2, 2, 0), multiply them element-wise and sum the result (2 * 2 + 3 * 2 + 4 * 0 = 10). Note that the resulting matrix has dimensions equal to the number of rows in the first matrix and number of columns in the second matrix.</em></i></figcaption></figure><p>Why is matrix multiplication not simply element-wise (which actually exists and is called Hadamard product)? What is the intuition behind it? To answer that, we need to understand several concepts from linear algebra.</p><h2 id="what-is-a-vector"><strong>What is a vector?</strong></h2><p>A vector has many definitions. Perhaps the most well known is the one from physics: an arrow in space with a direction and a magnitude, usually represented as coordinates in a space.</p><p>If you are a programmer, you might know it as an array-like data structure, that is an ordered collection of elements. Both of these definitions are most likely known to you if you are working with AI systems, in which vectors often play a crucial role, e.g. as features in a dataset or as low-dimensional representations of high-dimensional data (embeddings).</p><p>What interests us here is the mathematical definition: A vector is an element of a vector space. What is a vector space then?</p><p>To avoid spelling the whole mathematical definition here, it suffices to say that a vector space is a set of elements with following properties:</p><ul><li>It is possible to add any two elements and the result is also in the set.</li><li>It is possible to multiply any element by a scalar (a real number) and the result is also in the set.</li><li>There exists an element called zero vector, which is such that adding it to any element does not change the latter.</li></ul><p>These two operations are connected by a distributive property, which states that scalar multiplication of a sum is the sum of scalar multiplications: a * (u + v) = a * u + a * v.</p><p>As you have probably noticed, this is analogous to the operations of addition and multiplication on real numbers. The important thing to note is that the vector space definition does not require the vector by vector multiplication to be defined. It is defined for some vector spaces, but we won't concern ourselves with it in this blog.</p><p>All of that is pretty abstract, so let's consider some examples. Possibly the most well known vector spaces are R<sup>2</sup> and R<sup>3</sup>, which are spaces of vectors with 2 and 3 coordinates respectively. The generalization of those is R<sup>n</sup>, which is a space of vectors with n coordinates. The elements (vectors) of those spaces have a geometric interpretation as arrows or points. Notice how this aligns with the interpretation of vectors as known from physics.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_HQKxpR2kF7wAJTFii8XerpBaHpwh3HY0R9Njh2OWz_4N3HU04PhLGleRHr5C8B_Fd8gwdChOKwQjAWYz3LnLhFkcqkFukJnAgrI9-hrSMwi7lXWcE9nNWZy37UOEIY9DTjLmXi658H-_eUu9gi6_xRHF6u-Gv-ln4GoHUsteF_S6pI2FlHzWxQJriglEyUXo3utZ44iP-GxkEvUzmnbJOHwUXCEhi6ciiu8ElCvi6Kl1Bzc3zsOvIT8f5Ulw0T7p0vpNImCq68Gl7BFkjKHYcHRfThDHHprrcJCPYHB3-OEa9jCo9B2em0sDqUdMXhAjkITzfOMUhhU5a0nv_6a7SCRB_QtZJZFDyFvC4Ri1JNBmOggBeUvMH_ZS6y8bK3AWyTyGvW6FDyxc2Fj-ibRsuZzLLOXM_eW3xYpeuiOuaUPUnwZ0yrca7deWOhqCiCTLPhDuUB4K6OxmJ-Y4bVu7JvOhIcl7o-YiAt1TrRt8eemMzbzoa7CthkTpp_gQa3aCmE5nj9=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="544" height="238"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Images of R</em></i><sup style="white-space: pre-wrap;"><span>2</span></sup><i><em class="italic" style="white-space: pre-wrap;"> and R</em></i><sup style="white-space: pre-wrap;"><span>3</span></sup><i><em class="italic" style="white-space: pre-wrap;">, with some vectors marked. It is common to draw vectors as arrows starting from the origin, but the vector is not defined by its anchor point. Graphically, all vectors with the same length and direction are the same vector.</em></i></figcaption></figure><h2 id="linear-combination-of-vectors-span-and-linear-independence"><strong>Linear combination of vectors, span and linear independence</strong></h2><p>We know that vectors can be added and multiplied by scalars. A linear combination of vectors is a sum of scalar multiples of those vectors. Consider these examples in R<sup>2</sup> and R<sup>3</sup>:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_HuvPtyltTf31_xNKZiu7j1YMlGUWunIQ6Zhj0I1uF4g2bP1-ITlYaizm53E_Uystsw8fqDCE4FK8f0eT1pyJXJVFEoeLOvD686HtGWERMcy5oxKotAuMNYDcg4iNuGPzw7bXGG19-YhnJXgof-xjoyShg6fy2I2Ve4ci3fH9JyGNmJnmVgBVBXNxFM9vU2UrvzkneZ5XssRZqRks9Pvd4z83UZ2ZsgLXLMGZ1Ym51pw2FuuqLhcJ348Tt-oolfY9r-seLxvV7tszvc6uAFqhq80AQO9kbbA5K9FbxbD20wpYM8FaufmVV2TlpEswCT7NdogAQkIEizluvrw9U1cfWBMAsrropstKjHD_Y0VOjPlfwldo_xB6W3wJxc_qAhZEk8bJwyft65m87vlH6GNP4YXWYt61reIOlV-vgIiJ97lVhB6gfKP1Nf6ri_295D2vbe9w4v-GOrktm97LxSSSIh9C-X_p9I_Ue_w0yEqTmy6rBEaM20zSz9-W3HOb4vEjywmdcT=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="505" height="339"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Geometric interpretation of linear combination of two vectors in R</em></i><sup style="white-space: pre-wrap;"><span>2</span></sup><i><em class="italic" style="white-space: pre-wrap;">.</em></i></figcaption></figure><p>A span of a finite set of vectors is a set of all possible linear combinations of those vectors. Geometrically, a span of one vector in R<sup>2</sup> and R<sup>3</sup> is a line through the origin (all scalar multiples of the vector), while a span of two vectors <strong>might be</strong> a plane through the origin (which is the whole space in case of R<sup>2</sup>).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_FAAfzIbjxGS8ORwam_M7gFBz1s-qsCB0G6IqTIqhWnaFhzXXCs9X5yFhZbBXWVrjVCP93iq4pE7wfonhtbMpzg6fcyivJhpQxmZCpQlbNfZ91qz-e9pe5HDAZ5zs25R4BYHvd0tlP3T8Zo8GB51bB1JvOIFVMyc4tnhRD0598fdy-vn6uaIWmcv1PDJwnSKdXdCyFBUgnkULO-UzZIxvHzgKlLJPwWTVAhxP0OfYC0SJ4nShxMg9HG4iPOZvdzzZTyQsaLbEuBkQ2VlPCLBiMhZbmEJH2LaPh7UU6sA93_9FoOJe03raSvpvVBxT_zRengxuU-ClO4H0qDMK6bZqKIPGjbWA_IO4DCqksQro-agNuPRJnEyk4Mph54D4ArXIEOI7KIE6qeRtHvHnTokJge0UOQjLg6sNjJPZ-Mbd0MyHBzIYiTPnyoMmtwGuqas3bWi4PLjffhH5iwiw0plxtjSsyoaPIBiBU62Vj9RsIL8vKRh5OE5lmwJxJRnC6wzEGdpxxx=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="419" height="369"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Geometric interpretation of the span of two vectors in R</em></i><sup style="white-space: pre-wrap;"><span>3</span></sup><i><em class="italic" style="white-space: pre-wrap;">. Their span is a plane through the origin (which is admittedly hard to draw).</em></i></figcaption></figure><p>Why might? Consider two vectors lying on the same line. No matter what scalar coefficients we take for the linear combination, the result will lie on the same line. Their individual spans are identical to the span of the set of those two vectors. We say that those two vectors are <strong>linearly dependent</strong>.</p><p>Let's consider a set of three vectors in R<sup>3</sup>. They can either all lie on the same line, all lie on the same plane, or they can be such that their span is the whole space. In the first two cases, the vectors are linearly dependent, in the last case they are <strong>linearly independent</strong>. Two vectors in R<sup>2</sup> spanning the whole space are also linearly independent.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_Hi4wMLz7I04azyrsn2x-Nxv0JAF5hfXtzaTt79q9WJLFw118fkEUw3fnileqqC7FS_UE22a5Q7a05_sq5mCUlAtoaASzS_1ZqHo30GuGm1Ei4wRqlFI-pC0W-2Bv_Mt44gM-WcyYHU2e3_hzBsaHRcJzggacSPFhRK5D9g7sEeYo8bW2IbWJ8azWVIJomYl-0oWoXe56z-YkprRA6y_iBken_BWFZBoDhmv6Hht2bm7dtDTSnmpjeI7y5J7Ior_3HeEXpKdDmLoghw6iNmLeAMD_mmXGlQ93VVIkegKcgBSbAwZZf0fAHaCPm1ysQXSQY6fQA_pOS0wy17hxa7YxQs1a5pUomDJb7K6-kYbnOBQkxRBJL8RpDTi5x6G3zYKIm9BOTqtvn3egNyGp58yH66O5RUD9HGi4Xot16rkeDrIB0Z9CMJdSwzpLXDJyaSaSiTQnFrT4wJDVQn7fSxvnNOnbBfKDZ2H6W8H5chkcwMgtzV96W4AGR_h2xbjFk9BVhmxbld=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="624" height="256"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Geometric interpretation of spans of linearly dependent vectors in R</em></i><sup style="white-space: pre-wrap;"><span>3</span></sup><i><em class="italic" style="white-space: pre-wrap;">. All three vectors on the second image lie on the same plane (which contains the origin).</em></i></figcaption></figure><p>Rigorously speaking, a set of vectors in vector space is linearly independent if no vector in the set can be written as a linear combination of the other vectors in the set (in other words, it does not lie in the span of the rest of the vectors). Intuitively, vectors are linearly independent if each one of them contributes a unique "direction" to the span.</p><p>Linearly independent vectors have a very important property: each vector in their span can be <strong>uniquely</strong> represented as a linear combination of those vectors.</p><h2 id="basis"><strong>Basis</strong></h2><p>Not all vector spaces can be spanned by a finite set of vectors. For example, the space of all polynomials (which with proper definition of addition and scalar multiplication is valid vector space) is infinite-dimensional, because no matter how many polynomials we have, we can always find a polynomial that has a higher degree than all of them.</p><p>Contrarily, if we can find a finite set of vectors that spans the whole space, we say that the vector space is finite-dimensional. Only these spaces are relevant for the purposes of this blog.</p><p>Every finite-dimensional vector space has a basis. A basis is a set of linearly independent vectors that span the whole space. In R<sup>2</sup>, a basis can consist of two non-collinear vectors. In R<sup>3</sup>, a basis can consist of three vectors that do not lie on the same plane. Note that a basis is not necessarily unique - e.g. in R<sup>n</sup>, we can choose different vectors that will still span the same space and be linearly independent.</p><p>Notice how I stated that a basis in R<sup>2</sup> consists of two vectors, while in R<sup>3</sup> it consists of three vectors. A set of three vectors in R<sup>2</sup> is guaranteed to be linearly dependent, so it cannot be a basis. On the other hand, one vector cannot span R<sup>2</sup>. Likewise, we cannot find four linearly independent vectors in R<sup>3</sup>, but less than three vectors cannot span R<sup>3</sup>.</p><p>Skipping the proof, it is a true statement that every basis of a finite-dimensional vector space has the same number of vectors. This number is called the dimension of the vector space. By this, R<sup>n</sup> has a dimension of n, which plays nicely with our geometric interpretation of R<sup>n</sup> as n-dimensional space.</p><p>For R<sup>n</sup>, we define a standard basis as a set of n vectors, where each vector has exactly one non-zero coordinate, which is 1. For example, in R<sup>3</sup>, the standard basis is {(1, 0, 0), (0, 1, 0), (0, 0, 1)}.</p><p>Why do we care about a basis? Since a basis is a set of linearly independent vectors that span the whole space, any vector in that space can be <strong>uniquely</strong> represented as a linear combination of vectors from the basis. That means that for every finite-dimensional vector space, no matter how abstract or exotic, we can always represent any of its vectors as a list of numbers (coefficients of linear combination of chosen basis).</p><h2 id="linear-maps"><strong>Linear maps</strong></h2><p>Now we are ready to define a linear map. A linear map (sometimes also called linear transformation), defined for vector spaces V and W, is a function that takes a vector from V as an input and returns a vector from W. It must satisfy two properties:</p><ul><li><strong>Additivity:</strong> f(u + v) = f(u) + f(v)</li><li><strong>Homogeneity:</strong> f(a * u) = a * f(u)</li></ul><p>These properties ensure that linear maps preserve the linear structure of vector spaces - parallel vectors remain parallel, and origin remains at the origin.</p><p>While it may seem that linear maps are a very restricted class of functions, they can be used to represent a wide variety of transformations. For example, a linear map in R<sup>2</sup> can be used to represent:</p><ul><li>Rotation</li><li>Scaling</li><li>Reflection</li><li>Shearing</li><li>Any combination of the above</li></ul><p>One operation you cannot represent with a linear map is translation (moving every point by the same vector), since the origin must remain at the origin.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_HALd_AdetvVwttaeoIzTknyZH1OkpVAnWGSV8Uw0nLUi6U7va0I11rNjSzWPByvZ1Qfv3N-KbSV9KV8f0LWNxafg6JWkEP4OYN3Zvcbx-TlkK6y57odCRU-RRj_qTAZ2_N44uSidTzy4PU4lvibtFJ2DNUemv4Pg2CV1GLaUurvCrtHev-p6nhy_CkZxfKzqF9MbsTVHxxItx5l1LakrmT1xXsd-jbB_MGpLZYuiYC_xNRLW6E8N35lvwD8K3tcJeV1g0C2wdYpDyRdN1AWG1WjzI6X3qpLiAvU5eZZZen5zd09NuwfuHZfb96BAZxaVJsKBfN0aKhOJxbYes1lA-WIIz2lLdgh2jDfC1zhS0Lbj37Oe0aTMaYBKW6Ya3j7s-rYaFaXhPNw07UsShG1Z997RYAeZUYhd53tAxJ7i3LaXKiQuPD8nXU1XLWm8k1LdPmnY_aQTGiMB0mkxFZJ4feN6E0PS8nU1HMvikE4G6-Y_8XVWoyXM6nPD1CZJzEVGBHmYPI=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="366" height="318"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Shear operation in R</em></i><sup style="white-space: pre-wrap;"><span>2</span></sup><i><em class="italic" style="white-space: pre-wrap;">.</em></i></figcaption></figure><p>As mentioned in the introduction, they are also extremely prevalent in machine learning, e.g. in neural networks. While I am not going to prove this, the connections (weights) between linear layers are equivalent to linear maps from R<sup>n</sup> to R<sup>m</sup>, where n is the dimension of the input and m is the dimension of the output. Since you can represent these connections as a matrix, it's a hint that <strong>matrices are intimately connected to linear maps</strong>. We'll come back to this later.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_EEwij6O9IeT7iLgVoBqpjpnIL8YCiiY7mS7hZng0mjZjhyHx37016rec9_D-W8VyKiRCKN3qC3qY2gFGVgCp7PpUZ-38Q1aY5GKfP4pkIqfGU1ewtIi1sDAdtBRLO25Cse1IWU98tnd7KJIj9d2bvFay1CRDYbOdtElO216VGmEMjVSABdE76FMeRpRcbL9QMJhpo2ly6mdwzxy5it4RX4V0HYzC8esEERqqLW6_kOE0vtNC5VPoMxh6ICIZ1fs3Vn2LJasM0Dr3s4T9P52SWR-1lO1HVlTFBTh2DdIWZaPiqUlxSudTO_B0LKseaUA3n5BoywAWJCM_NCU2r63L6DvXvAt3spH39GfvArbHFj6aLUAOlYqdCJmc3AdFOx7x51suP5h7M9Jj1wRBDbtkRdOwblis9nBm9C1vjU3btM5XlH4Gih-XlS0YqmKJ6CJz1N2givvDr2oI-AncAf89N6weJ3QOpW2z5Y9G61HnMt-3qG4KDxhlHzdywSWhnV50T2p900=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="178" height="324"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Two fully connected layers in a neural network without activation functions or biases. They are equivalent to a linear map from R</em></i><sup style="white-space: pre-wrap;"><span>5</span></sup><i><em class="italic" style="white-space: pre-wrap;"> to R</em></i><sup style="white-space: pre-wrap;"><span>7</span></sup><i><em class="italic" style="white-space: pre-wrap;"> - each input is a vector in R</em></i><sup style="white-space: pre-wrap;"><span>5</span></sup><i><em class="italic" style="white-space: pre-wrap;">, and each output is a vector in R</em></i><sup style="white-space: pre-wrap;"><span>7</span></sup><i><em class="italic" style="white-space: pre-wrap;">.</em></i></figcaption></figure><p>We can define a set of operations on linear maps (let T and S be linear maps, and c an arbitrary scalar):</p><ul><li><strong>Addition: </strong>(T + S)(v) = T(v) + S(v)</li><li><strong>Scalar multiplication:</strong> (c * T)(v) = c * T(v)</li><li><strong>Composition: </strong>(T * S)(v) = T(S(v))</li></ul><p>A very important property of linear maps is that <strong>a linear map is fully defined by its values on basis vectors</strong>, for a chosen basis of input space. Let's say we have a linear map T and a basis B = {b<sub>1</sub>, b<sub>2</sub>, ..., b<sub>n</sub>} of input space V. For any v in V, we can write v as a linear combination of basis vectors: v = c<sub>1</sub> * b<sub>1</sub> + c<sub>2</sub> * b<sub>2</sub> + ... + c<sub>n</sub> * b<sub>n</sub>. Then T(v) = c<sub>1</sub> * T(b<sub>1</sub>) + c<sub>2</sub> * T(b<sub>2</sub>) + ... + c<sub>n</sub> * T(b<sub>n</sub>). This means that if we know what T does to each vector in the basis, we know what T does to any vector in the space.</p><h2 id="matrix-as-representation-of-linear-map"><strong>Matrix as representation of linear map</strong></h2><p>We know that every linear map T: V -&gt; W (where V has dimension n and W has dimension m) and for a chosen basis Bv = {v<sub>1</sub>, v<sub>2</sub>, ..., v<sub>n</sub>} of V, T is fully defined by values of T(v<sub>1</sub>), T(v<sub>2</sub>), ..., T(v<sub>n</sub>).</p><p>Let's take a closer look at one of those values, say T(v<sub>1</sub>). We know that T(v<sub>1</sub>) is a vector in W, so we can write it as a linear combination of a chosen basis of W: T(v<sub>1</sub>) = d<sub>1</sub> * w<sub>1</sub> + d<sub>2</sub> * w<sub>2</sub> + ... + d<sub>m</sub> * w<sub>m</sub>. We can represent the coefficients of this linear combination as a list of numbers: [d<sub>1</sub>, d<sub>2</sub>, ..., d<sub>m</sub>]. This list is uniquely determined by the linear map T and the chosen basis of V, and it is called the column vector representation of T(v<sub>1</sub>).</p><p>We can do the same for T(v<sub>2</sub>), T(v<sub>3</sub>), and so on, up to T(v<sub>n</sub>). In this way, we can associate with our linear map T a matrix A, where the j-th column is the column vector representation of T(v<sub>j</sub>). This matrix A is called the matrix representation of the linear map T. That is, <strong>a matrix with m rows and n columns can be interpreted as a representation of a linear map from linear space of dimension n to linear space of dimension m</strong>. When representing a linear map with a matrix, choice of bases is important - different bases will yield different matrices. That is why when not clear from the context, we must specify the bases for both the input and output spaces.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_FdRpJDV5zInZqPJgicW-G0_0lh_hsCs8LQnDFZrNruIWrHrpwPjkzPtPnc6jBsrLsgF56KDkP5n6Or0ZTUJgiylXnjA2ET2DU4VumB6nwh5Y9MCsJkwegaD3sCCwpMako7_go4G5YGMTE3_tCBTjz5DhLHKLR9z76SXca_9lCpeJcs0Iv9y9NNfh9-bdEOtuf7JLfPJKr-lT_wSjPmUQxXGoTGKjve40hypXjhVkAxshzRr-3JKnRapDWm3KPN41EVTTQBO9VPCcWS8UkbbICd_jvp4FB8hotryUhptZCxcuFf_7KWqmNbYYVAxTbwxxvLHyukVmBYAZwhAj3oMyKyVrE7cSIBVBmJ1Q6sygvan1-2FYcMZSvVRz2x_Ap5QriKN_GKhm-aovPODuAyO1FNuudAjf2qoIHWJPQYs2fisq0rU4_QuNK_Wo6URPyHQ_SVGo6gzuvVrs-ghcKvjpuBZ2hZ5yHpMzQvksO1MwTM6tZt4AN91w9zhRLaitrQLfzTWflp=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="318" height="242"><figcaption><i><em class="italic" style="white-space: pre-wrap;">A representation of a particular linear map T: V -&gt; W as a matrix. V has dimension 3, while W has dimension 2. Thus, the matrix has 2 rows and 3 columns.</em></i></figcaption></figure><p>It is important to note that such a matrix can be created for any linear map between finite-dimensional vector spaces - it is not limited to R<sup>n</sup>. The common misconception is that the columns or rows of such a matrix are vectors, but in general they are not - they are coefficients of linear combinations. It is a coincidence that in the case of T: R<sup>n</sup> -&gt; R<sup>m</sup> and if we choose the standard basis for R<sup>m</sup>, the columns of the matrix representation are vectors in R<sup>n</sup>.</p><h2 id="matrix-operations-as-operations-on-linear-maps"><strong>Matrix operations as operations on linear maps</strong></h2><p>If matrices represent linear maps, do the matrix operations represent operations on linear maps? It turns out that they do.</p><p>It is easy (albeit a bit tedious) to prove, that if A and B are matrices representing linear maps T and S, then:</p><ul><li>A + B represents the linear map T + S</li><li>c * A represents the linear map c * T</li><li>A * B represents the linear map T * S</li></ul><p>Keep in mind that matrix multiplication is not commutative, i.e. A * B is not necessarily the same as B * A (even if both make sense dimension-wise).</p><ul><li>Matrix addition is only defined for matrices of the same dimensions, which is consistent with the fact that addition of linear maps is only defined for maps between the same spaces.</li><li>Matrix multiplication by scalar is defined for any matrix, which is consistent with the fact that scalar multiplication of linear maps is defined for any linear map.</li><li>Matrix multiplication is defined for any two matrices, provided that the number of columns in the first matrix is the same as the number of rows in the second matrix. This is consistent with the fact that composition of linear maps is only defined for maps where the output space of the first map is the same as the input space of the second map.</li></ul><p>While adding and multiplying by scalar are pretty intuitive operations, matrix multiplication is not that obvious. <strong>It has actually been defined so that composition of linear maps is represented by multiplication of their matrices</strong>, which you are encouraged to verify.</p><p>Aside from linear map composition, matrix multiplication can be used to apply a linear map to a vector. Say we have a linear map T: V -&gt; W represented by matrix A, and a vector v in V. First we need to represent v as a nx1 column matrix. We'll call it Mat(v). Then we can compute A * Mat(v), which will be a vector in W.</p><p>This type of matrix multiplication can be computed as follows, where a<sub>j</sub> is the j-th column of A, while m<sub>1j</sub> is the j-th element of Mat(v): </p><figure class="kg-card kg-image-card"><img src="../../../labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png" class="kg-image" alt="" loading="lazy" width="631" height="199" srcset="https://labelbox.ghost.io/blog/content/images/size/w600/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 600w, https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 631w"></figure><p>Applying T to v can be written as T(v) = c<sub>1</sub> * T(v<sub>1</sub>) + c<sub>2</sub> * T(v<sub>2</sub>) + ... + c<sub>n</sub> * T(v<sub>n</sub>).</p><p>Remembering that a column j of matrix A represents T(v<sub>j</sub>), we can see that multiplying A by Mat(v) is indeed equivalent to applying T to v.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://work.fife.usercontent.google.com/fife/ALs6j_EON1iViFpvXdz_HfDvcRIKkjYF7dKw3NejrD5LiU-UTURAHbS1SZzkZolnW1adIsDlHZyzhg2cG393mMUDo9c_UxLGJm0O26pQsYKHhNIBaaZiJpL6-U9Is9XLaNRBZpyoIT1vNhqcwgLNnptpMasF6F9qHN5waxAX_QPVvcny5288jIwwWYRePKAZ5CaB2ff1ctZWvRWHbm-mb7Y1MOddUOIvrkPyU7-BZZPp9X6WmycP7rwAsLBGMOOR8AxRv42OmdN7idoWREU3O0_5h6ZEzVm1G4b1UEuSCQsgJu2FXprBfLBDs9GOdxKtSgwu2bVLPQi2WsEBqCgmVcynPEarXuEhLoS8q5O6V3l8geXjD32X5Hay74WNPC5Rl7rSKzycsWcAVPHLlOtGFFHJ9QD8mWZkJjQvjeuzZwldYQ9fLREXfbv9RtbbvbKKpiO167BP8zN2cGEuRVqnPCGNUYJ_XgIknrjqyp5cndvhMMDCz-6g_EoC0Bmu3awQA7thvax8Qpr6=s1600?key=ODPo2fm0CLrLSvUFi5qEnIvd" class="kg-image" alt="" loading="lazy" width="624" height="248"><figcaption><i><em class="italic" style="white-space: pre-wrap;">A particular way to perform matrix multiplication when the second operand is a column matrix.</em></i></figcaption></figure><h2 id="conclusion"><strong>Conclusion</strong></h2><p>We have now covered all the necessary concepts from linear algebra to understand matrix multiplication. We have seen that matrices can be interpreted as representations of linear maps, and that matrix operations can be interpreted as operations on linear maps. We have also seen that matrix multiplication is not just an arbitrary operation, but rather a composition of linear maps. While this blog barely scratched the surface of math involved in creating AI systems, hopefully it gave you a good intuition on the subject of linear maps and matrices.</p><p>In conclusion, matrices are a fundamental tool in the AI toolkit, enabling efficient data manipulation and transformation. Whether you're building a simple linear regression model or a complex deep learning architecture, a solid grasp of matrix operations will empower you to create more effective and efficient AI solutions.</p></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index632b.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F03%2FBlog_CustomerStories-1.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Esther Na<span class="mx-2">•</span>March 6, 2025</p></div><a href="../the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">The power of human expertise: Transforming audio and multimodal STEM models with Quantumworks Lab Services</p><p class="text-base max-w-2xl undefined line-clamp-3">In this blog, learn about two AI lab customers who utilized Quantumworks Lab&#x27;s top-tier AI trainers to drive innovation in their audio and multimodal STEM models. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../how-to-generate-industry-specific-data-for-ai-training-with-labelbox/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index49ca.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F02%2FBlog_industry-specific.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>February 25, 2025</p></div><a href="../how-to-generate-industry-specific-data-for-ai-training-with-labelbox/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to generate industry-specific data for AI training with Quantumworks Lab</p><p class="text-base max-w-2xl undefined line-clamp-3">This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index4144.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Dmytro Apollonin<span class="mx-2">•</span>December 20, 2024</p></div><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Code Runner: Secure, scalable code execution for model evaluation</p><p class="text-base max-w-2xl undefined line-clamp-3">Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"inside-the-matrix-a-look-into-the-math-behind-ai","id":"6757cf3acb24830001b1d4b1","uuid":"3ff80ee2-cd3b-4596-9a78-88c340d62032","title":"Inside the matrix: A look into the math behind AI","html":"\u003ch2 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eMatrices are omnipresent in math and computer science, both theoretical and applied. They are often used as data structures, such as in graph theory. They are a computational workhorse in many AI fields, such as deep learning, computer vision and natural language processing. Why is that? Why would a rectangular array of numbers, with famously unintuitive multiplication rules, be so prevalent in AI?\u003c/p\u003e\u003cp\u003eAI methods (with emphasis on machine learning) are all about processing multi-dimensional data. A lot of that processing is done in a linear way - input data points are multiplied by scalars and added together to create output data. While that sounds limiting, a lot can be achieved with just that, for example:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLinear layers in neural networks (excluding possibly non-linear activations)\u003c/li\u003e\u003cli\u003ePrincipal component analysis\u003c/li\u003e\u003cli\u003eWord embeddings\u003c/li\u003e\u003cli\u003eImage processing\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis particular kind of processing data has a name in mathematics - linear map, which is a concept from linear algebra. I will formally define it later in this blog. For now it suffices to say that you can represent any linear map as a matrix, and matrix operations are intimately connected to operations on linear maps. This is the main reason why matrices are so ubiquitous in AI.\u003c/p\u003e\u003cp\u003eWhile you don't necessarily need to know linear algebra to do machine learning, it is very helpful to have a good intuition for the concepts. This blog is an attempt to demystify matrices and linear algebra surrounding them in a way that strikes a balance between mathematical rigor and intuitive understanding. Contrary to most introductory material on the subject, we won't restrict ourselves to the usual Rn spaces, but I'll still give examples in R2 and R3 for clarity. If you don't know what R\u003csup\u003e2\u003c/sup\u003e, R\u003csup\u003e3\u003c/sup\u003e and R\u003csup\u003en\u003c/sup\u003e are, don't worry - we'll get to that.\u003c/p\u003e\u003cp\u003eI will start with formally defining what a matrix is. We will gradually build up to understanding matrix multiplication, and by the end of the article we will have covered all the necessary concepts.\u003c/p\u003e\u003ch2 id=\"definition-of-a-matrix\"\u003e\u003cstrong\u003eDefinition of a matrix\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA matrix is a rectangular array of numbers. The numbers are called elements of the matrix. The horizontal lines of elements are called rows, the vertical lines are called columns.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeE-ZtcxxSEfqHBbKD496nYV8uU8Gh85QW_nlkNA9LBe7PJhOm-N4b6LLx7oDfUFppbj0Mza3dQKv5GezLOb3OL6DyY0Uot0pxn_NU8xBOhUkRPx9AyUPX1eqzltwPcs519ZmAphg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"306\" height=\"215\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e\u0026nbsp;A real-valued matrix with 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThere are many operations we can perform on matrices, but for the purpose of this article we only need to know three:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition:\u003c/strong\u003e Element-wise addition, only matrices of the same dimensions can be added\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e Multiplying each element by a scalar\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMatrix multiplication:\u003c/strong\u003e Multiplying two matrices, resulting in a matrix with dimensions equal to the number of rows in the second matrix and number of columns in the first matrix\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeHPKl6kqvGJrURhsqbjIz4gZ4lEl_ScId7w3a07BTMrr9O1wn30BKljl5ovYAENHIJbqGxa_tnuZk6Qud6OURSD2PnfD-t8azHRkm90mILIkvwE8m3tnw0kSBA9cuHuihQvSms?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"257\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix addition and scalar multiplication.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe first two operations are pretty straightforward, but matrix multiplication is a bit more complex. There are several algorithms to do it, all resulting in the same end product. \u003c/p\u003e\u003cp\u003eOne of the most common algorithms is this: For element in j-th row and k-th column of the resulting matrix, take the element-wise product of j-th row of the first matrix and k-th column of the second matrix, and sum all the elements of the resulting vector.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeR0jhCg2ufM0vZv_Yyp_6PklvhKVGJ_Zft_vzWMWywsN_GYnzEoeOH4McE3p1D4HLojhYrTzysbjYfAgQ2DxqoSwX0Iaxo4XeWN4tHvSBaNLBJgPreIUuPveGDeQcd_zoA9aLF?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"155\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix multiplication. To compute the element in the first row and first column of the resulting matrix (10), take the first row of the first matrix (2, 3, 4) and the first column of the second matrix (2, 2, 0), multiply them element-wise and sum the result (2 * 2 + 3 * 2 + 4 * 0 = 10). Note that the resulting matrix has dimensions equal to the number of rows in the first matrix and number of columns in the second matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy is matrix multiplication not simply element-wise (which actually exists and is called Hadamard product)? What is the intuition behind it? To answer that, we need to understand several concepts from linear algebra.\u003c/p\u003e\u003ch2 id=\"what-is-a-vector\"\u003e\u003cstrong\u003eWhat is a vector?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA vector has many definitions. Perhaps the most well known is the one from physics: an arrow in space with a direction and a magnitude, usually represented as coordinates in a space.\u003c/p\u003e\u003cp\u003eIf you are a programmer, you might know it as an array-like data structure, that is an ordered collection of elements. Both of these definitions are most likely known to you if you are working with AI systems, in which vectors often play a crucial role, e.g. as features in a dataset or as low-dimensional representations of high-dimensional data (embeddings).\u003c/p\u003e\u003cp\u003eWhat interests us here is the mathematical definition: A vector is an element of a vector space. What is a vector space then?\u003c/p\u003e\u003cp\u003eTo avoid spelling the whole mathematical definition here, it suffices to say that a vector space is a set of elements with following properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIt is possible to add any two elements and the result is also in the set.\u003c/li\u003e\u003cli\u003eIt is possible to multiply any element by a scalar (a real number) and the result is also in the set.\u003c/li\u003e\u003cli\u003eThere exists an element called zero vector, which is such that adding it to any element does not change the latter.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese two operations are connected by a distributive property, which states that scalar multiplication of a sum is the sum of scalar multiplications: a * (u + v) = a * u + a * v.\u003c/p\u003e\u003cp\u003eAs you have probably noticed, this is analogous to the operations of addition and multiplication on real numbers. The important thing to note is that the vector space definition does not require the vector by vector multiplication to be defined. It is defined for some vector spaces, but we won't concern ourselves with it in this blog.\u003c/p\u003e\u003cp\u003eAll of that is pretty abstract, so let's consider some examples. Possibly the most well known vector spaces are R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e, which are spaces of vectors with 2 and 3 coordinates respectively. The generalization of those is R\u003csup\u003en\u003c/sup\u003e, which is a space of vectors with n coordinates. The elements (vectors) of those spaces have a geometric interpretation as arrows or points. Notice how this aligns with the interpretation of vectors as known from physics.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXciYwCq1HZTGnHkYJWxNJex6c52A-UpTxDRkM1DbAOj2n-Vx9r5PPFqosNeQ6MjMzmjExEuWL6aDpUHJUKVF70rDWeMtbhdOFoJPjAR66btoxgXO5fCsyRl9vbAsJZiWvsmm568gw?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"544\" height=\"238\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eImages of R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e and R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, with some vectors marked. It is common to draw vectors as arrows starting from the origin, but the vector is not defined by its anchor point. Graphically, all vectors with the same length and direction are the same vector.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"linear-combination-of-vectors-span-and-linear-independence\"\u003e\u003cstrong\u003eLinear combination of vectors, span and linear independence\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that vectors can be added and multiplied by scalars. A linear combination of vectors is a sum of scalar multiples of those vectors. Consider these examples in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e:\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXetIiIpcEGjnii7eRWzOwH3onH7IgJEGl8tkJ42x1IkjQI41rhP_n4hWW5EJLfCzV8e-oLFcfEVvAklY5tcdUDBjTGekkfJsxFDgVhm5VGXrfLRdm5lfQSi0pm90gEGugHW3XQ9Kg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"505\" height=\"339\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of linear combination of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eA span of a finite set of vectors is a set of all possible linear combinations of those vectors. Geometrically, a span of one vector in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e is a line through the origin (all scalar multiples of the vector), while a span of two vectors \u003cstrong\u003emight be\u003c/strong\u003e a plane through the origin (which is the whole space in case of R\u003csup\u003e2\u003c/sup\u003e).\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeS90Xw5U7e8SCrauz6PfboZLkMATSOTsQ8p-ugGkVlC4tiuXekAuTzHV6FYhXZHPHQOSXuiQ_poclCAKdRYm2bXKK_IQdRlI4Po-HHG1pllr_EmFwSaQLXIjQaw86d92NtsnMIdQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"419\" height=\"369\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of the span of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. Their span is a plane through the origin (which is admittedly hard to draw).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy might? Consider two vectors lying on the same line. No matter what scalar coefficients we take for the linear combination, the result will lie on the same line. Their individual spans are identical to the span of the set of those two vectors. We say that those two vectors are \u003cstrong\u003elinearly dependent\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eLet's consider a set of three vectors in R\u003csup\u003e3\u003c/sup\u003e. They can either all lie on the same line, all lie on the same plane, or they can be such that their span is the whole space. In the first two cases, the vectors are linearly dependent, in the last case they are \u003cstrong\u003elinearly independent\u003c/strong\u003e. Two vectors in R\u003csup\u003e2\u003c/sup\u003e spanning the whole space are also linearly independent.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf8_KYv6dtal1uf07fhGwyO7Dq3aBbTydEuW84z2V0WOO-uFZInEdskzS6ztAWm5pvUevcUSSC-0PxpiH5F0X-4iNc4D98z157Vb7nfHcsb-3fE6VtEEu0AQZTN5I37wYxixRmuOQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"256\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of spans of linearly dependent vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. All three vectors on the second image lie on the same plane (which contains the origin).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRigorously speaking, a set of vectors in vector space is linearly independent if no vector in the set can be written as a linear combination of the other vectors in the set (in other words, it does not lie in the span of the rest of the vectors). Intuitively, vectors are linearly independent if each one of them contributes a unique \"direction\" to the span.\u003c/p\u003e\u003cp\u003eLinearly independent vectors have a very important property: each vector in their span can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of those vectors.\u003c/p\u003e\u003ch2 id=\"basis\"\u003e\u003cstrong\u003eBasis\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNot all vector spaces can be spanned by a finite set of vectors. For example, the space of all polynomials (which with proper definition of addition and scalar multiplication is valid vector space) is infinite-dimensional, because no matter how many polynomials we have, we can always find a polynomial that has a higher degree than all of them.\u003c/p\u003e\u003cp\u003eContrarily, if we can find a finite set of vectors that spans the whole space, we say that the vector space is finite-dimensional. Only these spaces are relevant for the purposes of this blog.\u003c/p\u003e\u003cp\u003eEvery finite-dimensional vector space has a basis. A basis is a set of linearly independent vectors that span the whole space. In R\u003csup\u003e2\u003c/sup\u003e, a basis can consist of two non-collinear vectors. In R\u003csup\u003e3\u003c/sup\u003e, a basis can consist of three vectors that do not lie on the same plane. Note that a basis is not necessarily unique - e.g. in R\u003csup\u003en\u003c/sup\u003e, we can choose different vectors that will still span the same space and be linearly independent.\u003c/p\u003e\u003cp\u003eNotice how I stated that a basis in R\u003csup\u003e2\u003c/sup\u003e consists of two vectors, while in R\u003csup\u003e3\u003c/sup\u003e it consists of three vectors. A set of three vectors in R\u003csup\u003e2\u003c/sup\u003e is guaranteed to be linearly dependent, so it cannot be a basis. On the other hand, one vector cannot span R\u003csup\u003e2\u003c/sup\u003e. Likewise, we cannot find four linearly independent vectors in R\u003csup\u003e3\u003c/sup\u003e, but less than three vectors cannot span R\u003csup\u003e3\u003c/sup\u003e.\u003c/p\u003e\u003cp\u003eSkipping the proof, it is a true statement that every basis of a finite-dimensional vector space has the same number of vectors. This number is called the dimension of the vector space. By this, R\u003csup\u003en\u003c/sup\u003e has a dimension of n, which plays nicely with our geometric interpretation of R\u003csup\u003en\u003c/sup\u003e as n-dimensional space.\u003c/p\u003e\u003cp\u003eFor R\u003csup\u003en\u003c/sup\u003e, we define a standard basis as a set of n vectors, where each vector has exactly one non-zero coordinate, which is 1. For example, in R\u003csup\u003e3\u003c/sup\u003e, the standard basis is {(1, 0, 0), (0, 1, 0), (0, 0, 1)}.\u003c/p\u003e\u003cp\u003eWhy do we care about a basis? Since a basis is a set of linearly independent vectors that span the whole space, any vector in that space can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of vectors from the basis. That means that for every finite-dimensional vector space, no matter how abstract or exotic, we can always represent any of its vectors as a list of numbers (coefficients of linear combination of chosen basis).\u003c/p\u003e\u003ch2 id=\"linear-maps\"\u003e\u003cstrong\u003eLinear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow we are ready to define a linear map. A linear map (sometimes also called linear transformation), defined for vector spaces V and W, is a function that takes a vector from V as an input and returns a vector from W. It must satisfy two properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAdditivity:\u003c/strong\u003e f(u + v) = f(u) + f(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHomogeneity:\u003c/strong\u003e f(a * u) = a * f(u)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese properties ensure that linear maps preserve the linear structure of vector spaces - parallel vectors remain parallel, and origin remains at the origin.\u003c/p\u003e\u003cp\u003eWhile it may seem that linear maps are a very restricted class of functions, they can be used to represent a wide variety of transformations. For example, a linear map in R\u003csup\u003e2\u003c/sup\u003e can be used to represent:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRotation\u003c/li\u003e\u003cli\u003eScaling\u003c/li\u003e\u003cli\u003eReflection\u003c/li\u003e\u003cli\u003eShearing\u003c/li\u003e\u003cli\u003eAny combination of the above\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOne operation you cannot represent with a linear map is translation (moving every point by the same vector), since the origin must remain at the origin.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfcM7o_gKJk2c7hx0wjIEoZmu2OHveEQvO065rsVLYH5Ca5-v_vyWj9OGREyFacWuopomsh0gm9WLDkvOewl5S8JPJmeq1TRQwQrRab4klX2oJT-Tg0fqJ6rkBA3B6zps5tNFLIbg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"366\" height=\"318\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eShear operation in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAs mentioned in the introduction, they are also extremely prevalent in machine learning, e.g. in neural networks. While I am not going to prove this, the connections (weights) between linear layers are equivalent to linear maps from R\u003csup\u003en\u003c/sup\u003e to R\u003csup\u003em\u003c/sup\u003e, where n is the dimension of the input and m is the dimension of the output. Since you can represent these connections as a matrix, it's a hint that \u003cstrong\u003ematrices are intimately connected to linear maps\u003c/strong\u003e. We'll come back to this later.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeCp-3F2w7zsnKxYYjLu9Kp02nGlruiHhAbHii9zsGLP8xUvIQjpe9LIjxCrrV8nW5kaLXPYl7iwYc8hXUtfjOBnTS8sDwn-nWbgXz_DsQIN7UjOHG4rlRcGLoD5AOy5DVCrQD9uA?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"178\" height=\"324\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eTwo fully connected layers in a neural network without activation functions or biases. They are equivalent to a linear map from R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e to R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e - each input is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, and each output is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWe can define a set of operations on linear maps (let T and S be linear maps, and c an arbitrary scalar):\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition: \u003c/strong\u003e(T + S)(v) = T(v) + S(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e (c * T)(v) = c * T(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eComposition: \u003c/strong\u003e(T * S)(v) = T(S(v))\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA very important property of linear maps is that \u003cstrong\u003ea linear map is fully defined by its values on basis vectors\u003c/strong\u003e, for a chosen basis of input space. Let's say we have a linear map T and a basis B = {b\u003csub\u003e1\u003c/sub\u003e, b\u003csub\u003e2\u003c/sub\u003e, ..., b\u003csub\u003en\u003c/sub\u003e} of input space V. For any v in V, we can write v as a linear combination of basis vectors: v = c\u003csub\u003e1\u003c/sub\u003e * b\u003csub\u003e1\u003c/sub\u003e + c\u003csub\u003e2\u003c/sub\u003e * b\u003csub\u003e2\u003c/sub\u003e + ... + c\u003csub\u003en\u003c/sub\u003e * b\u003csub\u003en\u003c/sub\u003e. Then T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(b\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(b\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(b\u003csub\u003en\u003c/sub\u003e). This means that if we know what T does to each vector in the basis, we know what T does to any vector in the space.\u003c/p\u003e\u003ch2 id=\"matrix-as-representation-of-linear-map\"\u003e\u003cstrong\u003eMatrix as representation of linear map\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that every linear map T: V -\u0026gt; W (where V has dimension n and W has dimension m) and for a chosen basis Bv = {v\u003csub\u003e1\u003c/sub\u003e, v\u003csub\u003e2\u003c/sub\u003e, ..., v\u003csub\u003en\u003c/sub\u003e} of V, T is fully defined by values of T(v\u003csub\u003e1\u003c/sub\u003e), T(v\u003csub\u003e2\u003c/sub\u003e), ..., T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eLet's take a closer look at one of those values, say T(v\u003csub\u003e1\u003c/sub\u003e). We know that T(v\u003csub\u003e1\u003c/sub\u003e) is a vector in W, so we can write it as a linear combination of a chosen basis of W: T(v\u003csub\u003e1\u003c/sub\u003e) = d\u003csub\u003e1\u003c/sub\u003e * w\u003csub\u003e1\u003c/sub\u003e + d\u003csub\u003e2\u003c/sub\u003e * w\u003csub\u003e2\u003c/sub\u003e + ... + d\u003csub\u003em\u003c/sub\u003e * w\u003csub\u003em\u003c/sub\u003e. We can represent the coefficients of this linear combination as a list of numbers: [d\u003csub\u003e1\u003c/sub\u003e, d\u003csub\u003e2\u003c/sub\u003e, ..., d\u003csub\u003em\u003c/sub\u003e]. This list is uniquely determined by the linear map T and the chosen basis of V, and it is called the column vector representation of T(v\u003csub\u003e1\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eWe can do the same for T(v\u003csub\u003e2\u003c/sub\u003e), T(v\u003csub\u003e3\u003c/sub\u003e), and so on, up to T(v\u003csub\u003en\u003c/sub\u003e). In this way, we can associate with our linear map T a matrix A, where the j-th column is the column vector representation of T(v\u003csub\u003ej\u003c/sub\u003e). This matrix A is called the matrix representation of the linear map T. That is, \u003cstrong\u003ea matrix with m rows and n columns can be interpreted as a representation of a linear map from linear space of dimension n to linear space of dimension m\u003c/strong\u003e. When representing a linear map with a matrix, choice of bases is important - different bases will yield different matrices. That is why when not clear from the context, we must specify the bases for both the input and output spaces.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe36MNl-rRXhG4KwL8YAyQToQLcJq13rDEanIpgYDVG9ge7XCFf-IEVdHSvJdKPzMLQV_H4xzGzERyFyurj_kIzXuZqY0RQpAt9wri3SCB2oYnRHMcnTlJnFqULPTq_4gjZMakp_g?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"318\" height=\"242\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA representation of a particular linear map T: V -\u0026gt; W as a matrix. V has dimension 3, while W has dimension 2. Thus, the matrix has 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIt is important to note that such a matrix can be created for any linear map between finite-dimensional vector spaces - it is not limited to R\u003csup\u003en\u003c/sup\u003e. The common misconception is that the columns or rows of such a matrix are vectors, but in general they are not - they are coefficients of linear combinations. It is a coincidence that in the case of T: R\u003csup\u003en\u003c/sup\u003e -\u0026gt; R\u003csup\u003em\u003c/sup\u003e and if we choose the standard basis for R\u003csup\u003em\u003c/sup\u003e, the columns of the matrix representation are vectors in R\u003csup\u003en\u003c/sup\u003e.\u003c/p\u003e\u003ch2 id=\"matrix-operations-as-operations-on-linear-maps\"\u003e\u003cstrong\u003eMatrix operations as operations on linear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eIf matrices represent linear maps, do the matrix operations represent operations on linear maps? It turns out that they do.\u003c/p\u003e\u003cp\u003eIt is easy (albeit a bit tedious) to prove, that if A and B are matrices representing linear maps T and S, then:\u003c/p\u003e\u003cul\u003e\u003cli\u003eA + B represents the linear map T + S\u003c/li\u003e\u003cli\u003ec * A represents the linear map c * T\u003c/li\u003e\u003cli\u003eA * B represents the linear map T * S\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eKeep in mind that matrix multiplication is not commutative, i.e. A * B is not necessarily the same as B * A (even if both make sense dimension-wise).\u003c/p\u003e\u003cul\u003e\u003cli\u003eMatrix addition is only defined for matrices of the same dimensions, which is consistent with the fact that addition of linear maps is only defined for maps between the same spaces.\u003c/li\u003e\u003cli\u003eMatrix multiplication by scalar is defined for any matrix, which is consistent with the fact that scalar multiplication of linear maps is defined for any linear map.\u003c/li\u003e\u003cli\u003eMatrix multiplication is defined for any two matrices, provided that the number of columns in the first matrix is the same as the number of rows in the second matrix. This is consistent with the fact that composition of linear maps is only defined for maps where the output space of the first map is the same as the input space of the second map.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhile adding and multiplying by scalar are pretty intuitive operations, matrix multiplication is not that obvious. \u003cstrong\u003eIt has actually been defined so that composition of linear maps is represented by multiplication of their matrices\u003c/strong\u003e, which you are encouraged to verify.\u003c/p\u003e\u003cp\u003eAside from linear map composition, matrix multiplication can be used to apply a linear map to a vector. Say we have a linear map T: V -\u0026gt; W represented by matrix A, and a vector v in V. First we need to represent v as a nx1 column matrix. We'll call it Mat(v). Then we can compute A * Mat(v), which will be a vector in W.\u003c/p\u003e\u003cp\u003eThis type of matrix multiplication can be computed as follows, where a\u003csub\u003ej\u003c/sub\u003e is the j-th column of A, while m\u003csub\u003e1j\u003c/sub\u003e is the j-th element of Mat(v): \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"631\" height=\"199\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 600w, https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 631w\"\u003e\u003c/figure\u003e\u003cp\u003eApplying T to v can be written as T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(v\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(v\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eRemembering that a column j of matrix A represents T(v\u003csub\u003ej\u003c/sub\u003e), we can see that multiplying A by Mat(v) is indeed equivalent to applying T to v.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXevqSOQivzWeKcTeOPhUmNT4z0psVVGyrYtls1oLPQGJQnCcVW8QlGLQuM2-iS5fNegBS3CtgeAQ9PKokTe3FmxOHAnoui6DdLwTr7eUN0NPFP9qafWCA5-a1Qo18nur2ApU4g_?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"248\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA particular way to perform matrix multiplication when the second operand is a column matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe have now covered all the necessary concepts from linear algebra to understand matrix multiplication. We have seen that matrices can be interpreted as representations of linear maps, and that matrix operations can be interpreted as operations on linear maps. We have also seen that matrix multiplication is not just an arbitrary operation, but rather a composition of linear maps. While this blog barely scratched the surface of math involved in creating AI systems, hopefully it gave you a good intuition on the subject of linear maps and matrices.\u003c/p\u003e\u003cp\u003eIn conclusion, matrices are a fundamental tool in the AI toolkit, enabling efficient data manipulation and transformation. Whether you're building a simple linear regression model or a complex deep learning architecture, a solid grasp of matrix operations will empower you to create more effective and efficient AI solutions.\u003c/p\u003e","comment_id":"6757cf3acb24830001b1d4b1","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Matrices.png","featured":false,"visibility":"public","created_at":"2024-12-09T21:18:50.000-08:00","updated_at":"2025-03-12T11:59:32.000-07:00","published_at":"2024-12-11T10:38:57.000-08:00","custom_excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"}],"authors":[{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"}],"primary_author":{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/inside-the-matrix-a-look-into-the-math-behind-ai/","excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"recommended":[{"id":"67ca1d6cb890cf0001e11bef","uuid":"16aa9964-ac17-468a-bef9-f6dddf71c1a7","title":"The power of human expertise: Transforming audio and multimodal STEM models with Quantumworks Lab Services","slug":"the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services","html":"\u003cp\u003eLeading frontier AI builders leverage domain-and language-specific expertise to differentiate their models across data modalities—including audio, multimodal, image, text, and video—and to train them for more complex tasks. As the capabilities of AI expands, the need for post-training processes like SFT, RLHF, and human evaluation remain strong. These tasks depend on expert human knowledge to guide models toward higher performance.This is where we come in. Quantumworks Lab is the AI data factory that delivers high-quality data across all modalities, including specialized domains like STEM, finance, coding, and law—across a wide range of languages for each.\u0026nbsp; \u003c/p\u003e\u003cp\u003eWith \u003ca href=\"https://labelbox.com/services/labeling/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox Labeling Services\u003c/u\u003e\u003c/a\u003e, we harness our skilled talent network, \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr\u003c/u\u003e\u003c/a\u003e, to source, vet, and onboard custom teams of human experts who can align models and generate new training data with domain-specific knowledge. Quantumworks Lab can operate and fully-manage a project with Alignerrs and the Quantumworks Lab Platform that generates new training data for our customers, or through \u003ca href=\"https://labelbox.com/services/alignerr-connect/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr Connect\u003c/u\u003e\u003c/a\u003e, customers can browse and select top-tier experts to staff their existing projects and utilize their in-house tools and processes. In this blog, we highlight two recent customers who utilized our top-tier human experts to drive innovation in their cutting-edge audio and multimodal STEM models.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"driving-breakthroughs-in-the-ai-audio-landscape\"\u003eDriving breakthroughs in the AI audio landscape\u0026nbsp;\u003c/h2\u003e\u003cp\u003eA growing AI audio startup aimed to enhance its voice, speech, and sound models by training with expert-labeled data. They faced challenges due to the subjectivity of labeling large volumes of complex audio. Quantumworks Lab addressed this through our platform’s custom audio editor and building a team of trainers with expertise in voice acting and speech. Their background enabled them to label nuanced audio segments with greater accuracy than generalists.\u003c/p\u003e\u003cp\u003eOne of the Alignerrs on the project, Jeff K., has a PhD in Theater and Performance Studies. He shared this about his experience on the project:\u003c/p\u003e\u003cp\u003e\u003cem\u003e“Through years of performing and teaching the arts, I've developed a deep understanding of voice dynamics. I have mental checklists for how and where voices change, which makes it natural for me to identify the various emotions in speech and understand their impact on the listener.\" \u003c/em\u003e\u003cbr\u003e\u003cbr\u003eThis specialized level of human expertise was critical in enabling the startup to create high-quality audio datasets and enhance their AI models, driving the adoption of their advanced audio technology. \u003cbr\u003e\u003cbr\u003eWant to explore the full story behind this success? Read more \u003ca href=\"https://labelbox.com/customers/cutting-edge-audio-models-customer-story/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"improving-multimodal-reasoning-capabilities-with-stem-experts\"\u003eImproving multimodal reasoning capabilities with STEM experts\u003c/h2\u003e\u003cp\u003eA leading AI lab aimed to enhance its large language model (LLM) by identifying weaknesses in K-12 STEM education responses, but they needed a diverse team of STEM experts to create new training data.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox’s Labeling Services brought together a team of highly skilled experts with PhDs and Masters in STEM, who were tasked with reviewing multimodal prompts and responses spanning various domains, including natural science, physics, earth science, and language comprehension. Each task included reviewing the model’s response to a question that contained metadata such as question format, subject category, and an associated image URL.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe AI trainers then had to rate the answers across a number of different areas, including examining the model’s ability to read text, analyze image, and respond correctly. This collaboration helped the lab pinpoint areas for improvement and boost performance with high-quality, domain-specific STEM data.\u003c/p\u003e\u003cp\u003eIf you are interested in learning more about this work, read more \u003ca href=\"https://labelbox.com/customers/multimodal-STEM-customer-story/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"looking-to-leverage-labelbox%E2%80%99s-expert-ai-trainers\"\u003eLooking to leverage Quantumworks Lab’s expert AI trainers?\u003c/h2\u003e\u003cp\u003eThese two customer stories highlight a few examples of the groundbreaking work Quantumworks Lab is performing with frontier model builders.\u0026nbsp;\u003c/p\u003e\u003cp\u003eIf you’d like to learn more about the expert teams we offer and are ready to discuss your data needs, \u003ca href=\"https://labelbox.com/sales/?ref=labelbox.ghost.io\"\u003e\u003cu\u003econtact our team\u003c/u\u003e\u003c/a\u003e anytime on how we can help. You can also directly explore profiles of some of our AI trainers \u003ca href=\"https://labelbox.com/services/alignerr-connect/trainers/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e","comment_id":"67ca1d6cb890cf0001e11bef","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/03/Blog_CustomerStories-1.png","featured":false,"visibility":"public","created_at":"2025-03-06T14:10:52.000-08:00","updated_at":"2025-03-31T14:44:29.000-07:00","published_at":"2025-03-06T14:19:30.000-08:00","custom_excerpt":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"671a9e7504d48b00016d39a3","name":"Esther Na","slug":"esther","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/esther/"}],"tags":[{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"66e9be59d0584c0001886b42","name":"Services","slug":"services","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/services/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"670018ec863cb90001f263e9","name":"Customers","slug":"customers","description":"Quantumworks Lab customer stories","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/customers/"}],"primary_author":{"id":"671a9e7504d48b00016d39a3","name":"Esther Na","slug":"esther","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/esther/"},"primary_tag":{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},"url":"https://labelbox.ghost.io/blog/the-power-of-human-expertise-transforming-audio-and-multimodal-stem-models-with-labelbox-services/","excerpt":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","reading_time":3,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Customers transform audio and multimodal AI with Quantumworks Lab Services","meta_description":"In this blog, learn about two AI lab customers who utilized Quantumworks Lab's top-tier AI trainers to drive innovation in their audio and multimodal STEM models. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"67bd005c3d2f94000130cf29","uuid":"3f09970f-5674-4723-9240-ac8ba605d717","title":"How to generate industry-specific data for AI training with Quantumworks Lab","slug":"how-to-generate-industry-specific-data-for-ai-training-with-labelbox","html":"\u003cp\u003eGenerative AI models are becoming increasingly sophisticated thanks to advances in post-training and model alignment tasks. As a result, the demand for models that not only understand language but also grasp the nuances of specific industries is skyrocketing.\u003c/p\u003e\u003cp\u003eWhile general-purpose large language models (LLMs) have made significant strides, they often fall short when faced with tasks requiring deep domain expertise. Many industries require AI systems capable of industry-specific reasoning that can navigate complex, domain-specific scenarios with expert-level understanding.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe journey to creating AI that truly \"gets\" a particular field goes beyond simply feeding it more data. It requires a targeted approach that focuses on enhancing the model's ability to understand and apply the unique language, concepts, and problem-solving frameworks inherent to a particular field. This is where industry-specific reasoning comes in, and it is the key to unlocking the true potential of AI across sectors like finance, law, medicine, and insurance. By building and using higher quality training data, companies are creating a competitive advantage and opening the door to new opportunities.\u003c/p\u003e\u003cp\u003eThis guide will walk you through the process of generating domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. We'll explore real-world examples in finance and law, delve into the intricacies of creating post-training datasets, and provide a step-by-step walkthrough of creating a project in the Quantumworks Lab platform. We will also discuss the importance of selecting the right AI trainers and crafting clear instructions and ontology.\u0026nbsp;\u003c/p\u003e\u003cp\u003eBy the end of this guide, you'll be equipped with the knowledge and tools to embark on your own journey toward creating powerful training data to help you build AI models that are not just intelligent, but industry-smart.\u003c/p\u003e\u003ch2 id=\"examples-of-how-industry-specific-reasoning-is-becoming-a-reality\"\u003eExamples of how industry-specific reasoning is becoming a reality\u003c/h2\u003e\u003cp\u003eThe power of industry-specific reasoning in AI is not merely theoretical; it's being realized today by forward-thinking companies leveraging advanced tools and expert human insights. Before explaining how to use the Quantumworks Lab platform to build a dataset for training models on industry-specific reasons, let's examine two real-world examples where Quantumworks Lab has helped clients in the finance and legal sectors expand the capabilities of foundational models.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThese examples showcase how targeted data labeling, guided by domain experts, can enhance an LLM's ability to support different industries. And while each example discusses a specific industry’s use case, we’ll later see how the process and usage of Quantumworks Lab can be extended to a much broader range of domains and uses, paving the way for a deeper dive into the practical steps involved in creating your own successful projects.\u003c/p\u003e\u003ch4 id=\"finance-training-models-on-financial-analysis\"\u003e\u003cstrong\u003eFinance: Training models on financial analysis\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA leading AI lab wanted to improve their LLM’s performance in financial analysis and argumentation. They hoped to train the LLM to provide meaningful insights on any public company when provided a ticker symbol and the latest financial reports of a company. In addition, they wanted the model trained and prepared to answer the most common questions financial analyst might ask.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo reach this level of financial expertise, they needed training on detailed, domain-specific datasets that were accurately labeled by a team of Chartered Financial Analysts (CFAs) and financial experts. The CFAs needed to have advanced industry knowledge and experience reviewing and analyzing financial models and details.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, they faced two major challenges: (1) sourcing financial experts who could accurately evaluate and rank responses through multi-step analyses, and (2) managing a complex process where each piece of data could take an hour or more to properly analyze and fully label.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe company turned to Quantumworks Lab to help source experts with financial expertise. Quantumworks Lab leveraged their Alignerr network of expert human labelers to quickly recruit and onboard a skilled team of financial experts with backgrounds in CFA, MBA, and Masters in Finance. The team built a customized project consisting of a complex ontology, detailed instructions, and numerous attachments per dataset to review and prepare hypothetical questions and scenarios around.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"legal-automating-case-evaluation-and-data-discovery\"\u003e\u003cstrong\u003eLegal: Automating case evaluation and data discovery\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA forward-thinking legal tech company wants to revolutionize how plaintiff firms operate. By using AI-driven tools with industry-specific reasoning, they want to significantly enhance their ability to evaluate cases, analyze key facts and claims, and ultimately deliver results for their clients more efficiently and transparently.\u003c/p\u003e\u003cp\u003eTo achieve this, they needed to imbue their foundational AI model with deep legal expertise, particularly in understanding long legal documents, interpreting insurance and medical bills, and assessing case value.\u003c/p\u003e\u003cp\u003eThe company partnered with Quantumworks Lab to create specialized datasets for post-training their model. Quantumworks Lab's network of legal experts reviewed a long list of example prompts that were each associated with many multi-page legal documents. They were tasked with identifying key information based on the prompt, crafting well-reasoned responses supported by evidence found in the documents, and evaluating the models responses for accuracy, safety, and reasoning. They were also used to build a dataset based on understanding insurance and medical billing details and learning how to extra the correct details.\u003c/p\u003e\u003cp\u003eSimilar to the finance example above, this project involved creating a custom ontology and using the flexibility of the Quantumworks Lab text editor to generate responses to sample prompts from industry experts, identify key data in attached documents, and use their own expertise to properly interpret complex documents.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"importance-of-high-quality-training-datasets\"\u003eImportance of high-quality training datasets\u0026nbsp;\u003c/h2\u003e\u003cp\u003eThe above finance and legal examples, while distinct in their domain-specific challenges, underscore a fundamental truth about building industry-specific reasoning into AI: the underlying approach remains consistent across industries, whether it's finance, medicine, insurance, or any other specialized field.\u0026nbsp;\u003c/p\u003e\u003cp\u003eAt its core, the process revolves around creating unique and differentiated datasets that capture the specific nuances, knowledge, and reasoning patterns of the target domain. These datasets serve as the bedrock for training models to perform the desired capabilities, enabling them to go beyond general understanding and develop true expertise.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"strategies-to-remember-when-planning-your-project\"\u003e\u003cstrong\u003eStrategies to remember when planning your project\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eBefore kicking off a project or starting the process of building a post-training dataset for industry-specific reasoning, organizations should take the time to think through the following steps:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIdentifying key domain-specific competencies required\u003c/li\u003e\u003cli\u003eDefining clear evaluation criteria for expert knowledge\u003c/li\u003e\u003cli\u003eGathering supporting documentation and examples to attach to the project\u003c/li\u003e\u003cli\u003eWriting hypothetical scenarios and questions you want the model to answer\u003c/li\u003e\u003cli\u003eEstablishing metrics for measuring improvement in domain understanding\u003c/li\u003e\u003cli\u003eSetting realistic scope and scale for the training dataset\u003c/li\u003e\u003cli\u003ePreparing a model evaluation process for side-by-side comparisons\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis list may be shortened by some users and for others there may be other key considerations to add; however, we’ve learned that the most successful projects involve advanced planning and often a fair amount of preparation to gather necessary documents, built prompt examples, and think through the key scenarios that require examples and labeled data to sufficiently train the model.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"selecting-the-right-ai-trainers\"\u003e\u003cstrong\u003eSelecting the right AI trainers\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe next big AI breakthroughs will be fueled by unique, high-quality data. The massive quantity of available data from the internet has been used to train all of the most popular AI models—meaning they all have similar core capabilities and areas of weakness.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo properly train these models on new domain-specific knowledge and reasoning it’s imperative that we tap into new information and capture data from domain experts. As a result, the focus must be on properly identifying and recruiting AI trainers with unique skills—like the \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr network\u003c/u\u003e\u003c/a\u003e of highly educated industry experts—to label data, generate new responses, evaluate models, and perform critical model post-training alignment tasks.\u003c/p\u003e\u003cp\u003eBased on our experience from leading the Alignerr network and working with AI labs and model builders to form teams of experts, it’s important to keep the following in mind:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDomain expertise:\u003c/strong\u003e Look for annotators with relevant qualifications, certifications, and experience in the target industry (e.g., CFA, JD, MD).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAnalytical skills:\u003c/strong\u003e Choose individuals who can demonstrate strong analytical and reasoning abilities.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAttention to detail:\u003c/strong\u003e Ensure the annotators are meticulous and capable of identifying subtle nuances in the data.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCommunication skills:\u003c/strong\u003e Select annotators who can clearly articulate their reasoning and provide constructive feedback.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePrevious success metrics:\u003c/strong\u003e For annotators that have worked on AI training before and used a complete AI platform, then you should be able to review past performance metrics to assist in the evaluations.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAI interviews: \u003c/strong\u003eAbilities can only be determined so much by reviewing resumes and profiles, so using interviews tailored to their specific background provides the most powerful data.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"key-labelbox-features-for-generating-industry-specific-training-data\"\u003eKey Quantumworks Lab features for generating industry-specific training data\u003c/h2\u003e\u003cp\u003eHaving outlined strategic considerations to review before starting a project as well as the keys to selecting the right domain experts, the next crucial step is understanding how to operationalize this process efficiently and effectively. This is where a robust and versatile platform like Quantumworks Lab becomes indispensable.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox Platform is an industry-leading software tool with the flexibility and advanced features needed to translate your vision into a concrete, well-structured labeling project tailored for industry-specific reasoning.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFrom selecting the appropriate editor—often the flexible text editor for tasks involving complex analysis and document reviews—to building a comprehensive ontology with a mix of selection tools and free-form text inputs, Quantumworks Lab can capture the nuances of your target domain. In addition, the built-in quality assurance and project management capabilities ensure that your project stays on track, maintains high accuracy, and ultimately delivers a dataset that enhances your AI model's performance.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLet's briefly explore the key components of the Quantumworks Lab platform that we see used most often in industry-specific reasoning tasks and discuss how they can be leveraged to build the foundation for your industry-specific AI.\u003c/p\u003e\u003ch4 id=\"data-types-editors\"\u003e\u003cstrong\u003eData types \u0026amp; editors\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox supports a range of data types, including text, video, image, audio, PDFs, multimodal, and more. For each data type, a customized editor exists to serve as the core interface for labeling that specific data type. While tailored to specific datatypes, the editors are extremely flexible and can be customized to help label and capture the specific data needed for a given industry.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor most industry-specific reasoning projects, we have seen the core \u003ca href=\"https://docs.labelbox.com/docs/text-editor?ref=labelbox.ghost.io\"\u003e\u003cu\u003etext editor\u003c/u\u003e\u003c/a\u003e serve as the key editor. It was the editor used in both the finance and legal examples shared earlier. The editor supports these annotation types: entity, relationships, radio classification, checklist classification, and free-form text classification. The latter is often used to capture detailed information and sample responses from domain experts on a given prompt or to provide detailed information on specific information found or extracted from an attached document.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"ontology\"\u003e\u003cstrong\u003eOntology\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe \u003ca href=\"https://docs.labelbox.com/docs/labelbox-ontology?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox ontology\u003c/u\u003e\u003c/a\u003e defines the structure and categories for labeling data. Ontologies can be reused across different projects and they are required for data labeling, model training, and evaluation. When you are in the editor, the ontology appears in the Tools panel.\u003c/p\u003e\u003cp\u003eOntologies can be customized for any given project and supports classifications, object detection, segmentation, relationships, messaging ranking, prompt rating, step-by-step rating, and more. The available ontology tasks will vary based on the selected editor and data type.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOntologies also allow for hierarchical relationships between classes, allowing you to create complex labeling tasks with detailed information.\u0026nbsp;\u003c/p\u003e\u003ch4 id=\"quality-assurance\"\u003e\u003cstrong\u003eQuality assurance\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox offers a suite of quality assurance features to deliver high-quality labeled data, which is particularly crucial when dealing with complex, industry-specific reasoning tasks. Consensus allows you to measure the agreement between multiple labelers on the same data point, providing a statistical measure of confidence in the assigned labels. Benchmarks enable you to incorporate known ground-truth data into your project, allowing you to directly assess labeler accuracy against established standards.\u0026nbsp;\u003c/p\u003e\u003cp\u003eCalibration tools help identify and correct for systematic biases that individual labelers might exhibit, further refining the consistency of your dataset. Moreover, Quantumworks Lab Monitor provides real-time insights into your labeling operations, allowing you to track key metrics, identify trends, and quickly spot any outliers in labeler performance. With Monitor, you can proactively address issues and make adjustments as needed, ensuring that your project stays on course.\u003c/p\u003e\u003ch4 id=\"project-management\"\u003e\u003cstrong\u003eProject management\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eLabelbox provides robust project management tools to manage and track your industry-specific reasoning projects from start to finish. Unlike many labeling services and solutions, the Quantumworks Lab platform offers transparency into project progress, allowing you to monitor the status of individual tasks, track labeler performance, and gain a clear overview of the entire project's health. Real-time communication features enable seamless interaction with your team of expert labelers, facilitating quick clarification of instructions, addressing questions, and providing feedback directly within the platform.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox also allows you to build customized workflows tailored to your specific review and quality control processes, ensuring that each piece of data undergoes the appropriate level of scrutiny before being incorporated into your training set. Furthermore, robust data versioning capabilities provide a comprehensive history of all changes made to your data and ontology, allowing for easy rollback if needed and providing a clear audit trail for maintaining data integrity.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"creating-an-industry-specific-reasoning-project-in-labelbox\"\u003eCreating an industry-specific reasoning project in Quantumworks Lab\u003c/h2\u003e\u003cp\u003eHaving explored the core features of the Quantumworks Lab platform, let’s examine the key steps to creating and executing on a project to generate new data for training your AI models and apps on industry-specific reasoning.\u003c/p\u003e\u003cp\u003eThis section provides a practical roadmap, walking you through each stage of the process, from crafting clear and comprehensive instructions for your expert labelers to setting up your project within the Quantumworks Lab environment, configuring the ideal ontology, managing the labeling operation, and conducting thorough reviews to ensure the highest level of data quality.\u0026nbsp;\u003c/p\u003e\u003cp\u003eUsing these steps as a framework for your project, you can start exploring how the Quantumworks Lab Platform can be used for your unique project. You’ll learn what it takes to build a new training dataset for your specific needs. \u003c/p\u003e\u003ch4 id=\"1-identify-desired-outcomes-and-goals\"\u003e\u003cstrong\u003e1. Identify desired outcomes and goals\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eBefore diving into the mechanics of using Quantumworks Lab, it's crucial to establish a clear understanding of your project's objectives. Training frontier models for industry-specific reasoning requires a well-defined target. What specific problem are you trying to solve? What capabilities do you want your model to possess? Answering these questions will guide your data collection and annotation strategy, ultimately determining the success of your project. For example, are you aiming to build a model that can summarize legal documents, predict financial market trends, or diagnose medical conditions? Each of these scenarios demands a different approach to data and annotation.\u003c/p\u003e\u003cp\u003eThis initial phase focuses on defining the desired outcomes and the key capabilities you want your model to achieve. Let's consider a practical example: building a model to assist legal experts in reviewing case files. The desired outcome might be to reduce the time spent on initial case review by automating the identification of key legal arguments and relevant precedents. This translates into key capabilities like: understanding legal terminology, identifying relationships between different parts of a case file, and summarizing complex legal arguments. We need to capture training data that reflects these capabilities. This might include labeled examples of legal arguments, summaries of past cases, and annotations highlighting the relationships between different legal concepts within a document.\u003c/p\u003e\u003ch4 id=\"2-write-clear-instructions\"\u003e\u003cstrong\u003e2. Write clear instructions\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe quality of your training data hinges on the clarity and completeness of the instructions provided to your AI trainers. Ambiguous guidelines lead to inconsistent annotations, which ultimately undermines the performance of your frontier model. This section outlines the key components of effective instruction design, ensuring your team can accurately and efficiently generate the high-quality data you need.\u003c/p\u003e\u003cp\u003eA comprehensive instruction set begins with a clear overview of the task. Explain the project's overall goal and how the annotations contribute to achieving that goal. Frame the task within the context of the larger project, emphasizing the importance of accurate labeling. For our legal case review example, this overview might explain how the labeled data will train a model to assist lawyers in quickly identifying key information within case files, ultimately saving time and resources.\u003c/p\u003e\u003cp\u003eNext, provide a detailed explanation of the ontology and all relevant terminology. Clearly define each label, category, or rating, avoiding jargon or technical terms that the labelers might not understand. Use simple language and provide real-world examples to illustrate each concept. For instance, instead of simply defining \"legal precedent,\" explain it with a concrete example: \"Legal precedent refers to a previous court decision that serves as a guide for similar cases in the future. For example, the 1954 Supreme Court case Brown v. Board of Education established a precedent for desegregating public schools.\" Provide multiple examples for each category to cover a range of scenarios. For financial analysis, this might include defining terms like \"bull market,\" \"bear market,\" and \"market volatility,\" each with illustrative examples from real-world financial news.\u003c/p\u003e\u003cp\u003eAddressing edge cases and exceptions is crucial. Anticipate situations where the correct label might be unclear or ambiguous. Provide specific guidance on how to handle these situations. And it’s important to provide guidance on what a trainer should do if they don’t feel qualified or confident in a given task. The instructions should clearly state: \"If you are unsure about the correct label, or if you encounter a situation not covered in these guidelines, do not guess. Instead, flag the case for review by a subject matter expert.\" This emphasis on accuracy over completeness is essential for maintaining data quality.\u003c/p\u003e\u003cp\u003eFinally, establish a clear process for feedback, questions, and clarification. Provide a designated channel for labelers to ask questions, report issues, or suggest improvements to the guidelines. Regularly review and incorporate feedback to refine the instructions and address any ambiguities that arise during the annotation process. This iterative approach ensures that the labeling process becomes more accurate and efficient over time. A well-defined communication channel also empowers labelers to contribute valuable insights based on their experience with the data.\u003c/p\u003e\u003ch4 id=\"3-create-a-new-project-and-select-the-right-editor\"\u003e\u003cstrong\u003e3. Create a new project and select the right editor\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eYou're ready to create your project within the Quantumworks Lab platform. Begin by logging into your \u003ca href=\"https://app.labelbox.com/home?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox account\u003c/u\u003e\u003c/a\u003e. Once logged in, click “Create project.”\u003c/p\u003e\u003cp\u003eThe first step is to select the appropriate data modality or task type for your project. This choice is crucial as it determines the tools and interface available to your labelers. For industry-specific reasoning projects involving long-form text analysis, such as reviewing legal documents or analyzing financial reports, the \u003cem\u003eText editor\u003c/em\u003e is often the most suitable option.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe6JVMOwP2YQkAGOA_b1BMZyK0LV3m9Q2h2XMLsFwDVxpjmwIOZS0RUTSfdijAF_LkaewSJmvA_Gh_-30qE8wTAxOawA4Eohobyp2izBk85Tl2f6w4BROD4ls1LVmuYKBy_J3-gQA?key=n3W5WytgaR_uk4G4uepV7qDG\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"379\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eCreate a new project in Quantumworks Lab by selecting the appropriate data modality or task type\u003c/em\u003e\u003c/p\u003e\u003cp\u003eLabelbox also supports other modalities like image, video, audio, and multimodal chat, allowing you to adapt to various data types. For example, if your project involves evaluating the quality of responses from a large language model in a live chat conversation, you may use the multimodal chat editor. If your project involves processing audio recordings of earnings calls, you may select audio. Select the modality that best reflects the nature of your data.\u003c/p\u003e\u003cp\u003eProvide your project with a descriptive and informative \u003cem\u003ename\u003c/em\u003e. This will help you easily identify and manage your project within Labelbox. For our legal case review example, a name like \"Legal Case Review - Contract Analysis\" would be appropriate. For financial analysis, it might be “Financial Report Analysis - Risk Assessment.”\u003c/p\u003e\u003cp\u003eFinally, \u003cem\u003eupload any existing data\u003c/em\u003e that you plan to use in the project. Quantumworks Lab supports various data formats, making it easy to import your data. This might include PDFs, plain text files, CSV files, or even connections to cloud storage. Consider organizing your data into logical batches or datasets before uploading to simplify project management. While uploading, ensure that your data is properly formatted and structured for optimal use within the Quantumworks Lab platform. For large datasets, consider using Quantumworks Lab's data import capabilities to streamline the process.\u003c/p\u003e\u003ch4 id=\"4-customize-your-ontology\"\u003e\u003cstrong\u003e4. Customize your ontology\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eA well-defined ontology is the backbone of your labeling project. It provides the structure and vocabulary for your AI trainers, ensuring consistency and accuracy in their annotations.\u003c/p\u003e\u003cp\u003eNavigate to the \"Ontology\" tab within your newly created project. This is where you'll define the building blocks of your annotation schema.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf-803iyhcp4sokBV32MavTuHSP0jcDW7l72SZFdzMBoCiUcEnhz-qpo2cIw3qGSdA7Mh4ebaIH1WHQIikgzFJRus8lbpU6tGFtz5VrAdSQhWKz4e8suPlvKSI_cS2Z0qFMerEhig?key=n3W5WytgaR_uk4G4uepV7qDG\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"391\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eExample of an ontology configured to collect both ratings and free responses on a given datarow\u003c/em\u003e\u003c/p\u003e\u003cp\u003eClean, thoughtful ontologies help create high-quality labeled data with minimal errors and inconsistencies. Ontologies are an essential part of the Quantumworks Lab labeling platform. Every time you create a project or a model in Quantumworks Lab, you will need to select an ontology.\u003c/p\u003e\u003cp\u003eAlong with the core objects, classifications, and relationships that you’ll use in the text editor, you can also establish \u003cem\u003ehierarchical relationships\u003c/em\u003e between classes if it makes sense for your domain. This allows you to create a more structured and organized ontology. For instance, \"Breach of Contract\" could be a subclass of a more general class called \"Contractual Issue.\" Hierarchical relationships can help your model learn more general concepts from specific examples. They can also make the labeling process more efficient by allowing labelers to quickly navigate through related concepts. For complex ontologies, consider using Quantumworks Lab's hierarchical labeling features to simplify the annotation process.\u003c/p\u003e\u003cp\u003eFor most of today’s complex tasks for generative AI, consider incorporating \u003cem\u003efree text fields\u003c/em\u003e to capture richer insights from your AI trainers. These fields give the trainers the ability to rewrite prompts or responses, provide detailed feedback, and explain the rationale behind their ratings or labels. This qualitative information can be invaluable for understanding model behavior and improving its performance.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor instance, a free text field could allow a labeler to explain why they chose a particular label, highlight ambiguities in the data, or suggest improvements to the ontology. This feedback loop is crucial for refining your model and ensuring it aligns with your desired outcomes.\u003c/p\u003e\u003ch4 id=\"5-execute-the-project-label-rate-and-align\"\u003e\u003cstrong\u003e5. Execute the project: label, rate and align\u0026nbsp;\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eWith your project configured, data loaded, and a robust ontology in place, you're ready to invite your team to begin executing on the tasks and generating new training data.\u003c/p\u003e\u003cp\u003eFirst, invite your selected AI trainers to the project. Quantumworks Lab makes it easy to add team members and assign them specific roles. Ensure that each annotator has the necessary training and understands the project's goals, the ontology, and the annotation guidelines. Consider providing a brief onboarding session to familiarize annotators with the Quantumworks Lab platform and the specific requirements of your project.\u003c/p\u003e\u003cp\u003eNext, assign data batches to the annotators. Organize your data into manageable batches to streamline the annotation workflow. Quantumworks Lab provides tools for batch management, allowing you to distribute data evenly among your team members. Consider assigning smaller batches initially to allow for early feedback and adjustments to the annotation process. As annotators become more proficient, you can increase the batch size.\u003c/p\u003e\u003cp\u003eMonitor the labeling progress regularly. The \u003ca href=\"https://docs.labelbox.com/docs/monitor?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox workspace monitor\u003c/u\u003e\u003c/a\u003e provides dashboards and reporting tools that allow you to track the progress of each annotator and identify any potential bottlenecks or issues. Regular monitoring also allows you to provide timely feedback to annotators and address any questions or concerns they may have. This proactive approach helps maintain data quality and ensures that the project stays on track.\u003c/p\u003e\u003cp\u003eUtilize Consensus, Benchmarks, and Calibration to ensure data quality. These features are essential for maintaining consistency and accuracy in your annotations. Consensus involves having multiple annotators label the same data points and then comparing their annotations. Discrepancies can be discussed and resolved, leading to higher quality data.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cem\u003eBenchmarks\u003c/em\u003e are pre-labeled data points that serve as a gold standard for evaluating annotator performance. Regularly testing annotators on benchmarks can help identify areas where they may need additional training or guidance.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cem\u003eCalibration\u003c/em\u003e is the process of adjusting the annotation guidelines or training materials based on feedback from annotators and insights gained from consensus and benchmark analysis. This iterative approach ensures that your data quality continuously improves throughout the project lifecycle. By actively managing your team and implementing these quality control measures, you can generate the high-quality training data needed to power your frontier models.\u003c/p\u003e\u003ch4 id=\"6-review-and-perform-qa\"\u003e\u003cstrong\u003e6. Review and perform QA\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eEven with well-defined instructions and diligent annotators, a robust review process is essential for guaranteeing the highest quality training data.\u003c/p\u003e\u003cp\u003eEstablishing a strong review process within Quantumworks Lab allows you to implement multiple layers of quality control. You can configure reviews on a per-project basis, tailoring the process to the specific needs of your task. For example, you might require all annotations to be reviewed by a subject matter expert before being accepted into the training dataset. Alternatively, you could implement a tiered review system, where a subset of annotations are reviewed by a senior annotator, and only those that meet a certain quality threshold are then passed on to a subject matter expert for final review. Quantumworks Lab's review workflows can be customized to fit your specific requirements, allowing you to create a scalable and efficient quality control system. Consider implementing a system where annotations are reviewed by a different annotator than the one who originally labeled the data. This helps to catch potential biases or inconsistencies.\u003c/p\u003e\u003cp\u003eBeyond manual review, Quantumworks Lab offers AutoQA features that can significantly improve data quality. AutoQA leverages machine learning models to automatically identify potential errors or inconsistencies in your annotations. These features can flag annotations that deviate significantly from the consensus, highlight areas where annotators disagree, or identify annotations that are inconsistent with pre-defined rules or constraints. By proactively identifying potential issues, AutoQA allows you to focus your review efforts on the most critical areas, saving time and resources.\u0026nbsp;\u003c/p\u003e\u003cp\u003eBy combining manual review with AutoQA, you can create a comprehensive quality assurance system that ensures your training data is accurate, consistent, and reliable. This, in turn, will lead to better performing frontier models capable of industry-specific reasoning.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"disrupting-your-industry-with-advanced-ai-capabilities\"\u003eDisrupting your industry with advanced AI capabilities\u003c/h2\u003e\u003cp\u003eThe pursuit of AI excellence demands a shift from generic to specialized. As we've explored in this guide, building industry-specific reasoning into LLMs and AI models is not just a technical challenge, but a strategic imperative. By leveraging platforms like Quantumworks Lab and embracing a data-centric approach, companies can unlock the true potential of AI and create models that are not just intelligent, but also insightful, reliable, and tailored to the unique demands of their respective industries.\u003c/p\u003e\u003cp\u003eThis guide has provided a roadmap for embarking on this transformative journey. From crafting clear instructions and building robust ontologies to selecting the right AI trainers and leveraging the powerful features of the Quantumworks Lab platform, you now have the foundational knowledge to create your own industry-specific reasoning projects. Remember that the key to success lies in a meticulous, iterative approach, where continuous learning and improvement are paramount.\u003c/p\u003e\u003cp\u003eAs you venture forth, keep in mind that the landscape of AI is constantly evolving. Stay curious, embrace new challenges, and never stop refining your approach. The future of AI is not just about building smarter models, but about building models that truly understand the world in all its specialized complexity. And with Quantumworks Lab as your partner, you're well-equipped to lead the charge toward a future where AI is not just a tool, but a true industry expert.\u003c/p\u003e\u003ch2 id=\"additional-resources\"\u003eAdditional resources:\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox documentation\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/customers/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLabelbox customer stories\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"67bd005c3d2f94000130cf29","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/02/Blog_industry-specific.png","featured":false,"visibility":"public","created_at":"2025-02-24T15:27:24.000-08:00","updated_at":"2025-03-31T14:46:10.000-07:00","published_at":"2025-02-24T16:03:56.000-08:00","custom_excerpt":"This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/how-to-generate-industry-specific-data-for-ai-training-with-labelbox/","excerpt":"This guide will teach you how to generate domain-specific data with the Quantumworks Lab data factory to train your LLMs and AI models on industry-specific reasoning. ","reading_time":17,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Ultimate guide to generating industry-specific AI training data","meta_description":"This guide teaches you how to generate domain-specific data with the Quantumworks Lab data factory to train your AI models on industry-specific knowledge.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6765b8c06f63bf0001f1ca72","uuid":"9f912bc0-54da-4ac6-ab5f-78d8f926463c","title":"Code Runner: Secure, scalable code execution for model evaluation","slug":"code-runner-secure-scalable-code-execution-for-model-evaluation-2","html":"\u003cp\u003eIn the world of large language models (LLMs), evaluating their responses effectively is a fundamental aspect of improving model performance. We’re excited to announce the latest addition to the Quantumworks Lab platform: Code Runner.\u003cstrong\u003e \u003c/strong\u003eThis new capability pushes the boundaries of interactivity by allowing users to execute written code directly within the evaluation workflow.\u003c/p\u003e\u003cp\u003eCode Runner helps eliminate errors, optimizes functionality, and validates outputs, leading to higher-quality datasets. Today, we’ll introduce this new feature and then dive into the technical details of the infrastructure powering this feature, highlighting how it was designed with security, scalability, and\u003cstrong\u003e \u003c/strong\u003erobustness at its core.\u003c/p\u003e\u003ch2 id=\"what-is-code-runner\"\u003e\u003cstrong\u003eWhat is Code Runner?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner is a new built-in feature of the Quantumworks Lab platform designed to improve the quality of responses and labels generated in any coding-related projects. The new features enables users to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDirectly execute code found in either model responses or user-written responses \u003c/li\u003e\u003cli\u003eReceive precise outputs including:\u003cul\u003e\u003cli\u003eStandard output (stdout)\u003c/li\u003e\u003cli\u003eStandard error (stderr)\u003c/li\u003e\u003cli\u003eExecution time\u003c/li\u003e\u003cli\u003eWarnings or runtime errors\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy integrating Code Runner into the evaluation pipeline, we aim to simplify the process of verifying the accuracy, efficiency, and functionality of code responses, all without users needing to leave the platform.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBDN_1bnU_bTrPrWS59SWalVqw22Gxq3AIxNnbsOJmZGPap3weXHYFEgzrlPnEyhVK1GOjzCVClvQycomfMfhQsulqPk4wdQGqniZv8aIaHGP69wzgcFjdDdr5FgooITwNJCsp?key=GRyWmie9kDWaUfN6osDAF8J7\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"389\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOur system automatically detects the language in the text area and suggests the appropriate environment for execution, whether Python or JavaScript (and more to come).\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut what makes this feature stand out is the sophisticated infrastructure behind it, designed to ensure seamless execution while maintaining strict security and privacy standards.\u003c/p\u003e\u003ch2 id=\"code-runner-infrastructure-a-deep-dive\"\u003e\u003cstrong\u003eCode Runner infrastructure: A deep dive\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eAt the heart of Code Runner’s infrastructure lies Google Cloud Run, a fully managed compute platform that runs containerized applications in a secure, scalable manner. Here are the key components and principles driving the system:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1. Cloud Run for language-specific environments\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEvery code execution happens in a dedicated Cloud Run instance. Each instance is tailored to a specific programming language environment (e.g., Python, JavaScript, etc.) and is spun up dynamically based on the code type detected in the user response.\u003c/p\u003e\u003cp\u003eThis design includes the following characteristics to ensure security and speed:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eIsolation\u003c/strong\u003e: Each execution is fully containerized, completely isolating the runtime environment from others.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTemporary directories\u003c/strong\u003e: Code is executed in a temporary directory within the container, and it is deleted immediately after execution, leaving no trace behind.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage-specific tools\u003c/strong\u003e: Each environment comes preloaded with the necessary packages and libraries to ensure compatibility and speed.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e2. Enhanced security with separate GCP projects \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Cloud Run service is hosted in a separate Google Cloud Platform (GCP) project, distinct from our main infrastructure. This segmentation provides an additional layer of security by isolating code execution from our core services. Even in the unlikely event of a compromise, the blast radius is contained.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Communication via private service connect\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo ensure secure and controlled communication, all interactions between the main evaluation system and the Cloud Run service occur over Private Service Connect, which provides the following advantages: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eNo public exposure\u003c/strong\u003e: The Cloud Run endpoint is never exposed to the public internet, reducing the risk of unauthorized access.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOne-way communication\u003c/strong\u003e: The Private Service Connect setup restricts outbound networking from the Cloud Run service, ensuring that executed code cannot make arbitrary network requests. \u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGranular networking controls\u003c/strong\u003e: The private network allows for precise control over what resources the Cloud Run service can access.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e4. Automatic cleanup\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo maintain a lightweight and secure runtime, the system delivers:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEphemeral execution\u003c/strong\u003e: Each execution request is handled in a stateless, temporary environment.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAutomatic deletion\u003c/strong\u003e: Files, logs, and temporary directories are wiped as soon as execution completes, leaving no residual data.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"how-code-runner-works-a-step-by-step-overview\"\u003e\u003cstrong\u003eHow Code Runner works: A step-by-step overview\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow that you have an understanding of the powerful infrastructure underneath Code Runner, here is a summary of how the feature works from start to finish:\u0026nbsp;\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eCode submission\u003c/strong\u003e: A user requests code execution from the evaluation interface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage detection\u003c/strong\u003e: The system detects the programming language and forwards the request to the corresponding Cloud Run service.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e: The Cloud Run instance spins up a container, executes the code in a sandboxed environment, and collects the results.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResult delivery\u003c/strong\u003e: The system returns the output (stdout, stderr, execution time, and any warnings) to the user for analysis.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCleanup\u003c/strong\u003e: The container and all related resources are terminated and deleted.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"advantages-of-labelbox%E2%80%99s-built-in-code-execution\"\u003e\u003cstrong\u003eAdvantages of Quantumworks Lab’s built-in code execution\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner’s infrastructure was designed specifically to provide the previously discussed benefits and to address several key challenges that other solutions may face:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSecurity\u003c/strong\u003e: By isolating execution environments and ensuring no public exposure, we eliminate a significant attack surface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability\u003c/strong\u003e: Cloud Run’s serverless nature allows us to scale dynamically with demand, handling thousands of requests efficiently.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eReliability\u003c/strong\u003e: The use of ephemeral containers ensures that each execution starts in a clean slate, avoiding cross-contamination or resource conflicts.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"explore-it-yourself\"\u003e\u003cstrong\u003eExplore it yourself\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWith Code Runner, we’re empowering users to go beyond static evaluations, enabling dynamic, interactive testing that’s as secure as it is scalable. As always, we’re excited to hear your feedback and explore how we can push this feature even further.\u003c/p\u003e\u003cp\u003e If you want to explore Code Runner and other LLM evaluation tools, \u003ca href=\"https://app.labelbox.com/signup?_r=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/?utm_keyword=Quantumworks Lab\u0026utm_source=house\u0026utm_medium=email\u0026utm_campaign=1224%2520\u0026gclid=CjwKCAiA34S7BhAtEiwACZzv4a9veoKXnMnMvo2rWJvXkH46oHs4Lb5VFQi2ERBN_sQ5kgypV_zfBxoC0yMQAvD_BwE\u0026landingPageAnonymousId=%22e3f2f82f-be24-4045-b2b9-50a49cb801e8%22\u0026referrer_url=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/\"\u003e\u003cu\u003esign up\u003c/u\u003e\u003c/a\u003e for our platform today.\u0026nbsp;\u003c/p\u003e\u003cp\u003eStay tuned for updates, and happy coding!\u003c/p\u003e","comment_id":"6765b8c06f63bf0001f1ca72","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Labelbox-code-runner--1-.png","featured":false,"visibility":"public","created_at":"2024-12-20T10:34:40.000-08:00","updated_at":"2025-03-12T12:01:43.000-07:00","published_at":"2024-12-20T12:44:45.000-08:00","custom_excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"65303cb64e99900001fc05a5","name":"Labeling automation","slug":"labeling-automation","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/labeling-automation/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"}],"primary_author":{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/code-runner-secure-scalable-code-execution-for-model-evaluation-2/","excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"inside-the-matrix-a-look-into-the-math-behind-ai"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/blog/inside-the-matrix-a-look-into-the-math-behind-ai/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:47:03 GMT -->
</html>