<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/llm-fine-tuning-with-peft/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:05:35 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Efficient LLM fine-tuning with PEFT</title><meta name="description" data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Efficient LLM fine-tuning with PEFT" data-next-head=""/><meta property="og:description" data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/llm-fine-tuning-with-peft/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2024/11/fine-tuning-foundation-models.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Efficient LLM fine-tuning with PEFT" data-next-head=""/><meta name="twitter:description" data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/llm-fine-tuning-with-peft/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2024/11/fine-tuning-foundation-models.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
<link rel="stylesheet" href="fix-footer-visibility.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Michał Jóźwiak<span class="mx-2">•</span>October 10, 2024</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">Efficient LLM fine-tuning with PEFT</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2024/11/fine-tuning-foundation-models.png"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><p><a href="../using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/indexc625.html?ref=labelbox.ghost.io"><u>In a previous article</u></a>, we discussed how to use Reinforcement Learning from Human Feedback (RLHF) to align Large Language Models (LLMs) with our preferences. We also briefly discussed the crucial initial step of Supervised Fine-Tuning (SFT). These two techniques are commonly used together to tune modern LLMs like GPT or Llama models.</p><p>SFT is typically used first to teach pre-trained model the “skills” we care about, for example:&nbsp;</p><ul><li><strong>Downstream (“concrete”) tasks</strong>: text summarization, math/science reasoning, function calling, etc.</li><li><strong>Response behavior</strong>: act like a chatbot, adopt a different persona or writing style, provide recommendations, etc.</li><li><strong>Content moderation</strong>: prevent the model from giving controversial answers, enforce platform-specific rules, identify toxic content, etc.</li></ul><p>After SFT, we need to further align the model responses with our preferences. Human preferences are often hard to specify as a machine-readable objective. RLHF addresses that by using a reward model to score LLM responses just as a human would. This model is then used in a reinforcement learning loop. You can read more about RLHF <a href="../using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/indexc625.html?ref=labelbox.ghost.io"><u>in our previous blog</u></a>.</p><p>Today, we explore the data and computational requirements of fine-tuning techniques and how you can leverage Quantumworks Lab and Parameter-Efficient Fine-Tuning (PEFT) to meet them.</p><h2 id="need-for-high-quality-data"><strong>Need for high-quality data</strong></h2><p>Both SFT and RLHF require appropriate data. Since SFT works virtually the same as pre-training, you need a dataset consisting of prompt-response pairs.&nbsp;</p><p>Training a reward model for RLHF, on the other hand, requires a dataset where multiple LLM responses to the same prompt are ranked or rated. For best results, you might need to create your own datasets, tailored to your needs. Unfortunately, manually creating datasets of sufficient size is a tedious process that can be a roadblock for many AI teams.</p><p>The Quantumworks Lab platform is designed to make that easier. As an industry-leading data factory, it can help you with every step of creating bespoke datasets—from processing and storing your assets, to creating custom workflows and managing the labeling workforce, to generating sophisticated ratings and labels through advanced tooling.&nbsp;&nbsp;</p><p>Read more about our capabilities for different AI tasks below:</p><ul><li><a href="https://docs.labelbox.com/docs/multimodal-chat-evaluation-editor?ref=labelbox.ghost.io"><u>Multimodal chat evaluation</u></a></li><li><a href="https://docs.labelbox.com/docs/prompt-and-response-generation-editor?ref=labelbox.ghost.io"><u>Prompt and response generation</u></a></li><li><a href="https://docs.labelbox.com/docs/llm-response-evaluation-editor?ref=labelbox.ghost.io"><u>LLM human preference</u></a></li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../../../lh7-rt.googleusercontent.com/docsz/AD_4nXfIIAhGV5iIkRz3F8c2Tq4WWUTg2XTBMqB_JAEKp71tG1l_GT8VgxTptej1-tkSXs73j8nM6L1EVJSBqEQE3vtcIDM4JpbW5H9PCOb5dta4qbH-4RqbQ7RXlv8zQ08ULM0vchCwKDFgXLMfHQhy_JNdFbHv.b890918?key=uCGUcK8mA_VGk8caCxEYLA" class="kg-image" alt="" loading="lazy" width="624" height="320"><figcaption><span style="white-space: pre-wrap;">Chat arena experience comparing three multimodal models in a live, multi-turn conversaion.</span></figcaption></figure><p>Alternatively, you can try these approaches:</p><ul><li>For SFT: use datasets from the Internet or try to generate one automatically (as shown by the authors of <a href="https://arxiv.org/abs/2212.10560?ref=labelbox.ghost.io"><u>Self-Instruct: Aligning Language Models with Self-Generated Instructions</u></a>)</li><li>For RLHF: you can leverage an off-the-shelf AI model for reward prediction rather than train one on human annotated data. This of course comes with tradeoffs. More on this approach in <a href="../rlhf-vs-rlaif/indexc625.html?ref=labelbox.ghost.io"><u>this blog post</u></a></li></ul><h2 id="computational-considerations"><strong>Computational considerations</strong></h2><p>Modern LLMs contain a huge number of parameters. Meta’s latest open source model, Llama 3.1, comes in three versions: 8, 70 and 405 billion parameters. If you use the smallest model in half precision mode (where each parameter takes two bytes of memory), you need approximately 16Gb of RAM and/or VRAM for inference. That’s not too bad, until you realize that fine-tuning might take 4 times more memory, depending on the optimization algorithm used (typically more for RLFT than SFT).&nbsp;</p><p><a href="https://rahulschand.github.io/gpu_poor/?ref=labelbox.ghost.io"><u>There is a useful tool</u></a> available online, where you can approximate your memory needs. Naturally, the computational overhead for fine-tuning is also much larger than for inference.</p><p>How do we fine-tune the models without a hefty cloud computing bill? The answer is to limit the number of changed parameters to a minimum. That’s where Parameter-Efficient Fine-Tuning (PEFT) methods come into play.</p><h2 id="parameter-efficient-fine-tuning-peft"><strong>Parameter-Efficient Fine-Tuning (PEFT)</strong></h2><p>Broadly speaking, we can identify three strategies to limit the number of trainable parameters:</p><ol><li><strong>Additive methods</strong>: Add a small number of parameters and freeze the existing ones</li><li><strong>Selective methods</strong>: Select a small number of parameters from the model and freeze the rest</li><li><strong>Reparametrization-based methods</strong>: Represent changes to model parameters as a much smaller parameter space</li></ol><h3 id="additive-methods"><strong>Additive methods</strong></h3><p>Additive methods consist of adding a relatively small number of new parameters (typically less than 1% of the original number). While it sounds counterintuitive, only those new parameters are updated during fine-tuning, resulting in a big computational and memory efficiency gain.</p><p>The hope is that these new parameters are enough to encode task-specific knowledge.</p><p>Additive methods vary in how the new parameters are added to the model architecture:</p><ul><li>Adapter-style methods [<a href="https://arxiv.org/abs/1902.00751?ref=labelbox.ghost.io"><em><u>original paper</u></em></a>] introduce new fully connected layers in each transformer block.</li><li>Other methods introduce parameters which you concatenate to the embedded input (<a href="https://arxiv.org/abs/2104.08691?ref=labelbox.ghost.io"><u>Prompt tuning</u></a>) or hidden states of every layer (<a href="https://arxiv.org/abs/2101.00190?ref=labelbox.ghost.io"><u>Prefix-tuning</u></a>, <a href="https://arxiv.org/abs/2110.07602?ref=labelbox.ghost.io"><u>P-tuning</u></a>). These belong to a subcategory called “soft prompts”, because they are inspired by in-context learning, where you concatenate “hard”/normal tokens to the prompt.</li><li>There are also additive methods which do not belong to the subcategories above. An example is <a href="https://arxiv.org/abs/2206.06522?ref=labelbox.ghost.io"><u>Ladder-Side tuning</u></a>, which aims to train a small transformer model that reads some of the parameters from the big pre-trained network.</li></ul><p>A drawback of additive methods is that they introduce computational overhead during model inference.</p><h3 id="selective-methods"><strong>Selective methods</strong></h3><p>Selective methods are all about selecting a subset of parameters from the model for training. <a href="https://arxiv.org/abs/2106.10199?ref=labelbox.ghost.io"><u>BitFit</u></a> only fine-tunes biases of linear or convolutional layers, which constitute less than 0.1% of all parameters. Other methods like <a href="https://arxiv.org/abs/2012.07463?ref=labelbox.ghost.io"><u>Diff Pruning</u></a>, <a href="https://arxiv.org/abs/2111.09839?ref=labelbox.ghost.io"><u>FishMask</u></a>, and <a href="https://arxiv.org/abs/2205.01541?ref=labelbox.ghost.io"><u>FAR</u></a> learn which parameters are most important during the initial passes of&nbsp; fine-tuning.</p><h3 id="reparametrization-based-methods"><strong>Reparametrization-based methods</strong></h3><p>Reparametrization-based methods represent updates to the original parameters in a very compact way, which leads to the drastic reduction of trained parameters. After fine-tuning, the updates are transformed/expanded and simply added to the original model.</p><p>The most widely used method from this family is <a href="https://arxiv.org/abs/2106.09685?ref=labelbox.ghost.io"><u>LoRa</u></a>. The idea behind it is surprisingly simple: for each parameter matrix (of size NxM) we want to fine-tune, we train an update matrix (NxM), represented by a multiplication of two smaller matrices (NxR and RxM). The hyper-parameter R denotes rank, which is a term from linear algebra. Intuitively though, the higher the R, the more trainable parameters we have, which in principle results in more capacity to learn. In practice, for large enough models, keeping the R fairly low (even single digits low according to some sources) yields the same model accuracy as higher values.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../../../lh7-rt.googleusercontent.com/docsz/AD_4nXf_vkr8rAE3XfRTKgaXO_FnirNR8mR2MxmnGjwu-wvtCTZO2eavpBti9EuY4GGBBA7BMG7cohvbBij-_D_z86n3BQOkL4ttaW2VfK3PhPCXqhD1h5SM5fo7ofbZpxnQyXnAv1MZOPO1wkdlbtiGYX3Vc4o.b8a0918.d?key=uCGUcK8mA_VGk8caCxEYLA" class="kg-image" alt="" loading="lazy" width="624" height="240"><figcaption><span style="white-space: pre-wrap;">Simplified visual representation of fine-tuning with LoRa. Only blue matrices are updated. Matrices A and B are in total smaller than the full weight update matrix ΔW (how much smaller depends on hyperparameter R).</span></figcaption></figure><p>Additional methods aim to improve the efficiency and/or quality of LoRa through various means:</p><ul><li><a href="https://arxiv.org/abs/2212.10650?ref=labelbox.ghost.io"><u>KronA</u></a> - uses different matrix factorization (to get the original parameter matrix, you apply <a href="https://en.wikipedia.org/wiki/Kronecker_product?ref=labelbox.ghost.io"><u>Kronecker product</u></a> to the factor matrices instead of “normal” multiplication), which leads to better learning capacity for the same R.</li><li><a href="https://arxiv.org/abs/2305.14314?ref=labelbox.ghost.io"><u>QLoRa</u></a> - introduces sophisticated parameter quantization and clever RAM utilization to allow for fine-tuning even large LLMs on a single GPU. It is however more computationally demanding.</li></ul><h3 id="hybrid-methods"><strong>Hybrid methods</strong></h3><p>A number of methods do not strictly fit into any of the above categories, but blend them. Some of these methods are: <a href="https://arxiv.org/abs/2301.01821?ref=labelbox.ghost.io"><u>S4-model</u></a>, <a href="https://arxiv.org/abs/2106.04647?ref=labelbox.ghost.io"><u>Compacter</u></a>, <a href="https://arxiv.org/abs/2110.07577?ref=labelbox.ghost.io"><u>UniPELT</u></a>.</p><h3 id="libraries"><strong>Libraries</strong></h3><p><a href="https://huggingface.co/docs/peft/en/index?ref=labelbox.ghost.io"><u>Hugging Face’s PEFT</u></a> library is a convenient solution for applying PEFT methods to transformer models. It has first class support in <a href="https://huggingface.co/docs/trl/index?ref=labelbox.ghost.io"><u>Hugging Face’s TRL</u></a> library, which in turn provides a full LLM fine-tuning pipeline (from SFT to RLHF). You can find complete code examples <a href="https://huggingface.co/docs/trl/en/lora_tuning_peft?ref=labelbox.ghost.io"><u>here</u></a>.</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>LLM fine-tuning requires a lot less data than pre-training, but the kind of data needed is limited. Quantumworks Lab can help you create an appropriate high-quality dataset, both for SFT and RLHF.</p><p>Modern LLMs tend to be so large, even the small variants require a lot of memory and computation to fine-tune. Fortunately, you can leverage PEFT methods to reduce the number of trained parameters, which can make the process feasible even on single-GPU machines for medium-sized models (using QLoRa).</p><h3 id="sources"><strong>Sources</strong></h3><ul><li>Vladislav Lialin, Vijeta Deshpande, Anna Rumshisky “Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning”, <em>arXiv</em> <a href="https://arxiv.org/abs/2303.15647?ref=labelbox.ghost.io"><u>https://arxiv.org/abs/2303.15647</u></a> (2023)</li><li>Tayyib Ul Hassan Gondal, “One stop guide for QLoRA”, <em>Medium</em> <a href="https://medium.com/@tayyibgondal2003/one-stop-guide-for-qlora-72abbad9fd0f?ref=labelbox.ghost.io"><u>https://medium.com/@tayyibgondal2003/one-stop-guide-for-qlora-72abbad9fd0f</u></a> (2024)</li><li>Cameron R. Wolfe “Easily Train a Specialized LLM: PEFT, LoRA, QLoRA, LLaMA-Adapter, and More”, <em>Deep (Learning) Focus, </em><a href="https://cameronrwolfe.substack.com/p/easily-train-a-specialized-llm-peft?utm_source=publication-search"><u>https://cameronrwolfe.substack.com/p/easily-train-a-specialized-llm-peft?utm_source=publication-search</u></a> (2023)</li></ul></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../rubric-evals-fuel-next-wave-of-reinforcement-learning-rl/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/indexe566.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_RubricEvals.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>May 16, 2025</p></div><a href="../rubric-evals-fuel-next-wave-of-reinforcement-learning-rl/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Rubric evaluations: Fueling the next wave of reinforcement learning</p><p class="text-base max-w-2xl undefined line-clamp-3">See how Quantumworks Lab utilizes custom rubric-based evaluations to help leading AI labs train and assess advanced frontier models with depth and nuance.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../how-to-improve-ai-app-generators-and-prompt-to-app-with-rubric-evaluations/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/indexdc33.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog-Header_AI-App-Generator3.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>May 15, 2025</p></div><a href="../how-to-improve-ai-app-generators-and-prompt-to-app-with-rubric-evaluations/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Prompt to production: How to improve AI app generators with rubric evals</p><p class="text-base max-w-2xl undefined line-clamp-3">Discover how modern rubric-based evaluations and human evaluation are crucial for advancing the capabilities of prompt-to-app and AI app generators. </p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../how-to-create-data-for-reinforcement-learning-with-verifiable-rewards-rlvr/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index7178.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2025%2F05%2FBlog_RLVR_Header.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>May 6, 2025</p></div><a href="../how-to-create-data-for-reinforcement-learning-with-verifiable-rewards-rlvr/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">How to fill your RLVR pipeline with advanced reasoning data</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to fill your Reinforcement Learning with Verifiable Rewards (RLVR) pipelines to teach your models effective reasoning, especially for logic, math, and coding problems with clear solutions.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer>
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"llm-fine-tuning-with-peft","id":"6705a362eeb2b1000180d4db","uuid":"e266a4fa-a6ac-4a38-a2ab-ce8d92ee185b","title":"Efficient LLM fine-tuning with PEFT","html":"\u003cp\u003e\u003ca href=\"https://labelbox.com/blog/using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eIn a previous article\u003c/u\u003e\u003c/a\u003e, we discussed how to use Reinforcement Learning from Human Feedback (RLHF) to align Large Language Models (LLMs) with our preferences. We also briefly discussed the crucial initial step of Supervised Fine-Tuning (SFT). These two techniques are commonly used together to tune modern LLMs like GPT or Llama models.\u003c/p\u003e\u003cp\u003eSFT is typically used first to teach pre-trained model the “skills” we care about, for example:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDownstream (“concrete”) tasks\u003c/strong\u003e: text summarization, math/science reasoning, function calling, etc.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResponse behavior\u003c/strong\u003e: act like a chatbot, adopt a different persona or writing style, provide recommendations, etc.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eContent moderation\u003c/strong\u003e: prevent the model from giving controversial answers, enforce platform-specific rules, identify toxic content, etc.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAfter SFT, we need to further align the model responses with our preferences. Human preferences are often hard to specify as a machine-readable objective. RLHF addresses that by using a reward model to score LLM responses just as a human would. This model is then used in a reinforcement learning loop. You can read more about RLHF \u003ca href=\"https://labelbox.com/blog/using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ein our previous blog\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eToday, we explore the data and computational requirements of fine-tuning techniques and how you can leverage Quantumworks Lab and Parameter-Efficient Fine-Tuning (PEFT) to meet them.\u003c/p\u003e\u003ch2 id=\"need-for-high-quality-data\"\u003e\u003cstrong\u003eNeed for high-quality data\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eBoth SFT and RLHF require appropriate data. Since SFT works virtually the same as pre-training, you need a dataset consisting of prompt-response pairs.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTraining a reward model for RLHF, on the other hand, requires a dataset where multiple LLM responses to the same prompt are ranked or rated. For best results, you might need to create your own datasets, tailored to your needs. Unfortunately, manually creating datasets of sufficient size is a tedious process that can be a roadblock for many AI teams.\u003c/p\u003e\u003cp\u003eThe Quantumworks Lab platform is designed to make that easier. As an industry-leading data factory, it can help you with every step of creating bespoke datasets—from processing and storing your assets, to creating custom workflows and managing the labeling workforce, to generating sophisticated ratings and labels through advanced tooling.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cp\u003eRead more about our capabilities for different AI tasks below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/multimodal-chat-evaluation-editor?ref=labelbox.ghost.io\"\u003e\u003cu\u003eMultimodal chat evaluation\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/prompt-and-response-generation-editor?ref=labelbox.ghost.io\"\u003e\u003cu\u003ePrompt and response generation\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.labelbox.com/docs/llm-response-evaluation-editor?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLLM human preference\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfIIAhGV5iIkRz3F8c2Tq4WWUTg2XTBMqB_JAEKp71tG1l_GT8VgxTptej1-tkSXs73j8nM6L1EVJSBqEQE3vtcIDM4JpbW5H9PCOb5dta4qbH-4RqbQ7RXlv8zQ08ULM0vchCwKDFgXLMfHQhy_JNdFbHv?key=uCGUcK8mA_VGk8caCxEYLA\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"320\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eChat arena experience comparing three multimodal models in a live, multi-turn conversaion.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAlternatively, you can try these approaches:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor SFT: use datasets from the Internet or try to generate one automatically (as shown by the authors of \u003ca href=\"https://arxiv.org/abs/2212.10560?ref=labelbox.ghost.io\"\u003e\u003cu\u003eSelf-Instruct: Aligning Language Models with Self-Generated Instructions\u003c/u\u003e\u003c/a\u003e)\u003c/li\u003e\u003cli\u003eFor RLHF: you can leverage an off-the-shelf AI model for reward prediction rather than train one on human annotated data. This of course comes with tradeoffs. More on this approach in \u003ca href=\"https://labelbox.com/blog/rlhf-vs-rlaif/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ethis blog post\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"computational-considerations\"\u003e\u003cstrong\u003eComputational considerations\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eModern LLMs contain a huge number of parameters. Meta’s latest open source model, Llama 3.1, comes in three versions: 8, 70 and 405 billion parameters. If you use the smallest model in half precision mode (where each parameter takes two bytes of memory), you need approximately 16Gb of RAM and/or VRAM for inference. That’s not too bad, until you realize that fine-tuning might take 4 times more memory, depending on the optimization algorithm used (typically more for RLFT than SFT).\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://rahulschand.github.io/gpu_poor/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eThere is a useful tool\u003c/u\u003e\u003c/a\u003e available online, where you can approximate your memory needs. Naturally, the computational overhead for fine-tuning is also much larger than for inference.\u003c/p\u003e\u003cp\u003eHow do we fine-tune the models without a hefty cloud computing bill? The answer is to limit the number of changed parameters to a minimum. That’s where Parameter-Efficient Fine-Tuning (PEFT) methods come into play.\u003c/p\u003e\u003ch2 id=\"parameter-efficient-fine-tuning-peft\"\u003e\u003cstrong\u003eParameter-Efficient Fine-Tuning (PEFT)\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eBroadly speaking, we can identify three strategies to limit the number of trainable parameters:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eAdditive methods\u003c/strong\u003e: Add a small number of parameters and freeze the existing ones\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSelective methods\u003c/strong\u003e: Select a small number of parameters from the model and freeze the rest\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eReparametrization-based methods\u003c/strong\u003e: Represent changes to model parameters as a much smaller parameter space\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"additive-methods\"\u003e\u003cstrong\u003eAdditive methods\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAdditive methods consist of adding a relatively small number of new parameters (typically less than 1% of the original number). While it sounds counterintuitive, only those new parameters are updated during fine-tuning, resulting in a big computational and memory efficiency gain.\u003c/p\u003e\u003cp\u003eThe hope is that these new parameters are enough to encode task-specific knowledge.\u003c/p\u003e\u003cp\u003eAdditive methods vary in how the new parameters are added to the model architecture:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAdapter-style methods [\u003ca href=\"https://arxiv.org/abs/1902.00751?ref=labelbox.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eoriginal paper\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e] introduce new fully connected layers in each transformer block.\u003c/li\u003e\u003cli\u003eOther methods introduce parameters which you concatenate to the embedded input (\u003ca href=\"https://arxiv.org/abs/2104.08691?ref=labelbox.ghost.io\"\u003e\u003cu\u003ePrompt tuning\u003c/u\u003e\u003c/a\u003e) or hidden states of every layer (\u003ca href=\"https://arxiv.org/abs/2101.00190?ref=labelbox.ghost.io\"\u003e\u003cu\u003ePrefix-tuning\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2110.07602?ref=labelbox.ghost.io\"\u003e\u003cu\u003eP-tuning\u003c/u\u003e\u003c/a\u003e). These belong to a subcategory called “soft prompts”, because they are inspired by in-context learning, where you concatenate “hard”/normal tokens to the prompt.\u003c/li\u003e\u003cli\u003eThere are also additive methods which do not belong to the subcategories above. An example is \u003ca href=\"https://arxiv.org/abs/2206.06522?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLadder-Side tuning\u003c/u\u003e\u003c/a\u003e, which aims to train a small transformer model that reads some of the parameters from the big pre-trained network.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA drawback of additive methods is that they introduce computational overhead during model inference.\u003c/p\u003e\u003ch3 id=\"selective-methods\"\u003e\u003cstrong\u003eSelective methods\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eSelective methods are all about selecting a subset of parameters from the model for training. \u003ca href=\"https://arxiv.org/abs/2106.10199?ref=labelbox.ghost.io\"\u003e\u003cu\u003eBitFit\u003c/u\u003e\u003c/a\u003e only fine-tunes biases of linear or convolutional layers, which constitute less than 0.1% of all parameters. Other methods like \u003ca href=\"https://arxiv.org/abs/2012.07463?ref=labelbox.ghost.io\"\u003e\u003cu\u003eDiff Pruning\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2111.09839?ref=labelbox.ghost.io\"\u003e\u003cu\u003eFishMask\u003c/u\u003e\u003c/a\u003e, and \u003ca href=\"https://arxiv.org/abs/2205.01541?ref=labelbox.ghost.io\"\u003e\u003cu\u003eFAR\u003c/u\u003e\u003c/a\u003e learn which parameters are most important during the initial passes of\u0026nbsp; fine-tuning.\u003c/p\u003e\u003ch3 id=\"reparametrization-based-methods\"\u003e\u003cstrong\u003eReparametrization-based methods\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eReparametrization-based methods represent updates to the original parameters in a very compact way, which leads to the drastic reduction of trained parameters. After fine-tuning, the updates are transformed/expanded and simply added to the original model.\u003c/p\u003e\u003cp\u003eThe most widely used method from this family is \u003ca href=\"https://arxiv.org/abs/2106.09685?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLoRa\u003c/u\u003e\u003c/a\u003e. The idea behind it is surprisingly simple: for each parameter matrix (of size NxM) we want to fine-tune, we train an update matrix (NxM), represented by a multiplication of two smaller matrices (NxR and RxM). The hyper-parameter R denotes rank, which is a term from linear algebra. Intuitively though, the higher the R, the more trainable parameters we have, which in principle results in more capacity to learn. In practice, for large enough models, keeping the R fairly low (even single digits low according to some sources) yields the same model accuracy as higher values.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf_vkr8rAE3XfRTKgaXO_FnirNR8mR2MxmnGjwu-wvtCTZO2eavpBti9EuY4GGBBA7BMG7cohvbBij-_D_z86n3BQOkL4ttaW2VfK3PhPCXqhD1h5SM5fo7ofbZpxnQyXnAv1MZOPO1wkdlbtiGYX3Vc4o?key=uCGUcK8mA_VGk8caCxEYLA\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"240\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSimplified visual representation of fine-tuning with LoRa. Only blue matrices are updated. Matrices A and B are in total smaller than the full weight update matrix ΔW (how much smaller depends on hyperparameter R).\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAdditional methods aim to improve the efficiency and/or quality of LoRa through various means:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2212.10650?ref=labelbox.ghost.io\"\u003e\u003cu\u003eKronA\u003c/u\u003e\u003c/a\u003e - uses different matrix factorization (to get the original parameter matrix, you apply \u003ca href=\"https://en.wikipedia.org/wiki/Kronecker_product?ref=labelbox.ghost.io\"\u003e\u003cu\u003eKronecker product\u003c/u\u003e\u003c/a\u003e to the factor matrices instead of “normal” multiplication), which leads to better learning capacity for the same R.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2305.14314?ref=labelbox.ghost.io\"\u003e\u003cu\u003eQLoRa\u003c/u\u003e\u003c/a\u003e - introduces sophisticated parameter quantization and clever RAM utilization to allow for fine-tuning even large LLMs on a single GPU. It is however more computationally demanding.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"hybrid-methods\"\u003e\u003cstrong\u003eHybrid methods\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eA number of methods do not strictly fit into any of the above categories, but blend them. Some of these methods are: \u003ca href=\"https://arxiv.org/abs/2301.01821?ref=labelbox.ghost.io\"\u003e\u003cu\u003eS4-model\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2106.04647?ref=labelbox.ghost.io\"\u003e\u003cu\u003eCompacter\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2110.07577?ref=labelbox.ghost.io\"\u003e\u003cu\u003eUniPELT\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"libraries\"\u003e\u003cstrong\u003eLibraries\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://huggingface.co/docs/peft/en/index?ref=labelbox.ghost.io\"\u003e\u003cu\u003eHugging Face’s PEFT\u003c/u\u003e\u003c/a\u003e library is a convenient solution for applying PEFT methods to transformer models. It has first class support in \u003ca href=\"https://huggingface.co/docs/trl/index?ref=labelbox.ghost.io\"\u003e\u003cu\u003eHugging Face’s TRL\u003c/u\u003e\u003c/a\u003e library, which in turn provides a full LLM fine-tuning pipeline (from SFT to RLHF). You can find complete code examples \u003ca href=\"https://huggingface.co/docs/trl/en/lora_tuning_peft?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"conclusion\"\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eLLM fine-tuning requires a lot less data than pre-training, but the kind of data needed is limited. Quantumworks Lab can help you create an appropriate high-quality dataset, both for SFT and RLHF.\u003c/p\u003e\u003cp\u003eModern LLMs tend to be so large, even the small variants require a lot of memory and computation to fine-tune. Fortunately, you can leverage PEFT methods to reduce the number of trained parameters, which can make the process feasible even on single-GPU machines for medium-sized models (using QLoRa).\u003c/p\u003e\u003ch3 id=\"sources\"\u003e\u003cstrong\u003eSources\u003c/strong\u003e\u003c/h3\u003e\u003cul\u003e\u003cli\u003eVladislav Lialin, Vijeta Deshpande, Anna Rumshisky “Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning”, \u003cem\u003earXiv\u003c/em\u003e \u003ca href=\"https://arxiv.org/abs/2303.15647?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://arxiv.org/abs/2303.15647\u003c/u\u003e\u003c/a\u003e (2023)\u003c/li\u003e\u003cli\u003eTayyib Ul Hassan Gondal, “One stop guide for QLoRA”, \u003cem\u003eMedium\u003c/em\u003e \u003ca href=\"https://medium.com/@tayyibgondal2003/one-stop-guide-for-qlora-72abbad9fd0f?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://medium.com/@tayyibgondal2003/one-stop-guide-for-qlora-72abbad9fd0f\u003c/u\u003e\u003c/a\u003e (2024)\u003c/li\u003e\u003cli\u003eCameron R. Wolfe “Easily Train a Specialized LLM: PEFT, LoRA, QLoRA, LLaMA-Adapter, and More”, \u003cem\u003eDeep (Learning) Focus, \u003c/em\u003e\u003ca href=\"https://cameronrwolfe.substack.com/p/easily-train-a-specialized-llm-peft?utm_source=publication-search\"\u003e\u003cu\u003ehttps://cameronrwolfe.substack.com/p/easily-train-a-specialized-llm-peft?utm_source=publication-search\u003c/u\u003e\u003c/a\u003e (2023)\u003c/li\u003e\u003c/ul\u003e","comment_id":"6705a362eeb2b1000180d4db","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/11/fine-tuning-foundation-models.png","featured":false,"visibility":"public","created_at":"2024-10-08T14:25:54.000-07:00","updated_at":"2024-11-18T16:58:58.000-08:00","published_at":"2024-10-10T10:00:34.000-07:00","custom_excerpt":"Explore the data and computational requirements of fine-tuning techniques and how you can leverage PEFT to meet them.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"}],"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"}],"primary_author":{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/llm-fine-tuning-with-peft/","excerpt":"Explore the data and computational requirements of fine-tuning techniques and how you can leverage PEFT to meet them.","reading_time":6,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"recommended":[{"id":"68267ca89c75fb000140be75","uuid":"7c2a2cf7-2220-4a15-9315-a42ba62b00ca","title":"Rubric evaluations: Fueling the next wave of reinforcement learning","slug":"rubric-evals-fuel-next-wave-of-reinforcement-learning-rl","html":"\u003cp\u003eThe AI landscape is constantly evolving, and with it, the methods we use to train and evaluate sophisticated models. For complex tasks, particularly those leveraging reinforcement learning (RL), the traditional reliance on a single \"golden answer\" or \"golden dataset\" is proving insufficient. We're seeing a significant trend towards rubric-based evaluations, a methodology that provides the nuanced, actionable feedback necessary to refine and improve the next generation of AI.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRubric evaluations offer a more granular and insightful approach, scoring responses across multiple dimensions. This provides specific, actionable feedback that is crucial for the iterative improvement cycles inherent in RL. As AI capabilities expand, the need for evaluation methods that can scale, provide detailed feedback, and align with automated processes is paramount.\u003c/p\u003e\u003ch2 id=\"golden-datasets-vs-rubric-based-evaluations\"\u003eGolden datasets vs. rubric-based evaluations\u003c/h2\u003e\u003cp\u003eFor a long time, the gold standard for evaluating AI models, especially in supervised learning, was the \"golden dataset.\" This dataset contains curated examples of the ideal or correct answer for a given input. While useful for foundational tasks, this approach has limitations when applied to more advanced AI systems, particularly those using RL to navigate complex decision-making processes.\u003c/p\u003e\u003cp\u003eThe challenges with relying solely on golden datasets for RL include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eLimited scope for creativity and nuance:\u003c/strong\u003e Many complex problems don't have a single \"golden\" answer. Think about evaluating the quality of code generated by an AI, the helpfulness of a chatbot's conversational turn, or the strategic soundness of a move in a complex game. A single correct answer often doesn’t capture the full spectrum of acceptable or even excellent responses.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDifficulty in assessing partial correctness:\u003c/strong\u003e RL agents often learn through trial and error, producing solutions that might be partially correct or demonstrate understanding of certain aspects of a problem but not others.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability issues for complex feedback:\u003c/strong\u003e As tasks become more intricate, defining a comprehensive golden dataset that covers all desirable attributes and potential pitfalls becomes increasingly challenging and time-consuming.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRubric-based evaluations address these limitations by providing a structured framework to assess responses against a set of predefined criteria, each with varying levels of achievement. This allows for a holistic, detailed understanding of an AI's performance. It is especially vital in RL, where the agent learns by maximizing a reward signal; rubrics help define that reward signal with much greater precision.\u003c/p\u003e\u003ch2 id=\"what-are-rubric-based-evaluations\"\u003eWhat are rubric-based evaluations\u003c/h2\u003e\u003cp\u003eA rubric is a structured assessment tool that clearly outlines the criteria for evaluating a piece of work, the different levels of performance for each criterion, and the scoring guidelines. While traditionally used in education to assess student work and ensure consistent grading, rubrics are proving invaluable for evaluating the outputs of AI models.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Blog_GenericRubric.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1236\" height=\"764\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Blog_GenericRubric.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2025/05/Blog_GenericRubric.png 1000w, https://labelbox.ghost.io/blog/content/images/2025/05/Blog_GenericRubric.png 1236w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eRubric-based evaluation for evaluating complex AI responses\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn the context of AI, rubrics contain a set of criteria tailored to the specific task. For example, when evaluating AI-generated code, criteria might include adherence to naming conventions, efficiency, readability, and correctness. For AI-powered business research, criteria could focus on accuracy, relevance, comprehensiveness, and avoidance of jargon or unnecessary acronyms.\u003c/p\u003e\u003cp\u003eRubric evaluations can range in complexity:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSimple \"correctness rubrics\"\u003c/strong\u003e may use a series of yes/no questions for each criterion. While easy to implement, they often lack the depth needed for nuanced tasks.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRobust rubrics\u003c/strong\u003e assign point values to each criterion, often weighted by importance. Critical aspects of a solution receive higher potential scores, directly impacting the overall evaluation.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAI model responses are then assessed against these criteria, either by human evaluators, an LLM-as-a-judge, or a combination of both. The outcome is a detailed score for each criterion and an overall score that can be benchmarked. For broad or multifaceted topics, different themes (e.g., clarity, relevance, instruction adherence) can each have their own custom rubric.\u003c/p\u003e\u003cp\u003eKey aspects of rubric evaluation include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDefinition of criteria\u003c/strong\u003e: Specific aspects of the performance to be evaluated\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLevels of achievement\u003c/strong\u003e: Descriptions of performance quality for each criterion (e.g., Needs Improvement, Fair, Good, Excellent)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScoring guidelines\u003c/strong\u003e: How scores are assigned or weighted for each level\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eClear communication\u003c/strong\u003e: Shared understanding of expectations for the AI's output\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eFair and consistent assessment\u003c/strong\u003e: Standardized framework for reliable evaluation\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eFeedback\u003c/strong\u003e: Specific, constructive insights pinpointing areas for model improvement\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEfficiency\u003c/strong\u003e: Streamlined evaluation process due to clear, objective measures\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRubric evaluations are versatile and can be applied to diverse AI tasks, including AI application generators (prompt-to-app solutions), search query relevance, and the complex reasoning and chain-of-thought (CoT) capabilities of state-of-the-art models across numerous domains.\u003c/p\u003e\u003ch2 id=\"how-does-a-rubric-improve-reinforcement-learning-rl\"\u003e\u003cstrong\u003eHow does a rubric improve reinforcement learning (RL)?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eFor reinforcement learning systems to truly learn and improve, especially in complex environments, the feedback they receive needs to be more than just a simple reward. Rubric-based evaluations enhance RL processes by providing evaluation signals that are:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eHigh utility\u003c/strong\u003e: Scores derived from rubrics align more closely with the real-world impact and quality of an AI's response. For complex prompts or situations, a simple right/wrong is insufficient. Rubrics offer detailed scores that reflect different facets of a solution, providing granular insights that can directly inform the reward mechanism in RL and guide the model toward more desirable behaviors. This addresses the common RL challenge of reward sparsity or misspecification.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eClear\u003c/strong\u003e: The evaluation criteria are explicit and easily understood. Each criterion targets a specific, well-defined aspect of the response. This clarity helps model builders and the RL agent itself (through the reward signal) to recognize precisely which areas need improvement.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConsistent and reliable\u003c/strong\u003e: When well-designed and based on the expertise of domain specialists, rubrics ensure that evaluations are dependable and reproducible.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEfficient\u003c/strong\u003e: While setting up a robust rubric requires initial effort, it can significantly streamline the evaluation process in the long run. By providing transparent and objective measures, rubrics can reduce the ambiguity and time often associated with evaluating complex AI outputs.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFurthermore, the structured nature of rubric evaluations makes them highly scalable for automated evaluation, including leveraging LLMs as judges. The detailed, multi-dimensional feedback from rubrics can be more effectively translated into the reward signals that drive RL policies, leading to more sophisticated and reliable AI systems. This also aligns with the increased investment in tools and platforms designed for LLM-as-a-judge evaluations.\u003c/p\u003e\u003ch2 id=\"examples-of-modern-rubrics-for-ai-training\"\u003e\u003cstrong\u003eExamples of modern rubrics for AI training\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eThe application of rubrics in AI evaluation is broad and expanding. Here are a few examples:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEvaluating AI-generated code\u003c/strong\u003e: Criteria could include correctness (does the code run without errors and produce the desired output?), efficiency (is the code optimized for speed and resource usage?), readability (is the code well-commented and easy to understand?), security (does the code avoid common vulnerabilities?), and adherence to style guidelines.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAssessing chatbot responses\u003c/strong\u003e: Rubrics can evaluate helpfulness (does the response accurately and completely answer the user's query?), relevance (is the response on-topic?), tone (is the tone appropriate for the context?), safety (does the response avoid harmful, biased, or inappropriate content?), and conciseness (is the information presented without unnecessary verbosity?).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eJudging creative writing or content generation\u003c/strong\u003e: Criteria might involve originality, coherence, grammatical correctness, engagement, adherence to prompt constraints, and stylistic consistency.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEvaluating complex reasoning (e.g., Chain-of-Thought)\u003c/strong\u003e: Rubrics can break down the reasoning process, assessing the logical validity of each step, the accuracy of factual claims, the completeness of the argument, and the clarity of the explanation.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn each of these cases, a rubric allows for a much richer assessment than a simple \"good\" or \"bad\" label. It identifies specific strengths and weaknesses, providing clear pathways for improvement.\u003c/p\u003e\u003cp\u003eEach criterion is worth a certain number of points, with critical criterion worth more points. An example rubric for web application may look like the following. In this example, an excellent solution would receive between 42 and 46 total points across the 5 criteria. Good, satisfactory, needs improvement, and failing solutions would fall into point totals below that.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Screenshot-2025-05-15-at-4.30.34-PM-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"647\" height=\"490\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Screenshot-2025-05-15-at-4.30.34-PM-1.png 600w, https://labelbox.ghost.io/blog/content/images/2025/05/Screenshot-2025-05-15-at-4.30.34-PM-1.png 647w\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample rubric for judging five elements of an AI app generator solution\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"labelbox-services-adopt-rubric-based-evaluations\"\u003e\u003cstrong\u003eLabelbox services: Adopt rubric-based evaluations\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eAt Quantumworks Lab, we partner with leading AI labs to pioneer rubric-based evaluations for their most advanced frontier models. These sophisticated evaluations are crucial for training models on complex responses and are in high demand due to their powerful, actionable insights. Leveraging our \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr network\u003c/u\u003e\u003c/a\u003e of specialized domain experts, we collaboratively develop custom rubrics. These are then seamlessly applied through our platform, supporting human evaluations and integration into automated LLM-as-a-judge systems.\u003c/p\u003e\u003cp\u003eThis collaboration has enabled us to establish a robust, repeatable framework for generating high-utility evaluation data. Our methodology ensures that AI models are assessed with the necessary depth and nuance:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eDefine clear tasks \u0026amp; outcomes: \u003c/strong\u003eWe start by precisely articulating the AI's objective and the characteristics of a high-quality response or output.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDevelop custom rubrics: \u003c/strong\u003eWe develop rubrics that pinpoint key criteria essential for task success, establish distinct achievement levels for each criterion, write clear descriptors for each performance level, and assign weighted scores.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLeverage expert \u0026amp; AI evaluators:\u003c/strong\u003e Utilize human domain experts from the Alignerr network, trained annotators, or LLMs-as-judges, ensuring consistency through training and calibration.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConduct rigorous evaluations: \u003c/strong\u003eSystematically assess AI outputs against the rubric, covering various data types like text, code, or images.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScore, aggregate \u0026amp; analyze: \u003c/strong\u003eCalculate detailed scores for individual criteria and overall performance, identifying specific strengths and weaknesses.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDrive iterative improvement: \u003c/strong\u003eTranslate rich rubric feedback into actionable insights to refine models, adjust training data, or optimize RL reward functions.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eA key reason we are using rubric-based assessment more and more over traditional right/wrong evaluations is its ability to identify \u003cstrong\u003epartial correctness\u003c/strong\u003e. An AI response might meet some criteria exceptionally well while falling short on others. Rubrics capture this nuance, providing a more accurate and actionable picture of the model's capabilities. This detailed feedback loop is crucial for the iterative nature of AI development and is particularly potent when fed into various RL process, such as \u003ca href=\"https://labelbox.com/solutions/rlhf/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eRLHF (Reinforcement Learning from Human Feedback)\u003c/a\u003e or \u003ca href=\"https://labelbox.com/blog/how-to-create-data-for-reinforcement-learning-with-verifiable-rewards-rlvr/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eRLVR (Reinforcement Learning from Verifiable Rewards)\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"next-steps-for-improving-your-frontier-models\"\u003e\u003cstrong\u003eNext steps for improving your frontier models\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eThe move from simple golden dataset comparisons to nuanced, multi-dimensional rubric evaluations marks a significant maturation in how we develop and refine AI systems, especially in the domain of reinforcement learning. Rubrics provide the structured, detailed, and actionable feedback required to train AI on complex tasks where shades of quality matter more than a binary notion of correctness.\u0026nbsp;\u003c/p\u003e\u003cp\u003eInterested in implementing robust rubric-based evaluations for your AI projects?\u003cstrong\u003e \u003c/strong\u003e\u003ca href=\"https://labelbox.com/sales?ref=labelbox.ghost.io\"\u003e\u003cstrong\u003e\u003cu\u003eContact us\u003c/u\u003e\u003c/strong\u003e\u003c/a\u003e to\u003cstrong\u003e \u003c/strong\u003eexplore how Quantumworks Lab can help operate a powerful evaluation of your models. \u003c/p\u003e","comment_id":"68267ca89c75fb000140be75","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/05/Blog-Header_RubricEvals.png","featured":false,"visibility":"public","created_at":"2025-05-15T16:45:44.000-07:00","updated_at":"2025-06-16T10:08:52.000-07:00","published_at":"2025-05-16T08:30:10.000-07:00","custom_excerpt":"See how Quantumworks Lab utilizes custom rubric-based evaluations to help leading AI labs train and assess advanced frontier models with depth and nuance.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/rubric-evals-fuel-next-wave-of-reinforcement-learning-rl/","excerpt":"See how Quantumworks Lab utilizes custom rubric-based evaluations to help leading AI labs train and assess advanced frontier models with depth and nuance.","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Rubric-based evaluations fuel the next wave of RL data","meta_description":"Explore the shift from \"golden answers\" to multi-dimensional rubric evaluations for more precise and scalable AI assessment and development.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"682510d2cbb612000150d938","uuid":"5ded7b4d-f782-4cc4-8b7d-cd52350ebb98","title":"Prompt to production: How to improve AI app generators with rubric evals","slug":"how-to-improve-ai-app-generators-and-prompt-to-app-with-rubric-evaluations","html":"\u003cp\u003eThe ability to transform a simple text prompt into a fully functional web application is no longer science fiction. Functional \"prompt-to-app\" or \"AI app generator\" solutions are rapidly emerging and fueling the next evolution in coding capabilities of frontier models.\u0026nbsp;\u003c/p\u003e\u003cp\u003eAs this new frontier expands, the journey from an initial AI-generated app to a sophisticated, secure, and user-friendly production-ready application is fraught with challenges. To truly unlock the transformative power of AI app generators, the underlying frontier models require detailed training data and robust evaluation frameworks—precisely what \u003ca href=\"https://labelbox.com/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eLabelbox\u003c/a\u003e delivers to help build more reliable, versatile, and intelligent AI-powered development tools.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRead on to learn about the most common hurdles facing today’s AI app generators and to learn about our approach to helping them improve their prompt-to-app coding capabilities. \u003c/p\u003e\u003ch3 id=\"what-are-ai-app-generators-and-prompt-to-app-tools\"\u003e\u003cstrong\u003eWhat are AI app generators and prompt-to-app tools?\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAI app generators, also known as prompt-to-app or AI app builder solutions, use frontier AI models to translate user prompts directly into fully functional, standalone web applications. Startups like and \u003ca href=\"https://bolt.new/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eBolt\u003c/a\u003e, \u003ca href=\"https://lovable.dev/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eLovable\u003c/a\u003e and \u003ca href=\"https://www.tempo.new/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eTempo\u003c/a\u003e along with offerings like \u003ca href=\"https://v0.dev/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003ev0\u003c/a\u003e from Vercel are at the forefront of the AI app generator landscape.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Blog_AIAppGen_Bolt.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1058\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Blog_AIAppGen_Bolt.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2025/05/Blog_AIAppGen_Bolt.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2025/05/Blog_AIAppGen_Bolt.png 1600w, https://labelbox.ghost.io/blog/content/images/size/w2400/2025/05/Blog_AIAppGen_Bolt.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eThe simplicity of bolt.new that takes a text prompt and generate a complete application\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThis technology marks a transformative shift in software development by allowing users, regardless of their coding expertise, to create interactive and dynamic products simply by describing their intentions in natural language. They offer a new level of abstraction where natural language and visual concepts replace traditional SDKs and frameworks.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cp\u003eThese AI app generators are a significant focus for AI labs today due to the immense potential they hold and the rapidly growing demand for such capabilities. The ability to seamlessly convert user intentions into robust applications represents a new competitive frontier for both foundational AI model developers and coding application startups. Leading AI labs are investing heavily in this area to push the boundaries of AI and deliver truly transformative tools that can significantly lower the barrier to software creation.\u0026nbsp; \u0026nbsp; \u003c/p\u003e\u003ch3 id=\"hurdles-why-todays-ai-app-generators-need-a-boost\"\u003e\u003cstrong\u003eHurdles: Why today's AI app generators need a boost\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWhile the early successes of AI app generators are impressive, persistent challenges hinder their full potential. Current platforms often struggle with:\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eInterpreting complex user needs:\u003c/strong\u003e Translating nuanced or intricate user requirements into accurate application logic remains a significant hurdle.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEnsuring code quality and security:\u003c/strong\u003e The generated code may lack the robustness, security standards, and efficiency required for production environments.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCrafting intuitive user experiences:\u003c/strong\u003e Creating truly engaging and intuitive user interfaces (UI) and user experiences (UX) through AI alone is a complex task.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAddressing \"big-picture\" thinking:\u003c/strong\u003e AI models can falter when tasks require a deep contextual understanding of how different components of an application interconnect or how changes in one area impact others.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAvoiding bias:\u003c/strong\u003e AI models can inadvertently perpetuate biases present in their training data, leading to unfair or skewed application behavior.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese limitations highlight that while AI can significantly lower the barrier to entry for application creation, the path to deploying complex and reliable software requires a more refined approach.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"how-to-elevate-ai-app-generators-with-superior-data-and-evaluation\"\u003e\u003cstrong\u003eHow to elevate AI app generators with superior data and evaluation?\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eSignificant advancements in two core areas are crucial to overcoming these challenges: \u003cstrong\u003edata and evaluation\u003c/strong\u003e. This is where Quantumworks Lab's expertise and experience working with leading AI labs to solve this exact problem becomes paramount.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Blog_AIAppGen.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"837\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Blog_AIAppGen.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2025/05/Blog_AIAppGen.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2025/05/Blog_AIAppGen.png 1600w, https://labelbox.ghost.io/blog/content/images/size/w2400/2025/05/Blog_AIAppGen.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003ePrompt-to-app example to create a board game recommendation app\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eTo build more capable prompt-to-app systems, models need to be trained on high-quality, diverse, and highly specific datasets. Quantumworks Lab facilitates the creation of these crucial datasets, moving beyond generic code repositories to include:\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eTargeted training datasets:\u003c/strong\u003e We help develop comprehensive suites of meticulously crafted examples, featuring diverse user prompts and their corresponding validated, working application code and structures. This includes specialized data for UI/UX best practices, secure coding standards, and complex application logic.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEthical and quality-focused annotation:\u003c/strong\u003e Ensuring data is annotated with precision and sourced ethically is critical for building fair and capable AI systems.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhile, current benchmarks often fall short in assessing the true capabilities of AI app generators, Quantumworks Lab champions more holistic and human-centric evaluation methodologies that rigorously measure:\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFunctional correctness:\u003c/strong\u003e Does the application perform as intended based on the prompt?\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCode quality \u0026amp; security:\u003c/strong\u003e Is the generated code well-structured, efficient, and secure?\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUsability:\u003c/strong\u003e Is the application intuitive and easy to use?\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAlignment with user intent:\u003c/strong\u003e How well does the final application match the user's original vision?\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis is achieved by employing an integrated methodology, actively providing prompt-to-app data and iterative enhancement for leading AI labs. This framework includes:\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eReviewing model-generated applications:\u003c/strong\u003e Analyzing prompts and application structures to identify issues.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEnsuring code executability:\u003c/strong\u003e Transforming initial AI outputs into fully working web applications.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eError diagnosis and resolution:\u003c/strong\u003e Systematically executing applications, documenting failures, and capturing issues for targeted model retraining.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eIterative model evaluation:\u003c/strong\u003e Submitting refined prompts and corrected components back to the model, rigorously assessing improvements, and manually resolving persistent issues when necessary. This involves techniques like Reinforcement Learning from Human Feedback (RLHF) to align AI outputs with human preferences.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA detailed framework for this process involves meticulous steps from environment setup and baseline capture to model output evaluation and, if needed, human-crafted \"golden solutions\" to ensure the highest quality. This iterative feedback loop is essential for refining AI models and fostering a collaborative relationship between human developers and AI. \u0026nbsp;\u003c/p\u003e\u003ch3 id=\"defining-success-the-importance-of-a-comprehensive-rubric-for-evaluation\"\u003e\u003cstrong\u003eDefining success: The importance of a comprehensive rubric for evaluation\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eTo objectively improve AI app generators, evaluation must go beyond simple pass/fail metrics. Quantumworks Lab advocates for and utilizes comprehensive rubrics to analyze and rate AI-generated web applications across multiple criteria.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThese rubrics assess aspects like, but not limited to: core requirements implementation, user interface quality \u0026amp; responsive design, authentication \u0026amp; security, and error handling \u0026amp; performance optimization.\u003c/p\u003e\u003cp\u003eEach criterion is worth a certain number of points, with critical criterion worth more points. An example rubric for web application may look like the following. In this example, an excellent solution scores between 42 and 46 points and then good, satisfactory, needs improvement, and failing solutions fall into point totals below that.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Screenshot-2025-05-15-at-4.30.34-PM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"647\" height=\"490\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Screenshot-2025-05-15-at-4.30.34-PM.png 600w, https://labelbox.ghost.io/blog/content/images/2025/05/Screenshot-2025-05-15-at-4.30.34-PM.png 647w\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample rubric for judging five elements of an AI app generator solution\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBy embracing a detailed evaluation framework, you can gain deeper insights into your model’s performance and identify specific areas for improvement.\u0026nbsp;\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"improve-prompt-to-app-capabilities-today\"\u003e\u003cstrong\u003eImprove prompt-to-app capabilities today\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe emergence of prompt-to-app technology represents a monumental shift in software development. While the path to perfecting these AI app generators has its hurdles, the combination of advanced AI models with high-quality, specialized training data and rigorous \u003ca href=\"https://labelbox.com/solutions/model-evaluation/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003ehuman-in-the-loop evaluation\u003c/a\u003e offers a clear way forward.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLabelbox prides itself on being at the forefront of this evolution, providing the critical data infrastructure and expertise to help train and refine the frontier models that will power the next generation of AI-driven development. \u0026nbsp; \u003c/p\u003e","comment_id":"682510d2cbb612000150d938","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/05/Blog-Header_AI-App-Generator3.png","featured":false,"visibility":"public","created_at":"2025-05-14T14:53:22.000-07:00","updated_at":"2025-06-16T10:09:03.000-07:00","published_at":"2025-05-15T16:33:55.000-07:00","custom_excerpt":"Discover how modern rubric-based evaluations and human evaluation are crucial for advancing the capabilities of prompt-to-app and AI app generators. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/how-to-improve-ai-app-generators-and-prompt-to-app-with-rubric-evaluations/","excerpt":"Discover how modern rubric-based evaluations and human evaluation are crucial for advancing the capabilities of prompt-to-app and AI app generators. ","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"How to improve AI app generators and prompt-to-app tools","meta_description":"Overcome current AI app generator and prompt-to-app limitations with rubric evaluations and human-centric evaluations from Labelbox. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"68194646f5df1d000117b2f8","uuid":"5bff3235-143b-4f06-8bb0-e0dcc26a9fc9","title":"How to fill your RLVR pipeline with advanced reasoning data","slug":"how-to-create-data-for-reinforcement-learning-with-verifiable-rewards-rlvr","html":"\u003cp\u003eUnlocking the next level of AI performance and utility, particularly for complex tasks requiring sophisticated planning and execution (the foundation of future AI agents), demands more than just scale. It requires robust \u003cstrong\u003ereasoning capabilities\u003c/strong\u003e. \u003c/p\u003e\u003cp\u003eReinforcement learning (RL)—or specifically the fast growing adoption of \u003ca href=\"https://labelbox.com/solutions/reinforcement-learning-with-verifiable-rewards/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eReinforcement Learning with Verifiable Rewards (RLVR)\u003c/a\u003e—offers a powerful and efficient pathway to teach models \u003cem\u003ehow\u003c/em\u003e to reason effectively, especially for problems with clear, verifiable solutions.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2025/05/Blog_RLVR_Gray.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"942\" height=\"675\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2025/05/Blog_RLVR_Gray.png 600w, https://labelbox.ghost.io/blog/content/images/2025/05/Blog_RLVR_Gray.png 942w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eReinforcement learning with verifiable rewards (RLVR) process supported by Quantumworks Lab\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAt Quantumworks Lab, we're pioneering RL data services designed to supercharge this process and fill your AI training pipelines. Read below to discover how we’re approaching this problem and already helping some leading AI labs dramatically improve the reasoning capabilities of their frontier models.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"rl-vs-dporlhf-choosing-the-right-method-for-enhanced-reasoning\"\u003e\u003cstrong\u003eRL vs. DPO/RLHF: Choosing the right method for enhanced reasoning\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eAs AI development matures, training methodologies are evolving. Alignment, whether through the classic \u003ca href=\"https://labelbox.com/solutions/rlhf/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eRLHF (Reinforcement Learning from Human Feedback)\u003c/a\u003e methods or more recent DPO (Direct Preference Optimization) methods, has been instrumental in aligning models with human preferences. These methods are important for subjective tasks like adjusting tone and improving conversational flow. The tuning methods involve humans comparing two model outputs and indicating which is \"better,\" guiding the model towards preferred styles and behaviors.\u0026nbsp;\u003c/p\u003e\u003cp\u003eBut what is “better” is a complicated question (and beyond the scope of our blog today). DPO and RLHF is critical to aligning AI models with human preferences, and is one reason we operate our diverse, global network of Alignerrs.\u0026nbsp;\u003c/p\u003e\u003cp\u003eHowever, when it comes to tasks demanding \u003cstrong\u003eobjective correctness\u003c/strong\u003e—like mathematical calculations, code generation, logical deduction, or complex planning—a different flavor of RL shines: \u003cstrong\u003eReinforcement Learning from Verifiable Rewards (RLVR)\u003c/strong\u003e. Instead of subjective preference, RLVR relies on a clear, often binary (correct/incorrect) signal based on whether the model's output meets predefined criteria.\u003c/p\u003e\u003cp\u003eWhy is this crucial now? As we move towards AI agents that need to perform multi-step tasks accurately in the real world, their underlying reasoning \u003cem\u003emust\u003c/em\u003e be sound. RLVR is ideal for instilling this logical rigor. It allows models to learn complex procedures by receiving unambiguous feedback on their problem-solving attempts. This ensures the model develops accurate internal logic before attempting to use tools or interact with external systems—a critical prerequisite for reliable agentic behavior.\u003c/p\u003e\u003ch3 id=\"training-a-leading-frontier-model-a-case-study-in-scaling-rl-for-reasoning\"\u003e\u003cstrong\u003eTraining a leading frontier model: A case study in scaling RL for reasoning\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eLabelbox is already at the forefront, collaborating with leading AI labs to enhance their models' reasoning abilities through targeted RL strategies. In a recent successful engagement, we partnered with a major AI research lab grappling with the challenge of scaling RL training specifically for \u003cstrong\u003ecomplex planning tasks\u003c/strong\u003e. Their goal was ambitious: significantly improve their model's ability to reason through intricate scenarios, laying the groundwork for advanced agentic capabilities.\u003c/p\u003e\u003cp\u003eThis wasn't a standard data annotation project. It required a sophisticated approach to generate the high-quality, diverse data needed to train a model on planning across various domains. Our process involved defining problem domains, generating a diverse set of prompts, and developing verifiable reward functions.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThe result? We successfully helped the lab supercharge their RL pipeline, improving their model's reasoning and agentic task performance by over 15%.\u0026nbsp;\u003c/p\u003e\u003ch3 id=\"building-agent-ready-rl-pipelines-with-labelbox\"\u003e\u003cstrong\u003eBuilding agent-ready RL pipelines with Quantumworks Lab\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe success of this project highlights a core Quantumworks Lab capability: providing the specialized data generation, advanced verification services, and proven system needed to fuel sophisticated RL pipelines. We understand that teaching models complex reasoning requires more than just raw data; it requires \u003cem\u003estructured, diverse, and verifiable\u003c/em\u003e training signals.\u003c/p\u003e\u003cp\u003eOur framework, proven with leading labs, is repeatable and scalable:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1) Collaborative domain definition:\u003c/strong\u003e We work with you to identify the critical reasoning domains your models need to master.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e2) Systematic prompt generation:\u003c/strong\u003e Leveraging our expertise and your domain knowledge, we create vast sets of realistic problem variations, focusing on linguistic, structural, and parametric diversity. Our methodology includes varying:\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eStructure/format:\u003c/strong\u003e Paragraphs, bullets, markdown tables, etc.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInformation ordering\u003c/strong\u003e: Changing the sequence of constraints and details.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTone \u0026amp; phrasing\u003c/strong\u003e: Formal, informal, shorthand, detailed explanations.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSyntax \u0026amp; specifics\u003c/strong\u003e: $ vs USD, 14:00 vs 2 pm, numerical vs. written numbers.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConstraint presentation\u003c/strong\u003e: Grouping vs. distributing constraints.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePlacement of key Info\u003c/strong\u003e: Varying where critical data like budgets or deadlines appear.\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e3) Verifier reward function development:\u003c/strong\u003e We design and implement custom verifier and solver programs that provide the objective, automated reward signals necessary for efficient RL training.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e4) Expert execution:\u003c/strong\u003e We utilize Quantumworks Lab's extensive, highly skilled \u003cstrong\u003eAlignerr network, \u003c/strong\u003ewho are expert AI trainers adept at handling the complexity of prompt generation, data structuring, and refinement needed for these advanced projects.\u003c/p\u003e\u003cp\u003eThis comprehensive approach allows us to generate the precise inputs needed to train your models on nuanced reasoning across any domain, preparing them for the complex, multi-step tasks required by sophisticated AI agents.\u003c/p\u003e\u003ch3 id=\"build-more-capable-agentic-ready-models\"\u003e\u003cstrong\u003eBuild more capable, agentic-ready models\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe ability to reason effectively is the next frontier for AI. Reinforcement Learning, particularly reinforcement learning with verifiable rewards, provides a direct path to teaching models the complex logic required for advanced applications and agentic behavior. Quantumworks Lab offers the expertise, process, and scalable resources to generate the high-quality reasoning data and RL services needed to accelerate your model development.\u003c/p\u003e\u003cp\u003eReady to supercharge your RL pipeline and prepare your models for the future of AI? Learn more about \u003ca href=\"https://labelbox.com/solutions/reinforcement-learning-with-verifiable-rewards/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eLabelbox's RLVR solution\u003c/a\u003e or \u003ca href=\"https://labelbox.com/sales?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003econtact us\u003c/a\u003e to discuss your immediate data needs.\u0026nbsp;\u003c/p\u003e\u003cp\u003eLet Quantumworks Lab help you build models that don't just predict, but \u003cem\u003ereason\u003c/em\u003e.\u003c/p\u003e","comment_id":"68194646f5df1d000117b2f8","feature_image":"https://labelbox.ghost.io/blog/content/images/2025/05/Blog_RLVR_Header.png","featured":false,"visibility":"public","created_at":"2025-05-05T16:14:14.000-07:00","updated_at":"2025-06-16T10:09:13.000-07:00","published_at":"2025-05-06T08:45:26.000-07:00","custom_excerpt":"Learn how to fill your Reinforcement Learning with Verifiable Rewards (RLVR) pipelines to teach your models effective reasoning, especially for logic, math, and coding problems with clear solutions.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/how-to-create-data-for-reinforcement-learning-with-verifiable-rewards-rlvr/","excerpt":"Learn how to fill your Reinforcement Learning with Verifiable Rewards (RLVR) pipelines to teach your models effective reasoning, especially for logic, math, and coding problems with clear solutions.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Reinforcement Learning from Verifiable Rewards (RLVR) | Quantumworks Lab guide","meta_description":"Learn how to improve RLVR pipelines with advanced training data to improve frontier AI model performance for complex tasks.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"llm-fine-tuning-with-peft"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/blog/llm-fine-tuning-with-peft/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:05:41 GMT -->
</html>