<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:27:28 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Faster image segmentation with Meta’s Segment Anything 2.0</title><meta name="description" data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="Faster image segmentation with Meta’s Segment Anything 2.0" data-next-head=""/><meta property="og:description" data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2024/08/Screenshot-2024-08-07-at-10.07.18-AM.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Faster image segmentation with Meta’s Segment Anything 2.0" data-next-head=""/><meta name="twitter:description" data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2024/08/Screenshot-2024-08-07-at-10.07.18-AM.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
<link rel="stylesheet" href="fix-footer-visibility.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>August 7, 2024</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">Faster image segmentation with Meta’s Segment Anything 2.0</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2024/08/Screenshot-2024-08-07-at-10.07.18-AM.png"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><p>We are thrilled to introduce our enhanced image Auto-Segment tool that takes advantage of Segment Anything 2.0, Meta’s latest foundation model release for  image segmentation. The upgrade Auto-Segment tool is available today in the Quantumworks Lab image editor. To use, simply choose the AutoSegment icon and start drawing masks at a much faster pace than before!</p><p>Segment Anything 2.0 is a state-of-the-art computer vision model that performs better at zero-shot segmentation tasks on both image and video. It builds on the success of Segment Anything by improving speed and accuracy of interactive segmentation tasks.</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe src="https://fast.wistia.net/embed/iframe/264fjzrf4m" title="Segment Anything 2.0 Demo Video" allow="autoplay; fullscreen" allowtransparency="true" frameborder="0" scrolling="no" class="wistia_embed" name="wistia_embed" msallowfullscreen="" width="960" height="598"></iframe>
<script src="../../../fast.wistia.net/assets/external/E-v1.js" async=""></script><figcaption><p><span style="white-space: pre-wrap;">Watch SAM 2.0 in action in this comprehensive demo.</span></p></figcaption></figure><h3 id="what-is-sam-2"><strong>What is SAM 2?</strong></h3><p>Segment Anything Model 2 (SAM 2) is a computer vision model developed by Meta. It is designed for real-time promptable object segmentation in both images and videos, achieving state-of-the-art performance. SAM 2 builds on the original Segment Anything Model (SAM) by introducing significant improvements in segmentation accuracy and speed, especially for video content​. This model leverages a new dataset, SA-V, which includes approximately 51,000 real-world videos and over 600,000 masklets, enabling it to segment any object in any visual domain without custom adaptation.</p><h3 id="differences-between-sam-and-sam-2"><strong>Differences between SAM and SAM 2</strong></h3><p>The primary differences between SAM and SAM 2 lie in their capabilities and performance enhancements. SAM was groundbreaking for image segmentation, providing accurate results with minimal user interaction. However, SAM 2 extends these capabilities to video segmentation, introducing a unified model that handles both images and videos seamlessly. SAM 2 incorporates a memory mechanism that stores information about the object and user interactions throughout the video, allowing it to maintain accurate segmentation across frames. This results in better video segmentation performance with three times fewer interactions and six times faster processing in images compared to SAM.</p><h3 id="why-we-should-be-excited-about-sam-2-in-labelbox"><strong>Why we should be excited about SAM 2 in Quantumworks Lab</strong></h3><p>The integration of SAM 2 into Quantumworks Lab’s image editor is a significant advancement for users who require precise and efficient image segmentation tools. SAM 2’s ability to provide real-time, high-accuracy segmentation for both images and videos means that users can achieve better results with less manual effort. This is particularly beneficial for industries such as autonomous driving, robotics, and content creation, where fast and accurate object segmentation is crucial​. Additionally, the open-source nature of SAM 2 and the extensive SA-V dataset promote broader adoption and innovation in computer vision applications. By incorporating SAM 2 into Quantumworks Lab, users can now leverage cutting-edge technology to enhance their workflows and achieve superior segmentation results.</p><p>For context, please read the previous article about our AutoSegment functionality: <a href="../coming-soon-auto-segment-powered-by-sam/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer"><u>"Auto-Segment 2.0 powered by Meta's Segment Anything Model"</u></a></p><p>Meanwhile,​​ <u>s</u><a href="https://app.labelbox.com/signup?utm_source=google&amp;utm_medium=paid-search&amp;utm_campaign=20490363302&amp;utm_keyword=Quantumworks Lab%2520pricing&amp;gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_HaRJu-zYfq545Dxl9HUqyPBNDpQAHecf-NxYsnKueRGjicsKGXfRoCzlsQAvD_BwE&amp;landingPageAnonymousId=%22a83b92ec-b8b4-41cd-9622-4e3725a530bf%22&amp;referrer_url=https://www.google.com/"><u>ign up for a free</u></a> Quantumworks Lab account to try it out, or <a href="../../sales/indexc625.html?ref=labelbox.ghost.io"><u>contact us</u></a> to learn more.</p></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index447c.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Stanislav Issayenko<span class="mx-2">•</span>December 19, 2024</p></div><a href="../bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Bringing AI to the browser: SAM2 for interactive image segmentation</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../enhanced-labelbox-video-editors-adds-deeply-nested-classifications/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/indexca1d.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F11%2Fhuman-in-the-loop-6.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>November 14, 2024</p></div><a href="../enhanced-labelbox-video-editors-adds-deeply-nested-classifications/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Enhanced video editor adds  deeply nested classifications to improve visibility and efficiency</p><p class="text-base max-w-2xl undefined line-clamp-3">Streamline video data labeling with new features for deeply nested classifications and overall improved video editor functionality.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/indexf450.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F09%2Fleaderboard_blog_hero.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>September 24, 2024</p></div><a href="../labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Quantumworks Lab leaderboards: Redefining AI evaluation with private, transparent, and human-centric assessments</p><p class="text-base max-w-2xl undefined line-clamp-3">Introducing our groundbreaking Quantumworks Lab leaderboards: an innovative, scientific process to rank multimodal AI models that goes beyond conventional benchmarks.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div>
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor","id":"66b3a55dcd81c100011a9437","uuid":"1a62fdef-f3dd-41ca-9d4d-1c4cf849c91d","title":"Faster image segmentation with Meta’s Segment Anything 2.0","html":"\u003cp\u003eWe are thrilled to introduce our enhanced image Auto-Segment tool that takes advantage of Segment Anything 2.0, Meta’s latest foundation model release for  image segmentation. The upgrade Auto-Segment tool is available today in the Quantumworks Lab image editor. To use, simply choose the AutoSegment icon and start drawing masks at a much faster pace than before!\u003c/p\u003e\u003cp\u003eSegment Anything 2.0 is a state-of-the-art computer vision model that performs better at zero-shot segmentation tasks on both image and video. It builds on the success of Segment Anything by improving speed and accuracy of interactive segmentation tasks.\u003c/p\u003e\u003cfigure class=\"kg-card kg-embed-card kg-card-hascaption\"\u003e\u003ciframe src=\"https://fast.wistia.net/embed/iframe/264fjzrf4m\" title=\"Segment Anything 2.0 Demo Video\" allow=\"autoplay; fullscreen\" allowtransparency=\"true\" frameborder=\"0\" scrolling=\"no\" class=\"wistia_embed\" name=\"wistia_embed\" msallowfullscreen=\"\" width=\"960\" height=\"598\"\u003e\u003c/iframe\u003e\n\u003cscript src=\"https://fast.wistia.net/assets/external/E-v1.js\" async=\"\"\u003e\u003c/script\u003e\u003cfigcaption\u003e\u003cp\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eWatch SAM 2.0 in action in this comprehensive demo.\u003c/span\u003e\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"what-is-sam-2\"\u003e\u003cstrong\u003eWhat is SAM 2?\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eSegment Anything Model 2 (SAM 2) is a computer vision model developed by Meta. It is designed for real-time promptable object segmentation in both images and videos, achieving state-of-the-art performance. SAM 2 builds on the original Segment Anything Model (SAM) by introducing significant improvements in segmentation accuracy and speed, especially for video content​. This model leverages a new dataset, SA-V, which includes approximately 51,000 real-world videos and over 600,000 masklets, enabling it to segment any object in any visual domain without custom adaptation.\u003c/p\u003e\u003ch3 id=\"differences-between-sam-and-sam-2\"\u003e\u003cstrong\u003eDifferences between SAM and SAM 2\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe primary differences between SAM and SAM 2 lie in their capabilities and performance enhancements. SAM was groundbreaking for image segmentation, providing accurate results with minimal user interaction. However, SAM 2 extends these capabilities to video segmentation, introducing a unified model that handles both images and videos seamlessly. SAM 2 incorporates a memory mechanism that stores information about the object and user interactions throughout the video, allowing it to maintain accurate segmentation across frames. This results in better video segmentation performance with three times fewer interactions and six times faster processing in images compared to SAM.\u003c/p\u003e\u003ch3 id=\"why-we-should-be-excited-about-sam-2-in-labelbox\"\u003e\u003cstrong\u003eWhy we should be excited about SAM 2 in Quantumworks Lab\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eThe integration of SAM 2 into Quantumworks Lab’s image editor is a significant advancement for users who require precise and efficient image segmentation tools. SAM 2’s ability to provide real-time, high-accuracy segmentation for both images and videos means that users can achieve better results with less manual effort. This is particularly beneficial for industries such as autonomous driving, robotics, and content creation, where fast and accurate object segmentation is crucial​. Additionally, the open-source nature of SAM 2 and the extensive SA-V dataset promote broader adoption and innovation in computer vision applications. By incorporating SAM 2 into Quantumworks Lab, users can now leverage cutting-edge technology to enhance their workflows and achieve superior segmentation results.\u003c/p\u003e\u003cp\u003eFor context, please read the previous article about our AutoSegment functionality: \u003ca href=\"https://labelbox.com/blog/coming-soon-auto-segment-powered-by-sam/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003e\u003cu\u003e\"Auto-Segment 2.0 powered by Meta's Segment Anything Model\"\u003c/u\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eMeanwhile,​​ \u003cu\u003es\u003c/u\u003e\u003ca href=\"https://app.labelbox.com/signup?utm_source=google\u0026utm_medium=paid-search\u0026utm_campaign=20490363302\u0026utm_keyword=Quantumworks Lab%2520pricing\u0026gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_HaRJu-zYfq545Dxl9HUqyPBNDpQAHecf-NxYsnKueRGjicsKGXfRoCzlsQAvD_BwE\u0026landingPageAnonymousId=%22a83b92ec-b8b4-41cd-9622-4e3725a530bf%22\u0026referrer_url=https://www.google.com/\"\u003e\u003cu\u003eign up for a free\u003c/u\u003e\u003c/a\u003e Quantumworks Lab account to try it out, or \u003ca href=\"https://labelbox.com/sales/?ref=labelbox.ghost.io\"\u003e\u003cu\u003econtact us\u003c/u\u003e\u003c/a\u003e to learn more.\u003c/p\u003e","comment_id":"66b3a55dcd81c100011a9437","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/08/Screenshot-2024-08-07-at-10.07.18-AM.png","featured":false,"visibility":"public","created_at":"2024-08-07T09:48:29.000-07:00","updated_at":"2024-10-04T09:38:08.000-07:00","published_at":"2024-08-07T09:59:23.000-07:00","custom_excerpt":"Learn about our enhanced image Auto-Segment tool that takes advantage of Segment Anything 2.0, Meta’s latest foundation model release for improved image segmentation. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"67001915863cb90001f263eb","name":"Partners","slug":"partners","description":"Partnerships and technical integrations between 3rd party solutions and Quantumworks Lab","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/partners/"},{"id":"6700193d863cb90001f263ed","name":"Computer vision","slug":"computer-vision","description":"CV related features, best practices, and information","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/computer-vision/"}],"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"67001915863cb90001f263eb","name":"Partners","slug":"partners","description":"Partnerships and technical integrations between 3rd party solutions and Quantumworks Lab","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/partners/"},"url":"https://labelbox.ghost.io/blog/metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor/","excerpt":"Learn about our enhanced image Auto-Segment tool that takes advantage of Segment Anything 2.0, Meta’s latest foundation model release for improved image segmentation. ","reading_time":2,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"recommended":[{"id":"6759fc88a9b5bd0001989d30","uuid":"58632854-1031-4ac5-8fe3-87324337cbe7","title":"Bringing AI to the browser: SAM2 for interactive image segmentation","slug":"bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation","html":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\u003cp\u003eIn computer vision, image segmentation is crucial for object recognition, image editing, autonomous driving, and other common applications. The Segment Anything Model 2 (SAM2) pushes the boundaries of interactive image segmentation by allowing users to segment objects in images with minimal input.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTraditionally, running such models required powerful servers or specialized hardware. However, with advancements in web technologies and machine learning libraries, it's now possible to run complex models like SAM2 directly in a browser.\u003c/p\u003e\u003cp\u003eIn this article, we explore how to implement the SAM2 model in a web browser using ONNX Runtime Web (ort). We delve into the architecture of SAM2, how to load and run the model in a browser, and how to create an interactive user interface for real-time image segmentation.\u003c/p\u003e\u003ch2 id=\"understanding-the-sam2-architecture\"\u003eUnderstanding the SAM2 architecture\u003c/h2\u003e\u003ch3 id=\"encoder-decoder-framework\"\u003eEncoder-decoder framework\u003c/h3\u003e\u003cp\u003eSAM2 uses an encoder-decoder architecture:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEncoder:\u003c/strong\u003e Processes the input image to generate a high-dimensional embedding that captures essential features.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDecoder:\u003c/strong\u003e Takes the embedding and user-provided points (positive and negative) to generate segmentation masks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis architecture allows for interactive and highly accurate segmentation, while also allowing users to\u0026nbsp; iteratively refine the segmentation by adding more points.\u003c/p\u003e\u003ch3 id=\"why-run-sam2-in-the-browser\"\u003eWhy Run SAM2 in the Browser?\u003c/h3\u003e\u003cp\u003eRunning SAM2 in the browser offers several key benefits:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePrivacy:\u003c/strong\u003e Images are processed locally, ensuring user data isn't sent to external servers.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAccessibility:\u003c/strong\u003e Users can access the segmentation tool without installing specialized software.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInteractivity:\u003c/strong\u003e Real-time feedback enhances the user experience, allowing for quick iterations.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"implementing-the-encoder-encoderjs\"\u003eImplementing the encoder (encoder.js)\u003c/h2\u003e\u003ch3 id=\"initialization\"\u003eInitialization\u003c/h3\u003e\u003cp\u003eThe encoder loads the ONNX model and prepares it for inference:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003econst ENCODER_MODEL_URL = 'https://storage.googleapis.com/lb-artifacts-testing-public/sam2/sam2_hiera_tiny.encoder.ort';\n\nclass SAM2Encoder {\n  constructor() {\n    this.session = null;\n  }\n\n  async initialize() {\n    this.session = await ort.InferenceSession.create(ENCODER_MODEL_URL);\n    console.log('Encoder model loaded successfully');\n  }\n}\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"image-preprocessing\"\u003eImage preprocessing\u003c/h3\u003e\u003cp\u003eBefore passing the image to the encoder, it must be resized and normalized:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003e Resize:\u003c/strong\u003e Adjust the image to 1024x1024 pixels.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNormalize:\u003c/strong\u003e Scale pixel values to the [-1, 1] range.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eimageDataToTensor(image) {\n  const canvas = document.createElement('canvas');\n  const ctx = canvas.getContext('2d');\n  canvas.width = canvas.height = 1024;\n\n  ctx.drawImage(image, 0, 0, 1024, 1024);\n  const imageData = ctx.getImageData(0, 0, 1024, 1024).data;\n  const inputArray = new Float32Array(3 * 1024 * 1024);\n\n  for (let i = 0; i \u0026lt; 1024 * 1024; i++) {\n    inputArray[i] = (imageData[i * 4] / 255.0) * 2 - 1; // R channel\n    inputArray[i + 1024 * 1024] = (imageData[i * 4 + 1] / 255.0) * 2 - 1; // G channel\n    inputArray[i + 2 * 1024 * 1024] = (imageData[i * 4 + 2] / 255.0) * 2 - 1; // B channel\n  }\n\n  return new ort.Tensor('float32', inputArray, [1, 3, 1024, 1024]);\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"encoding-process\"\u003eEncoding process\u003c/h3\u003e\u003cp\u003eThe encode method runs the model and generates the image embedding:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003easync encode(image) {\n  const tensor = this.imageDataToTensor(image);\n  const feeds = { image: tensor };\n  const results = await this.session.run(feeds);\n  this.lastEmbeddings = results.image_embed;\n  return this.lastEmbeddings;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"implementing-the-decoder-decoderjs\"\u003eImplementing the decoder (decoder.js)\u003c/h2\u003e\u003ch3 id=\"initialization-1\"\u003eInitialization\u003c/h3\u003e\u003cp\u003eSimilar to the encoder, the decoder loads its ONNX model:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003econst DECODER_MODEL_URL = 'https://storage.googleapis.com/lb-artifacts-testing-public/sam2/sam2_hiera_tiny.decoder.onnx';\n\nclass SAM2Predictor {\n  constructor() {\n    this.session = null;\n  }\n\n  async initialize() {\n    this.session = await ort.InferenceSession.create(DECODER_MODEL_URL);\n    console.log('Decoder model loaded successfully');\n  }\n}\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"preparing-inputs\"\u003ePreparing inputs\u003c/h3\u003e\u003cp\u003eThe decoder requires several inputs, including the image embedding and user interaction points:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePoint coordinates (point_coords):\u003c/strong\u003e The (x, y) positions of user clicks.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePoint labels (point_labels):\u003c/strong\u003e Indicates positive (foreground) or negative (background) points.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMask input (mask_input):\u003c/strong\u003e An initial mask, set to zeros if not using a previous mask.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOther tensors:\u003c/strong\u003e Additional required inputs like has_mask_input, high_res_feats_0, and high_res_feats_1.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eprepareInputs(embedding, points) {\n  const numLabels = 1;\n  const numPoints = points.length;\n  const pointCoordsData = [];\n  const pointLabelsData = [];\n\n  for (let point of points) {\n    pointCoordsData.push([point.x, point.y]);\n    pointLabelsData.push(point.type);\n  }\n\n  return {\n    image_embed: embedding,\n    point_coords: new ort.Tensor('float32', Float32Array.from(pointCoordsData.flat()), [numLabels, numPoints, 2]),\n    point_labels: new ort.Tensor('float32', Float32Array.from(pointLabelsData), [numLabels, numPoints]),\n    mask_input: new ort.Tensor('float32', new Float32Array(numLabels * 1 * 256 * 256), [numLabels, 1, 256, 256]),\n    has_mask_input: new ort.Tensor('float32', new Float32Array([0.0]), [numLabels]),\n    high_res_feats_0: new ort.Tensor('float32', new Float32Array(1 * 32 * 256 * 256), [1, 32, 256, 256]),\n    high_res_feats_1: new ort.Tensor('float32', new Float32Array(1 * 64 * 128 * 128), [1, 64, 128, 128]),\n  };\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"prediction-process\"\u003ePrediction Process\u003c/h3\u003e\u003cp\u003eThe predict method runs the decoder model to generate the segmentation mask:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003easync predict(embedding, inputPoints) {\n  const inputs = this.prepareInputs(embedding, inputPoints);\n  const results = await this.session.run(inputs);\n  return results;\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"building-the-user-interface-appjs\"\u003eBuilding the user interface (app.js)\u003c/h2\u003e\u003ch3 id=\"setting-up-the-canvas\"\u003eSetting up the canvas\u003c/h3\u003e\u003cp\u003eWe use two HTML canvas elements:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSource canvas (sourceCanvas):\u003c/strong\u003e Displays the uploaded image and interaction points.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMask canvas (maskCanvas):\u003c/strong\u003e Overlays the segmentation mask.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"handling-user-interactions\"\u003eHandling user interactions\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003eImage upload\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWhen a user uploads an image two things happen:\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe image is drawn on the sourceCanvas.\u003c/li\u003e\u003cli\u003eThe encoder generates embeddings from the image.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eimageInput.addEventListener('change', async (e) =\u0026gt; {\n  // Load image and draw on canvas\n  // Encode the image\n  embedding = await encoder.encode(img);\n});\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eAdding interaction points\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eUsers can click on the image to add positive or negative points:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePositive points:\u003c/strong\u003e Indicate areas to include in the segmentation.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNegative points:\u003c/strong\u003e Indicate areas to exclude.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003esourceCanvas.addEventListener('click', async (e) =\u0026gt; {\n  const x = e.clientX - rect.left;\n  const y = e.clientY - rect.top;\n  const point = { x: x, y: y, type: isNegative ? 0 : 1 };\n  points.push(point);\n\n  // Draw point on canvas\n  drawPoint(sourceCtx, point);\n\n  // Run prediction\n  const results = await predictor.predict(embedding, points);\n\n  // Draw mask\n  drawMaskOnCanvas(maskCanvas, results['masks'], imageWidth, imageHeight);\n});\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eToggling point types\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eA button allows users to switch between positive and negative points:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003enegativeBtn.addEventListener('click', () =\u0026gt; {\n  isNegative = !isNegative;\n  negativeBtn.textContent = `Negative Points: ${isNegative ? 'ON' : 'OFF'}`;\n});\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"drawing-points-and-masks\"\u003eDrawing points and masks\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003eDrawing points\u003c/strong\u003e\u003c/p\u003e\u003cp\u003ePoints are drawn on the sourceCanvas to provide visual feedback:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003efunction drawPoint(ctx, point) {\n  ctx.fillStyle = point.type === 1 ? 'green' : 'red';\n  ctx.beginPath();\n  ctx.arc(point.x, point.y, 5, 0, 2 * Math.PI);\n  ctx.fill();\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eDrawing masks\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eMasks are drawn on the maskCanvas to display the segmentation result:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003efunction drawMaskOnCanvas(maskCanvas, maskData, imageWidth, imageHeight) {\n  // Process the mask tensor and draw it over the image\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"running-the-application\"\u003eRunning the application\u003c/h2\u003e\u003ch3 id=\"step-by-step-guide\"\u003eStep-by-step guide\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eSet up the server:\u003c/strong\u003e Start your local server to host the model files.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInclude scripts:\u003c/strong\u003e In your HTML file, include ort and your JavaScript modules.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOpen the application:\u003c/strong\u003e Access the HTML file through your browser.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUpload an image:\u003c/strong\u003e Use the file input to select an image.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInteract with the image:\u003c/strong\u003e Click on the image to add points and see the segmentation mask update in real-time.\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"demonstration\"\u003eDemonstration\u003c/h3\u003e\u003cp\u003eCheck out and play around with an interactive demo \u003ca href=\"https://storage.googleapis.com/lb-artifacts-testing-public/sam2/index.html?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003ehere\u003c/a\u003e. \u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eIn this article, we've demonstrated how to run the Segment Anything Model 2 (SAM2) directly in the web browser. By leveraging ONNX Runtime Web and thoughtful implementation of the encoder and decoder, we've created an interactive image segmentation tool that runs entirely on the user-side.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThis approach opens doors to privacy-preserving applications and makes advanced machine learning models more accessible. As web technologies continue to evolve, we can expect even more sophisticated models to run efficiently in the browser.\u003c/p\u003e\u003cp\u003eAt Quantumworks Lab, we’ve adopted a hybrid strategy, running SAM’s encoder on the server while executing its decoder right in the browser. This approach ensures real-time image segmentation, preserves user privacy, and expands access to cutting-edge machine learning. As web technologies advance, we look forward to delivering even more powerful models efficiently and securely in the browser.\u003c/p\u003e\u003ch2 id=\"check-out-these-additional-resources\"\u003eCheck out these additional resources:\u0026nbsp;\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eONNX Runtime Web Documentation:\u003c/strong\u003e \u003ca href=\"https://onnxruntime.ai/docs/api/javascript/index.html?ref=labelbox.ghost.io\"\u003e\u003cu\u003eONNX Runtime Web\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSAM2 Model Details:\u003c/strong\u003e \u003ca href=\"https://segment-anything.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eSegment Anything Model (SAM)\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGitHub Repository:\u003c/strong\u003e \u003ca href=\"https://github.com/Quantumworks Lab/sam2-web?ref=labelbox.ghost.io\"\u003e\u003cu\u003elink\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDemo:\u003c/strong\u003e \u003ca href=\"https://storage.googleapis.com/lb-artifacts-testing-public/sam2/index.html?ref=labelbox.ghost.io\"\u003e\u003cu\u003elink\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"6759fc88a9b5bd0001989d30","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Interactive-Image-Segmentation-in-the-Browser-with-SAM2.png","featured":false,"visibility":"public","created_at":"2024-12-11T12:56:40.000-08:00","updated_at":"2024-12-20T08:52:19.000-08:00","published_at":"2024-12-19T12:18:40.000-08:00","custom_excerpt":"Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"653030c34e99900001fc0531","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/using-computer-vision/"},{"id":"6700193d863cb90001f263ed","name":"Computer vision","slug":"computer-vision","description":"CV related features, best practices, and information","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/computer-vision/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"653030aa4e99900001fc052d","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/use-ai/"}],"authors":[{"id":"6764713c6f63bf0001f1ca64","name":"Stanislav Issayenko","slug":"stanislav","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/stanislav/"}],"primary_author":{"id":"6764713c6f63bf0001f1ca64","name":"Stanislav Issayenko","slug":"stanislav","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/stanislav/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/","excerpt":"Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6732aad9d02a4800018d3449","uuid":"472cfb24-5495-47f5-8d72-91aa098617b9","title":"Enhanced video editor adds  deeply nested classifications to improve visibility and efficiency","slug":"enhanced-labelbox-video-editors-adds-deeply-nested-classifications","html":"\u003cp\u003eIn response to customer feedback, we’ve added exciting new features to our video editor to improve data labeling visibility and efficiency. Key updates allow you to  create deeply nested classifications, to visualize classifications directly on the editor timeline, and to easily skip to specific frames. In addition, we've introduced a handful of essential fixes and enhancements to existing functionality.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRead on for details of how these updates are helping AI model builders accelerate and improve generative AI video tasks like text-to-video, video captioning, and more.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCreate and visualize deeply nested classifications\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eClassifications have been a core feature in the Quantumworks Lab video editor and ontology tools for years; however, they could not be arbitrarily nested. The lack of nested classifications made it difficult for you to create classification hierarchies that best reflected the real-world issues you want to model.\u0026nbsp;\u003c/p\u003e\u003cp\u003eFor example, imagine you are tasked with analyzing a large set of medical videos to find a variety of potential issues. You need to categorize the videos based on different medical conditions and then have sub-classifications under each to provide a more precise and granular analysis of the videos. Without this hierarchical formation, you would be limited to a flat structure, making it difficult to organize and search for specific segments within videos.\u003c/p\u003e\u003cp\u003eWith this update, you can now create complex classification hierarchies for any ontology!\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd_tI6qiXSky21dgMoZ4t9YuNnaim83j30bbC-Ga6WPrFALErmHByJwld_D32_RWtS_o_nwskImazNMOCXiCVOfq2wxO0xNnw6doFSD2ShBebAE_SuoWZE7jGos-vl8VREh0Odv?key=suV4c3bwYAUNwogpcRnWYF0d\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"589\" height=\"350\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eCreate as many sub-classifications as you need within a hierarchical format to label easier and more precisely.\u0026nbsp;\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn addition to the nested classifications, updates to the video editor make it easy to delete, edit, rearrange, and combine sub-classifications by visualizing per-frame classifications on the video editor’s timeline. You can view classes at a simple glance, helping streamline the annotation and review process. This is especially helpful for GenAI use cases like text-to-video and video-to-text.\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdJAU5P6v6iM8xUVMl80v8IG8IDWK_2pWMwF5KdOlJIzKzuCchKREaht72GVIhdKoa9i7bWCGq1Yp2PJjZWA_nxohYTwU4MxbjwWxroHeCElJ6uj8-_JPoar0YZTySXAaoUmPWFHQ?key=suV4c3bwYAUNwogpcRnWYF0d\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"681\" height=\"73\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eVisualize classifications at a glance directly on the video editor timeline.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eAdditional updates enhance the video labeling experience\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOther significant features to enhance your video labeling experiences include:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSkip N frames:\u003c/strong\u003e For longer videos with specific labeling needs (ex: labeling every 5th frame), users can select how many frames they want to skip.\u0026nbsp;\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eBug around toggle on/off feature addressed: \u003c/strong\u003eUsers can now accurately toggle on or off specific classifications in a given video.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDesigned to precisely annotate keyframes, these features provide the utmost flexibility, accuracy, and efficiency when labeling complex video data.\u003cem\u003e\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGet started today with video labeling\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eLabelbox is dedicated to continuous improvement based on customer feedback to make our tools the best it can be for your team. Ready to test out how to label your video data with ease? Simply \u003ca href=\"https://app.labelbox.com/home?_r=https://www.google.com/?utm_keyword=Quantumworks Lab\u0026utm_source=google\u0026utm_medium=paid-search\u0026utm_campaign=20490363302\u0026gclid=Cj0KCQiA57G5BhDUARIsACgCYnwYIWcntlazP2RZRqnKXOghCTuLTxFKOFiM7p_W8PWzao9Z6ACXQOkaAhPtEALw_wcB\u0026landingPageAnonymousId=%22ce322bab-56ea-43b8-a113-000851a3ebaf%22\u0026referrer_url=https://www.google.com/\"\u003e\u003cu\u003elogin to Quantumworks Lab\u003c/u\u003e\u003c/a\u003e, navigate to the Annotate tab, and select video as the data modality in your Quantumworks Lab platform homepage to get started. \u003c/p\u003e\u003cp\u003eIf you only have a few minutes, learn more about the power of deeply nested classifications in our video editor with this \u003ca href=\"https://app.arcade.software/flows/Du1WfyRQ8tllcLE8UBQK/view?ref=labelbox.ghost.io\"\u003e\u003cu\u003equick, click-through demo\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eContact our team anytime with questions or if you are ready to discuss your AI video labeling needs and discover how Quantumworks Lab might be able to help.\u003c/p\u003e","comment_id":"6732aad9d02a4800018d3449","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/11/human-in-the-loop-6.png","featured":false,"visibility":"public","created_at":"2024-11-11T17:09:45.000-08:00","updated_at":"2024-11-19T10:57:16.000-08:00","published_at":"2024-11-14T08:42:11.000-08:00","custom_excerpt":"Streamline video data labeling with new features for deeply nested classifications and overall improved video editor functionality.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"5e1517c870aad900380bc812","name":"Release Notes","slug":"release-notes","description":"IMPORTANT: Don't change the name of this Tag, it is referenced inside the theme's code in a way that filters out all of the posts that contain it.\nIf you want to change this name, you should also change it in the loop_index.hbs file in the theme's repository.","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/release-notes/"},{"id":"6700193d863cb90001f263ed","name":"Computer vision","slug":"computer-vision","description":"CV related features, best practices, and information","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/computer-vision/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"}],"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5e1517c870aad900380bc812","name":"Release Notes","slug":"release-notes","description":"IMPORTANT: Don't change the name of this Tag, it is referenced inside the theme's code in a way that filters out all of the posts that contain it.\nIf you want to change this name, you should also change it in the loop_index.hbs file in the theme's repository.","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/release-notes/"},"url":"https://labelbox.ghost.io/blog/enhanced-labelbox-video-editors-adds-deeply-nested-classifications/","excerpt":"Streamline video data labeling with new features for deeply nested classifications and overall improved video editor functionality.","reading_time":2,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"66f2d68a713a8e0001d391e0","uuid":"619359f2-9443-456c-8b37-f18c8dbefaeb","title":"Quantumworks Lab leaderboards: Redefining AI evaluation with private, transparent, and human-centric assessments","slug":"labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments","html":"\u003cp\u003eIn the rapidly evolving landscape of artificial intelligence, traditional benchmarks are no longer sufficient to capture the true capabilities of AI models. At Quantumworks Lab, we're excited to introduce our groundbreaking \u003ca href=\"https://labelbox.com/leaderboards/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eLabelbox leaderboards\u003c/a\u003e — an innovative, scientific process to rank multimodal AI models that goes beyond conventional benchmarks.\u003c/p\u003e\u003ch2 id=\"the-limitations-of-current-benchmarks-and-leaderboards\"\u003e\u003cstrong\u003eThe limitations of current benchmarks and leaderboards\u003c/strong\u003e\u003c/h2\u003e\u003ch3 id=\"benchmark-contamination\"\u003e\u003cstrong\u003eBenchmark contamination\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eOne of the most pressing issues in AI evaluation today is benchmark contamination. As large language models are trained on vast amounts of internet data, they often inadvertently include the very datasets used to evaluate them. This leads to inflated performance metrics that don't accurately reflect real-world capabilities. For example:\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe LAMBADA dataset, designed to test language understanding, has been found in the training data of several popular language models, with an \u003ca href=\"https://hitz-zentroa.github.io/lm-contamination/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLM Contamination Index\u003c/u\u003e\u003c/a\u003e of 29.3%.\u003c/li\u003e\u003cli\u003ePortions of the SQuAD question-answering dataset have been discovered in the pretraining corpora of multiple large language models.\u003c/li\u003e\u003cli\u003eEven coding benchmarks like HumanEval have seen their \u003ca href=\"https://arxiv.org/pdf/2407.07565?ref=labelbox.ghost.io\"\u003e\u003cu\u003esolutions leaked online\u003c/u\u003e\u003c/a\u003e, potentially contaminating future model training.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis contamination makes it increasingly difficult to trust traditional benchmark results, as models may be “cheating” by memorizing test data rather than demonstrating true understanding or capability.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-wide\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/09/Frame-4364-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"83\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/09/Frame-4364-2.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2024/09/Frame-4364-2.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2024/09/Frame-4364-2.png 1600w, https://labelbox.ghost.io/blog/content/images/size/w2400/2024/09/Frame-4364-2.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"\u003e\u003c/figure\u003e\u003ch3 id=\"existing-leaderboards-a-step-forward-but-not-enough\"\u003e\u003cstrong\u003eExisting leaderboards: A step forward, but not enough\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWhile several leaderboards have emerged to address the limitations of traditional benchmarks, they each come with their own set of challenges.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eLMSYS chatbot arena\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eLMSYS Chatbot Arena, despite its broad accessibility, faces notable challenges in providing objective AI evaluations. Its reliance on non-expert assessments and emphasis on chat-based evaluations may introduce personal biases, potentially favoring engaging responses over true intelligence. Researchers worry that this approach could lead companies to prioritize optimizing for superficial metrics rather than genuine real-world performance. Furthermore, LMSYS's commercial ties raise concerns about impartiality and the potential for an uneven evaluation playing field, as usage data may be selectively shared with certain partners. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003eScale AI's SEAL\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eScale’s Safety, Evaluations, and Alignment Lab (SEAL), released few months ago, offers detailed insights/evaluations for topics such as reasoning, coding, and agentic tool use. However, the infrequent updates and primary focus on language models, while useful, may not capture the full spectrum of rapidly advancing multimodal AI capabilities.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-wide\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-3.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"117\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/09/Leaderboard6-3.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2024/09/Leaderboard6-3.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2024/09/Leaderboard6-3.png 1600w, https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-3.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"\u003e\u003c/figure\u003e\u003ch2 id=\"challenges-in-ai-evaluation\"\u003e\u003cstrong\u003eChallenges in AI evaluation\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eThese and other existing leaderboards all run into core challenges with AI evaluations:\u003c/p\u003e\u003cp\u003e1) Data contamination and overfitting to public benchmarks\u003c/p\u003e\u003cp\u003e2) Scalability issues as models improve and more are added\u003c/p\u003e\u003cp\u003e3) Lack of standards for evaluation instructions and criteria\u003c/p\u003e\u003cp\u003e4) Difficulty in linking evaluation results to real-world outcomes\u003c/p\u003e\u003cp\u003e5) Potential bias in human evaluations\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-wide\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-1.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"117\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/09/Leaderboard6-1.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2024/09/Leaderboard6-1.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2024/09/Leaderboard6-1.png 1600w, https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-1.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"\u003e\u003c/figure\u003e\u003ch2 id=\"introducing-the-labelbox-leaderboards-a-comprehensive-approach-to-ai-evaluation\"\u003e\u003cstrong\u003eIntroducing the Quantumworks Lab leaderboards: A comprehensive approach to AI evaluation\u0026nbsp;\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eThe Quantumworks Lab leaderboards are the first to tackle these challenges by conducting structured evaluations on subjective AI model outputs using human experts and a scientific process that provides detailed feature-level metrics and multiple ratings. Leaderboards are available for \u003ca href=\"https://labelbox.com/leaderboards/image-generation/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eImage Generation\u003c/u\u003e\u003c/a\u003e, \u003ca href=\"https://labelbox.com/leaderboards/speech-generation?ref=labelbox.ghost.io\"\u003e\u003cu\u003eSpeech Generation\u003c/u\u003e\u003c/a\u003e, and \u003ca href=\"https://labelbox.com/leaderboards/video-generation?ref=labelbox.ghost.io\"\u003e\u003cu\u003eVideo Generation\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eOur goal is to go beyond traditional leaderboards and benchmarks by incorporating the following elements:\u003c/p\u003e\u003ch3 id=\"1-multimodal-and-niche-focus\"\u003e\u003cstrong\u003e1. Multimodal and niche focus\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eUnlike leaderboards that primarily focus on text-based large language models, we evaluate a diverse range of AI modalities and specialized applications, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eImage generation and analysis\u003c/li\u003e\u003cli\u003eAudio processing and synthesis\u003c/li\u003e\u003cli\u003eVideo creation and manipulation\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"2-expert-human-evaluation\"\u003e\u003cstrong\u003e2. Expert human evaluation\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eFor every evaluation, public or private, it’s critical for the raters to reflect your target audience. We place expert human judgment, using our \u003ca href=\"https://www.alignerr.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eAlignerr\u003c/u\u003e\u003c/a\u003e workforce, at the core of the evaluation process to ensure:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSubjective quality assessment:\u003c/strong\u003e Humans assess aspects like aesthetic appeal, realism, and expressiveness.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eContextual understanding:\u003c/strong\u003e Evaluators consider the broader context and intended use.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAlignment with human preferences:\u003c/strong\u003e Raters ensure evaluations reflect criteria that matter to end-users.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResistance to contamination:\u003c/strong\u003e Human evaluations on novel tasks are less prone to data contamination.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"3-reliable-and-transparent-methodology\"\u003e\u003cstrong\u003e3. Reliable and transparent methodology\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eWe are committed to performing trustworthy evaluations using a variety of sophisticated metrics. Quantumworks Lab balances privacy with openness by providing detailed feature-level metrics (e.g. prompt alignment, visual appeal, and numerical count for text-image models) and multiple ratings.\u003c/p\u003e\u003cp\u003eIn addition to critical human experts performing the evaluations, our methodology utilizes the Lablebox platform to generate advanced metrics on both the rater and model performance. We provide the following metrics across our three leaderboards:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eElo rating system:\u003c/strong\u003e Adapted from competitive chess, our Elo system provides a dynamic rating that adjusts based on head-to-head comparisons between models. This allows us to capture relative performance in a way that's responsive to improvements over time.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTrueSkill rating:\u003c/strong\u003e Originally developed for Xbox Live, TrueSkill offers a more nuanced rating that accounts for both a model's performance and the uncertainty in that performance. This is particularly useful for newer models or those with fewer evaluations.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRank percentages:\u003c/strong\u003e We track how often each model achieves each rank (1st through 5th) in direct comparisons. This provides insight into not just average performance, but consistency of top-tier results.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAverage rating:\u003c/strong\u003e A straightforward metric that gives an overall sense of model performance across all evaluations.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn addition to these key metrics, our methodology incorporates the following characteristics to ensure a balanced and fair evaluation:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eExpert evaluators:\u003c/strong\u003e Utilizing skilled professionals from our Alignerr platform to provide nuanced, context-aware assessments.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eComprehensive and novel datasets:\u003c/strong\u003e Curated to reflect real-world scenarios while minimizing contamination.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTransparent reporting:\u003c/strong\u003e Detailed insights into our methodologies and results without compromising proprietary information.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"4-continuously-updated-evaluations\"\u003e\u003cstrong\u003e4. Continuously updated evaluations\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eOur leaderboard isn't static; we plan to regularly update our evaluations to include the latest models and evaluation metrics, ensuring stakeholders have access to current and relevant information.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-wide\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6--1-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"118\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/09/Leaderboard6--1-.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2024/09/Leaderboard6--1-.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2024/09/Leaderboard6--1-.png 1600w, https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6--1-.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"\u003e\u003c/figure\u003e\u003ch2 id=\"leaderboard-insights-a-glimpse-into-model-performance\"\u003e\u003cstrong\u003eLeaderboard insights: A glimpse into model performance\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eTo illustrate the power of our comprehensive evaluation approach, let's look at some recent data from our image generation model leaderboard:\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfa7kVpchCn4HRb65trrs8ARip4Xqx5uupmK0fiXZe8XFGYXbML54GamuU5cKbnGrfNHHaid7ZbI_P-xgeJR6s4LlTiMfKRN6KPElewslEiG6VYtY2GOcAoQ_x2CzRyFhtMrGN010frmm4765Bo166qpA-a?key=3MFL55uQU4fOywJG4V4zzg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"295\"\u003e\u003c/figure\u003e\u003cp\u003e1) Elo ratings:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDALL-E 3 leads with 2825, followed by Flux 1.5 at 2763\u003c/li\u003e\u003cli\u003eDALL-E 3 consistently outperforms other models in head-to-head comparisons\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdSMyYD5nqyXxwYXLCQAFojIxWujns2fADF31BW059iKMW_RqKw1pzjNeWnGvDYPMIJ-E9xbzJAeQHWNk8Q5cHx12M1E0gKAE_KBjOu7CVbkAeRGzPfqbU4dnB7qE1pqDh7Rqbi-1gcmOMcBiOtH57f5v0?key=3MFL55uQU4fOywJG4V4zzg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"295\"\u003e\u003c/figure\u003e\u003cp\u003e2) TrueSkill ratings:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDALL-E 3 again leads with 1009.46, with Stable Diffusion 3 following at 988.26\u003c/li\u003e\u003cli\u003eThis indicates high expected performance for DALL-E 3 with relatively low uncertainty\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdH0YQGfMRC9ObK7k0Fs6Ade3D8onejY5vBMF5Gkhg5-qkspQJGAhiUYRLLyt8nJLb94N0_sXN0zoS30rhiFpUp09c3yBGOxUzX_IiGdwFASKsAfFAea1bd5VFAYs7I-EbXilVH9cwm-PVNLo3SBmD5mBVB?key=3MFL55uQU4fOywJG4V4zzg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"295\"\u003e\u003c/figure\u003e\u003cp\u003e3) Rank percentages:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDALL-E 3 achieves the top rank 27.07% of the time, followed by Ideogram 2 at 23.07%\u003c/li\u003e\u003cli\u003eThis shows DALL-E 3's consistency in achieving top results, but also highlights Ideogram 2's strong performance\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXciWSshu-Q0Fr1AR6nUTlEvZd3cObOlO5Lc0NjPV6nQH23WcBFuGG7bn-yhfeRz5TYlwtZX2ZAssCC8aSgtc4twAaNF3yVsxQ7SnwjstFd6Qmo7r-nJmwBDV3nouoZsyF45Utuc_W50rx9bcmyotbBSCGmm?key=3MFL55uQU4fOywJG4V4zzg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"295\"\u003e\u003c/figure\u003e\u003cp\u003e4) Average rank:\u003c/p\u003e\u003cul\u003e\u003cli\u003eImagen 3 slightly edges out DALL-E 3 with an average rating of 2.88 vs 2.89 (lower is better)\u003c/li\u003e\u003cli\u003eThis suggests Imagen 3 performs well in direct comparisons despite lower Elo and TrueSkill ratings\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese metrics provide a multi-faceted view of model performance, allowing users to understand not just which model is \"best\" overall, but which might be most suitable for their specific use case. For instance, while DALL-E 3 leads in most metrics, Imagen 3's strong average rating suggests it is a reliable choice for consistent performance across a range of tasks.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-wide\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-2.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"117\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/09/Leaderboard6-2.png 600w, https://labelbox.ghost.io/blog/content/images/size/w1000/2024/09/Leaderboard6-2.png 1000w, https://labelbox.ghost.io/blog/content/images/size/w1600/2024/09/Leaderboard6-2.png 1600w, https://labelbox.ghost.io/blog/content/images/2024/09/Leaderboard6-2.png 2400w\" sizes=\"(min-width: 1200px) 1200px\"\u003e\u003c/figure\u003e\u003ch2 id=\"join-the-revolution-beyond-the-benchmark\"\u003e\u003cstrong\u003eJoin the revolution: Beyond the benchmark\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eThe Quantumworks Lab leaderboards represent a significant advance in AI evaluation, pushing past traditional leaderboards by incorporating expert human evaluations for subjective generative AI models using comprehensive metrics. We are uniquely able to achieve this thanks to our modern AI data factory that combines human experts and our scalable platform with years of operational excellence evaluating AI models.\u003c/p\u003e\u003cp\u003eWe invite you to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCheck out the \u003ca href=\"http://labelbox.com/leaderboards?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003e\u003cu\u003eLabelbox leaderboards\u003c/u\u003e\u003c/a\u003e to explore our latest evaluations across various AI modalities and niche applications.\u003c/li\u003e\u003cli\u003e\u003ca href=\"mailto:leaderboard@labelbox.com\"\u003e\u003cu\u003eLet us know\u003c/u\u003e\u003c/a\u003e if you have suggestions or want a specific model included in future assessments.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/sales/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eContact us\u003c/u\u003e\u003c/a\u003e to learn more about how we can help you evaluate and improve your AI models across all modalities.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eReady to go beyond the benchmark? Let's redefine AI evaluation — together—and drive the field toward more meaningful, human-aligned progress that truly captures the capabilities of next-generation AI models.\u003c/p\u003e","comment_id":"66f2d68a713a8e0001d391e0","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/09/leaderboard_blog_hero.png","featured":false,"visibility":"public","created_at":"2024-09-24T08:11:06.000-07:00","updated_at":"2024-10-04T09:36:24.000-07:00","published_at":"2024-09-24T16:15:10.000-07:00","custom_excerpt":"Introducing our groundbreaking Quantumworks Lab leaderboards: an innovative, scientific process to rank multimodal AI models that goes beyond conventional benchmarks.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"65302ef44e99900001fc0519","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox.ghost.io/blog/tag/industry-any/"},{"id":"67001915863cb90001f263eb","name":"Partners","slug":"partners","description":"Partnerships and technical integrations between 3rd party solutions and Quantumworks Lab","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/partners/"}],"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},"url":"https://labelbox.ghost.io/blog/labelbox-leaderboards-redefining-ai-evaluation-with-private-transparent-and-human-centric-assessments/","excerpt":"Introducing our groundbreaking Quantumworks Lab leaderboards: an innovative, scientific process to rank multimodal AI models that goes beyond conventional benchmarks.","reading_time":6,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script>
    

    <footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>

                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="/static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer>
</body>
<!-- Mirrored from labelbox.com/blog/metas-segment-anything-2-0-is-now-available-in-labelbox-image-editor/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:27:29 GMT -->
</html>