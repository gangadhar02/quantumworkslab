<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:06:23 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">How to confidently compare, test, and evaluate models for machine learning</title><meta name="description" content="Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. " data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="How to confidently compare, test, and evaluate models for machine learning" data-next-head=""/><meta property="og:description" content="Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. " data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1-.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="How to confidently compare, test, and evaluate models for machine learning" data-next-head=""/><meta name="twitter:description" content="Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. " data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1-.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>June 29, 2023</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">How to confidently compare, test, and evaluate models for machine learning</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1-.png"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><p><em>This is the fourth post in a </em><a href="../model-foundry-automating-data-tasks-with-foundation-models/indexc625.html?ref=labelbox.ghost.io"><em>blog series</em></a><em> showcasing how </em><a href="../../product/model/foundry-models/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer"><em>Model Foundry</em></a><em> brings the power of foundation models into Labelbox. Learn how to leverage Quantumworks Lab for model comparison and A/B testing.</em></p><hr><h2 id="overview">Overview</h2><p>For many AI teams, the rise of off-the-shelf and foundation models has transformed the way they build and train models. Some can simply choose an existing model and fine-tune it for their specific requirements, making the AI development process much faster. Even if that's not possible for your use case, using foundation and off-the-shelf models can accelerate your process if you use them to pre-label data for your use case.</p><p>Choosing the best algorithm for the task, however, is key to ensuring the best results — starting with the wrong model can cause delays and less optimal model performance. That's why leading teams are adding a comprehensive model comparison process to their AI development workflow by evaluating different models based on performance metrics, how well the model performs on unseen data, and how well suited a model is to their ultimate business goals. Beyond measuring model performance, model comparison is useful in helping teams tracking ML experiments and creating a “store of record” for future reference and to help improve model performance. </p><p>While model comparison is a critical part of the ML workflow to ensure you’re using the best and most efficient model for your use case, ML teams encounter some common challenges during this process, such as:</p><ul><li>Confidently assessing the potential and limitations of pre-trained models</li><li>Visualizing models’ performance for comparison</li><li>Effectively sharing experiment results</li></ul><p>In this blog post, we’ll explore how you can tackle these challenges with <a href="../../product/model/foundry-models/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">Model Foundry</a>, a soon-to-be beta released solution from Quantumworks Lab that enables ML teams to better leverage foundation models for AI development.</p><h2 id="why-is-model-comparison-important">Why is model comparison important?</h2><p>A/B testing in machine learning allows teams to quickly experiment and iterate in order to improve and reach their business objectives. When it comes to leveraging foundation models, A/B testing can refer to evaluating how two models perform in production. </p><p>Foundation models are base models that are trained on inherent scale data and that act as a starting point for various downstream tasks or applications. A/B testing allows you to effectively assess the performance of different versions or variations of a foundation model. By comparing their effectiveness, you can determine which model performs better in terms of metrics such as accuracy, precision, or recall on your data and for your specific business use case. This approach also lets you systematically make improvements based on qualitative and quantitative metrics – allowing you to optimize the foundation model’s performance and enhance its capabilities over time. </p><p>However, effective A/B testing requires a platform that is not only able to provide sufficient metrics on assessing the performance of models, but one that also allows teams to share experiment findings and have a store of record. When models are evaluated, having a store of record of the model experiment is crucial so that a team can retrace the steps leading to the model selection and compare the next iteration of the model against the previous version.</p><h2 id="introducing-model-foundry">Introducing Model Foundry</h2><figure class="kg-card kg-image-card"><img src="../../../labelbox-guides.ghost.io/content/images/2023/06/Group-2616--2-.png" class="kg-image" alt="" loading="lazy" width="1501" height="845"></figure><p><br>Foundation models are changing the landscape of AI – automating complex tasks such as data labeling and enrichment. With <a href="../../product/model/foundry-models/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">Model Foundry</a>, teams have the ability to easily A/B test and compare a wide-range of open-source and third-party foundation models in a single platform. </p><p>You can test, compare, and evaluate models across various prompts and hyperparameters to confidently select the best model to perform pre-labeling or data enrichment tasks on your data. Selecting the best performing model on your data is crucial to continuously improving and scaling model performance in less time and at a lower cost. Regardless of your team’s AI maturity and business use case, you can experiment with foundation models in a no-code environment and continue to evaluate and iterate on model performance.</p><h3 id="access-the-world%E2%80%99s-best-ai-models">Access the world’s best AI models</h3><p>Model Foundry will feature various public and private models computer vision (CV) and natural language processing (NLP) use cases, such as SAM, YOLOv8, OWL-ViT, and GPT, as well as popular models from Google, OpenAI, Databricks, and Anthropic​​.</p><p>Automatically gain insight into how a specific model performs on a subset of data. Rather than doing this through a Colab notebook, quickly generate pre-labels from a chosen model in a few clicks and understand how a model performs on the given task.</p><h3 id="save-time-with-a-streamlined-ab-testing-framework">Save time with a streamlined A/B testing framework</h3><p>To conduct a comprehensive analysis of a model, it helps to be able to compare the predictions of each model with the original ground truth labels side-by-side. A <a href="https://docs.labelbox.com/docs/model-runs?ref=labelbox.ghost.io">model run</a> in Quantumworks Lab provides a versioned data snapshot of the data rows, annotations, and data splits for that given model run. At the end of each Model Foundry job, a model run will automatically be populated for your analysis. </p><p>As you continue iterating on your model and data, it is likely that you’ll end up with many model runs. The goal of comparing models is to measure and understand the marginal value of every machine learning iteration. Each model run is a versioned snapshot of an experiment that can be revisited and analyzed by your team at any given time. To make A/B testing even easier, Quantumworks Lab Model provides a model comparison view that allows you to visually compare the performance of two models as well as compare the two models with scalar and confusion metrics.</p><h3 id="dig-into-comprehensive-evaluation-metrics">Dig into comprehensive evaluation metrics</h3><p>In order to compare or ensure the effectiveness of a model, you need to understand how it has performed on the given task. Leveraging Quantumworks Lab’s Model, you can conduct a comprehensive analysis of a model’s performance with holistic metrics that evaluate its performance.</p><p>Dive into auto-generated quantitative model metrics, such as precision, recall, F-1 score, and more. To gain a deeper understanding of each model’s performance, it is important to analyze where the models are performing well and where they might be struggling. Model metrics are valuable in helping surface low-confident predictions, areas of agreement/disagreement between model predictions and ground truths, and can help your team analyze model performance, detect labeling mistakes, and find model errors. While most metrics are auto-generated by Quantumworks Lab, you can also update your own custom metrics depending on your specific use case.</p><h2 id="model-comparison-in-practice">Model comparison in practice</h2><p>Let’s take a look at a real-world example – comparing GPT-4 and Claude – two powerful LLMs developed to date. In this experiment, we will be comparing how these two models perform on a custom text datasets and systematically evaluate and compare their zero-shot predictive accuracy and generative ability.</p><h3 id="dataset-and-problem-setup">Dataset and problem setup</h3><p>For this experiment, we obtained 100 data points from the Kaggle <a href="https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots?ref=labelbox.ghost.io">Wikipedia Movie Plots</a> dataset, which provides detailed information on movie plots, genre, and more. We are interested in assessing the predictive capabilities of GPT-4 and Claude in determining the movie genre based on plot and also their ability to generate a suitable and concise summary. </p><p>To narrow the scope, we are only interested in the following categories: ‘comedy’, ‘animated’, ‘sci-fi’, ‘thriller’, ‘action’, ‘family’, ‘fantasy’, ‘horror’, ‘adventure’, and ‘drama’. We’ll also be evaluating models on their precision, recall, F1 scores, and confusion matrix.</p><h3 id="model-and-prompt-setup">Model and prompt setup</h3><p>When working with these models, creating effective prompts is important and there are a variety of techniques available for prompt engineering. For the purpose of this experiment, we chose to use simple prompt templates that clearly describe the ML task and the expected output format, which is a structured JSON format. This made it easy for us to incorporate the prompts into our existing workflows. To ensure a fair comparison, we used the exact same prompts for both models during evaluation.</p><p>The prompt without examples:</p><pre><code class="language-python">For this movie plot description, describe plot_summary, or answer N/A if you are not confident.The plot summary should be short 1 sentence description. Classify movie genres by picking one or more of the options: [comedy, animated, sci-fi, thriller, action, family, fantasy, horror, adventure, drama]. 
Return the result as a json: {"plot_summary" : "&lt;answer&gt;", "movie_genres" : ["&lt;prediction&gt;"]} 

{insert movie plot}</code></pre><p>The prompt above asks the LLM to provide one sentence summary to classify the movie genres and return the answer in a structured JSON format with the predicted text at the end. After specifying the prompt and running inference, we can automatically see the model outputs in a model run in Quantumworks Lab Model.</p><h3 id="findings-and-results">Findings and results</h3><p>Once the model job is complete, you can visualize and evaluate the results of the ChatGPT on product categorization and summary in Quantumworks Lab <a href="../../product/catalog/indexc625.html?ref=labelbox.ghost.io">Catalog</a> and <a href="../../product/model/indexc625.html?ref=labelbox.ghost.io">Model</a>.</p><p>In a model run, you can evaluate model results for a comprehensive view of quantitative and qualitative metrics. In the dropdown, you can select two model runs of your choice for comparison – Quantumworks Lab automatically assigns each model run a different color so that it can be distinguished in metrics and visualizations. </p><h3 id="quantitative-comparison">Quantitative comparison</h3><p>In our evaluation, we found that both models demonstrate impressive out-of-the-box zero-shot performance. Claude scored higher on the overall F-1 score, whereas GPT-4 scored higher on all other overall metric scores.</p><p><a href="https://docs.labelbox.com/docs/model-metrics?ref=labelbox.ghost.io" rel="noreferrer">Auto-generated metrics</a> provide a deeper understanding of each model’s performance, allowing for analysis on where the models performed well and where they might be struggling. By conducting an analysis by class, we can gain insight into specific areas where the models are successful and where they are falling short.</p><p>For example, although both models perform well in terms of recall for ‘sci-fi’ and ‘adventure’ genres for recall, they have a low precision score, indicating that both models are overly confident in assigning these labels to movie plots. As a result, only a small portion of sci-fi and adventure genre predictions correspond to the actual ground truth labels, contributing to the low precision score. This is also true for Claude’s performance in the fantasy genre.  </p><p>On the other hand, both models are very good at classifying ‘comedy’ genres. The genre ‘animated’ and family had a very small sample size of only one data point each, which isn’t sufficient for meaningful analysis.</p><h3 id="qualitative-comparison">Qualitative comparison</h3><p>Let’s now take a look at how GPT-4 and Claude summarize selected movie plots. Overall, both models performed well in being able to capture the movie plot in a single sentence, although they differed slightly in their level of consciousness and abstraction. Claude was able to generate shorter summaries, while GPT-4 was able to convey more captivating plot details. </p><p>Check out a few examples below:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;"><colgroup><col width="341"><col width="156"><col width="127"></colgroup><tbody><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Original Movie plot</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Claude Summary</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">GPT-4 summary&nbsp;</span></p></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Jesse Owens, a promising black American runner, attends Ohio State University, despite facing racial discrimination and slurs from the white athletes. He attracts the attention of coach Larry Snyder, who believes Owens has enormous potential but needs work on his form and technique. When Snyder suggests he is good enough to compete at the 1936 Berlin Olympic Games, Owens is interested, but hesitant because of racial propaganda in Nazi Germany. The U.S. Olympic Committee is already considering boycotting the Olympics over Germany's discriminatory policies, only agreeing to participate when Nazi official Joseph Goebbels gives personal assurances they will allow foreign athletes of any race to compete, as well as promising to rein in their propaganda.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">As Owens struggles to support his girlfriend Ruth and young daughter, he takes a job at a service station, upsetting Snyder when his job conflicts with his commitment to train. When Snyder learns Owens has a family to support, he gets him a no-show job, allowing him to focus on running. Owens goes on to break several records, including some of Snyder's, and begins a relationship with a woman whose attentions he attracts with his newfound fame. When Ruth threatens him with a lawsuit, Owens becomes distracted and loses a race to runner Eulace Peacock. Owens decides to return to Ruth to reconcile, convincing her to marry him. As the Olympics draw closer, the NAACP asks him not to go to Berlin for political reasons. Owens is conflicted, but Peacock urges him to compete to defy Nazi racial ideology.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">In Berlin, Owens wins his first gold medal in the 100 m dash, but when he is brought by International Olympic Committee member Avery Brundage to receive congratulations from Adolf Hitler, he is told the Chancellor has left the stadium early to avoid traffic. Brundage warns Goebbels that Hitler must congratulate all winners or no winners, with Goebbels replying Hitler will not appear with "that". Owens next qualifies for the broad jump after German rival Luz Long unexpectedly gives him tips on his technique. Owens wins another medal, and Luz publicly shakes his hand and joins him for a victory lap, privately expressing concern about national politics. Owens wins his fourth and final medal in the 4 x 100 m relay, filling in for two Jewish American athletes cut by Brundage, who is convinced by Goebbels to do so to avoid a scandal over a business arrangement Brundage entered with the Nazis before the games. Director Leni Riefenstahl films the event against Goebbels' orders, then asks Owens to repeat his medal-winning broad jump to get a few more shots for her next film, Olympia.</span></p><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Jesse Owens, a promising black sprinter, faces discrimination while attending Ohio State University in the 1930s. He qualifies for the 1936 Berlin Olympics, where he wins four gold medals, defeating Nazi propaganda about Aryan supremacy.</span></p><br><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Jesse Owens, a talented black American runner, overcomes racial discrimination and personal struggles to win four gold medals at the 1936 Berlin Olympics, defying Nazi propaganda and racial ideology.</span></p><br></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Bernard "Bernie" Webber, a crewman at the Coast Guard station in Chatham, Massachusetts, on Cape Cod, has fallen in love with a local girl, Miriam Pentinen. The two plan to marry on April 16, but in accordance with Coast Guard regulations, Bernie must seek permission from the station's commander, Daniel Cluff. On the day he is due to ask permission, the oil tanker SS Pendleton shears in half off the Chatham coast after getting caught in a nor'easter. With the majority of the station's crew already underway with the rescue of the similarly damaged SS Fort Mercer, Bernie is dispatched to pilot motor lifeboat CG 36500 to rescue the crew of Pendleton. Andrew Fitzgerald, Ervin Maske, and Richard P. Livesey volunteer to join Bernie on the rescue mission.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Meanwhile, the Pendleton's engineer, Ray Sybert, as the surviving senior officer, organizes the surviving seamen to steer the sinking stern of the tanker onto a submerged reef, where it can lodge until rescuers arrive.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">When Miriam hears that Bernie is leading the rescue effort, she, like a number of townspeople, thinks this is a suicide mission. Few people in Chatham trust Cluff, since he is not from the area and does not know its treacherous weather. Miriam drives to the station, demanding that Cluff call Bernie back. Cluff refuses, and brusquely orders Miriam out.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Between the Chatham harbor and the open sea lies a bar, a series of shoals that are very dangerous even in good weather. Bernie must time bursts of his engine to ride each approaching wave before it breaks as he pilots CG 36500 across the bar. Although he makes it over the bar, he loses his compass.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Bernie steers CG 36500 to the stricken tanker. Although his boat's designated capacity is only 12 people, Bernie manages to rescue 32 crewmen. The stern of Pendleton begins sinking more rapidly during the rescue and goes down shortly after the last crewman comes aboard Bernie's boat. Relying on his knowledge of the coast and prevailing winds in place of his compass, Bernie steers CG 36500 toward home—a task made more difficult as Chatham loses power. Miriam and the other townspeople drive their cars to the pier and turn on their headlights to guide Bernie in.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">The film shows photographs from the event that briefly document the aftermath of the rescue. Two months later, Bernie and Miriam marry; they stay together for 58 years until Bernie's death in 2009. Webber and his crew receive the Gold Lifesaving Medal.</span></p><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">A small Coast Guard crew conducts a dangerous rescue mission in a storm to save the lives of 32 crewmen from an oil tanker that has split in half.</span></p><br><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">In a dangerous rescue mission, Coast Guard crewman Bernie Webber and his team save 32 crewmen from an oil tanker split in half during a storm, using only their knowledge of the coast to navigate and return home.</span></p><br><br></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Flamboyant television financial expert Lee Gates is in the midst of the latest edition of his show, Money Monster. Less than 24 hours earlier, IBIS Clear Capital's stock inexplicably cratered, apparently due to a glitch in a trading algorithm, costing investors $800 million. Lee planned to have IBIS CEO Walt Camby appear for an interview about the crash, but Camby unexpectedly left for a business trip to Geneva.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Midway through the show, a deliveryman wanders onto the set, pulls a gun and takes Lee hostage, forcing him to put on a vest laden with explosives. He is Kyle Budwell, who invested $60,000—his entire life savings—in IBIS after Lee endorsed the company on the show. Kyle was wiped out along with the other investors. Unless he gets some answers, he will blow up Lee before killing himself. Once police are notified, they discover that the receiver to the bomb's vest is located over Lee's kidney. The only way to destroy the receiver—and with it, Kyle's leverage—is to shoot Lee and hope he survives.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">With the help of longtime director Patty Fenn, Lee tries to calm Kyle and find Camby for him, though Kyle is not satisfied when both Lee and IBIS chief communications officer Diane Lester offer to compensate him for his financial loss. He also is not satisfied by Diane's insistence that the algorithm is to blame. Diane is not satisfied by her own explanation, either, and defies colleagues to contact a programmer who created the algorithm, Won Joon. Reached in Seoul, Joon insists that an algorithm could not take such a large, lopsided position unless someone meddled with it.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Lee appeals to his TV viewers for help, seeking to recoup the lost investment, but is dejected by their response. New York City police find Kyle's pregnant girlfriend Molly and allow her to talk to Kyle through a video feed. When she learns that he lost everything, she viciously berates him before the police cut the feed. Lee, seemingly taking pity on Kyle, agrees to help his captor discover what went wrong.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Once Camby finally returns, Diane flips through his passport, discovering that he did not go to Geneva but to Johannesburg. With this clue, along with messages from Camby's phone, Patty and the Money Monster team contact a group of Icelandic hackers to seek the truth. After a police sniper takes a shot at Lee and misses, he and Kyle resolve to corner Camby at Federal Hall National Memorial, where Camby is headed according to Diane. They head out with one of the network's cameramen, Lenny, plus the police and a mob of fans and jeerers alike. Kyle accidentally shoots and wounds producer Ron Sprecher when Ron throws Lee a new earpiece. Kyle and Lee finally confront Camby with video evidence obtained by the hackers.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">It turns out that Camby bribed a South African miners' union, planning to have IBIS make an $800 million investment in a platinum mine while the union was on strike. The strike lowered the mine's owners stock, allowing Camby to buy it at a low price. If Camby's plan had succeeded, IBIS would have generated a multibillion-dollar profit when work resumed at the mine and the stock of the mine's owner rose again. The gambit backfired when the union stayed on the picket line. Camby attempted to bribe the union leader, Moshe Mambo, in order to stop the strike, but Mambo refused and continued the strike, causing IBIS' stock to sink under the weight of its position in the flailing company.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Despite the evidence, Camby refuses to admit his swindle until Kyle takes the explosive vest off Lee and puts it on him. Camby admits to his wrongdoing to Kyle on live camera. Satisfied with the outcome, Kyle throws the detonator away, then much to Lee's dismay gets fatally shot by the police. In the aftermath, the SEC announces that IBIS will be put under investigation, while Camby is charged with violations of the Foreign Corrupt Practices Act.</span></p></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">A financial TV host is taken hostage while on air by a man whose life savings were lost when the stock of a company the host had endorsed crashed.</span></p><br><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">A disgruntled investor takes a financial TV host hostage on air, demanding the truth behind a recent stock market crash, ultimately unraveling a corporate conspiracy.</span></p></td></tr><tr style="height:0pt"><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">When the Little Red-Haired Girl moves into his neighborhood, Charlie Brown becomes infatuated with her, though worries his long-running streak of failures will prevent her from noticing him. After Lucy tells him he should try being more confident, Charlie Brown decides to embark upon a series of new activities in hope of finding one that will get the Little Red-Haired Girl to notice him. His first attempt is to participate in the school's talent show with a magic act, helped by Snoopy and Woodstock. However, when Sally's act goes wrong, Charlie Brown sacrifices his time for her, rescues his sister from being humiliated, and is humiliated himself in return. Attempting to impress the Little Red-Haired Girl with his dance skills, Charlie Brown signs up for the school dance and gets Snoopy to teach him all his best moves. At the dance, Charlie Brown attracts praise for his skills but slips and sets off the sprinkler system, causing the dance to be cut short and all the other students to look down upon him once more.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Charlie Brown is partnered with the Little Red-Haired Girl to write a book report. At first, he is excited to have a chance to be with her, but she is called away for a week to deal with a family illness, leaving Charlie Brown to write the report all by himself. Hoping to impress both the Little Red-Haired Girl and his teacher, Charlie Brown writes his report on the collegiate-level novel War and Peace. At the same time, Charlie Brown finds he is the only student to get a perfect score on a standardized test. His friends and the other students congratulate him, and his popularity begins to climb. When he goes to accept a medal at a school assembly, however, he learns the test papers are accidentally mixed up and the perfect score actually belongs to Peppermint Patty; Charlie Brown declines the medal, losing all his new-found popularity. His book report is destroyed by a Red Baron model plane, and he admits to the Little Red-Haired Girl he has caused them to both fail the assignment.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Before leaving school for the summer, Charlie Brown is surprised when the Little Red-Haired Girl chooses him for a pen pal. Linus convinces Charlie Brown he needs to tell the Little Red-Haired Girl how he feels about her before she leaves for the summer. Racing to her house, he discovers she is about to leave on a bus for summer camp. He tries to chase the bus but is prevented from reaching it. Just as he is about to give up, thinking the whole world is against him, Charlie Brown sees a kite fall from the Kite-Eating Tree. The string becomes entangled around his waist and sails away with him. Amazed to see Charlie Brown flying a kite, his friends follow.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Upon reaching the bus, Charlie Brown finally asks the Little Red-Haired Girl why she has chosen him in spite of his failures. The Little Red-Haired Girl explains she admires his selflessness and his determination and praises him as an honest, caring, and compassionate person. The two promise to write to one another; the other children congratulate him as a true friend and carry him off.</span></p><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">In a subplot, after finding a typewriter in the school dumpster, Snoopy writes a novel about the World War I Flying Ace, trying to save Fifi from the Red Baron with Woodstock and his friends' help, using the key events and situations surrounding Charlie Brown as inspiration to develop his story. He acts out his adventure physically, pulling himself across a line of lights, and, imagining it as a rope across a broken bridge, he comes across Charlie Brown and the gang several times along the way. Snoopy defeats the Red Baron and rescues Fifi from an airplane. When Lucy finishes reading, she calls it the dumbest story she has ever read, so Snoopy throws the typewriter at her in retaliation and kisses her nose causing her to run away in disgust yelling that she has "dog germs".</span></p><br><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Charlie Brown tries to impress the Little Red-Haired Girl in various ways, but fails; however, she admires him for his kindness and they become pen pals.</span></p><br></td><td style="border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Charlie Brown embarks on various activities to gain the attention of the Little Red-Haired Girl, eventually winning her admiration through his selflessness and determination.</span></p><br><br></td></tr></tbody></table>
<!--kg-card-end: html-->
<p><br>For additional learning and to view another model comparison example, check out our recent <a href="../gpt4-vs-palm-assessing-performance-of-llm-models/indexc625.html?ref=labelbox.ghost.io">blog post on GPT-4 vs PaLM</a>.</p><h2 id="conclusion">Conclusion</h2><p>In conclusion, the availability of off-the-shelf foundation models has introduced breakthroughs in AI development by reducing the barrier to kick-start model development. Teams of any AI maturity can speed up their development process by selecting the most suitable foundation model for their specific use case. The key to maximizing iteration cycles lies in selecting the right algorithm and conducting a comprehensive model comparison process to assess the model’s alignment with business goals. While confidently evaluating pre-trained models can be challenging, Quantumworks Lab Model and Model Foundry provide ML teams with the tools to effectively compare, evaluate, and leverage foundation models for AI development.</p><hr><p></p><p><em>Quantumworks Lab recently announced </em><a href="../../product/model/foundry-models/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer"><em>access to Model Foundry</em></a><em> – the easiest place to build model prediction workflows based on your use case, integrate model results with your labeling workflow, and compare and evaluate model results.</em></p></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index4144.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Dmytro Apollonin<span class="mx-2">•</span>December 20, 2024</p></div><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Code Runner: Secure, scalable code execution for model evaluation</p><p class="text-base max-w-2xl undefined line-clamp-3">Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index447c.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FInteractive-Image-Segmentation-in-the-Browser-with-SAM2.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Stanislav Issayenko<span class="mx-2">•</span>December 19, 2024</p></div><a href="../bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Bringing AI to the browser: SAM2 for interactive image segmentation</p><p class="text-base max-w-2xl undefined line-clamp-3">Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../inside-the-matrix-a-look-into-the-math-behind-ai/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index45ff.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Michał Jóźwiak<span class="mx-2">•</span>December 11, 2024</p></div><a href="../inside-the-matrix-a-look-into-the-math-behind-ai/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Inside the matrix: A look into the math behind AI</p><p class="text-base max-w-2xl undefined line-clamp-3">Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"how-to-confidently-compare-test-and-evaluate-models-for-machine-learning","id":"649c9b7f1f77de00014de9bc","uuid":"906c8ba9-ff15-4c42-aa33-f77cce899a19","title":"How to confidently compare, test, and evaluate models for machine learning","html":"\u003cp\u003e\u003cem\u003eThis is the fourth post in a \u003c/em\u003e\u003ca href=\"https://labelbox.com/blog/model-foundry-automating-data-tasks-with-foundation-models/?ref=labelbox.ghost.io\"\u003e\u003cem\u003eblog series\u003c/em\u003e\u003c/a\u003e\u003cem\u003e showcasing how \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/model/foundry-models/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003e\u003cem\u003eModel Foundry\u003c/em\u003e\u003c/a\u003e\u003cem\u003e brings the power of foundation models into Labelbox. Learn how to leverage Quantumworks Lab for model comparison and A/B testing.\u003c/em\u003e\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\u003cp\u003eFor many AI teams, the rise of off-the-shelf and foundation models has transformed the way they build and train models. Some can simply choose an existing model and fine-tune it for their specific requirements, making the AI development process much faster. Even if that's not possible for your use case, using foundation and off-the-shelf models can accelerate your process if you use them to pre-label data for your use case.\u003c/p\u003e\u003cp\u003eChoosing the best algorithm for the task, however, is key to ensuring the best results — starting with the wrong model can cause delays and less optimal model performance. That's why leading teams are adding a comprehensive model comparison process to their AI development workflow by evaluating different models based on performance metrics, how well the model performs on unseen data, and how well suited a model is to their ultimate business goals. Beyond measuring model performance, model comparison is useful in helping teams tracking ML experiments and creating a “store of record” for future reference and to help improve model performance. \u003c/p\u003e\u003cp\u003eWhile model comparison is a critical part of the ML workflow to ensure you’re using the best and most efficient model for your use case, ML teams encounter some common challenges during this process, such as:\u003c/p\u003e\u003cul\u003e\u003cli\u003eConfidently assessing the potential and limitations of pre-trained models\u003c/li\u003e\u003cli\u003eVisualizing models’ performance for comparison\u003c/li\u003e\u003cli\u003eEffectively sharing experiment results\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn this blog post, we’ll explore how you can tackle these challenges with \u003ca href=\"https://labelbox.com/product/model/foundry-models/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eModel Foundry\u003c/a\u003e, a soon-to-be beta released solution from Quantumworks Lab that enables ML teams to better leverage foundation models for AI development.\u003c/p\u003e\u003ch2 id=\"why-is-model-comparison-important\"\u003eWhy is model comparison important?\u003c/h2\u003e\u003cp\u003eA/B testing in machine learning allows teams to quickly experiment and iterate in order to improve and reach their business objectives. When it comes to leveraging foundation models, A/B testing can refer to evaluating how two models perform in production. \u003c/p\u003e\u003cp\u003eFoundation models are base models that are trained on inherent scale data and that act as a starting point for various downstream tasks or applications. A/B testing allows you to effectively assess the performance of different versions or variations of a foundation model. By comparing their effectiveness, you can determine which model performs better in terms of metrics such as accuracy, precision, or recall on your data and for your specific business use case. This approach also lets you systematically make improvements based on qualitative and quantitative metrics – allowing you to optimize the foundation model’s performance and enhance its capabilities over time. \u003c/p\u003e\u003cp\u003eHowever, effective A/B testing requires a platform that is not only able to provide sufficient metrics on assessing the performance of models, but one that also allows teams to share experiment findings and have a store of record. When models are evaluated, having a store of record of the model experiment is crucial so that a team can retrace the steps leading to the model selection and compare the next iteration of the model against the previous version.\u003c/p\u003e\u003ch2 id=\"introducing-model-foundry\"\u003eIntroducing Model Foundry\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox-guides.ghost.io/content/images/2023/06/Group-2616--2-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1501\" height=\"845\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cbr\u003eFoundation models are changing the landscape of AI – automating complex tasks such as data labeling and enrichment. With \u003ca href=\"https://labelbox.com/product/model/foundry-models/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eModel Foundry\u003c/a\u003e, teams have the ability to easily A/B test and compare a wide-range of open-source and third-party foundation models in a single platform. \u003c/p\u003e\u003cp\u003eYou can test, compare, and evaluate models across various prompts and hyperparameters to confidently select the best model to perform pre-labeling or data enrichment tasks on your data. Selecting the best performing model on your data is crucial to continuously improving and scaling model performance in less time and at a lower cost. Regardless of your team’s AI maturity and business use case, you can experiment with foundation models in a no-code environment and continue to evaluate and iterate on model performance.\u003c/p\u003e\u003ch3 id=\"access-the-world%E2%80%99s-best-ai-models\"\u003eAccess the world’s best AI models\u003c/h3\u003e\u003cp\u003eModel Foundry will feature various public and private models computer vision (CV) and natural language processing (NLP) use cases, such as SAM, YOLOv8, OWL-ViT, and GPT, as well as popular models from Google, OpenAI, Databricks, and Anthropic​​.\u003c/p\u003e\u003cp\u003eAutomatically gain insight into how a specific model performs on a subset of data. Rather than doing this through a Colab notebook, quickly generate pre-labels from a chosen model in a few clicks and understand how a model performs on the given task.\u003c/p\u003e\u003ch3 id=\"save-time-with-a-streamlined-ab-testing-framework\"\u003eSave time with a streamlined A/B testing framework\u003c/h3\u003e\u003cp\u003eTo conduct a comprehensive analysis of a model, it helps to be able to compare the predictions of each model with the original ground truth labels side-by-side. A \u003ca href=\"https://docs.labelbox.com/docs/model-runs?ref=labelbox.ghost.io\"\u003emodel run\u003c/a\u003e in Quantumworks Lab provides a versioned data snapshot of the data rows, annotations, and data splits for that given model run. At the end of each Model Foundry job, a model run will automatically be populated for your analysis. \u003c/p\u003e\u003cp\u003eAs you continue iterating on your model and data, it is likely that you’ll end up with many model runs. The goal of comparing models is to measure and understand the marginal value of every machine learning iteration. Each model run is a versioned snapshot of an experiment that can be revisited and analyzed by your team at any given time. To make A/B testing even easier, Quantumworks Lab Model provides a model comparison view that allows you to visually compare the performance of two models as well as compare the two models with scalar and confusion metrics.\u003c/p\u003e\u003ch3 id=\"dig-into-comprehensive-evaluation-metrics\"\u003eDig into comprehensive evaluation metrics\u003c/h3\u003e\u003cp\u003eIn order to compare or ensure the effectiveness of a model, you need to understand how it has performed on the given task. Leveraging Quantumworks Lab’s Model, you can conduct a comprehensive analysis of a model’s performance with holistic metrics that evaluate its performance.\u003c/p\u003e\u003cp\u003eDive into auto-generated quantitative model metrics, such as precision, recall, F-1 score, and more. To gain a deeper understanding of each model’s performance, it is important to analyze where the models are performing well and where they might be struggling. Model metrics are valuable in helping surface low-confident predictions, areas of agreement/disagreement between model predictions and ground truths, and can help your team analyze model performance, detect labeling mistakes, and find model errors. While most metrics are auto-generated by Quantumworks Lab, you can also update your own custom metrics depending on your specific use case.\u003c/p\u003e\u003ch2 id=\"model-comparison-in-practice\"\u003eModel comparison in practice\u003c/h2\u003e\u003cp\u003eLet’s take a look at a real-world example – comparing GPT-4 and Claude – two powerful LLMs developed to date. In this experiment, we will be comparing how these two models perform on a custom text datasets and systematically evaluate and compare their zero-shot predictive accuracy and generative ability.\u003c/p\u003e\u003ch3 id=\"dataset-and-problem-setup\"\u003eDataset and problem setup\u003c/h3\u003e\u003cp\u003eFor this experiment, we obtained 100 data points from the Kaggle \u003ca href=\"https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots?ref=labelbox.ghost.io\"\u003eWikipedia Movie Plots\u003c/a\u003e dataset, which provides detailed information on movie plots, genre, and more. We are interested in assessing the predictive capabilities of GPT-4 and Claude in determining the movie genre based on plot and also their ability to generate a suitable and concise summary. \u003c/p\u003e\u003cp\u003eTo narrow the scope, we are only interested in the following categories: ‘comedy’, ‘animated’, ‘sci-fi’, ‘thriller’, ‘action’, ‘family’, ‘fantasy’, ‘horror’, ‘adventure’, and ‘drama’. We’ll also be evaluating models on their precision, recall, F1 scores, and confusion matrix.\u003c/p\u003e\u003ch3 id=\"model-and-prompt-setup\"\u003eModel and prompt setup\u003c/h3\u003e\u003cp\u003eWhen working with these models, creating effective prompts is important and there are a variety of techniques available for prompt engineering. For the purpose of this experiment, we chose to use simple prompt templates that clearly describe the ML task and the expected output format, which is a structured JSON format. This made it easy for us to incorporate the prompts into our existing workflows. To ensure a fair comparison, we used the exact same prompts for both models during evaluation.\u003c/p\u003e\u003cp\u003eThe prompt without examples:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003eFor this movie plot description, describe plot_summary, or answer N/A if you are not confident.The plot summary should be short 1 sentence description. Classify movie genres by picking one or more of the options: [comedy, animated, sci-fi, thriller, action, family, fantasy, horror, adventure, drama]. \nReturn the result as a json: {\"plot_summary\" : \"\u0026lt;answer\u0026gt;\", \"movie_genres\" : [\"\u0026lt;prediction\u0026gt;\"]} \n\n{insert movie plot}\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe prompt above asks the LLM to provide one sentence summary to classify the movie genres and return the answer in a structured JSON format with the predicted text at the end. After specifying the prompt and running inference, we can automatically see the model outputs in a model run in Quantumworks Lab Model.\u003c/p\u003e\u003ch3 id=\"findings-and-results\"\u003eFindings and results\u003c/h3\u003e\u003cp\u003eOnce the model job is complete, you can visualize and evaluate the results of the ChatGPT on product categorization and summary in Quantumworks Lab \u003ca href=\"https://labelbox.com/product/catalog/?ref=labelbox.ghost.io\"\u003eCatalog\u003c/a\u003e and \u003ca href=\"https://labelbox.com/product/model/?ref=labelbox.ghost.io\"\u003eModel\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn a model run, you can evaluate model results for a comprehensive view of quantitative and qualitative metrics. In the dropdown, you can select two model runs of your choice for comparison – Quantumworks Lab automatically assigns each model run a different color so that it can be distinguished in metrics and visualizations. \u003c/p\u003e\u003ch3 id=\"quantitative-comparison\"\u003eQuantitative comparison\u003c/h3\u003e\u003cp\u003eIn our evaluation, we found that both models demonstrate impressive out-of-the-box zero-shot performance. Claude scored higher on the overall F-1 score, whereas GPT-4 scored higher on all other overall metric scores.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://docs.labelbox.com/docs/model-metrics?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eAuto-generated metrics\u003c/a\u003e provide a deeper understanding of each model’s performance, allowing for analysis on where the models performed well and where they might be struggling. By conducting an analysis by class, we can gain insight into specific areas where the models are successful and where they are falling short.\u003c/p\u003e\u003cp\u003eFor example, although both models perform well in terms of recall for ‘sci-fi’ and ‘adventure’ genres for recall, they have a low precision score, indicating that both models are overly confident in assigning these labels to movie plots. As a result, only a small portion of sci-fi and adventure genre predictions correspond to the actual ground truth labels, contributing to the low precision score. This is also true for Claude’s performance in the fantasy genre.  \u003c/p\u003e\u003cp\u003eOn the other hand, both models are very good at classifying ‘comedy’ genres. The genre ‘animated’ and family had a very small sample size of only one data point each, which isn’t sufficient for meaningful analysis.\u003c/p\u003e\u003ch3 id=\"qualitative-comparison\"\u003eQualitative comparison\u003c/h3\u003e\u003cp\u003eLet’s now take a look at how GPT-4 and Claude summarize selected movie plots. Overall, both models performed well in being able to capture the movie plot in a single sentence, although they differed slightly in their level of consciousness and abstraction. Claude was able to generate shorter summaries, while GPT-4 was able to convey more captivating plot details. \u003c/p\u003e\u003cp\u003eCheck out a few examples below:\u003c/p\u003e\n\u003c!--kg-card-begin: html--\u003e\n\u003ctable style=\"border:none;border-collapse:collapse;\"\u003e\u003ccolgroup\u003e\u003ccol width=\"341\"\u003e\u003ccol width=\"156\"\u003e\u003ccol width=\"127\"\u003e\u003c/colgroup\u003e\u003ctbody\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eOriginal Movie plot\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eClaude Summary\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eGPT-4 summary\u0026nbsp;\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eJesse Owens, a promising black American runner, attends Ohio State University, despite facing racial discrimination and slurs from the white athletes. He attracts the attention of coach Larry Snyder, who believes Owens has enormous potential but needs work on his form and technique. When Snyder suggests he is good enough to compete at the 1936 Berlin Olympic Games, Owens is interested, but hesitant because of racial propaganda in Nazi Germany. The U.S. Olympic Committee is already considering boycotting the Olympics over Germany's discriminatory policies, only agreeing to participate when Nazi official Joseph Goebbels gives personal assurances they will allow foreign athletes of any race to compete, as well as promising to rein in their propaganda.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eAs Owens struggles to support his girlfriend Ruth and young daughter, he takes a job at a service station, upsetting Snyder when his job conflicts with his commitment to train. When Snyder learns Owens has a family to support, he gets him a no-show job, allowing him to focus on running. Owens goes on to break several records, including some of Snyder's, and begins a relationship with a woman whose attentions he attracts with his newfound fame. When Ruth threatens him with a lawsuit, Owens becomes distracted and loses a race to runner Eulace Peacock. Owens decides to return to Ruth to reconcile, convincing her to marry him. As the Olympics draw closer, the NAACP asks him not to go to Berlin for political reasons. Owens is conflicted, but Peacock urges him to compete to defy Nazi racial ideology.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eIn Berlin, Owens wins his first gold medal in the 100 m dash, but when he is brought by International Olympic Committee member Avery Brundage to receive congratulations from Adolf Hitler, he is told the Chancellor has left the stadium early to avoid traffic. Brundage warns Goebbels that Hitler must congratulate all winners or no winners, with Goebbels replying Hitler will not appear with \"that\". Owens next qualifies for the broad jump after German rival Luz Long unexpectedly gives him tips on his technique. Owens wins another medal, and Luz publicly shakes his hand and joins him for a victory lap, privately expressing concern about national politics. Owens wins his fourth and final medal in the 4 x 100 m relay, filling in for two Jewish American athletes cut by Brundage, who is convinced by Goebbels to do so to avoid a scandal over a business arrangement Brundage entered with the Nazis before the games. Director Leni Riefenstahl films the event against Goebbels' orders, then asks Owens to repeat his medal-winning broad jump to get a few more shots for her next film, Olympia.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eJesse Owens, a promising black sprinter, faces discrimination while attending Ohio State University in the 1930s. He qualifies for the 1936 Berlin Olympics, where he wins four gold medals, defeating Nazi propaganda about Aryan supremacy.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eJesse Owens, a talented black American runner, overcomes racial discrimination and personal struggles to win four gold medals at the 1936 Berlin Olympics, defying Nazi propaganda and racial ideology.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eBernard \"Bernie\" Webber, a crewman at the Coast Guard station in Chatham, Massachusetts, on Cape Cod, has fallen in love with a local girl, Miriam Pentinen. The two plan to marry on April 16, but in accordance with Coast Guard regulations, Bernie must seek permission from the station's commander, Daniel Cluff. On the day he is due to ask permission, the oil tanker SS Pendleton shears in half off the Chatham coast after getting caught in a nor'easter. With the majority of the station's crew already underway with the rescue of the similarly damaged SS Fort Mercer, Bernie is dispatched to pilot motor lifeboat CG 36500 to rescue the crew of Pendleton. Andrew Fitzgerald, Ervin Maske, and Richard P. Livesey volunteer to join Bernie on the rescue mission.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eMeanwhile, the Pendleton's engineer, Ray Sybert, as the surviving senior officer, organizes the surviving seamen to steer the sinking stern of the tanker onto a submerged reef, where it can lodge until rescuers arrive.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eWhen Miriam hears that Bernie is leading the rescue effort, she, like a number of townspeople, thinks this is a suicide mission. Few people in Chatham trust Cluff, since he is not from the area and does not know its treacherous weather. Miriam drives to the station, demanding that Cluff call Bernie back. Cluff refuses, and brusquely orders Miriam out.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eBetween the Chatham harbor and the open sea lies a bar, a series of shoals that are very dangerous even in good weather. Bernie must time bursts of his engine to ride each approaching wave before it breaks as he pilots CG 36500 across the bar. Although he makes it over the bar, he loses his compass.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eBernie steers CG 36500 to the stricken tanker. Although his boat's designated capacity is only 12 people, Bernie manages to rescue 32 crewmen. The stern of Pendleton begins sinking more rapidly during the rescue and goes down shortly after the last crewman comes aboard Bernie's boat. Relying on his knowledge of the coast and prevailing winds in place of his compass, Bernie steers CG 36500 toward home—a task made more difficult as Chatham loses power. Miriam and the other townspeople drive their cars to the pier and turn on their headlights to guide Bernie in.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eThe film shows photographs from the event that briefly document the aftermath of the rescue. Two months later, Bernie and Miriam marry; they stay together for 58 years until Bernie's death in 2009. Webber and his crew receive the Gold Lifesaving Medal.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eA small Coast Guard crew conducts a dangerous rescue mission in a storm to save the lives of 32 crewmen from an oil tanker that has split in half.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eIn a dangerous rescue mission, Coast Guard crewman Bernie Webber and his team save 32 crewmen from an oil tanker split in half during a storm, using only their knowledge of the coast to navigate and return home.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eFlamboyant television financial expert Lee Gates is in the midst of the latest edition of his show, Money Monster. Less than 24 hours earlier, IBIS Clear Capital's stock inexplicably cratered, apparently due to a glitch in a trading algorithm, costing investors $800 million. Lee planned to have IBIS CEO Walt Camby appear for an interview about the crash, but Camby unexpectedly left for a business trip to Geneva.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eMidway through the show, a deliveryman wanders onto the set, pulls a gun and takes Lee hostage, forcing him to put on a vest laden with explosives. He is Kyle Budwell, who invested $60,000—his entire life savings—in IBIS after Lee endorsed the company on the show. Kyle was wiped out along with the other investors. Unless he gets some answers, he will blow up Lee before killing himself. Once police are notified, they discover that the receiver to the bomb's vest is located over Lee's kidney. The only way to destroy the receiver—and with it, Kyle's leverage—is to shoot Lee and hope he survives.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eWith the help of longtime director Patty Fenn, Lee tries to calm Kyle and find Camby for him, though Kyle is not satisfied when both Lee and IBIS chief communications officer Diane Lester offer to compensate him for his financial loss. He also is not satisfied by Diane's insistence that the algorithm is to blame. Diane is not satisfied by her own explanation, either, and defies colleagues to contact a programmer who created the algorithm, Won Joon. Reached in Seoul, Joon insists that an algorithm could not take such a large, lopsided position unless someone meddled with it.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eLee appeals to his TV viewers for help, seeking to recoup the lost investment, but is dejected by their response. New York City police find Kyle's pregnant girlfriend Molly and allow her to talk to Kyle through a video feed. When she learns that he lost everything, she viciously berates him before the police cut the feed. Lee, seemingly taking pity on Kyle, agrees to help his captor discover what went wrong.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eOnce Camby finally returns, Diane flips through his passport, discovering that he did not go to Geneva but to Johannesburg. With this clue, along with messages from Camby's phone, Patty and the Money Monster team contact a group of Icelandic hackers to seek the truth. After a police sniper takes a shot at Lee and misses, he and Kyle resolve to corner Camby at Federal Hall National Memorial, where Camby is headed according to Diane. They head out with one of the network's cameramen, Lenny, plus the police and a mob of fans and jeerers alike. Kyle accidentally shoots and wounds producer Ron Sprecher when Ron throws Lee a new earpiece. Kyle and Lee finally confront Camby with video evidence obtained by the hackers.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eIt turns out that Camby bribed a South African miners' union, planning to have IBIS make an $800 million investment in a platinum mine while the union was on strike. The strike lowered the mine's owners stock, allowing Camby to buy it at a low price. If Camby's plan had succeeded, IBIS would have generated a multibillion-dollar profit when work resumed at the mine and the stock of the mine's owner rose again. The gambit backfired when the union stayed on the picket line. Camby attempted to bribe the union leader, Moshe Mambo, in order to stop the strike, but Mambo refused and continued the strike, causing IBIS' stock to sink under the weight of its position in the flailing company.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eDespite the evidence, Camby refuses to admit his swindle until Kyle takes the explosive vest off Lee and puts it on him. Camby admits to his wrongdoing to Kyle on live camera. Satisfied with the outcome, Kyle throws the detonator away, then much to Lee's dismay gets fatally shot by the police. In the aftermath, the SEC announces that IBIS will be put under investigation, while Camby is charged with violations of the Foreign Corrupt Practices Act.\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eA financial TV host is taken hostage while on air by a man whose life savings were lost when the stock of a company the host had endorsed crashed.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eA disgruntled investor takes a financial TV host hostage on air, demanding the truth behind a recent stock market crash, ultimately unraveling a corporate conspiracy.\u003c/span\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr style=\"height:0pt\"\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eWhen the Little Red-Haired Girl moves into his neighborhood, Charlie Brown becomes infatuated with her, though worries his long-running streak of failures will prevent her from noticing him. After Lucy tells him he should try being more confident, Charlie Brown decides to embark upon a series of new activities in hope of finding one that will get the Little Red-Haired Girl to notice him. His first attempt is to participate in the school's talent show with a magic act, helped by Snoopy and Woodstock. However, when Sally's act goes wrong, Charlie Brown sacrifices his time for her, rescues his sister from being humiliated, and is humiliated himself in return. Attempting to impress the Little Red-Haired Girl with his dance skills, Charlie Brown signs up for the school dance and gets Snoopy to teach him all his best moves. At the dance, Charlie Brown attracts praise for his skills but slips and sets off the sprinkler system, causing the dance to be cut short and all the other students to look down upon him once more.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCharlie Brown is partnered with the Little Red-Haired Girl to write a book report. At first, he is excited to have a chance to be with her, but she is called away for a week to deal with a family illness, leaving Charlie Brown to write the report all by himself. Hoping to impress both the Little Red-Haired Girl and his teacher, Charlie Brown writes his report on the collegiate-level novel War and Peace. At the same time, Charlie Brown finds he is the only student to get a perfect score on a standardized test. His friends and the other students congratulate him, and his popularity begins to climb. When he goes to accept a medal at a school assembly, however, he learns the test papers are accidentally mixed up and the perfect score actually belongs to Peppermint Patty; Charlie Brown declines the medal, losing all his new-found popularity. His book report is destroyed by a Red Baron model plane, and he admits to the Little Red-Haired Girl he has caused them to both fail the assignment.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eBefore leaving school for the summer, Charlie Brown is surprised when the Little Red-Haired Girl chooses him for a pen pal. Linus convinces Charlie Brown he needs to tell the Little Red-Haired Girl how he feels about her before she leaves for the summer. Racing to her house, he discovers she is about to leave on a bus for summer camp. He tries to chase the bus but is prevented from reaching it. Just as he is about to give up, thinking the whole world is against him, Charlie Brown sees a kite fall from the Kite-Eating Tree. The string becomes entangled around his waist and sails away with him. Amazed to see Charlie Brown flying a kite, his friends follow.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eUpon reaching the bus, Charlie Brown finally asks the Little Red-Haired Girl why she has chosen him in spite of his failures. The Little Red-Haired Girl explains she admires his selflessness and his determination and praises him as an honest, caring, and compassionate person. The two promise to write to one another; the other children congratulate him as a true friend and carry him off.\u003c/span\u003e\u003c/p\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:6.999999999999999pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eIn a subplot, after finding a typewriter in the school dumpster, Snoopy writes a novel about the World War I Flying Ace, trying to save Fifi from the Red Baron with Woodstock and his friends' help, using the key events and situations surrounding Charlie Brown as inspiration to develop his story. He acts out his adventure physically, pulling himself across a line of lights, and, imagining it as a rope across a broken bridge, he comes across Charlie Brown and the gang several times along the way. Snoopy defeats the Red Baron and rescues Fifi from an airplane. When Lucy finishes reading, she calls it the dumbest story she has ever read, so Snoopy throws the typewriter at her in retaliation and kisses her nose causing her to run away in disgust yelling that she has \"dog germs\".\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCharlie Brown tries to impress the Little Red-Haired Girl in various ways, but fails; however, she admires him for his kindness and they become pen pals.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003c/td\u003e\u003ctd style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"\u003e\u003cp dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"\u003e\u003cspan style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\"\u003eCharlie Brown embarks on various activities to gain the attention of the Little Red-Haired Girl, eventually winning her admiration through his selflessness and determination.\u003c/span\u003e\u003c/p\u003e\u003cbr\u003e\u003cbr\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003c!--kg-card-end: html--\u003e\n\u003cp\u003e\u003cbr\u003eFor additional learning and to view another model comparison example, check out our recent \u003ca href=\"https://labelbox.com/blog/gpt4-vs-palm-assessing-performance-of-llm-models/?ref=labelbox.ghost.io\"\u003eblog post on GPT-4 vs PaLM\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eIn conclusion, the availability of off-the-shelf foundation models has introduced breakthroughs in AI development by reducing the barrier to kick-start model development. Teams of any AI maturity can speed up their development process by selecting the most suitable foundation model for their specific use case. The key to maximizing iteration cycles lies in selecting the right algorithm and conducting a comprehensive model comparison process to assess the model’s alignment with business goals. While confidently evaluating pre-trained models can be challenging, Quantumworks Lab Model and Model Foundry provide ML teams with the tools to effectively compare, evaluate, and leverage foundation models for AI development.\u003c/p\u003e\u003chr\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLabelbox recently announced \u003c/em\u003e\u003ca href=\"https://labelbox.com/product/model/foundry-models/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003e\u003cem\u003eaccess to Model Foundry\u003c/em\u003e\u003c/a\u003e\u003cem\u003e – the easiest place to build model prediction workflows based on your use case, integrate model results with your labeling workflow, and compare and evaluate model results.\u003c/em\u003e\u003c/p\u003e","comment_id":"649c9b7f1f77de00014de9bc","feature_image":"https://labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1-.png","featured":false,"visibility":"public","created_at":"2023-06-28T13:43:43.000-07:00","updated_at":"2024-10-04T09:45:23.000-07:00","published_at":"2023-06-28T19:28:01.000-07:00","custom_excerpt":"Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"http://labelbox.com/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning","tags":[{"id":"653030aa4e99900001fc052d","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/use-ai/"},{"id":"65302ef44e99900001fc0519","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox.ghost.io/blog/tag/industry-any/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"},{"id":"653030c34e99900001fc0531","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/using-computer-vision/"},{"id":"653030b74e99900001fc052f","name":"Using LLMs","slug":"using-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/using-llms/"},{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"}],"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"653030aa4e99900001fc052d","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/use-ai/"},"url":"https://labelbox.ghost.io/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning/","excerpt":"Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. ","reading_time":17,"access":true,"comments":false,"og_image":"https://labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1--2.png","og_title":"How to confidently compare, test, and evaluate models for machine learning","og_description":"Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. ","twitter_image":"https://labelbox.ghost.io/blog/content/images/2023/06/Frame-3390--1--1.png","twitter_title":"How to confidently compare, test, and evaluate models for machine learning","twitter_description":"Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. ","meta_title":"How to confidently compare, test, and evaluate models for machine learning","meta_description":"Learn how to always choose the best and most efficient model for your use case. With Model Foundry, you can test, compare, and evaluate models to confidently select the best performing model. ","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"recommended":[{"id":"6765b8c06f63bf0001f1ca72","uuid":"9f912bc0-54da-4ac6-ab5f-78d8f926463c","title":"Code Runner: Secure, scalable code execution for model evaluation","slug":"code-runner-secure-scalable-code-execution-for-model-evaluation-2","html":"\u003cp\u003eIn the world of large language models (LLMs), evaluating their responses effectively is a fundamental aspect of improving model performance. We’re excited to announce the latest addition to the Quantumworks Lab platform: Code Runner.\u003cstrong\u003e \u003c/strong\u003eThis new capability pushes the boundaries of interactivity by allowing users to execute written code directly within the evaluation workflow.\u003c/p\u003e\u003cp\u003eCode Runner helps eliminate errors, optimizes functionality, and validates outputs, leading to higher-quality datasets. Today, we’ll introduce this new feature and then dive into the technical details of the infrastructure powering this feature, highlighting how it was designed with security, scalability, and\u003cstrong\u003e \u003c/strong\u003erobustness at its core.\u003c/p\u003e\u003ch2 id=\"what-is-code-runner\"\u003e\u003cstrong\u003eWhat is Code Runner?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner is a new built-in feature of the Quantumworks Lab platform designed to improve the quality of responses and labels generated in any coding-related projects. The new features enables users to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDirectly execute code found in either model responses or user-written responses \u003c/li\u003e\u003cli\u003eReceive precise outputs including:\u003cul\u003e\u003cli\u003eStandard output (stdout)\u003c/li\u003e\u003cli\u003eStandard error (stderr)\u003c/li\u003e\u003cli\u003eExecution time\u003c/li\u003e\u003cli\u003eWarnings or runtime errors\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy integrating Code Runner into the evaluation pipeline, we aim to simplify the process of verifying the accuracy, efficiency, and functionality of code responses, all without users needing to leave the platform.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBDN_1bnU_bTrPrWS59SWalVqw22Gxq3AIxNnbsOJmZGPap3weXHYFEgzrlPnEyhVK1GOjzCVClvQycomfMfhQsulqPk4wdQGqniZv8aIaHGP69wzgcFjdDdr5FgooITwNJCsp?key=GRyWmie9kDWaUfN6osDAF8J7\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"389\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOur system automatically detects the language in the text area and suggests the appropriate environment for execution, whether Python or JavaScript (and more to come).\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut what makes this feature stand out is the sophisticated infrastructure behind it, designed to ensure seamless execution while maintaining strict security and privacy standards.\u003c/p\u003e\u003ch2 id=\"code-runner-infrastructure-a-deep-dive\"\u003e\u003cstrong\u003eCode Runner infrastructure: A deep dive\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eAt the heart of Code Runner’s infrastructure lies Google Cloud Run, a fully managed compute platform that runs containerized applications in a secure, scalable manner. Here are the key components and principles driving the system:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1. Cloud Run for language-specific environments\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEvery code execution happens in a dedicated Cloud Run instance. Each instance is tailored to a specific programming language environment (e.g., Python, JavaScript, etc.) and is spun up dynamically based on the code type detected in the user response.\u003c/p\u003e\u003cp\u003eThis design includes the following characteristics to ensure security and speed:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eIsolation\u003c/strong\u003e: Each execution is fully containerized, completely isolating the runtime environment from others.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTemporary directories\u003c/strong\u003e: Code is executed in a temporary directory within the container, and it is deleted immediately after execution, leaving no trace behind.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage-specific tools\u003c/strong\u003e: Each environment comes preloaded with the necessary packages and libraries to ensure compatibility and speed.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e2. Enhanced security with separate GCP projects \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Cloud Run service is hosted in a separate Google Cloud Platform (GCP) project, distinct from our main infrastructure. This segmentation provides an additional layer of security by isolating code execution from our core services. Even in the unlikely event of a compromise, the blast radius is contained.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Communication via private service connect\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo ensure secure and controlled communication, all interactions between the main evaluation system and the Cloud Run service occur over Private Service Connect, which provides the following advantages: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eNo public exposure\u003c/strong\u003e: The Cloud Run endpoint is never exposed to the public internet, reducing the risk of unauthorized access.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOne-way communication\u003c/strong\u003e: The Private Service Connect setup restricts outbound networking from the Cloud Run service, ensuring that executed code cannot make arbitrary network requests. \u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGranular networking controls\u003c/strong\u003e: The private network allows for precise control over what resources the Cloud Run service can access.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e4. Automatic cleanup\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo maintain a lightweight and secure runtime, the system delivers:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEphemeral execution\u003c/strong\u003e: Each execution request is handled in a stateless, temporary environment.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAutomatic deletion\u003c/strong\u003e: Files, logs, and temporary directories are wiped as soon as execution completes, leaving no residual data.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"how-code-runner-works-a-step-by-step-overview\"\u003e\u003cstrong\u003eHow Code Runner works: A step-by-step overview\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow that you have an understanding of the powerful infrastructure underneath Code Runner, here is a summary of how the feature works from start to finish:\u0026nbsp;\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eCode submission\u003c/strong\u003e: A user requests code execution from the evaluation interface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage detection\u003c/strong\u003e: The system detects the programming language and forwards the request to the corresponding Cloud Run service.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e: The Cloud Run instance spins up a container, executes the code in a sandboxed environment, and collects the results.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResult delivery\u003c/strong\u003e: The system returns the output (stdout, stderr, execution time, and any warnings) to the user for analysis.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCleanup\u003c/strong\u003e: The container and all related resources are terminated and deleted.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"advantages-of-labelbox%E2%80%99s-built-in-code-execution\"\u003e\u003cstrong\u003eAdvantages of Quantumworks Lab’s built-in code execution\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner’s infrastructure was designed specifically to provide the previously discussed benefits and to address several key challenges that other solutions may face:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSecurity\u003c/strong\u003e: By isolating execution environments and ensuring no public exposure, we eliminate a significant attack surface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability\u003c/strong\u003e: Cloud Run’s serverless nature allows us to scale dynamically with demand, handling thousands of requests efficiently.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eReliability\u003c/strong\u003e: The use of ephemeral containers ensures that each execution starts in a clean slate, avoiding cross-contamination or resource conflicts.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"explore-it-yourself\"\u003e\u003cstrong\u003eExplore it yourself\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWith Code Runner, we’re empowering users to go beyond static evaluations, enabling dynamic, interactive testing that’s as secure as it is scalable. As always, we’re excited to hear your feedback and explore how we can push this feature even further.\u003c/p\u003e\u003cp\u003e If you want to explore Code Runner and other LLM evaluation tools, \u003ca href=\"https://app.labelbox.com/signup?_r=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/?utm_keyword=Quantumworks Lab\u0026utm_source=house\u0026utm_medium=email\u0026utm_campaign=1224%2520\u0026gclid=CjwKCAiA34S7BhAtEiwACZzv4a9veoKXnMnMvo2rWJvXkH46oHs4Lb5VFQi2ERBN_sQ5kgypV_zfBxoC0yMQAvD_BwE\u0026landingPageAnonymousId=%22e3f2f82f-be24-4045-b2b9-50a49cb801e8%22\u0026referrer_url=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/\"\u003e\u003cu\u003esign up\u003c/u\u003e\u003c/a\u003e for our platform today.\u0026nbsp;\u003c/p\u003e\u003cp\u003eStay tuned for updates, and happy coding!\u003c/p\u003e","comment_id":"6765b8c06f63bf0001f1ca72","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Labelbox-code-runner--1-.png","featured":false,"visibility":"public","created_at":"2024-12-20T10:34:40.000-08:00","updated_at":"2025-03-12T12:01:43.000-07:00","published_at":"2024-12-20T12:44:45.000-08:00","custom_excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"65303cb64e99900001fc05a5","name":"Labeling automation","slug":"labeling-automation","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/labeling-automation/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"}],"primary_author":{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/code-runner-secure-scalable-code-execution-for-model-evaluation-2/","excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6759fc88a9b5bd0001989d30","uuid":"58632854-1031-4ac5-8fe3-87324337cbe7","title":"Bringing AI to the browser: SAM2 for interactive image segmentation","slug":"bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation","html":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\u003cp\u003eIn computer vision, image segmentation is crucial for object recognition, image editing, autonomous driving, and other common applications. The Segment Anything Model 2 (SAM2) pushes the boundaries of interactive image segmentation by allowing users to segment objects in images with minimal input.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTraditionally, running such models required powerful servers or specialized hardware. However, with advancements in web technologies and machine learning libraries, it's now possible to run complex models like SAM2 directly in a browser.\u003c/p\u003e\u003cp\u003eIn this article, we explore how to implement the SAM2 model in a web browser using ONNX Runtime Web (ort). We delve into the architecture of SAM2, how to load and run the model in a browser, and how to create an interactive user interface for real-time image segmentation.\u003c/p\u003e\u003ch2 id=\"understanding-the-sam2-architecture\"\u003eUnderstanding the SAM2 architecture\u003c/h2\u003e\u003ch3 id=\"encoder-decoder-framework\"\u003eEncoder-decoder framework\u003c/h3\u003e\u003cp\u003eSAM2 uses an encoder-decoder architecture:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEncoder:\u003c/strong\u003e Processes the input image to generate a high-dimensional embedding that captures essential features.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDecoder:\u003c/strong\u003e Takes the embedding and user-provided points (positive and negative) to generate segmentation masks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis architecture allows for interactive and highly accurate segmentation, while also allowing users to\u0026nbsp; iteratively refine the segmentation by adding more points.\u003c/p\u003e\u003ch3 id=\"why-run-sam2-in-the-browser\"\u003eWhy Run SAM2 in the Browser?\u003c/h3\u003e\u003cp\u003eRunning SAM2 in the browser offers several key benefits:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePrivacy:\u003c/strong\u003e Images are processed locally, ensuring user data isn't sent to external servers.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAccessibility:\u003c/strong\u003e Users can access the segmentation tool without installing specialized software.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInteractivity:\u003c/strong\u003e Real-time feedback enhances the user experience, allowing for quick iterations.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"implementing-the-encoder-encoderjs\"\u003eImplementing the encoder (encoder.js)\u003c/h2\u003e\u003ch3 id=\"initialization\"\u003eInitialization\u003c/h3\u003e\u003cp\u003eThe encoder loads the ONNX model and prepares it for inference:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003econst ENCODER_MODEL_URL = 'https://storage.googleapis.com/lb-artifacts-testing-public/sam2/sam2_hiera_tiny.encoder.ort';\n\nclass SAM2Encoder {\n  constructor() {\n    this.session = null;\n  }\n\n  async initialize() {\n    this.session = await ort.InferenceSession.create(ENCODER_MODEL_URL);\n    console.log('Encoder model loaded successfully');\n  }\n}\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"image-preprocessing\"\u003eImage preprocessing\u003c/h3\u003e\u003cp\u003eBefore passing the image to the encoder, it must be resized and normalized:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003e Resize:\u003c/strong\u003e Adjust the image to 1024x1024 pixels.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNormalize:\u003c/strong\u003e Scale pixel values to the [-1, 1] range.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eimageDataToTensor(image) {\n  const canvas = document.createElement('canvas');\n  const ctx = canvas.getContext('2d');\n  canvas.width = canvas.height = 1024;\n\n  ctx.drawImage(image, 0, 0, 1024, 1024);\n  const imageData = ctx.getImageData(0, 0, 1024, 1024).data;\n  const inputArray = new Float32Array(3 * 1024 * 1024);\n\n  for (let i = 0; i \u0026lt; 1024 * 1024; i++) {\n    inputArray[i] = (imageData[i * 4] / 255.0) * 2 - 1; // R channel\n    inputArray[i + 1024 * 1024] = (imageData[i * 4 + 1] / 255.0) * 2 - 1; // G channel\n    inputArray[i + 2 * 1024 * 1024] = (imageData[i * 4 + 2] / 255.0) * 2 - 1; // B channel\n  }\n\n  return new ort.Tensor('float32', inputArray, [1, 3, 1024, 1024]);\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"encoding-process\"\u003eEncoding process\u003c/h3\u003e\u003cp\u003eThe encode method runs the model and generates the image embedding:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003easync encode(image) {\n  const tensor = this.imageDataToTensor(image);\n  const feeds = { image: tensor };\n  const results = await this.session.run(feeds);\n  this.lastEmbeddings = results.image_embed;\n  return this.lastEmbeddings;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"implementing-the-decoder-decoderjs\"\u003eImplementing the decoder (decoder.js)\u003c/h2\u003e\u003ch3 id=\"initialization-1\"\u003eInitialization\u003c/h3\u003e\u003cp\u003eSimilar to the encoder, the decoder loads its ONNX model:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003econst DECODER_MODEL_URL = 'https://storage.googleapis.com/lb-artifacts-testing-public/sam2/sam2_hiera_tiny.decoder.onnx';\n\nclass SAM2Predictor {\n  constructor() {\n    this.session = null;\n  }\n\n  async initialize() {\n    this.session = await ort.InferenceSession.create(DECODER_MODEL_URL);\n    console.log('Decoder model loaded successfully');\n  }\n}\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"preparing-inputs\"\u003ePreparing inputs\u003c/h3\u003e\u003cp\u003eThe decoder requires several inputs, including the image embedding and user interaction points:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePoint coordinates (point_coords):\u003c/strong\u003e The (x, y) positions of user clicks.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePoint labels (point_labels):\u003c/strong\u003e Indicates positive (foreground) or negative (background) points.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMask input (mask_input):\u003c/strong\u003e An initial mask, set to zeros if not using a previous mask.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOther tensors:\u003c/strong\u003e Additional required inputs like has_mask_input, high_res_feats_0, and high_res_feats_1.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eprepareInputs(embedding, points) {\n  const numLabels = 1;\n  const numPoints = points.length;\n  const pointCoordsData = [];\n  const pointLabelsData = [];\n\n  for (let point of points) {\n    pointCoordsData.push([point.x, point.y]);\n    pointLabelsData.push(point.type);\n  }\n\n  return {\n    image_embed: embedding,\n    point_coords: new ort.Tensor('float32', Float32Array.from(pointCoordsData.flat()), [numLabels, numPoints, 2]),\n    point_labels: new ort.Tensor('float32', Float32Array.from(pointLabelsData), [numLabels, numPoints]),\n    mask_input: new ort.Tensor('float32', new Float32Array(numLabels * 1 * 256 * 256), [numLabels, 1, 256, 256]),\n    has_mask_input: new ort.Tensor('float32', new Float32Array([0.0]), [numLabels]),\n    high_res_feats_0: new ort.Tensor('float32', new Float32Array(1 * 32 * 256 * 256), [1, 32, 256, 256]),\n    high_res_feats_1: new ort.Tensor('float32', new Float32Array(1 * 64 * 128 * 128), [1, 64, 128, 128]),\n  };\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"prediction-process\"\u003ePrediction Process\u003c/h3\u003e\u003cp\u003eThe predict method runs the decoder model to generate the segmentation mask:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003easync predict(embedding, inputPoints) {\n  const inputs = this.prepareInputs(embedding, inputPoints);\n  const results = await this.session.run(inputs);\n  return results;\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"building-the-user-interface-appjs\"\u003eBuilding the user interface (app.js)\u003c/h2\u003e\u003ch3 id=\"setting-up-the-canvas\"\u003eSetting up the canvas\u003c/h3\u003e\u003cp\u003eWe use two HTML canvas elements:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSource canvas (sourceCanvas):\u003c/strong\u003e Displays the uploaded image and interaction points.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMask canvas (maskCanvas):\u003c/strong\u003e Overlays the segmentation mask.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"handling-user-interactions\"\u003eHandling user interactions\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003eImage upload\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWhen a user uploads an image two things happen:\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe image is drawn on the sourceCanvas.\u003c/li\u003e\u003cli\u003eThe encoder generates embeddings from the image.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003eimageInput.addEventListener('change', async (e) =\u0026gt; {\n  // Load image and draw on canvas\n  // Encode the image\n  embedding = await encoder.encode(img);\n});\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eAdding interaction points\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eUsers can click on the image to add positive or negative points:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePositive points:\u003c/strong\u003e Indicate areas to include in the segmentation.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNegative points:\u003c/strong\u003e Indicate areas to exclude.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003esourceCanvas.addEventListener('click', async (e) =\u0026gt; {\n  const x = e.clientX - rect.left;\n  const y = e.clientY - rect.top;\n  const point = { x: x, y: y, type: isNegative ? 0 : 1 };\n  points.push(point);\n\n  // Draw point on canvas\n  drawPoint(sourceCtx, point);\n\n  // Run prediction\n  const results = await predictor.predict(embedding, points);\n\n  // Draw mask\n  drawMaskOnCanvas(maskCanvas, results['masks'], imageWidth, imageHeight);\n});\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eToggling point types\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eA button allows users to switch between positive and negative points:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003enegativeBtn.addEventListener('click', () =\u0026gt; {\n  isNegative = !isNegative;\n  negativeBtn.textContent = `Negative Points: ${isNegative ? 'ON' : 'OFF'}`;\n});\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"drawing-points-and-masks\"\u003eDrawing points and masks\u003c/h3\u003e\u003cp\u003e\u003cstrong\u003eDrawing points\u003c/strong\u003e\u003c/p\u003e\u003cp\u003ePoints are drawn on the sourceCanvas to provide visual feedback:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003efunction drawPoint(ctx, point) {\n  ctx.fillStyle = point.type === 1 ? 'green' : 'red';\n  ctx.beginPath();\n  ctx.arc(point.x, point.y, 5, 0, 2 * Math.PI);\n  ctx.fill();\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eDrawing masks\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eMasks are drawn on the maskCanvas to display the segmentation result:\u003c/p\u003e\u003cpre\u003e\u003ccode class=\"language-Javascript\"\u003efunction drawMaskOnCanvas(maskCanvas, maskData, imageWidth, imageHeight) {\n  // Process the mask tensor and draw it over the image\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"running-the-application\"\u003eRunning the application\u003c/h2\u003e\u003ch3 id=\"step-by-step-guide\"\u003eStep-by-step guide\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eSet up the server:\u003c/strong\u003e Start your local server to host the model files.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInclude scripts:\u003c/strong\u003e In your HTML file, include ort and your JavaScript modules.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOpen the application:\u003c/strong\u003e Access the HTML file through your browser.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUpload an image:\u003c/strong\u003e Use the file input to select an image.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eInteract with the image:\u003c/strong\u003e Click on the image to add points and see the segmentation mask update in real-time.\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"demonstration\"\u003eDemonstration\u003c/h3\u003e\u003cp\u003eCheck out and play around with an interactive demo \u003ca href=\"https://storage.googleapis.com/lb-artifacts-testing-public/sam2/index.html?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003ehere\u003c/a\u003e. \u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eIn this article, we've demonstrated how to run the Segment Anything Model 2 (SAM2) directly in the web browser. By leveraging ONNX Runtime Web and thoughtful implementation of the encoder and decoder, we've created an interactive image segmentation tool that runs entirely on the user-side.\u0026nbsp;\u003c/p\u003e\u003cp\u003eThis approach opens doors to privacy-preserving applications and makes advanced machine learning models more accessible. As web technologies continue to evolve, we can expect even more sophisticated models to run efficiently in the browser.\u003c/p\u003e\u003cp\u003eAt Quantumworks Lab, we’ve adopted a hybrid strategy, running SAM’s encoder on the server while executing its decoder right in the browser. This approach ensures real-time image segmentation, preserves user privacy, and expands access to cutting-edge machine learning. As web technologies advance, we look forward to delivering even more powerful models efficiently and securely in the browser.\u003c/p\u003e\u003ch2 id=\"check-out-these-additional-resources\"\u003eCheck out these additional resources:\u0026nbsp;\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eONNX Runtime Web Documentation:\u003c/strong\u003e \u003ca href=\"https://onnxruntime.ai/docs/api/javascript/index.html?ref=labelbox.ghost.io\"\u003e\u003cu\u003eONNX Runtime Web\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSAM2 Model Details:\u003c/strong\u003e \u003ca href=\"https://segment-anything.com/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eSegment Anything Model (SAM)\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGitHub Repository:\u003c/strong\u003e \u003ca href=\"https://github.com/Quantumworks Lab/sam2-web?ref=labelbox.ghost.io\"\u003e\u003cu\u003elink\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eDemo:\u003c/strong\u003e \u003ca href=\"https://storage.googleapis.com/lb-artifacts-testing-public/sam2/index.html?ref=labelbox.ghost.io\"\u003e\u003cu\u003elink\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e","comment_id":"6759fc88a9b5bd0001989d30","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Interactive-Image-Segmentation-in-the-Browser-with-SAM2.png","featured":false,"visibility":"public","created_at":"2024-12-11T12:56:40.000-08:00","updated_at":"2024-12-20T08:52:19.000-08:00","published_at":"2024-12-19T12:18:40.000-08:00","custom_excerpt":"Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6764713c6f63bf0001f1ca64","name":"Stanislav Issayenko","slug":"stanislav","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/stanislav/"}],"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"653030c34e99900001fc0531","name":"Using computer vision","slug":"using-computer-vision","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/using-computer-vision/"},{"id":"6700193d863cb90001f263ed","name":"Computer vision","slug":"computer-vision","description":"CV related features, best practices, and information","feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/computer-vision/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"653030aa4e99900001fc052d","name":"Use AI","slug":"use-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/use-ai/"}],"primary_author":{"id":"6764713c6f63bf0001f1ca64","name":"Stanislav Issayenko","slug":"stanislav","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/stanislav/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/bringing-ai-to-the-browser-sam2-for-interactive-image-segmentation/","excerpt":"Learn how to leverage the power of the SAM2 in a web browser, enabling interactive image segmentation without the need for powerful servers or specialized hardware.","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6757cf3acb24830001b1d4b1","uuid":"3ff80ee2-cd3b-4596-9a78-88c340d62032","title":"Inside the matrix: A look into the math behind AI","slug":"inside-the-matrix-a-look-into-the-math-behind-ai","html":"\u003ch2 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eMatrices are omnipresent in math and computer science, both theoretical and applied. They are often used as data structures, such as in graph theory. They are a computational workhorse in many AI fields, such as deep learning, computer vision and natural language processing. Why is that? Why would a rectangular array of numbers, with famously unintuitive multiplication rules, be so prevalent in AI?\u003c/p\u003e\u003cp\u003eAI methods (with emphasis on machine learning) are all about processing multi-dimensional data. A lot of that processing is done in a linear way - input data points are multiplied by scalars and added together to create output data. While that sounds limiting, a lot can be achieved with just that, for example:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLinear layers in neural networks (excluding possibly non-linear activations)\u003c/li\u003e\u003cli\u003ePrincipal component analysis\u003c/li\u003e\u003cli\u003eWord embeddings\u003c/li\u003e\u003cli\u003eImage processing\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis particular kind of processing data has a name in mathematics - linear map, which is a concept from linear algebra. I will formally define it later in this blog. For now it suffices to say that you can represent any linear map as a matrix, and matrix operations are intimately connected to operations on linear maps. This is the main reason why matrices are so ubiquitous in AI.\u003c/p\u003e\u003cp\u003eWhile you don't necessarily need to know linear algebra to do machine learning, it is very helpful to have a good intuition for the concepts. This blog is an attempt to demystify matrices and linear algebra surrounding them in a way that strikes a balance between mathematical rigor and intuitive understanding. Contrary to most introductory material on the subject, we won't restrict ourselves to the usual Rn spaces, but I'll still give examples in R2 and R3 for clarity. If you don't know what R\u003csup\u003e2\u003c/sup\u003e, R\u003csup\u003e3\u003c/sup\u003e and R\u003csup\u003en\u003c/sup\u003e are, don't worry - we'll get to that.\u003c/p\u003e\u003cp\u003eI will start with formally defining what a matrix is. We will gradually build up to understanding matrix multiplication, and by the end of the article we will have covered all the necessary concepts.\u003c/p\u003e\u003ch2 id=\"definition-of-a-matrix\"\u003e\u003cstrong\u003eDefinition of a matrix\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA matrix is a rectangular array of numbers. The numbers are called elements of the matrix. The horizontal lines of elements are called rows, the vertical lines are called columns.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeE-ZtcxxSEfqHBbKD496nYV8uU8Gh85QW_nlkNA9LBe7PJhOm-N4b6LLx7oDfUFppbj0Mza3dQKv5GezLOb3OL6DyY0Uot0pxn_NU8xBOhUkRPx9AyUPX1eqzltwPcs519ZmAphg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"306\" height=\"215\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e\u0026nbsp;A real-valued matrix with 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThere are many operations we can perform on matrices, but for the purpose of this article we only need to know three:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition:\u003c/strong\u003e Element-wise addition, only matrices of the same dimensions can be added\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e Multiplying each element by a scalar\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMatrix multiplication:\u003c/strong\u003e Multiplying two matrices, resulting in a matrix with dimensions equal to the number of rows in the second matrix and number of columns in the first matrix\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeHPKl6kqvGJrURhsqbjIz4gZ4lEl_ScId7w3a07BTMrr9O1wn30BKljl5ovYAENHIJbqGxa_tnuZk6Qud6OURSD2PnfD-t8azHRkm90mILIkvwE8m3tnw0kSBA9cuHuihQvSms?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"257\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix addition and scalar multiplication.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe first two operations are pretty straightforward, but matrix multiplication is a bit more complex. There are several algorithms to do it, all resulting in the same end product. \u003c/p\u003e\u003cp\u003eOne of the most common algorithms is this: For element in j-th row and k-th column of the resulting matrix, take the element-wise product of j-th row of the first matrix and k-th column of the second matrix, and sum all the elements of the resulting vector.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeR0jhCg2ufM0vZv_Yyp_6PklvhKVGJ_Zft_vzWMWywsN_GYnzEoeOH4McE3p1D4HLojhYrTzysbjYfAgQ2DxqoSwX0Iaxo4XeWN4tHvSBaNLBJgPreIUuPveGDeQcd_zoA9aLF?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"155\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix multiplication. To compute the element in the first row and first column of the resulting matrix (10), take the first row of the first matrix (2, 3, 4) and the first column of the second matrix (2, 2, 0), multiply them element-wise and sum the result (2 * 2 + 3 * 2 + 4 * 0 = 10). Note that the resulting matrix has dimensions equal to the number of rows in the first matrix and number of columns in the second matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy is matrix multiplication not simply element-wise (which actually exists and is called Hadamard product)? What is the intuition behind it? To answer that, we need to understand several concepts from linear algebra.\u003c/p\u003e\u003ch2 id=\"what-is-a-vector\"\u003e\u003cstrong\u003eWhat is a vector?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA vector has many definitions. Perhaps the most well known is the one from physics: an arrow in space with a direction and a magnitude, usually represented as coordinates in a space.\u003c/p\u003e\u003cp\u003eIf you are a programmer, you might know it as an array-like data structure, that is an ordered collection of elements. Both of these definitions are most likely known to you if you are working with AI systems, in which vectors often play a crucial role, e.g. as features in a dataset or as low-dimensional representations of high-dimensional data (embeddings).\u003c/p\u003e\u003cp\u003eWhat interests us here is the mathematical definition: A vector is an element of a vector space. What is a vector space then?\u003c/p\u003e\u003cp\u003eTo avoid spelling the whole mathematical definition here, it suffices to say that a vector space is a set of elements with following properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIt is possible to add any two elements and the result is also in the set.\u003c/li\u003e\u003cli\u003eIt is possible to multiply any element by a scalar (a real number) and the result is also in the set.\u003c/li\u003e\u003cli\u003eThere exists an element called zero vector, which is such that adding it to any element does not change the latter.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese two operations are connected by a distributive property, which states that scalar multiplication of a sum is the sum of scalar multiplications: a * (u + v) = a * u + a * v.\u003c/p\u003e\u003cp\u003eAs you have probably noticed, this is analogous to the operations of addition and multiplication on real numbers. The important thing to note is that the vector space definition does not require the vector by vector multiplication to be defined. It is defined for some vector spaces, but we won't concern ourselves with it in this blog.\u003c/p\u003e\u003cp\u003eAll of that is pretty abstract, so let's consider some examples. Possibly the most well known vector spaces are R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e, which are spaces of vectors with 2 and 3 coordinates respectively. The generalization of those is R\u003csup\u003en\u003c/sup\u003e, which is a space of vectors with n coordinates. The elements (vectors) of those spaces have a geometric interpretation as arrows or points. Notice how this aligns with the interpretation of vectors as known from physics.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXciYwCq1HZTGnHkYJWxNJex6c52A-UpTxDRkM1DbAOj2n-Vx9r5PPFqosNeQ6MjMzmjExEuWL6aDpUHJUKVF70rDWeMtbhdOFoJPjAR66btoxgXO5fCsyRl9vbAsJZiWvsmm568gw?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"544\" height=\"238\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eImages of R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e and R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, with some vectors marked. It is common to draw vectors as arrows starting from the origin, but the vector is not defined by its anchor point. Graphically, all vectors with the same length and direction are the same vector.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"linear-combination-of-vectors-span-and-linear-independence\"\u003e\u003cstrong\u003eLinear combination of vectors, span and linear independence\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that vectors can be added and multiplied by scalars. A linear combination of vectors is a sum of scalar multiples of those vectors. Consider these examples in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e:\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXetIiIpcEGjnii7eRWzOwH3onH7IgJEGl8tkJ42x1IkjQI41rhP_n4hWW5EJLfCzV8e-oLFcfEVvAklY5tcdUDBjTGekkfJsxFDgVhm5VGXrfLRdm5lfQSi0pm90gEGugHW3XQ9Kg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"505\" height=\"339\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of linear combination of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eA span of a finite set of vectors is a set of all possible linear combinations of those vectors. Geometrically, a span of one vector in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e is a line through the origin (all scalar multiples of the vector), while a span of two vectors \u003cstrong\u003emight be\u003c/strong\u003e a plane through the origin (which is the whole space in case of R\u003csup\u003e2\u003c/sup\u003e).\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeS90Xw5U7e8SCrauz6PfboZLkMATSOTsQ8p-ugGkVlC4tiuXekAuTzHV6FYhXZHPHQOSXuiQ_poclCAKdRYm2bXKK_IQdRlI4Po-HHG1pllr_EmFwSaQLXIjQaw86d92NtsnMIdQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"419\" height=\"369\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of the span of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. Their span is a plane through the origin (which is admittedly hard to draw).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy might? Consider two vectors lying on the same line. No matter what scalar coefficients we take for the linear combination, the result will lie on the same line. Their individual spans are identical to the span of the set of those two vectors. We say that those two vectors are \u003cstrong\u003elinearly dependent\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eLet's consider a set of three vectors in R\u003csup\u003e3\u003c/sup\u003e. They can either all lie on the same line, all lie on the same plane, or they can be such that their span is the whole space. In the first two cases, the vectors are linearly dependent, in the last case they are \u003cstrong\u003elinearly independent\u003c/strong\u003e. Two vectors in R\u003csup\u003e2\u003c/sup\u003e spanning the whole space are also linearly independent.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf8_KYv6dtal1uf07fhGwyO7Dq3aBbTydEuW84z2V0WOO-uFZInEdskzS6ztAWm5pvUevcUSSC-0PxpiH5F0X-4iNc4D98z157Vb7nfHcsb-3fE6VtEEu0AQZTN5I37wYxixRmuOQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"256\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of spans of linearly dependent vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. All three vectors on the second image lie on the same plane (which contains the origin).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRigorously speaking, a set of vectors in vector space is linearly independent if no vector in the set can be written as a linear combination of the other vectors in the set (in other words, it does not lie in the span of the rest of the vectors). Intuitively, vectors are linearly independent if each one of them contributes a unique \"direction\" to the span.\u003c/p\u003e\u003cp\u003eLinearly independent vectors have a very important property: each vector in their span can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of those vectors.\u003c/p\u003e\u003ch2 id=\"basis\"\u003e\u003cstrong\u003eBasis\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNot all vector spaces can be spanned by a finite set of vectors. For example, the space of all polynomials (which with proper definition of addition and scalar multiplication is valid vector space) is infinite-dimensional, because no matter how many polynomials we have, we can always find a polynomial that has a higher degree than all of them.\u003c/p\u003e\u003cp\u003eContrarily, if we can find a finite set of vectors that spans the whole space, we say that the vector space is finite-dimensional. Only these spaces are relevant for the purposes of this blog.\u003c/p\u003e\u003cp\u003eEvery finite-dimensional vector space has a basis. A basis is a set of linearly independent vectors that span the whole space. In R\u003csup\u003e2\u003c/sup\u003e, a basis can consist of two non-collinear vectors. In R\u003csup\u003e3\u003c/sup\u003e, a basis can consist of three vectors that do not lie on the same plane. Note that a basis is not necessarily unique - e.g. in R\u003csup\u003en\u003c/sup\u003e, we can choose different vectors that will still span the same space and be linearly independent.\u003c/p\u003e\u003cp\u003eNotice how I stated that a basis in R\u003csup\u003e2\u003c/sup\u003e consists of two vectors, while in R\u003csup\u003e3\u003c/sup\u003e it consists of three vectors. A set of three vectors in R\u003csup\u003e2\u003c/sup\u003e is guaranteed to be linearly dependent, so it cannot be a basis. On the other hand, one vector cannot span R\u003csup\u003e2\u003c/sup\u003e. Likewise, we cannot find four linearly independent vectors in R\u003csup\u003e3\u003c/sup\u003e, but less than three vectors cannot span R\u003csup\u003e3\u003c/sup\u003e.\u003c/p\u003e\u003cp\u003eSkipping the proof, it is a true statement that every basis of a finite-dimensional vector space has the same number of vectors. This number is called the dimension of the vector space. By this, R\u003csup\u003en\u003c/sup\u003e has a dimension of n, which plays nicely with our geometric interpretation of R\u003csup\u003en\u003c/sup\u003e as n-dimensional space.\u003c/p\u003e\u003cp\u003eFor R\u003csup\u003en\u003c/sup\u003e, we define a standard basis as a set of n vectors, where each vector has exactly one non-zero coordinate, which is 1. For example, in R\u003csup\u003e3\u003c/sup\u003e, the standard basis is {(1, 0, 0), (0, 1, 0), (0, 0, 1)}.\u003c/p\u003e\u003cp\u003eWhy do we care about a basis? Since a basis is a set of linearly independent vectors that span the whole space, any vector in that space can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of vectors from the basis. That means that for every finite-dimensional vector space, no matter how abstract or exotic, we can always represent any of its vectors as a list of numbers (coefficients of linear combination of chosen basis).\u003c/p\u003e\u003ch2 id=\"linear-maps\"\u003e\u003cstrong\u003eLinear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow we are ready to define a linear map. A linear map (sometimes also called linear transformation), defined for vector spaces V and W, is a function that takes a vector from V as an input and returns a vector from W. It must satisfy two properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAdditivity:\u003c/strong\u003e f(u + v) = f(u) + f(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHomogeneity:\u003c/strong\u003e f(a * u) = a * f(u)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese properties ensure that linear maps preserve the linear structure of vector spaces - parallel vectors remain parallel, and origin remains at the origin.\u003c/p\u003e\u003cp\u003eWhile it may seem that linear maps are a very restricted class of functions, they can be used to represent a wide variety of transformations. For example, a linear map in R\u003csup\u003e2\u003c/sup\u003e can be used to represent:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRotation\u003c/li\u003e\u003cli\u003eScaling\u003c/li\u003e\u003cli\u003eReflection\u003c/li\u003e\u003cli\u003eShearing\u003c/li\u003e\u003cli\u003eAny combination of the above\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOne operation you cannot represent with a linear map is translation (moving every point by the same vector), since the origin must remain at the origin.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfcM7o_gKJk2c7hx0wjIEoZmu2OHveEQvO065rsVLYH5Ca5-v_vyWj9OGREyFacWuopomsh0gm9WLDkvOewl5S8JPJmeq1TRQwQrRab4klX2oJT-Tg0fqJ6rkBA3B6zps5tNFLIbg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"366\" height=\"318\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eShear operation in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAs mentioned in the introduction, they are also extremely prevalent in machine learning, e.g. in neural networks. While I am not going to prove this, the connections (weights) between linear layers are equivalent to linear maps from R\u003csup\u003en\u003c/sup\u003e to R\u003csup\u003em\u003c/sup\u003e, where n is the dimension of the input and m is the dimension of the output. Since you can represent these connections as a matrix, it's a hint that \u003cstrong\u003ematrices are intimately connected to linear maps\u003c/strong\u003e. We'll come back to this later.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeCp-3F2w7zsnKxYYjLu9Kp02nGlruiHhAbHii9zsGLP8xUvIQjpe9LIjxCrrV8nW5kaLXPYl7iwYc8hXUtfjOBnTS8sDwn-nWbgXz_DsQIN7UjOHG4rlRcGLoD5AOy5DVCrQD9uA?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"178\" height=\"324\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eTwo fully connected layers in a neural network without activation functions or biases. They are equivalent to a linear map from R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e to R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e - each input is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, and each output is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWe can define a set of operations on linear maps (let T and S be linear maps, and c an arbitrary scalar):\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition: \u003c/strong\u003e(T + S)(v) = T(v) + S(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e (c * T)(v) = c * T(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eComposition: \u003c/strong\u003e(T * S)(v) = T(S(v))\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA very important property of linear maps is that \u003cstrong\u003ea linear map is fully defined by its values on basis vectors\u003c/strong\u003e, for a chosen basis of input space. Let's say we have a linear map T and a basis B = {b\u003csub\u003e1\u003c/sub\u003e, b\u003csub\u003e2\u003c/sub\u003e, ..., b\u003csub\u003en\u003c/sub\u003e} of input space V. For any v in V, we can write v as a linear combination of basis vectors: v = c\u003csub\u003e1\u003c/sub\u003e * b\u003csub\u003e1\u003c/sub\u003e + c\u003csub\u003e2\u003c/sub\u003e * b\u003csub\u003e2\u003c/sub\u003e + ... + c\u003csub\u003en\u003c/sub\u003e * b\u003csub\u003en\u003c/sub\u003e. Then T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(b\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(b\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(b\u003csub\u003en\u003c/sub\u003e). This means that if we know what T does to each vector in the basis, we know what T does to any vector in the space.\u003c/p\u003e\u003ch2 id=\"matrix-as-representation-of-linear-map\"\u003e\u003cstrong\u003eMatrix as representation of linear map\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that every linear map T: V -\u0026gt; W (where V has dimension n and W has dimension m) and for a chosen basis Bv = {v\u003csub\u003e1\u003c/sub\u003e, v\u003csub\u003e2\u003c/sub\u003e, ..., v\u003csub\u003en\u003c/sub\u003e} of V, T is fully defined by values of T(v\u003csub\u003e1\u003c/sub\u003e), T(v\u003csub\u003e2\u003c/sub\u003e), ..., T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eLet's take a closer look at one of those values, say T(v\u003csub\u003e1\u003c/sub\u003e). We know that T(v\u003csub\u003e1\u003c/sub\u003e) is a vector in W, so we can write it as a linear combination of a chosen basis of W: T(v\u003csub\u003e1\u003c/sub\u003e) = d\u003csub\u003e1\u003c/sub\u003e * w\u003csub\u003e1\u003c/sub\u003e + d\u003csub\u003e2\u003c/sub\u003e * w\u003csub\u003e2\u003c/sub\u003e + ... + d\u003csub\u003em\u003c/sub\u003e * w\u003csub\u003em\u003c/sub\u003e. We can represent the coefficients of this linear combination as a list of numbers: [d\u003csub\u003e1\u003c/sub\u003e, d\u003csub\u003e2\u003c/sub\u003e, ..., d\u003csub\u003em\u003c/sub\u003e]. This list is uniquely determined by the linear map T and the chosen basis of V, and it is called the column vector representation of T(v\u003csub\u003e1\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eWe can do the same for T(v\u003csub\u003e2\u003c/sub\u003e), T(v\u003csub\u003e3\u003c/sub\u003e), and so on, up to T(v\u003csub\u003en\u003c/sub\u003e). In this way, we can associate with our linear map T a matrix A, where the j-th column is the column vector representation of T(v\u003csub\u003ej\u003c/sub\u003e). This matrix A is called the matrix representation of the linear map T. That is, \u003cstrong\u003ea matrix with m rows and n columns can be interpreted as a representation of a linear map from linear space of dimension n to linear space of dimension m\u003c/strong\u003e. When representing a linear map with a matrix, choice of bases is important - different bases will yield different matrices. That is why when not clear from the context, we must specify the bases for both the input and output spaces.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe36MNl-rRXhG4KwL8YAyQToQLcJq13rDEanIpgYDVG9ge7XCFf-IEVdHSvJdKPzMLQV_H4xzGzERyFyurj_kIzXuZqY0RQpAt9wri3SCB2oYnRHMcnTlJnFqULPTq_4gjZMakp_g?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"318\" height=\"242\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA representation of a particular linear map T: V -\u0026gt; W as a matrix. V has dimension 3, while W has dimension 2. Thus, the matrix has 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIt is important to note that such a matrix can be created for any linear map between finite-dimensional vector spaces - it is not limited to R\u003csup\u003en\u003c/sup\u003e. The common misconception is that the columns or rows of such a matrix are vectors, but in general they are not - they are coefficients of linear combinations. It is a coincidence that in the case of T: R\u003csup\u003en\u003c/sup\u003e -\u0026gt; R\u003csup\u003em\u003c/sup\u003e and if we choose the standard basis for R\u003csup\u003em\u003c/sup\u003e, the columns of the matrix representation are vectors in R\u003csup\u003en\u003c/sup\u003e.\u003c/p\u003e\u003ch2 id=\"matrix-operations-as-operations-on-linear-maps\"\u003e\u003cstrong\u003eMatrix operations as operations on linear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eIf matrices represent linear maps, do the matrix operations represent operations on linear maps? It turns out that they do.\u003c/p\u003e\u003cp\u003eIt is easy (albeit a bit tedious) to prove, that if A and B are matrices representing linear maps T and S, then:\u003c/p\u003e\u003cul\u003e\u003cli\u003eA + B represents the linear map T + S\u003c/li\u003e\u003cli\u003ec * A represents the linear map c * T\u003c/li\u003e\u003cli\u003eA * B represents the linear map T * S\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eKeep in mind that matrix multiplication is not commutative, i.e. A * B is not necessarily the same as B * A (even if both make sense dimension-wise).\u003c/p\u003e\u003cul\u003e\u003cli\u003eMatrix addition is only defined for matrices of the same dimensions, which is consistent with the fact that addition of linear maps is only defined for maps between the same spaces.\u003c/li\u003e\u003cli\u003eMatrix multiplication by scalar is defined for any matrix, which is consistent with the fact that scalar multiplication of linear maps is defined for any linear map.\u003c/li\u003e\u003cli\u003eMatrix multiplication is defined for any two matrices, provided that the number of columns in the first matrix is the same as the number of rows in the second matrix. This is consistent with the fact that composition of linear maps is only defined for maps where the output space of the first map is the same as the input space of the second map.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhile adding and multiplying by scalar are pretty intuitive operations, matrix multiplication is not that obvious. \u003cstrong\u003eIt has actually been defined so that composition of linear maps is represented by multiplication of their matrices\u003c/strong\u003e, which you are encouraged to verify.\u003c/p\u003e\u003cp\u003eAside from linear map composition, matrix multiplication can be used to apply a linear map to a vector. Say we have a linear map T: V -\u0026gt; W represented by matrix A, and a vector v in V. First we need to represent v as a nx1 column matrix. We'll call it Mat(v). Then we can compute A * Mat(v), which will be a vector in W.\u003c/p\u003e\u003cp\u003eThis type of matrix multiplication can be computed as follows, where a\u003csub\u003ej\u003c/sub\u003e is the j-th column of A, while m\u003csub\u003e1j\u003c/sub\u003e is the j-th element of Mat(v): \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"631\" height=\"199\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 600w, https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 631w\"\u003e\u003c/figure\u003e\u003cp\u003eApplying T to v can be written as T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(v\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(v\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eRemembering that a column j of matrix A represents T(v\u003csub\u003ej\u003c/sub\u003e), we can see that multiplying A by Mat(v) is indeed equivalent to applying T to v.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXevqSOQivzWeKcTeOPhUmNT4z0psVVGyrYtls1oLPQGJQnCcVW8QlGLQuM2-iS5fNegBS3CtgeAQ9PKokTe3FmxOHAnoui6DdLwTr7eUN0NPFP9qafWCA5-a1Qo18nur2ApU4g_?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"248\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA particular way to perform matrix multiplication when the second operand is a column matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe have now covered all the necessary concepts from linear algebra to understand matrix multiplication. We have seen that matrices can be interpreted as representations of linear maps, and that matrix operations can be interpreted as operations on linear maps. We have also seen that matrix multiplication is not just an arbitrary operation, but rather a composition of linear maps. While this blog barely scratched the surface of math involved in creating AI systems, hopefully it gave you a good intuition on the subject of linear maps and matrices.\u003c/p\u003e\u003cp\u003eIn conclusion, matrices are a fundamental tool in the AI toolkit, enabling efficient data manipulation and transformation. Whether you're building a simple linear regression model or a complex deep learning architecture, a solid grasp of matrix operations will empower you to create more effective and efficient AI solutions.\u003c/p\u003e","comment_id":"6757cf3acb24830001b1d4b1","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Matrices.png","featured":false,"visibility":"public","created_at":"2024-12-09T21:18:50.000-08:00","updated_at":"2025-03-12T11:59:32.000-07:00","published_at":"2024-12-11T10:38:57.000-08:00","custom_excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"}],"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"}],"primary_author":{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/inside-the-matrix-a-look-into-the-math-behind-ai/","excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"how-to-confidently-compare-test-and-evaluate-models-for-machine-learning"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/blog/how-to-confidently-compare-test-and-evaluate-models-for-machine-learning/?ref=labelbox.ghost.io by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 13:06:23 GMT -->
</html>