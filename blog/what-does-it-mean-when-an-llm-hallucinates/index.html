<!DOCTYPE html><html>
<!-- Mirrored from labelbox.com/blog/what-does-it-mean-when-an-llm-hallucinates/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:50:56 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">What does it mean when an LLM “hallucinates” &amp; why do LLMs hallucinate?</title><meta name="description" content="LLM responses can be factually incorrect. Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations." data-next-head=""/><link rel="preconnect" href="../../../fonts.googleapis.com/index.html" data-next-head=""/><link rel="preconnect" href="../../../fonts.gstatic.com/index.html" crossorigin="" data-next-head=""/><link href="../../../fonts.googleapis.com/css2f4aa.css?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,600;0,700;1,100;1,200;1,300;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" data-next-head=""/><meta property="og:title" content="What does it mean when an LLM “hallucinates” &amp; why do LLMs hallucinate?" data-next-head=""/><meta property="og:description" content="LLM responses can be factually incorrect. Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations." data-next-head=""/><meta property="og:url" content="https://labelbox.ghost.io/blog/what-does-it-mean-when-an-llm-hallucinates/" data-next-head=""/><meta property="og:image" content="https://labelbox.ghost.io/blog/content/images/2023/04/DALL-E-2023-04-03-14.35.33---an-oil-painting-of-a-robot-hallucinating-flying-fish--dancing-elephants-on-a-beach-next-san-fransokyo--colorful--hyper-realistic.png" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="What does it mean when an LLM “hallucinates” &amp; why do LLMs hallucinate?" data-next-head=""/><meta name="twitter:description" content="LLM responses can be factually incorrect. Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations." data-next-head=""/><meta name="twitter:site" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:creator" content="@Quantumworks Lab" data-next-head=""/><meta name="twitter:url" content="https://labelbox.ghost.io/blog/what-does-it-mean-when-an-llm-hallucinates/" data-next-head=""/><meta property="twitter:image" content="https://labelbox.ghost.io/blog/content/images/2023/04/DALL-E-2023-04-03-14.35.33---an-oil-painting-of-a-robot-hallucinating-flying-fish--dancing-elephants-on-a-beach-next-san-fransokyo--colorful--hyper-realistic.png" data-next-head=""/><meta name="robots" content="noimageindex"/><meta name="google-site-verification" content="SRhmoKSVCTohF2mf6v399S1hBWnpttMgky5tXdr-3yg"/><meta name="google-site-verification" content="lI3zXS3UkxbozsCAWHpRCzkujEMbo92e1smM4A7_6lA"/><meta name="theme-color" content="#2876D4"/><meta name="referrer" content="origin-when-crossorigin"/><link rel="shortcut icon" href="../../static/images/favicon-v4-black.png"/><meta http-equiv="Content-Security-Policy" content=" default-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27;;  script-src * &#x27;unsafe-inline&#x27; &#x27;unsafe-eval&#x27; https://cdn.logrocket.io https://cdn.lr-ingest.io https://cdn.lr-in.com https://cdn.lr-in-prod.com;  connect-src * data: &#x27;unsafe-inline&#x27;;  img-src * data: blob: &#x27;unsafe-inline&#x27; https://*.logrocket.io https://*.lr-ingest.io https://*.logrocket.com https://*.lr-in.com https://*.lr-in-prod.com;  frame-src *;  style-src * &#x27;unsafe-inline&#x27;;  worker-src * &#x27;self&#x27; blob:;  child-src * &#x27;self&#x27; blob:; "/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-112801961-1"></script><script type="text/javascript" src="../../../cdn.bizible.com/scripts/bizible.js" async=""></script><script id="GTM">
                            window.dataLayer = window.dataLayer || [];
                            function gtag(){dataLayer.push(arguments);}
                            gtag('js', new Date());

                            gtag('config', 'UA-112801961-1');

                            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                            '../../../www.googletagmanager.com/gtm5445.html?id='+i+dl;f.parentNode.insertBefore(j,f);
                            })(window,document,'script','dataLayer','GTM-NXF2T87');
                        </script><link rel="stylesheet" href="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script src="../../../code.jquery.com/jquery-3.4.1.min.js"></script><script async="" defer="" id="Intercom" src="../../static/scripts/intercom.js"></script><script id="Munchkin1" src="../../../munchkin.marketo.net/munchkin.js" type="text/javascript"></script><script id="Munchkin2" src="../../static/scripts/munchkin.js"></script><script src="../../../discover.labelbox.com/rs/622-PVG-762/images/dpi-ppc-tracking-script.js"></script><style data-styled="" data-styled-version="5.3.11">.jsdymq{height:22px;width:30px;position:relative;}/*!sc*/
.jsdymq.dark-mode > div{background-color:white;}/*!sc*/
.jsdymq > div{height:4px;width:100%;background-color:black;position:absolute;left:0;margin:auto;-webkit-transition:.3s;transition:.3s;}/*!sc*/
.jsdymq > div#one{top:0;}/*!sc*/
.jsdymq > div#two{top:0;bottom:0;}/*!sc*/
.jsdymq > div#three{bottom:0;}/*!sc*/
.jsdymq.-open > div#one{top:40%;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}/*!sc*/
.jsdymq.-open > div#two{opacity:0;}/*!sc*/
.jsdymq.-open > div#three{bottom:40%;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}/*!sc*/
data-styled.g23[id="BurgerIcon__Wrapper-sc-1rg1iu4-0"]{content:"jsdymq,"}/*!sc*/
.hgDgWF{position:-webkit-sticky;position:sticky;width:100vw;top:0;left:0;background-color:rgba(255,255,255);-webkit-backdrop-filter:blur(150px);backdrop-filter:blur(150px);-webkit-backdrop-filter:blur(150px);z-index:100 !important;}/*!sc*/
.hgDgWF.dark-mode{background:#121619;}/*!sc*/
data-styled.g27[id="HeaderMobile__Outer-sc-1yu1mfn-0"]{content:"hgDgWF,"}/*!sc*/
.iPVOAg{height:72px !important;padding:0 24px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.iPVOAg > a > img.labelbox-logo{width:120px;}/*!sc*/
.iPVOAg > i.material-icons{font-size:36px;color:#2876D4;}/*!sc*/
data-styled.g28[id="HeaderMobile__Wrapper-sc-1yu1mfn-1"]{content:"iPVOAg,"}/*!sc*/
.eJChXt{padding-bottom:100px;}/*!sc*/
.eJChXt .sub-item{border-left:2px solid rgba(177,194,216,.21);}/*!sc*/
.eJChXt h6{font-size:20px;font-weight:500;margin-bottom:10px;}/*!sc*/
.eJChXt a{color:#49535F;}/*!sc*/
.eJChXt .IN-widget,.eJChXt #twitter-widget-0{margin:10px 0;}/*!sc*/
.eJChXt .footer-grid{grid-template-columns:repeat(5,1fr);margin:40px 0 100px;text-align:left;}/*!sc*/
.eJChXt .MuiTypography-body2{font-size:18px;}/*!sc*/
.eJChXt .MuiTypography-caption{display:inline-block;width:100%;line-height:26px;text-align:center;}/*!sc*/
@media (max-width:960px){.eJChXt{text-align:center;}.eJChXt .MuiTypography-caption{margin-top:10px;}}/*!sc*/
data-styled.g31[id="Footer__StyledFooter-sc-u68pnv-0"]{content:"eJChXt,"}/*!sc*/
.kDcKSx.no-overflow{overflow-x:hidden;}/*!sc*/
.kDcKSx.no-header{padding-top:0;}/*!sc*/
data-styled.g32[id="Layout__Wrapper-sc-jbj1sg-0"]{content:"kDcKSx,"}/*!sc*/
.cKNvnl a{color:#2563eb;}/*!sc*/
data-styled.g48[id="Footer__FooterSection-sc-172m51x-0"]{content:"cKNvnl,"}/*!sc*/
.eivcj #image-viewer{position:fixed;z-index:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;left:0;top:0;height:100vh;width:100%;background-color:rgb(255 255 255);cursor:-webkit-zoom-out;cursor:-moz-zoom-out;cursor:zoom-out;}/*!sc*/
.eivcj .modal-content{margin:auto;display:block;max-width:1000px;border:none;width:auto;height:auto;padding-top:10px;max-height:70vh;}/*!sc*/
.eivcj .modal-content{-webkit-animation-name:zoom;animation-name:zoom;-webkit-animation-duration:0.6s;animation-duration:0.6s;}/*!sc*/
@-webkit-keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
@keyframes zoom{from{-webkit-transform:scale(0.6);-ms-transform:scale(0.6);transform:scale(0.6);}to{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}}/*!sc*/
.eivcj #image-viewer .close{position:absolute;top:15px;right:35px;color:#f1f1f1;font-size:40px;font-weight:bold;-webkit-transition:0.3s;transition:0.3s;}/*!sc*/
.eivcj #image-viewer .close:hover,.eivcj #image-viewer .close:focus{color:#bbb;-webkit-text-decoration:none;text-decoration:none;cursor:pointer;}/*!sc*/
@media only screen and (max-width:700px){.eivcj .modal-content{width:100%;}}/*!sc*/
data-styled.g105[id="ImageModal__ImageModalWrapper-sc-1ey7m7r-0"]{content:"eivcj,"}/*!sc*/
.QsqTL .content p{-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:28px;font-size:19px;margin-bottom:20px;}/*!sc*/
.QsqTL .content h1{font-size:34px;line-height:44px;color:#21272c;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
.QsqTL .content h2{font-size:30px !important;color:#21272c;line-height:1.3;font-weight:600;padding-top:35px !important;margin-bottom:20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h2{padding-top:10px;}}/*!sc*/
.QsqTL .content h3{font-size:24px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 20px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h3{padding-top:10px;}}/*!sc*/
.QsqTL .content h4{font-size:20px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 16px;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content h4{padding-top:8px;}}/*!sc*/
.QsqTL .content h5{font-size:18px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 14px;}/*!sc*/
.QsqTL .content h6{font-size:16px;color:#21272c;line-height:1.3;font-weight:600;padding-top:5px;margin:0 0 12px;}/*!sc*/
.QsqTL .content a{color:#2563eb;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color linear 0.2s;transition:color linear 0.2s;}/*!sc*/
.QsqTL .content a:hover{color:#1e40af;}/*!sc*/
.QsqTL .content li{margin-bottom:20px;}/*!sc*/
.QsqTL .content ul{list-style:disc;padding-left:20px;}/*!sc*/
.QsqTL .content ol{list-style:decimal;padding-left:20px;}/*!sc*/
.QsqTL .content .table-container{overflow-x:auto;margin:40px 0;-webkit-overflow-scrolling:touch;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container{margin:30px -20px;padding:0 20px;}}/*!sc*/
.QsqTL .content table{width:100%;border-collapse:collapse;font-size:16px;background:white;border:1px solid #e5e7eb;border-radius:8px;overflow:hidden;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content table{font-size:14px;}}/*!sc*/
.QsqTL .content .table-container table{margin:0;min-width:600px;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-container table{min-width:700px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content .content table:not(.table-container table){margin:40px 0;min-width:auto;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .content table:not(.table-container table){margin:30px 0;min-width:auto;border-radius:8px;border:1px solid #e5e7eb;}}/*!sc*/
.QsqTL .content thead{background:#fafbfc;border-bottom:1px solid #d1d5db;}/*!sc*/
.QsqTL .content th{padding:16px 20px;text-align:left;font-weight:600;color:#374151;font-size:14px;-webkit-letter-spacing:0.025em;-moz-letter-spacing:0.025em;-ms-letter-spacing:0.025em;letter-spacing:0.025em;border-right:1px solid #f3f4f6;}/*!sc*/
.QsqTL .content th:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content th{padding:12px 16px;font-size:13px;}}/*!sc*/
.QsqTL .content td{padding:16px 20px;border-bottom:1px solid #f3f4f6;border-right:1px solid #f9fafb;color:#374151;line-height:1.5;}/*!sc*/
.QsqTL .content td:last-child{border-right:none;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content td{padding:12px 16px;}}/*!sc*/
.QsqTL .content tbody tr{-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}/*!sc*/
.QsqTL .content tbody tr:hover{background-color:#f8fafc;}/*!sc*/
.QsqTL .content tbody tr:last-child td{border-bottom:none;}/*!sc*/
.QsqTL .content .table-wrapper{overflow-x:auto;margin:40px 0;border:1px solid #e5e7eb;border-radius:8px;-webkit-overflow-scrolling:touch;}/*!sc*/
.QsqTL .content .table-wrapper table{margin:0;border:none;border-radius:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content .table-wrapper{margin:30px -20px;border-radius:0;border-left:none;border-right:none;}}/*!sc*/
.QsqTL .content code{background:#f1f5f9;padding:2px 6px;border-radius:4px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;color:#e11d48;}/*!sc*/
.QsqTL .content pre{background:#1e293b;color:#e2e8f0;padding:20px;border-radius:8px;overflow-x:auto;margin:30px 0;}/*!sc*/
.QsqTL .content pre code{background:transparent;padding:0;color:inherit;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content pre{margin:20px -20px;border-radius:0;padding:16px 20px;}}/*!sc*/
.QsqTL .content blockquote{border-left:4px solid #2563eb;padding:20px 24px;margin:30px 0;background:#f8fafc;border-radius:0 8px 8px 0;font-style:italic;color:#475569;}/*!sc*/
.QsqTL .content blockquote p{margin-bottom:0;}/*!sc*/
.QsqTL .content blockquote p:last-child{margin-bottom:0;}/*!sc*/
@media only screen and (max-width:48rem){.QsqTL .content blockquote{margin:20px 0;padding:16px 20px;}}/*!sc*/
.QsqTL .content hr{border:none;height:1px;background:linear-gradient(to right,transparent,#e5e7eb,transparent);margin:50px 0;}/*!sc*/
.QsqTL .content .kg-image-card{padding:20px 0 40px;margin:0 -20px;}/*!sc*/
.QsqTL .content .kg-image-card figcaption{text-align:center;-webkit-letter-spacing:0.1px;-moz-letter-spacing:0.1px;-ms-letter-spacing:0.1px;letter-spacing:0.1px;line-height:1.3;font-size:0.75rem;padding:10px 20px 0 20px;color:#6b7280;font-style:italic;}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card figcaption{font-size:0.875rem;padding:15px 0 0 0;}}/*!sc*/
@media only screen and (min-width:48rem){.QsqTL .content .kg-image-card{padding:20px 0 50px;margin:0;}}/*!sc*/
.QsqTL .content .kg-image{display:block;width:auto;max-width:100%;height:auto;margin:0 auto;cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-embed-card{margin:50px 0 50px 0px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-width:100%;position:relative;padding-top:56.5%;}/*!sc*/
.QsqTL .content .kg-embed-card iframe{position:absolute;top:0;left:0;width:100%;height:100%;margin:0 auto;border-radius:8px;}/*!sc*/
.QsqTL .content .kg-bookmark-card{background:white;border-radius:10px;margin-top:60px !important;border:1px solid #e5e7eb;-webkit-transition:border-color 0.3s ease;transition:border-color 0.3s ease;}/*!sc*/
.QsqTL .content .kg-bookmark-card:hover{border-color:#d1d5db;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;color:#262626 !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail{position:relative;min-width:30%;max-height:100%;overflow:hidden;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-thumbnail img{position:absolute;top:0;left:0;width:100% !important;height:100% !important;-o-object-fit:cover;object-position:left;object-fit:cover;border-radius:0 10px 10px 0;border-left:1px solid #f5f5f5;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;padding:20px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-title{font-size:1.125rem;line-height:1.3;font-weight:600;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-description{font-size:0.875rem;font-weight:400;line-height:1.4;margin-top:12px;overflow-y:hidden;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;font-size:0.9rem;font-weight:400;margin-top:14px;color:#6b7280;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata img{width:22px !important;height:22px !important;margin-right:8px !important;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-author{margin:4px;}/*!sc*/
.QsqTL .content .kg-bookmark-card .kg-bookmark-container .kg-bookmark-content .kg-bookmark-metadata .kg-bookmark-publisher{margin:4px;}/*!sc*/
.QsqTL .kg-gallery-container{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;margin:40px 0;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;margin-bottom:12px;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row .kg-gallery-image{margin:0 6px;border-radius:6px;overflow:hidden;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;display:block;margin:0;width:100%;height:100%;object-fit:cover;-webkit-transition:-webkit-transform 0.3s ease;-webkit-transition:transform 0.3s ease;transition:transform 0.3s ease;}/*!sc*/
.QsqTL .kg-gallery-container .kg-gallery-row img:hover{-webkit-transform:scale(1.02);-ms-transform:scale(1.02);transform:scale(1.02);}/*!sc*/
data-styled.g112[id="id__PostContentWrapper-sc-1hduup0-0"]{content:"QsqTL,"}/*!sc*/
@media (max-width:767px){.bwsQop.toc-container{display:none;}}/*!sc*/
.bwsQop.toc-container .js-toc{position:-webkit-sticky;position:sticky;top:148px;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;height:auto;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list{list-style:none;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .is-collapsed{max-height:1000px !important;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list .toc-list-item ol{padding-left:25px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li{margin-bottom:14px;margin-top:14px;line-height:18px;font-size:14px;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a{color:#6a7888;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li a.is-active-link{color:black;}/*!sc*/
.bwsQop.toc-container .js-toc .toc-list li .toc-link::before{background-color:none !important;}/*!sc*/
data-styled.g113[id="id__TocContainer-sc-1hduup0-1"]{content:"bwsQop,"}/*!sc*/
</style><script defer="" async="" id="Cookiebot" type="text/javascript" src="../../../consent.cookiebot.com/uc.js" data-cbid="f530ad95-5299-43fb-9606-954f44911c4c"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><script src="../../../platform.linkedin.com/in.js" type="text/javascript"> <!-- -->lang: en_US</script><link rel="preload" href="../../_next/static/css/77a4236f8e9a0455.css" as="style"/><link rel="stylesheet" href="../../_next/static/css/77a4236f8e9a0455.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="../../_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script data-partytown-config="">
            partytown = {
              lib: "/_next/static/~partytown/"
            };
          </script><script data-partytown="">!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=w[p]||{};c[f]=(c[f]||[])})(window,'partytown','forward');/* Partytown 0.9.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(t){p=r.createElement(t?"script":"iframe"),t||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(t?"atomics.js?v=0.9.2":"sandbox-sw.html?"+Date.now()),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);</script><script src="../../_next/static/chunks/webpack-66e4f841c974e844.js" defer=""></script><script src="../../_next/static/chunks/framework-f0f34dd321686665.js" defer=""></script><script src="../../_next/static/chunks/main-e0f96f365dc7fe29.js" defer=""></script><script src="../../_next/static/chunks/pages/_app-75d6dce28a8def7d.js" defer=""></script><script src="../../_next/static/chunks/8220-8c3b7d4a24781c26.js" defer=""></script><script src="../../_next/static/chunks/430-c66e465cc32ba99e.js" defer=""></script><script src="../../_next/static/chunks/3817-e3d316d0f77ffd1b.js" defer=""></script><script src="../../_next/static/chunks/385-070eb47cdc107155.js" defer=""></script><script src="../../_next/static/chunks/8853-67d854f782ed49e3.js" defer=""></script><script src="../../_next/static/chunks/4587-67f46a96540c8153.js" defer=""></script><script src="../../_next/static/chunks/8789-a321e4743358e199.js" defer=""></script><script src="../../_next/static/chunks/3341-ef29c07033cbc96b.js" defer=""></script><script src="../../_next/static/chunks/1907-5ca362d03230011c.js" defer=""></script><script src="../../_next/static/chunks/pages/blog/%5bid%5d-b80b73d0fd88ad55.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_buildManifest.js" defer=""></script><script src="../../_next/static/Tltx2tBe97VOu7U0vVrr8/_ssgManifest.js" defer=""></script><style>
        /* Footer styles */
        .footer {
            background-color: #ffffff;
            padding: 100px 0 40px 0;
            border-top: 1px solid #e5e7eb;
        }

        .footer-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .footer-content {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 40px;
            margin-bottom: 60px;
        }

        .footer-section h6 {
            font-size: 20px;
            font-weight: 500;
            margin-bottom: 20px;
            color: #1f2937;
        }

        .footer-section ul {
            list-style: none;
        }

        .footer-section ul li {
            margin-bottom: 12px;
        }

        .footer-section ul li a {
            color: #49535F;
            text-decoration: none;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .footer-section ul li a:hover {
            color: #2876D4;
        }

        .footer-bottom {
            text-align: center;
            padding-top: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .footer-logo {
            margin-bottom: 20px;
        }

        .footer-logo img {
            height: 36px;
            width: auto;
        }

        .footer-copyright {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            color: #1f2937;
            margin-bottom: 20px;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 16px;
            flex-wrap: wrap;
        }

        .footer-links a {
            color: #49535F;
            text-decoration: none;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 14px;
            transition: color 0.3s ease;
        }

        .footer-links a:hover {
            color: #2876D4;
        }

        .footer-divider {
            width: 1px;
            height: 16px;
            background-color: #e5e7eb;
            margin: 0 8px;
        }

        /* Responsive design */
        @media (max-width: 1024px) {
            .footer-content {
                grid-template-columns: repeat(3, 1fr);
                gap: 30px;
            }
        }

        @media (max-width: 768px) {
            .footer-content {
                grid-template-columns: repeat(2, 1fr);
                gap: 24px;
            }
            
            .footer {
                padding: 60px 0 30px 0;
            }
        }

        @media (max-width: 480px) {
            .footer-content {
                grid-template-columns: 1fr;
                text-align: center;
            }
            
            .footer-links {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
            
            .footer-divider {
                display: none;
            }
        }
    </style><link rel="stylesheet" href="/disable-js-footer.css">
<link rel="stylesheet" href="fix-footer-visibility.css">
</head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF2T87" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main><div class="Layout__Wrapper-sc-jbj1sg-0 kDcKSx transition-all duration-300 ease-in undefined  overflow"><div class=""></div><div class="HeaderMobile__Outer-sc-1yu1mfn-0 hgDgWF"><div class="HeaderMobile__Wrapper-sc-1yu1mfn-1 iPVOAg lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><a href="../../index.html"><img width="106" height="24" alt="logo" src="../../static/images/logo-v4.svg"/></a><div class="BurgerIcon__Wrapper-sc-1rg1iu4-0 jsdymq"><div id="one"></div><div id="two"></div><div id="three"></div></div></div></div><main class="ImageModal__ImageModalWrapper-sc-1ey7m7r-0 eivcj"><div id="image-viewer"><span class="close">×</span><img class="modal-content" id="full-image"/></div></main><div class="py-12 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="grid grid-cols-12 "><div class="col-span-12 md:col-span-3 lg:col-span-2"><div class="sticky top-24"><img src="../../static/images/guide.svg" class="h-10"/><a href="../index.html" class="flex text-md align-items-center mt-6"><img src="../../static/images/leftarrow.svg" class="img-fluid mr-2"/>All blog posts</a><main class="id__TocContainer-sc-1hduup0-1 bwsQop toc-container py-8"><div class="  js-toc"></div></main></div></div><div class="col-span-12 md:col-span-9 lg:col-span-10"><div class="md:px-24 mb-12"><div class=""><p class="my-4 text-sm font-medium">Nathana Sharma<span class="mx-2">•</span>March 8, 2023</p><h1 class="md:text-6xl lg:text-7xl font-future text-neutral-900 dark:text-neutral-50 text-2xl md:!text-4xl font-bold max-w-3xl mb-12" style="font-feature-settings:unset">What does it mean when an LLM “hallucinates” &amp; why do LLMs hallucinate?</h1></div><img class="img-fluid rounded-lg" src="../../../labelbox.ghost.io/blog/content/images/2023/04/DALL-E-2023-04-03-14.35.33---an-oil-painting-of-a-robot-hallucinating-flying-fish--dancing-elephants-on-a-beach-next-san-fransokyo--colorful--hyper-realistic"/></div><main class="id__PostContentWrapper-sc-1hduup0-0 QsqTL md:px-24"><div class="content js-toc-content"><p><em>How to know if your LLM is generating true information? Why LLMs need reinforcement learning (RLHF).</em></p><p>Large Language Models (LLMs) spins tales as easily as it recounts facts—a digital bard, if you will. It's a marvelous tool, but it has a quirk: sometimes it makes things up. It weaves stories that sound plausible, but they're actually pure fiction.</p><p>With the emergence of ChatGPT and similar tools, it's becoming a common occurrence to type in a seemingly perfect prompt into ChatGPT and get back a polished sophisticated essay on the science of cucumber farming in Costa Rica. The only problem is that some parts of the essay are just not factually true. But which ones?</p><p><u>LLMs</u> are a powerful tool to generate coherent and contextually appropriate text. LLMs can be used for everything from travel suggestions, marketing advice, to “helping” with homework. However, LLMs are susceptible to “hallucination”, where the model generates text that is factually incorrect or entirely fictional.</p><p>In this blog post, we will explore why hallucination occurs from a technical perspective and what can be done to mitigate this. We'll also dive into why there is a tremendous opportunity to supplement LLMs with steps to verify their output using <a href="../using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/indexc625.html?ref=labelbox.ghost.io"><u>reinforcement learning with human feedback (“RLHF”)</u></a>.</p><h2 id="what-is-a-llm-hallucination">What is a LLM Hallucination?</h2><p>Large language model hallucinations are when the output responses generated from the model are factually inaccurate.</p><p>These hallucinations might occur when using any of the popular LLM’s for certain input prompts. Examples of popular large language models include: <a href="../../product/model/foundry-models/gpt-3-5/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">OpenAI GPT-3.5</a>, <a href="../../product/model/foundry-models/gpt4/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">GPT-4.0</a>, <a href="../../product/model/foundry-models/claude-3-5-sonnet/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">Claude 3.5 Sonnet</a>, <a href="../../product/model/foundry-models/claude-3-opus/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">Claude 3 Opus</a> or <a href="../../product/model/foundry-models/gemini-1-5-pro/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">Google Gemini Pro</a>.</p><h2 id="llm-hallucination-example">LLM Hallucination Example</h2><p>I spent the summer of 2008 doing research on a Hebrew poet, Avraham ben Yitzchak, an influential modern Hebrew poet who published only 11 poems during his lifetime.</p><p>When asking ChatGPT about this poet, it confidently provided some incredibly detailed answers, including making up a poem and translation purportedly by Avraham ben Yitzchak, but is in fact completely made up by ChatGPT. It’s an incredible technology but if you don’t know that the poem is not real, you might think that it is in fact a translation of a real poem.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../../../lh7-us.googleusercontent.com/docsz/AD_4nXfX7yDj0rZW72gyEYiZP_iqr4gpS2_XBUnctl_3R2J3UxN16pcnDQt_hwqkxdlCJBWYzczqCF-bwp-2S7l-1ZnHO81ik9Kshrzxulvxfea-U_CjFy-jMQwtmeWV00tN9VMFZgnYT5Ng9T94x7BsQcmXvDQS.9c18aa1?key=7foKQ-lXOt8xKS4Xfspd5w" class="kg-image" alt="Example LLM hallucination in historical poetry using ChatGPT" loading="lazy" width="1327" height="1190"><figcaption><span style="white-space: pre-wrap;">Example LLM hallucination in historical poetry using ChatGPT</span></figcaption></figure><p>At its core, ChatGPT (using the latest versions of GPT) are neural networks trained on vast amounts of text data. It's a statistical machine, learning patterns and relationships from the data it ingests. During training, they are exposed to diverse sources of text, from scientific articles to works of fiction. It learns to predict the next word in a sentence based on the context provided by the preceding words.</p><h2 id="why-do-llms-hallucinate">Why do LLMs hallucinate?</h2><p>LLM hallucination occurs because the model's primary objective is to generate text that is coherent and contextually appropriate, rather than factually accurate. The model's training data may contain inaccuracies, inconsistencies, and fictional content, and the model has no way of distinguishing between fact and fiction. As a result, it may generate text that aligns with the patterns observed in the training data, but is not grounded in reality.</p><h3 id="ground-truth-issue">Ground Truth Issue</h3><p>From a technical perspective, hallucination in large language models can be attributed to a lack of ground truth from external sources.</p><p>Ground truth refers to data that accurately represents the real-world phenomena or outcomes that an AI model aims to predict, classify, or generate. It is considered the "gold standard" or reference point against which the model's predictions or outputs are compared.</p><p>Unlike traditional supervised learning tasks where ground truth labels are explicitly provided, ChatGPT is trained using a variant of the transformer architecture and is designed to predict the next word in a sentence given the preceding words.</p><p>The training process involves feeding the model large amounts of text data, and the model learns to predict the next word based on the context provided by the previous words. In this scenario, the ground truth is derived from the text data itself.</p><p>For example, if the input sentence is "The cat is sitting on the ___," the ground truth for the next word might be "mat." The model's objective is to generate text that aligns with the patterns observed in the training data, which serves as the ground truth.</p><p>ChatGPT generates answers based on patterns in the training data and does not check for factual accuracy in the model’s predictions.Unlike traditional supervised learning tasks, language models like ChatGPT do not rely on explicitly labeled data. Instead, they learn from the inherent structure of the text itself. While this self-supervised approach allows for training on large, unlabeled datasets, it also means that the model lacks access to external sources of ground truth for verification. As a result, the model may learn and propagate inaccuracies present in the training data.</p><p>Additionally, text data used for training large language models may include fictional content, such as literature, as well as subjective content, such as opinions and beliefs. The presence of fictional and subjective content poses challenges for defining ground truth, as the model must learn to generate text that is coherent and contextually appropriate, even if it is not factually accurate or objective.</p><h2 id="how-to-mitigate-llm-hallucinations">How to mitigate LLM hallucinations</h2><p>How do we teach LLMs to stick to the truth? To help reduce the risk of LLM hallucination output responses, you would use human feedback using reinforcement learning with human feedback (RLHF) as a guiding light to reward the model when it's right and nudge it back on track when it strays.</p><p><a href="../using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/indexc625.html?ref=labelbox.ghost.io" rel="noreferrer">RLHF</a>, is a method that lets us train language models like GPT-4 to be more discerning about the accuracy of their output.</p><p>As <a href="https://spectrum.ieee.org/ai-hallucination?ref=labelbox.ghost.io" rel="noreferrer">Ilya Sutskever, Chief Scientist at OpenAI has advanced</a>, “I'm quite hopeful that by simply improving this subsequent reinforcement learning from human feedback step, we can teach it to not hallucinate.”</p><p>Reinforcement learning (RL) is all about an agent learning to make decisions in an environment. The agent takes actions, receives feedback in the form of rewards or penalties, and iteratively adjusts its behavior to maximize cumulative reward. In our case, the agent is the language model, the actions are generating text, and the rewards come from human evaluators who assess the quality of the generated text.</p><p>Human feedback is the linchpin of this process, acting as the compass that points the model toward factual accuracy. Human evaluators assess the coherence, relevance, and truthfulness of the generated text, providing feedback that shapes the model's learning trajectory. This feedback is distilled into a reward signal that guides the model's quest for optimization.</p><h2 id="how-to-fine-tune-a-llm-to-help-reduce-hallucinations">How to Fine Tune a LLM to Help Reduce Hallucinations</h2><p></p><p>The process of fine-tuning a language model, like ChatGPT, using reinforcement learning with human feedback involves several key steps:</p><p><strong>Step 1 - Pre-training</strong>: We first start with a language model pre-trained on a vast corpus of text data. It's a treasure trove of language patterns, syntax, and semantics. This step lays the groundwork for the fine-tuning that follows.</p><p><strong>Step 2 - Data Collection</strong>: Human evaluators step in, reviewing input prompts and corresponding model-generated responses. They rank or rate the responses based on criteria like coherence, relevance, and factual accuracy. This step assembles a dataset of human preferences and evaluations.</p><p><strong>Step 3 - Reward Modeling</strong>: We use the collected human feedback to forge a reward model—a quantifier of text quality. This serves as a proxy for human judgment, a beacon that illuminates the path for reinforcement learning.</p><p><strong>Step 4 - Proximal Policy Optimization</strong>: Next, we fine-tune the language model using an RL algorithm like <a href="https://openai.com/research/openai-baselines-ppo?ref=labelbox.ghost.io"><u>Proximal Policy Optimization (PPO)</u></a>. The model generates text, receives rewards from the reward model, and iteratively updates its parameters to maximize cumulative reward.</p><p><strong>Step 5 - Evaluation and Validation</strong>: Lastly, we put the fine-tuned model to the test on new and unseen data. Human evaluators can join in to provide additional feedback and validate the model's output. We measure coherence, factual accuracy, and alignment with human preferences.</p><p>As you can see, fine-tuning LLM outputs requires us to set up ways to reliably get high-quality human feedback, which is a complex coordination challenge in of itself.</p><p>Some other active areas of research to mitigate hallucinations in LLMs include:</p><ul><li>domain specific fine tuning</li><li>adversarial training</li><li>multi-modal models.</li></ul><p></p><p>Note that all of these approaches require some level of verification for factual accuracy outside the model itself, currently best done with RLHF.</p><p><strong>Domain Specific Fine-Tuning</strong>: Fine-tuning the model on domain-specific or task-specific data can help improve its performance and reduce hallucination for specific use cases. Domain-specific fine-tuning can help the model better understand the context and conventions of a particular field, leading to more accurate and reliable output. Bloomberg GPT is an example of a new LLM that is domain specific to financial knowledge.</p><p><strong>Adversarial Training</strong>: Adversarial training involves training the model to recognize and avoid generating hallucinated content. This can be achieved by using adversarial examples, where the model is presented with text containing hallucinations and is trained to identify and correct them.</p><p><strong>Multi-Modal Models</strong>: Combining language models with other modalities, such as images or structured data, can provide additional context and help ground the model's output in reality. Multi-modal models can leverage information from multiple sources to generate more accurate and reliable text.</p><h2 id="final-thoughts-on-llm-hallucination">Final thoughts on LLM hallucination</h2><p>While LLMs are proving to be a breakthrough innovation, we need to remember that not everything that they confidently state is actually true. While they are showing strong promise in domains such as natural language processing, machine translation, and content generation, beware of hallucinations in LLMs as they can generate outputs that are either incorrect or potentially harmful. There is an immense opportunity to take the outputs from LLMs and improve them by including extra verification steps through reinforcement learning with human feedback.</p><p>References:</p><ul><li><a href="../../../cdn.openai.com/papers/gpt-4c625.pdf?ref=labelbox.ghost.io"><u>https://cdn.openai.com/papers/gpt-4.pdf</u></a></li><li><a href="https://openai.com/research/learning-to-summarize-with-human-feedback?ref=labelbox.ghost.io"><u>https://openai.com/research/learning-to-summarize-with-human-feedback</u></a></li><li><a href="https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=4759cd191218&amp;ref=labelbox.ghost.io"><u>https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=4759cd191218</u></a></li><li><a href="https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx?ref=labelbox.ghost.io"><u>https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx</u></a></li><li>Note that integrating ChatGPT with WolframAlpha can help with some computational hallucinations but does not in itself solve the hallucination problem(<a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/?ref=labelbox.ghost.io"><u>https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/</u></a>). ChatGPT still makes up confident answers in response to questions without flagging those answers as made up every time as you can see in the example of making up a poem in this post.</li><li><a href="https://www.arxiv-vanity.com/papers/2302.12813/?ref=labelbox.ghost.io"><u>https://www.arxiv-vanity.com/papers/2302.12813/</u></a></li><li><a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/?ref=labelbox.ghost.io"><u>https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/</u></a></li><li><a href="../../../openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adversarial_Feature_Hallucination_Networks_for_Few-Shot_Learning_CVPR_2020_paperc625.pdf?ref=labelbox.ghost.io"><u>https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adversarial_Feature_Hallucination_Networks_for_Few-Shot_Learning_CVPR_2020_paper.pdf</u></a></li><li><a href="https://arxiv.org/abs/2302.04023?ref=labelbox.ghost.io"><u>https://arxiv.org/abs/2302.04023</u></a></li></ul><p><br><br><br></p><p><br></p><p><br></p></div></main></div></div></div><div class="mt-5 lg:w-[88vw] max-w-6xl lg:max-w-8xl m-auto px-6"><div class="my-20 w-full h-[1px] bg-neutral-200"></div><div class="grid grid-cols-12 gap-2"><div class="col-span-12"><h2 class="mb-12 text-center text-3xl md:text-4xl font-medium">Continue reading</h2></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index4144.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FLabelbox-code-runner--1-.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Dmytro Apollonin<span class="mx-2">•</span>December 20, 2024</p></div><a href="../code-runner-secure-scalable-code-execution-for-model-evaluation-2/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Code Runner: Secure, scalable code execution for model evaluation</p><p class="text-base max-w-2xl undefined line-clamp-3">Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../advance-llm-reasoning-with-advanced-fact-checking-and-prompt-rating-tools/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index1614.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2Fllm-reasoning--2-.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Quantumworks Lab<span class="mx-2">•</span>December 17, 2024</p></div><a href="../advance-llm-reasoning-with-advanced-fact-checking-and-prompt-rating-tools/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Advance LLM reasoning with advanced fact-checking and prompt rating tools</p><p class="text-base max-w-2xl undefined line-clamp-3">Quantumworks Lab&#x27;s new fact-checking and prompt-rating tools improve LLM accuracy and reasoning capabilities by allowing users to evaluate responses, correct errors, and flag bad prompts.</p></a></div></div></div></div></div><div class="col-span-12 md:col-span-6 xl:col-span-4"><div class="h-100"><div class="bg-white rounded-lg h-100 flex flex-col"><a href="../inside-the-matrix-a-look-into-the-math-behind-ai/index.html" target="_self" class="relative aspect-video  undefined undefined"><img loading="lazy" decoding="async" data-nimg="fill" class="rounded-t-lg " style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:left;color:transparent" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=640&amp;q=70 640w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=750&amp;q=70 750w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=828&amp;q=70 828w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1080&amp;q=70 1080w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1200&amp;q=70 1200w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=1920&amp;q=70 1920w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=2048&amp;q=70 2048w, /_next/image/?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=3840&amp;q=70 3840w" src="../../_next/image/index45ff.html?url=https%3A%2F%2Flabelbox.ghost.io%2Fblog%2Fcontent%2Fimages%2F2024%2F12%2FMatrices.png&amp;w=3840&amp;q=70"/></a><div class="p-6 flex flex-col flex-grow justify-content-between"><div><div><p class="my-4 text-sm font-medium">Michał Jóźwiak<span class="mx-2">•</span>December 11, 2024</p></div><a href="../inside-the-matrix-a-look-into-the-math-behind-ai/index.html"><p class="text-xl lg:text-2xl leading-6 lg:leading-9 mb-2 max-w-3xl font-bold ">Inside the matrix: A look into the math behind AI</p><p class="text-base max-w-2xl undefined line-clamp-3">Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.</p></a></div></div></div></div></div></div></div><div class=""><div class="my-24 w-full h-[1px] bg-neutral-200"></div><section id="start-for-free-footer" class="
      max-w-xl
      m-auto flex flex-col gap-4 items-center justify-items-center text-center"><div class="Footer__FooterSection-sc-172m51x-0 cKNvnl flex flex-col gap-y-6 justify-center"><div class="w-160 m-auto pb-10"></div><h2 class="font-medium text-4xl sm:text-5xl lg:text-6xl  text-neutral-900 font-future">Try Quantumworks Lab today</h2><p class="text-neutral-500 font-medium  text-lg md:text-xl max-w-3xl m-auto">Get started for free or see how Quantumworks Lab can fit your specific needs by <a href="../../sales/index.html">requesting a demo</a></p></div><a href="https://app.labelbox.com/signup" class="group transition-all inline-flex justify-center items-center gap-[.5em] lb-button !outline-none focus:!outline-none focus-visible:!outline-none focus:!shadow-none focus:!drop-shadow-none active:shadow-none w-fit text-xl py-4 px-6 rounded-xl font-medium leading-[32px] bg-neutral-800 mix-blend-multiply hover:bg-black dark:bg-neutral-50 text-neutral-50 dark:text-neutral-900 mt-6" id="" target="_self" style="outline:0 !important">Start for free</a></section></div><footer class="footer">
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer>
        <div class="footer-container">
            <div class="footer-content">
                <!-- Product Section -->
                <div class="footer-section">
                    <h6>Product</h6>
                    <ul>
                        <li><a href="/product/platform/">Platform</a></li>
                        <li><a href="/product/model/foundry-models/">Model Foundry</a></li>
                        <li><a href="/product-demos/">Product Demos</a></li>
                        <li><a href="/recorded-demo/">Recorded Demo</a></li>
                    </ul>
                </div>

                <!-- Solutions Section -->
                <div class="footer-section">
                    <h6>Solutions</h6>
                    <ul>
                        <li><a href="/solutions/computer-vision/">Computer Vision</a></li>
                        <li><a href="/solutions/natural-language-processing/">Natural Language Processing</a></li>
                        <li><a href="/solutions/complex-reasoning/">Complex Reasoning</a></li>
                        <li><a href="/solutions/multimodal-reasoning/">Multimodal Reasoning</a></li>
                        <li><a href="/solutions/coding-tasks/">Coding</a></li>
                        <li><a href="/solutions/multilingual/">Multilingual</a></li>
                        <li><a href="/solutions/text-to-audio/">Audio</a></li>
                    </ul>
                </div>

                <!-- Learn Section (Resources) -->
                <div class="footer-section">
                    <h6>Learn</h6>
                    <ul>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/guides/">Guides</a></li>
                        <li><a href="https://docs.labelbox.com" target="_blank">Docs</a></li>
                        <li><a href="/faqs/">FAQs</a></li>
                        <li><a href="/research/">Research</a></li>
                        <li><a href="/product/model/foundry-models/">Models</a></li>
                        <li><a href="/datasets/">Public datasets</a></li>
                    </ul>
                </div>

                <!-- Company Section -->
                <div class="footer-section">
                    <h6>Company</h6>
                    <ul>
                        <li><a href="/company/about/">About</a></li>
                        <li><a href="/company/security/">Privacy & Security</a></li>
                        <li><a href="https://alignerr.com" target="_blank">Alignerr</a></li>
                    </ul>
                </div>

                <!-- Data Factory Section -->
                <div class="footer-section">
                    <h6>The data factory</h6>
                    <ul>
                        <li><a href="/why-labelbox/">Why Quantumworks Lab</a></li>
                        <li><a href="/services/labeling/">Labeling Services</a></li>
                        <li><a href="/services/alignerr-connect/">Alignerr Connect</a></li>
                        <li><a href="/model-foundry/">Model Foundry</a></li>
                        <li><a href="/leaderboards/">Leaderboards</a></li>
                    </ul>
                </div>
            </div>

            <div class="footer-bottom">
                <div class="footer-logo">
                    <img src="static/images/favicon-v4-black.png" alt="Quantumworks Lab logo" loading="lazy" height="36" width="36">
                </div>
                <div class="footer-copyright">
                    © Quantumworks Lab, Inc<br>
                    We enable breakthroughs
                </div>
                <div class="footer-links">
                    <a href="https://docs.labelbox.com/page/terms-of-service" target="_blank">Terms of Service</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/privacy-notice" target="_blank">Privacy Notice</a>
                    <div class="footer-divider"></div>
                    <a href="https://docs.labelbox.com/page/copyright-dispute-policy" target="_blank">Copyright Dispute Policy</a>
                </div>
            </div>
        </div>
    </footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"what-does-it-mean-when-an-llm-hallucinates","id":"642c3d5cdc9941003d59fe07","uuid":"fcf16dae-fd64-4ff7-af8d-e676c2e423b4","title":"What does it mean when an LLM “hallucinates” \u0026 why do LLMs hallucinate?","html":"\u003cp\u003e\u003cem\u003eHow to know if your LLM is generating true information? Why LLMs need reinforcement learning (RLHF).\u003c/em\u003e\u003c/p\u003e\u003cp\u003eLarge Language Models (LLMs) spins tales as easily as it recounts facts—a digital bard, if you will. It's a marvelous tool, but it has a quirk: sometimes it makes things up. It weaves stories that sound plausible, but they're actually pure fiction.\u003c/p\u003e\u003cp\u003eWith the emergence of ChatGPT and similar tools, it's becoming a common occurrence to type in a seemingly perfect prompt into ChatGPT and get back a polished sophisticated essay on the science of cucumber farming in Costa Rica. The only problem is that some parts of the essay are just not factually true. But which ones?\u003c/p\u003e\u003cp\u003e\u003cu\u003eLLMs\u003c/u\u003e are a powerful tool to generate coherent and contextually appropriate text. LLMs can be used for everything from travel suggestions, marketing advice, to “helping” with homework. However, LLMs are susceptible to “hallucination”, where the model generates text that is factually incorrect or entirely fictional.\u003c/p\u003e\u003cp\u003eIn this blog post, we will explore why hallucination occurs from a technical perspective and what can be done to mitigate this. We'll also dive into why there is a tremendous opportunity to supplement LLMs with steps to verify their output using \u003ca href=\"https://labelbox.com/blog/using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ereinforcement learning with human feedback (“RLHF”)\u003c/u\u003e\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"what-is-a-llm-hallucination\"\u003eWhat is a LLM Hallucination?\u003c/h2\u003e\u003cp\u003eLarge language model hallucinations are when the output responses generated from the model are factually inaccurate.\u003c/p\u003e\u003cp\u003eThese hallucinations might occur when using any of the popular LLM’s for certain input prompts. Examples of popular large language models include: \u003ca href=\"https://labelbox.com/product/model/foundry-models/gpt-3-5/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eOpenAI GPT-3.5\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/model/foundry-models/gpt4/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eGPT-4.0\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/model/foundry-models/claude-3-5-sonnet/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eClaude 3.5 Sonnet\u003c/a\u003e, \u003ca href=\"https://labelbox.com/product/model/foundry-models/claude-3-opus/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eClaude 3 Opus\u003c/a\u003e or \u003ca href=\"https://labelbox.com/product/model/foundry-models/gemini-1-5-pro/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eGoogle Gemini Pro\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"llm-hallucination-example\"\u003eLLM Hallucination Example\u003c/h2\u003e\u003cp\u003eI spent the summer of 2008 doing research on a Hebrew poet, Avraham ben Yitzchak, an influential modern Hebrew poet who published only 11 poems during his lifetime.\u003c/p\u003e\u003cp\u003eWhen asking ChatGPT about this poet, it confidently provided some incredibly detailed answers, including making up a poem and translation purportedly by Avraham ben Yitzchak, but is in fact completely made up by ChatGPT. It’s an incredible technology but if you don’t know that the poem is not real, you might think that it is in fact a translation of a real poem.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-us.googleusercontent.com/docsz/AD_4nXfX7yDj0rZW72gyEYiZP_iqr4gpS2_XBUnctl_3R2J3UxN16pcnDQt_hwqkxdlCJBWYzczqCF-bwp-2S7l-1ZnHO81ik9Kshrzxulvxfea-U_CjFy-jMQwtmeWV00tN9VMFZgnYT5Ng9T94x7BsQcmXvDQS?key=7foKQ-lXOt8xKS4Xfspd5w\" class=\"kg-image\" alt=\"Example LLM hallucination in historical poetry using ChatGPT\" loading=\"lazy\" width=\"1327\" height=\"1190\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eExample LLM hallucination in historical poetry using ChatGPT\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAt its core, ChatGPT (using the latest versions of GPT) are neural networks trained on vast amounts of text data. It's a statistical machine, learning patterns and relationships from the data it ingests. During training, they are exposed to diverse sources of text, from scientific articles to works of fiction. It learns to predict the next word in a sentence based on the context provided by the preceding words.\u003c/p\u003e\u003ch2 id=\"why-do-llms-hallucinate\"\u003eWhy do LLMs hallucinate?\u003c/h2\u003e\u003cp\u003eLLM hallucination occurs because the model's primary objective is to generate text that is coherent and contextually appropriate, rather than factually accurate. The model's training data may contain inaccuracies, inconsistencies, and fictional content, and the model has no way of distinguishing between fact and fiction. As a result, it may generate text that aligns with the patterns observed in the training data, but is not grounded in reality.\u003c/p\u003e\u003ch3 id=\"ground-truth-issue\"\u003eGround Truth Issue\u003c/h3\u003e\u003cp\u003eFrom a technical perspective, hallucination in large language models can be attributed to a lack of ground truth from external sources.\u003c/p\u003e\u003cp\u003eGround truth refers to data that accurately represents the real-world phenomena or outcomes that an AI model aims to predict, classify, or generate. It is considered the \"gold standard\" or reference point against which the model's predictions or outputs are compared.\u003c/p\u003e\u003cp\u003eUnlike traditional supervised learning tasks where ground truth labels are explicitly provided, ChatGPT is trained using a variant of the transformer architecture and is designed to predict the next word in a sentence given the preceding words.\u003c/p\u003e\u003cp\u003eThe training process involves feeding the model large amounts of text data, and the model learns to predict the next word based on the context provided by the previous words. In this scenario, the ground truth is derived from the text data itself.\u003c/p\u003e\u003cp\u003eFor example, if the input sentence is \"The cat is sitting on the ___,\" the ground truth for the next word might be \"mat.\" The model's objective is to generate text that aligns with the patterns observed in the training data, which serves as the ground truth.\u003c/p\u003e\u003cp\u003eChatGPT generates answers based on patterns in the training data and does not check for factual accuracy in the model’s predictions.Unlike traditional supervised learning tasks, language models like ChatGPT do not rely on explicitly labeled data. Instead, they learn from the inherent structure of the text itself. While this self-supervised approach allows for training on large, unlabeled datasets, it also means that the model lacks access to external sources of ground truth for verification. As a result, the model may learn and propagate inaccuracies present in the training data.\u003c/p\u003e\u003cp\u003eAdditionally, text data used for training large language models may include fictional content, such as literature, as well as subjective content, such as opinions and beliefs. The presence of fictional and subjective content poses challenges for defining ground truth, as the model must learn to generate text that is coherent and contextually appropriate, even if it is not factually accurate or objective.\u003c/p\u003e\u003ch2 id=\"how-to-mitigate-llm-hallucinations\"\u003eHow to mitigate LLM hallucinations\u003c/h2\u003e\u003cp\u003eHow do we teach LLMs to stick to the truth? To help reduce the risk of LLM hallucination output responses, you would use human feedback using reinforcement learning with human feedback (RLHF) as a guiding light to reward the model when it's right and nudge it back on track when it strays.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/blog/using-reinforcement-learning-from-human-feedback-to-fine-tune-large-language-models/?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eRLHF\u003c/a\u003e, is a method that lets us train language models like GPT-4 to be more discerning about the accuracy of their output.\u003c/p\u003e\u003cp\u003eAs \u003ca href=\"https://spectrum.ieee.org/ai-hallucination?ref=labelbox.ghost.io\" rel=\"noreferrer\"\u003eIlya Sutskever, Chief Scientist at OpenAI has advanced\u003c/a\u003e, “I'm quite hopeful that by simply improving this subsequent reinforcement learning from human feedback step, we can teach it to not hallucinate.”\u003c/p\u003e\u003cp\u003eReinforcement learning (RL) is all about an agent learning to make decisions in an environment. The agent takes actions, receives feedback in the form of rewards or penalties, and iteratively adjusts its behavior to maximize cumulative reward. In our case, the agent is the language model, the actions are generating text, and the rewards come from human evaluators who assess the quality of the generated text.\u003c/p\u003e\u003cp\u003eHuman feedback is the linchpin of this process, acting as the compass that points the model toward factual accuracy. Human evaluators assess the coherence, relevance, and truthfulness of the generated text, providing feedback that shapes the model's learning trajectory. This feedback is distilled into a reward signal that guides the model's quest for optimization.\u003c/p\u003e\u003ch2 id=\"how-to-fine-tune-a-llm-to-help-reduce-hallucinations\"\u003eHow to Fine Tune a LLM to Help Reduce Hallucinations\u003c/h2\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eThe process of fine-tuning a language model, like ChatGPT, using reinforcement learning with human feedback involves several key steps:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 1 - Pre-training\u003c/strong\u003e: We first start with a language model pre-trained on a vast corpus of text data. It's a treasure trove of language patterns, syntax, and semantics. This step lays the groundwork for the fine-tuning that follows.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 2 - Data Collection\u003c/strong\u003e: Human evaluators step in, reviewing input prompts and corresponding model-generated responses. They rank or rate the responses based on criteria like coherence, relevance, and factual accuracy. This step assembles a dataset of human preferences and evaluations.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 3 - Reward Modeling\u003c/strong\u003e: We use the collected human feedback to forge a reward model—a quantifier of text quality. This serves as a proxy for human judgment, a beacon that illuminates the path for reinforcement learning.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 4 - Proximal Policy Optimization\u003c/strong\u003e: Next, we fine-tune the language model using an RL algorithm like \u003ca href=\"https://openai.com/research/openai-baselines-ppo?ref=labelbox.ghost.io\"\u003e\u003cu\u003eProximal Policy Optimization (PPO)\u003c/u\u003e\u003c/a\u003e. The model generates text, receives rewards from the reward model, and iteratively updates its parameters to maximize cumulative reward.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 5 - Evaluation and Validation\u003c/strong\u003e: Lastly, we put the fine-tuned model to the test on new and unseen data. Human evaluators can join in to provide additional feedback and validate the model's output. We measure coherence, factual accuracy, and alignment with human preferences.\u003c/p\u003e\u003cp\u003eAs you can see, fine-tuning LLM outputs requires us to set up ways to reliably get high-quality human feedback, which is a complex coordination challenge in of itself.\u003c/p\u003e\u003cp\u003eSome other active areas of research to mitigate hallucinations in LLMs include:\u003c/p\u003e\u003cul\u003e\u003cli\u003edomain specific fine tuning\u003c/li\u003e\u003cli\u003eadversarial training\u003c/li\u003e\u003cli\u003emulti-modal models.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eNote that all of these approaches require some level of verification for factual accuracy outside the model itself, currently best done with RLHF.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDomain Specific Fine-Tuning\u003c/strong\u003e: Fine-tuning the model on domain-specific or task-specific data can help improve its performance and reduce hallucination for specific use cases. Domain-specific fine-tuning can help the model better understand the context and conventions of a particular field, leading to more accurate and reliable output. Bloomberg GPT is an example of a new LLM that is domain specific to financial knowledge.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdversarial Training\u003c/strong\u003e: Adversarial training involves training the model to recognize and avoid generating hallucinated content. This can be achieved by using adversarial examples, where the model is presented with text containing hallucinations and is trained to identify and correct them.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMulti-Modal Models\u003c/strong\u003e: Combining language models with other modalities, such as images or structured data, can provide additional context and help ground the model's output in reality. Multi-modal models can leverage information from multiple sources to generate more accurate and reliable text.\u003c/p\u003e\u003ch2 id=\"final-thoughts-on-llm-hallucination\"\u003eFinal thoughts on LLM hallucination\u003c/h2\u003e\u003cp\u003eWhile LLMs are proving to be a breakthrough innovation, we need to remember that not everything that they confidently state is actually true. While they are showing strong promise in domains such as natural language processing, machine translation, and content generation, beware of hallucinations in LLMs as they can generate outputs that are either incorrect or potentially harmful. There is an immense opportunity to take the outputs from LLMs and improve them by including extra verification steps through reinforcement learning with human feedback.\u003c/p\u003e\u003cp\u003eReferences:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://cdn.openai.com/papers/gpt-4.pdf?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://cdn.openai.com/papers/gpt-4.pdf\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://openai.com/research/learning-to-summarize-with-human-feedback?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://openai.com/research/learning-to-summarize-with-human-feedback\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=4759cd191218\u0026ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=4759cd191218\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003eNote that integrating ChatGPT with WolframAlpha can help with some computational hallucinations but does not in itself solve the hallucination problem(\u003ca href=\"https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/\u003c/u\u003e\u003c/a\u003e). ChatGPT still makes up confident answers in response to questions without flagging those answers as made up every time as you can see in the example of making up a poem in this post.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.arxiv-vanity.com/papers/2302.12813/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://www.arxiv-vanity.com/papers/2302.12813/\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adversarial_Feature_Hallucination_Networks_for_Few-Shot_Learning_CVPR_2020_paper.pdf?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adversarial_Feature_Hallucination_Networks_for_Few-Shot_Learning_CVPR_2020_paper.pdf\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2302.04023?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehttps://arxiv.org/abs/2302.04023\u003c/u\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e","comment_id":"642c3d5cdc9941003d59fe07","feature_image":"https://labelbox.ghost.io/blog/content/images/2023/04/DALL-E-2023-04-03-14.35.33---an-oil-painting-of-a-robot-hallucinating-flying-fish--dancing-elephants-on-a-beach-next-san-fransokyo--colorful--hyper-realistic.png","featured":false,"visibility":"public","created_at":"2023-04-04T08:08:12.000-07:00","updated_at":"2024-07-17T13:54:50.000-07:00","published_at":"2023-03-08T08:29:00.000-08:00","custom_excerpt":"As the popularity of large language models grow in adoption, how do you know if your LLM is generating true information? Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":"https://labelbox.com/blog/what-does-it-mean-when-an-llm-hallucinates/","tags":[{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"65302ef44e99900001fc0519","name":"Industry: Any","slug":"industry-any","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#4ADE80","url":"https://labelbox.ghost.io/blog/tag/industry-any/"}],"authors":[{"id":"5e15130970aad900380bc80d","name":"Nathana Sharma","slug":"nathana","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/nathana/"}],"primary_author":{"id":"5e15130970aad900380bc80d","name":"Nathana Sharma","slug":"nathana","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/nathana/"},"primary_tag":{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},"url":"https://labelbox.ghost.io/blog/what-does-it-mean-when-an-llm-hallucinates/","excerpt":"As the popularity of large language models grow in adoption, how do you know if your LLM is generating true information? Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations.","reading_time":7,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"LLM Hallucination Meaning, Causes + Recommended Solutions","meta_description":"LLM responses can be factually incorrect. Learn why reinforcement learning (RLHF) is important to help mitigate LLM hallucinations.","email_subject":null,"frontmatter":null,"feature_image_alt":"What does it mean when an LLM “hallucinates” \u0026 why do LLMs hallucinate?","feature_image_caption":null},"recommended":[{"id":"6765b8c06f63bf0001f1ca72","uuid":"9f912bc0-54da-4ac6-ab5f-78d8f926463c","title":"Code Runner: Secure, scalable code execution for model evaluation","slug":"code-runner-secure-scalable-code-execution-for-model-evaluation-2","html":"\u003cp\u003eIn the world of large language models (LLMs), evaluating their responses effectively is a fundamental aspect of improving model performance. We’re excited to announce the latest addition to the Quantumworks Lab platform: Code Runner.\u003cstrong\u003e \u003c/strong\u003eThis new capability pushes the boundaries of interactivity by allowing users to execute written code directly within the evaluation workflow.\u003c/p\u003e\u003cp\u003eCode Runner helps eliminate errors, optimizes functionality, and validates outputs, leading to higher-quality datasets. Today, we’ll introduce this new feature and then dive into the technical details of the infrastructure powering this feature, highlighting how it was designed with security, scalability, and\u003cstrong\u003e \u003c/strong\u003erobustness at its core.\u003c/p\u003e\u003ch2 id=\"what-is-code-runner\"\u003e\u003cstrong\u003eWhat is Code Runner?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner is a new built-in feature of the Quantumworks Lab platform designed to improve the quality of responses and labels generated in any coding-related projects. The new features enables users to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eDirectly execute code found in either model responses or user-written responses \u003c/li\u003e\u003cli\u003eReceive precise outputs including:\u003cul\u003e\u003cli\u003eStandard output (stdout)\u003c/li\u003e\u003cli\u003eStandard error (stderr)\u003c/li\u003e\u003cli\u003eExecution time\u003c/li\u003e\u003cli\u003eWarnings or runtime errors\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBy integrating Code Runner into the evaluation pipeline, we aim to simplify the process of verifying the accuracy, efficiency, and functionality of code responses, all without users needing to leave the platform.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBDN_1bnU_bTrPrWS59SWalVqw22Gxq3AIxNnbsOJmZGPap3weXHYFEgzrlPnEyhVK1GOjzCVClvQycomfMfhQsulqPk4wdQGqniZv8aIaHGP69wzgcFjdDdr5FgooITwNJCsp?key=GRyWmie9kDWaUfN6osDAF8J7\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"389\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eOur system automatically detects the language in the text area and suggests the appropriate environment for execution, whether Python or JavaScript (and more to come).\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut what makes this feature stand out is the sophisticated infrastructure behind it, designed to ensure seamless execution while maintaining strict security and privacy standards.\u003c/p\u003e\u003ch2 id=\"code-runner-infrastructure-a-deep-dive\"\u003e\u003cstrong\u003eCode Runner infrastructure: A deep dive\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eAt the heart of Code Runner’s infrastructure lies Google Cloud Run, a fully managed compute platform that runs containerized applications in a secure, scalable manner. Here are the key components and principles driving the system:\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1. Cloud Run for language-specific environments\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEvery code execution happens in a dedicated Cloud Run instance. Each instance is tailored to a specific programming language environment (e.g., Python, JavaScript, etc.) and is spun up dynamically based on the code type detected in the user response.\u003c/p\u003e\u003cp\u003eThis design includes the following characteristics to ensure security and speed:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eIsolation\u003c/strong\u003e: Each execution is fully containerized, completely isolating the runtime environment from others.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTemporary directories\u003c/strong\u003e: Code is executed in a temporary directory within the container, and it is deleted immediately after execution, leaving no trace behind.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage-specific tools\u003c/strong\u003e: Each environment comes preloaded with the necessary packages and libraries to ensure compatibility and speed.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e2. Enhanced security with separate GCP projects \u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe Cloud Run service is hosted in a separate Google Cloud Platform (GCP) project, distinct from our main infrastructure. This segmentation provides an additional layer of security by isolating code execution from our core services. Even in the unlikely event of a compromise, the blast radius is contained.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Communication via private service connect\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo ensure secure and controlled communication, all interactions between the main evaluation system and the Cloud Run service occur over Private Service Connect, which provides the following advantages: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eNo public exposure\u003c/strong\u003e: The Cloud Run endpoint is never exposed to the public internet, reducing the risk of unauthorized access.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eOne-way communication\u003c/strong\u003e: The Private Service Connect setup restricts outbound networking from the Cloud Run service, ensuring that executed code cannot make arbitrary network requests. \u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGranular networking controls\u003c/strong\u003e: The private network allows for precise control over what resources the Cloud Run service can access.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e4. Automatic cleanup\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eTo maintain a lightweight and secure runtime, the system delivers:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEphemeral execution\u003c/strong\u003e: Each execution request is handled in a stateless, temporary environment.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAutomatic deletion\u003c/strong\u003e: Files, logs, and temporary directories are wiped as soon as execution completes, leaving no residual data.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"how-code-runner-works-a-step-by-step-overview\"\u003e\u003cstrong\u003eHow Code Runner works: A step-by-step overview\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow that you have an understanding of the powerful infrastructure underneath Code Runner, here is a summary of how the feature works from start to finish:\u0026nbsp;\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eCode submission\u003c/strong\u003e: A user requests code execution from the evaluation interface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLanguage detection\u003c/strong\u003e: The system detects the programming language and forwards the request to the corresponding Cloud Run service.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e: The Cloud Run instance spins up a container, executes the code in a sandboxed environment, and collects the results.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eResult delivery\u003c/strong\u003e: The system returns the output (stdout, stderr, execution time, and any warnings) to the user for analysis.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eCleanup\u003c/strong\u003e: The container and all related resources are terminated and deleted.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"advantages-of-labelbox%E2%80%99s-built-in-code-execution\"\u003e\u003cstrong\u003eAdvantages of Quantumworks Lab’s built-in code execution\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eCode Runner’s infrastructure was designed specifically to provide the previously discussed benefits and to address several key challenges that other solutions may face:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eSecurity\u003c/strong\u003e: By isolating execution environments and ensuring no public exposure, we eliminate a significant attack surface.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalability\u003c/strong\u003e: Cloud Run’s serverless nature allows us to scale dynamically with demand, handling thousands of requests efficiently.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eReliability\u003c/strong\u003e: The use of ephemeral containers ensures that each execution starts in a clean slate, avoiding cross-contamination or resource conflicts.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"explore-it-yourself\"\u003e\u003cstrong\u003eExplore it yourself\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWith Code Runner, we’re empowering users to go beyond static evaluations, enabling dynamic, interactive testing that’s as secure as it is scalable. As always, we’re excited to hear your feedback and explore how we can push this feature even further.\u003c/p\u003e\u003cp\u003e If you want to explore Code Runner and other LLM evaluation tools, \u003ca href=\"https://app.labelbox.com/signup?_r=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/?utm_keyword=Quantumworks Lab\u0026utm_source=house\u0026utm_medium=email\u0026utm_campaign=1224%2520\u0026gclid=CjwKCAiA34S7BhAtEiwACZzv4a9veoKXnMnMvo2rWJvXkH46oHs4Lb5VFQi2ERBN_sQ5kgypV_zfBxoC0yMQAvD_BwE\u0026landingPageAnonymousId=%22e3f2f82f-be24-4045-b2b9-50a49cb801e8%22\u0026referrer_url=https://landing-page-git-uv-homepage-refresh-dec-24-labelbox.vercel.app/\"\u003e\u003cu\u003esign up\u003c/u\u003e\u003c/a\u003e for our platform today.\u0026nbsp;\u003c/p\u003e\u003cp\u003eStay tuned for updates, and happy coding!\u003c/p\u003e","comment_id":"6765b8c06f63bf0001f1ca72","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Labelbox-code-runner--1-.png","featured":false,"visibility":"public","created_at":"2024-12-20T10:34:40.000-08:00","updated_at":"2025-03-12T12:01:43.000-07:00","published_at":"2024-12-20T12:44:45.000-08:00","custom_excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"},{"id":"65303cb64e99900001fc05a5","name":"Labeling automation","slug":"labeling-automation","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/labeling-automation/"},{"id":"6530313c4e99900001fc0537","name":"Train \u0026 fine-tune AI","slug":"train-fine-tune-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#F68C00","url":"https://labelbox.ghost.io/blog/tag/train-fine-tune-ai/"}],"primary_author":{"id":"6765bb156f63bf0001f1ca8d","name":"Dmytro Apollonin","slug":"dmytro","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/dmytro/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/code-runner-secure-scalable-code-execution-for-model-evaluation-2/","excerpt":"Meet Code Runner, the new in-platform code execution engine designed to simplify coding-related tasks and deliver higher-quality datasets for coding-related projects.","reading_time":4,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6760b00aa9b5bd0001989da5","uuid":"d216f74b-532e-4556-8777-7630b460b9dd","title":"Advance LLM reasoning with advanced fact-checking and prompt rating tools","slug":"advance-llm-reasoning-with-advanced-fact-checking-and-prompt-rating-tools","html":"\u003cp\u003eLarge language models (LLMs) have made significant strides in recent years, but significant opportunities still exist to improve their reasoning and accuracy. Frontier models are expected to think critically, explain their logic, and produce reliable and accurate results.\u0026nbsp;\u003c/p\u003e\u003cp\u003eTo address these challenges, we are thrilled to announce two new features to assist AI teams in the advancement of frontier and task-specific models. We have expanded our multi-step reasoning tool to make it easy for raters to review the accuracy of each part of a complex response. In addition, a new prompt rating feature allows you to analyze prompts for compliance with specific guidelines to ensure raters spend time on valid responses and report poor prompts.\u0026nbsp;\u003c/p\u003e\u003cp\u003eRead on to learn more about how these features can help improve your model’s critical thinking and generate more accurate responses. You can see them in action as well through the interactive demos below.\u003c/p\u003e\u003ch2 id=\"simplify-the-evaluation-of-complex-prompts-and-responses\"\u003eSimplify the evaluation of complex prompts and responses\u003c/h2\u003e\u003cp\u003eLast month, we announced the release of a powerful new annotation type in our \u003ca href=\"https://labelbox.com/blog/new-multimodal-chat-evaluations-experience/?ref=labelbox.ghost.io\"\u003e\u003cu\u003emultimodal chat solution\u003c/u\u003e\u003c/a\u003e (MMC), \u003ca href=\"https://labelbox.com/blog/multi-step-reasoning-teach-llms-to-think-critically/?ref=labelbox.ghost.io\"\u003e\u003cu\u003emulti-step reasoning\u003c/u\u003e\u003c/a\u003e. Multi-step reasoning improves LLM training by automating the breakdown of complex responses into smaller, manageable steps. Individual evaluators can then score and, when necessary, rewrite a specific step, leading to improved model understanding and more accurate outputs.\u0026nbsp;\u003c/p\u003e\u003cp\u003eOur comprehensive Quantumworks Lab platform now includes these two key features:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFact-checking tasks:\u003c/strong\u003e Labelers can assess the accuracy of complex reasoning responses by guiding the Quantumworks Lab platform to automatically split complex responses into smaller, manageable pieces of information. Each piece of information can be individually rated—with options to include justifications and corrections for disputed claims.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePrompt rating tasks\u003c/strong\u003e: Issues with the prompt itself can now be instantly flagged for not meeting pre-defined criteria, such as being unratable, false, offensive, controversial, or self-contained. Quantumworks Lab's customizable ontology also allows for additional criteria to be added. When a prompt is flagged, any required tasks associated with it becomes optional, giving labelers the ability to skip bad prompts and focus on high-value entries.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLabelbox's new features are the latest example of how the team is committed to generating the highest-quality data and model evaluations in the industry. By adding another powerful feature in our set of quality control tools, we can help you achieve greater precision in your data and develop more accurate AI models.\u0026nbsp;\u003c/p\u003e\u003ch2 id=\"how-does-fact-checking-and-prompt-rating-work-in-labelbox\"\u003eHow does fact checking and prompt rating work in Quantumworks Lab?\u003c/h2\u003e\u003cp\u003eWith the addition of these new features in Quantumworks Lab’s multimodal chat editor, you can now easily determine the veracity of model responses as well as identify and flag any issues with a given prompt.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHere’s how to use the fact-checking feature in Quantumworks Lab’s platform:\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003eCreate a new project using the Multimodal chat task type and click to edit or create the ontology.\u0026nbsp;\u003c/li\u003e\u003cli\u003eGo to “Message step tasks” and select the radio button next to “Factual.” Give the task a name and review the options. Click save when you are done to complete the ontology configuration.\u0026nbsp;\u003c/li\u003e\u003c/ol\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd7V-dojiecR1_Sjz87op6kX81-Hwp89Qwe5-rcFwxFp1rB-_JHzm5rLOdgFSGLpsedZGT-2mdZWmqDxrPDdmGlvWYfhtvqiT_AK7_9HyeazchClJ-SUnwpvhtLLQrCA8joWKC4kA?key=1KGbUP_5-jRgULByV3dYLmKI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"216\" height=\"236\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eSelect the fact check statements task in the ontology setup to automatically classify your model’s response accuracy.\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003col start=\"3\"\u003e\u003cli\u003eAfter choosing a model(s) to evaluate and clicking Start labeling, enter a prompt to generate a model response (or multiple responses if evaluating more than one model).\u0026nbsp;\u003c/li\u003e\u003cli\u003eOnce the response is generated, click on “Fact check statements” on the left-hand side of the screen if it is not already selected. The multimodal chat editor will automatically split responses into individual steps and allow you to classify them as “ Accurate”, “Inaccurate”, “Disputed”, “Unsupported”, “Can’t confidently assess”, or “No factual information”.\u0026nbsp;\u003c/li\u003e\u003cli\u003eEvaluate and rate each step individually. If you select either “Accurate”, “Inaccurate” or “Disputed”, you will be asked to input additional justification.\u003c/li\u003e\u003c/ol\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdGirCisJZBpbIN0FoZuPVoU8VYld52OBfGbIZHBOtCYI1GTMIPE1NTWldR_kS_7kFr5VE6UuBlhOum1HmX0vHR6B9FaOMU7G0NJDw4RMK5VkA4m0i85ohvHc-6n5Vi0bgmjufe?key=1KGbUP_5-jRgULByV3dYLmKI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"271\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003e\u0026nbsp;If the step has been marked as either “Accurate”, “Inaccurate” or “Disputed”, the user is prompted to add a justification to the rating. For all other classifications, you will not be asked to add additional information.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003col start=\"6\"\u003e\u003cli\u003eIterate through this process until all steps have been fact checked.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThe new fact-checking feature provides a straightforward and effective process to generate high-quality and accurate responses.\u0026nbsp;\u003c/p\u003e\u003cp\u003eSee Quantumworks Lab’s new fact-checking feature in action \u003ca href=\"https://app.arcade.software/flows/tpITHjGYUAPC7Anoo4oO/view?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere\u003c/u\u003e\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHere’s how to use the prompt rating feature in Quantumworks Lab’s platform:\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli\u003eCreate a new project using the Multimodal chat task type, and click to create or edit the ontology.\u0026nbsp;\u003c/li\u003e\u003cli\u003eWithin the ontology configuration screen, add a “Prompt rating task” to the project. Enter a name for the task and then review and edit the options. Options can be configured using checklists, radio buttons, or free text fields.\u0026nbsp;If any of these pre-defined criteria are selected during labeling, then the entire conversation will be marked unratable and can be skipped.\u0026nbsp;\u003c/li\u003e\u003c/ol\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf_0QBvmaPhj0MWMiX-16Woaafcy8FU386HrHN91dwc7YDaEg8UPYMz3YwBOSkwgSeCDcsgZuj5Am1zPhCEkcSVQIQyQjflhUY38kQ8hZ0Fjh8-vs-5n0eVDZeM_ZzTu7P-zm4ngQ?key=1KGbUP_5-jRgULByV3dYLmKI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"180\" height=\"260\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eConfigure a prompt rating task in the ontology setup to easily rate the quality of your prompt.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003col start=\"3\"\u003e\u003cli\u003eAfter choosing a model(s) to evaluate and clicking Start labeling, enter a prompt to generate a model response(s).\u0026nbsp;\u003c/li\u003e\u003cli\u003eOnce the response is generated, you can flag any issues with the prompt. If any of the pre-defined options for the prompt issue are selected, the red asterisk will be removed from the response task and the labeler will have the option to skip labeling for that response.\u0026nbsp; \u003c/li\u003e\u003c/ol\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdZHRLrS0iyKx-1kSgMX6LGNF5G2Q_JcsR_CLOmPItHp9C8j1leHSAayHU4MOrIjYHkmPJr3duqTMCi9nfMNl5MGiGVPZ4IqRe1GFVG8KeurxIOc9q5AOdho8s4RxsaP01InAcw?key=1KGbUP_5-jRgULByV3dYLmKI\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"275\"\u003e\u003cfigcaption\u003e\u003cspan style=\"white-space: pre-wrap;\"\u003eThe red asterisk next to tasks under \"Response tasks\" indicates that labeling is still required, as a predefined option for \"Issues with the prompt?\" has not been selected. If an issue was flagged for the prompt, the asterisk would disappear, making labeling for that task optional.\u0026nbsp;\u003c/span\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBy carefully crafting and evaluating prompts, we can significantly improve the overall quality and relevance of LLM outputs. In addition we can help improve the efficiency and utility of the time spent rating responses.\u003c/p\u003e\u003cp\u003eSee Quantumworks Lab's new prompt rating feature in action \u003ca href=\"https://app.arcade.software/flows/CDRZAk0Xwaj2l6p91bEq/view?ref=labelbox.ghost.io\"\u003e\u003cu\u003ehere.\u003c/u\u003e\u003c/a\u003e\u0026nbsp; \u003c/p\u003e\u003ch2 id=\"achieve-further-advanced-reasoning-with-fact-checking-and-prompt-rating\"\u003eAchieve further advanced reasoning with fact-checking and prompt rating\u003c/h2\u003e\u003cp\u003eBy ensuring data quality and accuracy with our new quality control mechanisms, Quantumworks Lab can generate key datasets to train LLMs on complex reasoning and decision-making. Critical steps towards agentic reasoning that are supported by Quantumworks Lab’s fact-checking and prompt rating features include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDirectly improve accuracy: \u003c/strong\u003eFact-checking and prompt rating enhance LLM data quality by identifying and correcting inaccuracies and ensuring clear prompts.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eProvide valuable human feedback: \u003c/strong\u003eBoth features help bridge the gap between human and machine intelligence by serving as human-in-the-loop processes that provide expert guidance to the model's learning workflows.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRefine reasoning: \u003c/strong\u003eBy providing tools for justifications and corrections, labelers enable the model to learn from its mistakes, resulting in more accurate and reliable responses.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"the-future-of-ai-starts-with-labelbox\"\u003eThe future of AI starts with Quantumworks Lab\u003c/h2\u003e\u003cp\u003eThe addition of fact-checking and prompt rating tools marks a major advancement in training LLMs for complex and agentic reasoning tasks. These quality control features enable granular rating and classification of both prompts and model responses, ensuring the generation of high-quality, accurate training data.\u003c/p\u003e\u003cp\u003eWant to learn more? \u003c/p\u003e\u003cul\u003e\u003cli\u003eTry a \u003ca href=\"https://labelbox.com/product-demos/?ref=labelbox.ghost.io\"\u003e\u003cu\u003equick, interactive tour\u003c/u\u003e\u003c/a\u003e\u0026nbsp; into the demos for our fact checking and prompt rating features\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://labelbox.com/blog/multi-step-reasoning-teach-llms-to-think-critically/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eLearn more\u003c/u\u003e\u003c/a\u003e about our multi-step reasoning feature and how it helps train LLMs to think more critically.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003ca href=\"https://labelbox.com/sales/?ref=labelbox.ghost.io\"\u003e\u003cu\u003eContact our team\u003c/u\u003e\u003c/a\u003e anytime with questions or if you are ready to discuss your LLM training needs and how Quantumworks Lab might be able to help.\u0026nbsp;\u003c/p\u003e\u003ch1 id=\"\"\u003e\u003c/h1\u003e","comment_id":"6760b00aa9b5bd0001989da5","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/llm-reasoning--2-.png","featured":false,"visibility":"public","created_at":"2024-12-16T14:56:10.000-08:00","updated_at":"2025-06-16T10:09:59.000-07:00","published_at":"2024-12-17T12:31:57.000-08:00","custom_excerpt":"Quantumworks Lab's new fact-checking and prompt-rating tools improve LLM accuracy and reasoning capabilities by allowing users to evaluate responses, correct errors, and flag bad prompts.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"}],"tags":[{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"},{"id":"66e35bd2f39c8800019d9143","name":"Generative AI","slug":"generative-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/generative-ai/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"653031134e99900001fc0533","name":"Label data for AI","slug":"label-data-for-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#5CAAFF","url":"https://labelbox.ghost.io/blog/tag/label-data-for-ai/"}],"primary_author":{"id":"5c48ee4aa3b65500ccb6ae25","name":"Quantumworks Lab","slug":"Quantumworks Lab","profile_image":"https://labelbox.ghost.io/blog/content/images/2021/12/Frame-2227-1.svg","cover_image":null,"bio":"Quantumworks Lab is a collaborative training data platform empowering teams to rapidly build artificial intelligence applications.","website":null,"location":"San Francisco","facebook":"getlabelbox/","twitter":"@Quantumworks Lab","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/Quantumworks Lab/"},"primary_tag":{"id":"5fcebc2a9903c40039e8b87e","name":"Announcement","slug":"announcement","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#3B82F6","url":"https://labelbox.ghost.io/blog/tag/announcement/"},"url":"https://labelbox.ghost.io/blog/advance-llm-reasoning-with-advanced-fact-checking-and-prompt-rating-tools/","excerpt":"Quantumworks Lab's new fact-checking and prompt-rating tools improve LLM accuracy and reasoning capabilities by allowing users to evaluate responses, correct errors, and flag bad prompts.","reading_time":5,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6757cf3acb24830001b1d4b1","uuid":"3ff80ee2-cd3b-4596-9a78-88c340d62032","title":"Inside the matrix: A look into the math behind AI","slug":"inside-the-matrix-a-look-into-the-math-behind-ai","html":"\u003ch2 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eMatrices are omnipresent in math and computer science, both theoretical and applied. They are often used as data structures, such as in graph theory. They are a computational workhorse in many AI fields, such as deep learning, computer vision and natural language processing. Why is that? Why would a rectangular array of numbers, with famously unintuitive multiplication rules, be so prevalent in AI?\u003c/p\u003e\u003cp\u003eAI methods (with emphasis on machine learning) are all about processing multi-dimensional data. A lot of that processing is done in a linear way - input data points are multiplied by scalars and added together to create output data. While that sounds limiting, a lot can be achieved with just that, for example:\u003c/p\u003e\u003cul\u003e\u003cli\u003eLinear layers in neural networks (excluding possibly non-linear activations)\u003c/li\u003e\u003cli\u003ePrincipal component analysis\u003c/li\u003e\u003cli\u003eWord embeddings\u003c/li\u003e\u003cli\u003eImage processing\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis particular kind of processing data has a name in mathematics - linear map, which is a concept from linear algebra. I will formally define it later in this blog. For now it suffices to say that you can represent any linear map as a matrix, and matrix operations are intimately connected to operations on linear maps. This is the main reason why matrices are so ubiquitous in AI.\u003c/p\u003e\u003cp\u003eWhile you don't necessarily need to know linear algebra to do machine learning, it is very helpful to have a good intuition for the concepts. This blog is an attempt to demystify matrices and linear algebra surrounding them in a way that strikes a balance between mathematical rigor and intuitive understanding. Contrary to most introductory material on the subject, we won't restrict ourselves to the usual Rn spaces, but I'll still give examples in R2 and R3 for clarity. If you don't know what R\u003csup\u003e2\u003c/sup\u003e, R\u003csup\u003e3\u003c/sup\u003e and R\u003csup\u003en\u003c/sup\u003e are, don't worry - we'll get to that.\u003c/p\u003e\u003cp\u003eI will start with formally defining what a matrix is. We will gradually build up to understanding matrix multiplication, and by the end of the article we will have covered all the necessary concepts.\u003c/p\u003e\u003ch2 id=\"definition-of-a-matrix\"\u003e\u003cstrong\u003eDefinition of a matrix\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA matrix is a rectangular array of numbers. The numbers are called elements of the matrix. The horizontal lines of elements are called rows, the vertical lines are called columns.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeE-ZtcxxSEfqHBbKD496nYV8uU8Gh85QW_nlkNA9LBe7PJhOm-N4b6LLx7oDfUFppbj0Mza3dQKv5GezLOb3OL6DyY0Uot0pxn_NU8xBOhUkRPx9AyUPX1eqzltwPcs519ZmAphg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"306\" height=\"215\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e\u0026nbsp;A real-valued matrix with 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThere are many operations we can perform on matrices, but for the purpose of this article we only need to know three:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition:\u003c/strong\u003e Element-wise addition, only matrices of the same dimensions can be added\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e Multiplying each element by a scalar\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMatrix multiplication:\u003c/strong\u003e Multiplying two matrices, resulting in a matrix with dimensions equal to the number of rows in the second matrix and number of columns in the first matrix\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeHPKl6kqvGJrURhsqbjIz4gZ4lEl_ScId7w3a07BTMrr9O1wn30BKljl5ovYAENHIJbqGxa_tnuZk6Qud6OURSD2PnfD-t8azHRkm90mILIkvwE8m3tnw0kSBA9cuHuihQvSms?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"257\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix addition and scalar multiplication.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe first two operations are pretty straightforward, but matrix multiplication is a bit more complex. There are several algorithms to do it, all resulting in the same end product. \u003c/p\u003e\u003cp\u003eOne of the most common algorithms is this: For element in j-th row and k-th column of the resulting matrix, take the element-wise product of j-th row of the first matrix and k-th column of the second matrix, and sum all the elements of the resulting vector.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeR0jhCg2ufM0vZv_Yyp_6PklvhKVGJ_Zft_vzWMWywsN_GYnzEoeOH4McE3p1D4HLojhYrTzysbjYfAgQ2DxqoSwX0Iaxo4XeWN4tHvSBaNLBJgPreIUuPveGDeQcd_zoA9aLF?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"155\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eMatrix multiplication. To compute the element in the first row and first column of the resulting matrix (10), take the first row of the first matrix (2, 3, 4) and the first column of the second matrix (2, 2, 0), multiply them element-wise and sum the result (2 * 2 + 3 * 2 + 4 * 0 = 10). Note that the resulting matrix has dimensions equal to the number of rows in the first matrix and number of columns in the second matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy is matrix multiplication not simply element-wise (which actually exists and is called Hadamard product)? What is the intuition behind it? To answer that, we need to understand several concepts from linear algebra.\u003c/p\u003e\u003ch2 id=\"what-is-a-vector\"\u003e\u003cstrong\u003eWhat is a vector?\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eA vector has many definitions. Perhaps the most well known is the one from physics: an arrow in space with a direction and a magnitude, usually represented as coordinates in a space.\u003c/p\u003e\u003cp\u003eIf you are a programmer, you might know it as an array-like data structure, that is an ordered collection of elements. Both of these definitions are most likely known to you if you are working with AI systems, in which vectors often play a crucial role, e.g. as features in a dataset or as low-dimensional representations of high-dimensional data (embeddings).\u003c/p\u003e\u003cp\u003eWhat interests us here is the mathematical definition: A vector is an element of a vector space. What is a vector space then?\u003c/p\u003e\u003cp\u003eTo avoid spelling the whole mathematical definition here, it suffices to say that a vector space is a set of elements with following properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIt is possible to add any two elements and the result is also in the set.\u003c/li\u003e\u003cli\u003eIt is possible to multiply any element by a scalar (a real number) and the result is also in the set.\u003c/li\u003e\u003cli\u003eThere exists an element called zero vector, which is such that adding it to any element does not change the latter.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese two operations are connected by a distributive property, which states that scalar multiplication of a sum is the sum of scalar multiplications: a * (u + v) = a * u + a * v.\u003c/p\u003e\u003cp\u003eAs you have probably noticed, this is analogous to the operations of addition and multiplication on real numbers. The important thing to note is that the vector space definition does not require the vector by vector multiplication to be defined. It is defined for some vector spaces, but we won't concern ourselves with it in this blog.\u003c/p\u003e\u003cp\u003eAll of that is pretty abstract, so let's consider some examples. Possibly the most well known vector spaces are R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e, which are spaces of vectors with 2 and 3 coordinates respectively. The generalization of those is R\u003csup\u003en\u003c/sup\u003e, which is a space of vectors with n coordinates. The elements (vectors) of those spaces have a geometric interpretation as arrows or points. Notice how this aligns with the interpretation of vectors as known from physics.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXciYwCq1HZTGnHkYJWxNJex6c52A-UpTxDRkM1DbAOj2n-Vx9r5PPFqosNeQ6MjMzmjExEuWL6aDpUHJUKVF70rDWeMtbhdOFoJPjAR66btoxgXO5fCsyRl9vbAsJZiWvsmm568gw?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"544\" height=\"238\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eImages of R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e and R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, with some vectors marked. It is common to draw vectors as arrows starting from the origin, but the vector is not defined by its anchor point. Graphically, all vectors with the same length and direction are the same vector.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"linear-combination-of-vectors-span-and-linear-independence\"\u003e\u003cstrong\u003eLinear combination of vectors, span and linear independence\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that vectors can be added and multiplied by scalars. A linear combination of vectors is a sum of scalar multiples of those vectors. Consider these examples in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e:\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXetIiIpcEGjnii7eRWzOwH3onH7IgJEGl8tkJ42x1IkjQI41rhP_n4hWW5EJLfCzV8e-oLFcfEVvAklY5tcdUDBjTGekkfJsxFDgVhm5VGXrfLRdm5lfQSi0pm90gEGugHW3XQ9Kg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"505\" height=\"339\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of linear combination of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eA span of a finite set of vectors is a set of all possible linear combinations of those vectors. Geometrically, a span of one vector in R\u003csup\u003e2\u003c/sup\u003e and R\u003csup\u003e3\u003c/sup\u003e is a line through the origin (all scalar multiples of the vector), while a span of two vectors \u003cstrong\u003emight be\u003c/strong\u003e a plane through the origin (which is the whole space in case of R\u003csup\u003e2\u003c/sup\u003e).\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeS90Xw5U7e8SCrauz6PfboZLkMATSOTsQ8p-ugGkVlC4tiuXekAuTzHV6FYhXZHPHQOSXuiQ_poclCAKdRYm2bXKK_IQdRlI4Po-HHG1pllr_EmFwSaQLXIjQaw86d92NtsnMIdQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"419\" height=\"369\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of the span of two vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. Their span is a plane through the origin (which is admittedly hard to draw).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhy might? Consider two vectors lying on the same line. No matter what scalar coefficients we take for the linear combination, the result will lie on the same line. Their individual spans are identical to the span of the set of those two vectors. We say that those two vectors are \u003cstrong\u003elinearly dependent\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eLet's consider a set of three vectors in R\u003csup\u003e3\u003c/sup\u003e. They can either all lie on the same line, all lie on the same plane, or they can be such that their span is the whole space. In the first two cases, the vectors are linearly dependent, in the last case they are \u003cstrong\u003elinearly independent\u003c/strong\u003e. Two vectors in R\u003csup\u003e2\u003c/sup\u003e spanning the whole space are also linearly independent.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf8_KYv6dtal1uf07fhGwyO7Dq3aBbTydEuW84z2V0WOO-uFZInEdskzS6ztAWm5pvUevcUSSC-0PxpiH5F0X-4iNc4D98z157Vb7nfHcsb-3fE6VtEEu0AQZTN5I37wYxixRmuOQ?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"256\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eGeometric interpretation of spans of linearly dependent vectors in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e3\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e. All three vectors on the second image lie on the same plane (which contains the origin).\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRigorously speaking, a set of vectors in vector space is linearly independent if no vector in the set can be written as a linear combination of the other vectors in the set (in other words, it does not lie in the span of the rest of the vectors). Intuitively, vectors are linearly independent if each one of them contributes a unique \"direction\" to the span.\u003c/p\u003e\u003cp\u003eLinearly independent vectors have a very important property: each vector in their span can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of those vectors.\u003c/p\u003e\u003ch2 id=\"basis\"\u003e\u003cstrong\u003eBasis\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNot all vector spaces can be spanned by a finite set of vectors. For example, the space of all polynomials (which with proper definition of addition and scalar multiplication is valid vector space) is infinite-dimensional, because no matter how many polynomials we have, we can always find a polynomial that has a higher degree than all of them.\u003c/p\u003e\u003cp\u003eContrarily, if we can find a finite set of vectors that spans the whole space, we say that the vector space is finite-dimensional. Only these spaces are relevant for the purposes of this blog.\u003c/p\u003e\u003cp\u003eEvery finite-dimensional vector space has a basis. A basis is a set of linearly independent vectors that span the whole space. In R\u003csup\u003e2\u003c/sup\u003e, a basis can consist of two non-collinear vectors. In R\u003csup\u003e3\u003c/sup\u003e, a basis can consist of three vectors that do not lie on the same plane. Note that a basis is not necessarily unique - e.g. in R\u003csup\u003en\u003c/sup\u003e, we can choose different vectors that will still span the same space and be linearly independent.\u003c/p\u003e\u003cp\u003eNotice how I stated that a basis in R\u003csup\u003e2\u003c/sup\u003e consists of two vectors, while in R\u003csup\u003e3\u003c/sup\u003e it consists of three vectors. A set of three vectors in R\u003csup\u003e2\u003c/sup\u003e is guaranteed to be linearly dependent, so it cannot be a basis. On the other hand, one vector cannot span R\u003csup\u003e2\u003c/sup\u003e. Likewise, we cannot find four linearly independent vectors in R\u003csup\u003e3\u003c/sup\u003e, but less than three vectors cannot span R\u003csup\u003e3\u003c/sup\u003e.\u003c/p\u003e\u003cp\u003eSkipping the proof, it is a true statement that every basis of a finite-dimensional vector space has the same number of vectors. This number is called the dimension of the vector space. By this, R\u003csup\u003en\u003c/sup\u003e has a dimension of n, which plays nicely with our geometric interpretation of R\u003csup\u003en\u003c/sup\u003e as n-dimensional space.\u003c/p\u003e\u003cp\u003eFor R\u003csup\u003en\u003c/sup\u003e, we define a standard basis as a set of n vectors, where each vector has exactly one non-zero coordinate, which is 1. For example, in R\u003csup\u003e3\u003c/sup\u003e, the standard basis is {(1, 0, 0), (0, 1, 0), (0, 0, 1)}.\u003c/p\u003e\u003cp\u003eWhy do we care about a basis? Since a basis is a set of linearly independent vectors that span the whole space, any vector in that space can be \u003cstrong\u003euniquely\u003c/strong\u003e represented as a linear combination of vectors from the basis. That means that for every finite-dimensional vector space, no matter how abstract or exotic, we can always represent any of its vectors as a list of numbers (coefficients of linear combination of chosen basis).\u003c/p\u003e\u003ch2 id=\"linear-maps\"\u003e\u003cstrong\u003eLinear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eNow we are ready to define a linear map. A linear map (sometimes also called linear transformation), defined for vector spaces V and W, is a function that takes a vector from V as an input and returns a vector from W. It must satisfy two properties:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAdditivity:\u003c/strong\u003e f(u + v) = f(u) + f(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHomogeneity:\u003c/strong\u003e f(a * u) = a * f(u)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese properties ensure that linear maps preserve the linear structure of vector spaces - parallel vectors remain parallel, and origin remains at the origin.\u003c/p\u003e\u003cp\u003eWhile it may seem that linear maps are a very restricted class of functions, they can be used to represent a wide variety of transformations. For example, a linear map in R\u003csup\u003e2\u003c/sup\u003e can be used to represent:\u003c/p\u003e\u003cul\u003e\u003cli\u003eRotation\u003c/li\u003e\u003cli\u003eScaling\u003c/li\u003e\u003cli\u003eReflection\u003c/li\u003e\u003cli\u003eShearing\u003c/li\u003e\u003cli\u003eAny combination of the above\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOne operation you cannot represent with a linear map is translation (moving every point by the same vector), since the origin must remain at the origin.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfcM7o_gKJk2c7hx0wjIEoZmu2OHveEQvO065rsVLYH5Ca5-v_vyWj9OGREyFacWuopomsh0gm9WLDkvOewl5S8JPJmeq1TRQwQrRab4klX2oJT-Tg0fqJ6rkBA3B6zps5tNFLIbg?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"366\" height=\"318\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eShear operation in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e2\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAs mentioned in the introduction, they are also extremely prevalent in machine learning, e.g. in neural networks. While I am not going to prove this, the connections (weights) between linear layers are equivalent to linear maps from R\u003csup\u003en\u003c/sup\u003e to R\u003csup\u003em\u003c/sup\u003e, where n is the dimension of the input and m is the dimension of the output. Since you can represent these connections as a matrix, it's a hint that \u003cstrong\u003ematrices are intimately connected to linear maps\u003c/strong\u003e. We'll come back to this later.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeCp-3F2w7zsnKxYYjLu9Kp02nGlruiHhAbHii9zsGLP8xUvIQjpe9LIjxCrrV8nW5kaLXPYl7iwYc8hXUtfjOBnTS8sDwn-nWbgXz_DsQIN7UjOHG4rlRcGLoD5AOy5DVCrQD9uA?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"178\" height=\"324\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eTwo fully connected layers in a neural network without activation functions or biases. They are equivalent to a linear map from R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e to R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e - each input is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e5\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e, and each output is a vector in R\u003c/em\u003e\u003c/i\u003e\u003csup style=\"white-space: pre-wrap;\"\u003e\u003cspan\u003e7\u003c/span\u003e\u003c/sup\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003e.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWe can define a set of operations on linear maps (let T and S be linear maps, and c an arbitrary scalar):\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAddition: \u003c/strong\u003e(T + S)(v) = T(v) + S(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eScalar multiplication:\u003c/strong\u003e (c * T)(v) = c * T(v)\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eComposition: \u003c/strong\u003e(T * S)(v) = T(S(v))\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eA very important property of linear maps is that \u003cstrong\u003ea linear map is fully defined by its values on basis vectors\u003c/strong\u003e, for a chosen basis of input space. Let's say we have a linear map T and a basis B = {b\u003csub\u003e1\u003c/sub\u003e, b\u003csub\u003e2\u003c/sub\u003e, ..., b\u003csub\u003en\u003c/sub\u003e} of input space V. For any v in V, we can write v as a linear combination of basis vectors: v = c\u003csub\u003e1\u003c/sub\u003e * b\u003csub\u003e1\u003c/sub\u003e + c\u003csub\u003e2\u003c/sub\u003e * b\u003csub\u003e2\u003c/sub\u003e + ... + c\u003csub\u003en\u003c/sub\u003e * b\u003csub\u003en\u003c/sub\u003e. Then T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(b\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(b\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(b\u003csub\u003en\u003c/sub\u003e). This means that if we know what T does to each vector in the basis, we know what T does to any vector in the space.\u003c/p\u003e\u003ch2 id=\"matrix-as-representation-of-linear-map\"\u003e\u003cstrong\u003eMatrix as representation of linear map\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe know that every linear map T: V -\u0026gt; W (where V has dimension n and W has dimension m) and for a chosen basis Bv = {v\u003csub\u003e1\u003c/sub\u003e, v\u003csub\u003e2\u003c/sub\u003e, ..., v\u003csub\u003en\u003c/sub\u003e} of V, T is fully defined by values of T(v\u003csub\u003e1\u003c/sub\u003e), T(v\u003csub\u003e2\u003c/sub\u003e), ..., T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eLet's take a closer look at one of those values, say T(v\u003csub\u003e1\u003c/sub\u003e). We know that T(v\u003csub\u003e1\u003c/sub\u003e) is a vector in W, so we can write it as a linear combination of a chosen basis of W: T(v\u003csub\u003e1\u003c/sub\u003e) = d\u003csub\u003e1\u003c/sub\u003e * w\u003csub\u003e1\u003c/sub\u003e + d\u003csub\u003e2\u003c/sub\u003e * w\u003csub\u003e2\u003c/sub\u003e + ... + d\u003csub\u003em\u003c/sub\u003e * w\u003csub\u003em\u003c/sub\u003e. We can represent the coefficients of this linear combination as a list of numbers: [d\u003csub\u003e1\u003c/sub\u003e, d\u003csub\u003e2\u003c/sub\u003e, ..., d\u003csub\u003em\u003c/sub\u003e]. This list is uniquely determined by the linear map T and the chosen basis of V, and it is called the column vector representation of T(v\u003csub\u003e1\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eWe can do the same for T(v\u003csub\u003e2\u003c/sub\u003e), T(v\u003csub\u003e3\u003c/sub\u003e), and so on, up to T(v\u003csub\u003en\u003c/sub\u003e). In this way, we can associate with our linear map T a matrix A, where the j-th column is the column vector representation of T(v\u003csub\u003ej\u003c/sub\u003e). This matrix A is called the matrix representation of the linear map T. That is, \u003cstrong\u003ea matrix with m rows and n columns can be interpreted as a representation of a linear map from linear space of dimension n to linear space of dimension m\u003c/strong\u003e. When representing a linear map with a matrix, choice of bases is important - different bases will yield different matrices. That is why when not clear from the context, we must specify the bases for both the input and output spaces.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe36MNl-rRXhG4KwL8YAyQToQLcJq13rDEanIpgYDVG9ge7XCFf-IEVdHSvJdKPzMLQV_H4xzGzERyFyurj_kIzXuZqY0RQpAt9wri3SCB2oYnRHMcnTlJnFqULPTq_4gjZMakp_g?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"318\" height=\"242\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA representation of a particular linear map T: V -\u0026gt; W as a matrix. V has dimension 3, while W has dimension 2. Thus, the matrix has 2 rows and 3 columns.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIt is important to note that such a matrix can be created for any linear map between finite-dimensional vector spaces - it is not limited to R\u003csup\u003en\u003c/sup\u003e. The common misconception is that the columns or rows of such a matrix are vectors, but in general they are not - they are coefficients of linear combinations. It is a coincidence that in the case of T: R\u003csup\u003en\u003c/sup\u003e -\u0026gt; R\u003csup\u003em\u003c/sup\u003e and if we choose the standard basis for R\u003csup\u003em\u003c/sup\u003e, the columns of the matrix representation are vectors in R\u003csup\u003en\u003c/sup\u003e.\u003c/p\u003e\u003ch2 id=\"matrix-operations-as-operations-on-linear-maps\"\u003e\u003cstrong\u003eMatrix operations as operations on linear maps\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eIf matrices represent linear maps, do the matrix operations represent operations on linear maps? It turns out that they do.\u003c/p\u003e\u003cp\u003eIt is easy (albeit a bit tedious) to prove, that if A and B are matrices representing linear maps T and S, then:\u003c/p\u003e\u003cul\u003e\u003cli\u003eA + B represents the linear map T + S\u003c/li\u003e\u003cli\u003ec * A represents the linear map c * T\u003c/li\u003e\u003cli\u003eA * B represents the linear map T * S\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eKeep in mind that matrix multiplication is not commutative, i.e. A * B is not necessarily the same as B * A (even if both make sense dimension-wise).\u003c/p\u003e\u003cul\u003e\u003cli\u003eMatrix addition is only defined for matrices of the same dimensions, which is consistent with the fact that addition of linear maps is only defined for maps between the same spaces.\u003c/li\u003e\u003cli\u003eMatrix multiplication by scalar is defined for any matrix, which is consistent with the fact that scalar multiplication of linear maps is defined for any linear map.\u003c/li\u003e\u003cli\u003eMatrix multiplication is defined for any two matrices, provided that the number of columns in the first matrix is the same as the number of rows in the second matrix. This is consistent with the fact that composition of linear maps is only defined for maps where the output space of the first map is the same as the input space of the second map.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhile adding and multiplying by scalar are pretty intuitive operations, matrix multiplication is not that obvious. \u003cstrong\u003eIt has actually been defined so that composition of linear maps is represented by multiplication of their matrices\u003c/strong\u003e, which you are encouraged to verify.\u003c/p\u003e\u003cp\u003eAside from linear map composition, matrix multiplication can be used to apply a linear map to a vector. Say we have a linear map T: V -\u0026gt; W represented by matrix A, and a vector v in V. First we need to represent v as a nx1 column matrix. We'll call it Mat(v). Then we can compute A * Mat(v), which will be a vector in W.\u003c/p\u003e\u003cp\u003eThis type of matrix multiplication can be computed as follows, where a\u003csub\u003ej\u003c/sub\u003e is the j-th column of A, while m\u003csub\u003e1j\u003c/sub\u003e is the j-th element of Mat(v): \u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"631\" height=\"199\" srcset=\"https://labelbox.ghost.io/blog/content/images/size/w600/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 600w, https://labelbox.ghost.io/blog/content/images/2024/12/Screenshot-2024-12-13-at-11.22.37-AM.png 631w\"\u003e\u003c/figure\u003e\u003cp\u003eApplying T to v can be written as T(v) = c\u003csub\u003e1\u003c/sub\u003e * T(v\u003csub\u003e1\u003c/sub\u003e) + c\u003csub\u003e2\u003c/sub\u003e * T(v\u003csub\u003e2\u003c/sub\u003e) + ... + c\u003csub\u003en\u003c/sub\u003e * T(v\u003csub\u003en\u003c/sub\u003e).\u003c/p\u003e\u003cp\u003eRemembering that a column j of matrix A represents T(v\u003csub\u003ej\u003c/sub\u003e), we can see that multiplying A by Mat(v) is indeed equivalent to applying T to v.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card kg-card-hascaption\"\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXevqSOQivzWeKcTeOPhUmNT4z0psVVGyrYtls1oLPQGJQnCcVW8QlGLQuM2-iS5fNegBS3CtgeAQ9PKokTe3FmxOHAnoui6DdLwTr7eUN0NPFP9qafWCA5-a1Qo18nur2ApU4g_?key=ODPo2fm0CLrLSvUFi5qEnIvd\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"624\" height=\"248\"\u003e\u003cfigcaption\u003e\u003ci\u003e\u003cem class=\"italic\" style=\"white-space: pre-wrap;\"\u003eA particular way to perform matrix multiplication when the second operand is a column matrix.\u003c/em\u003e\u003c/i\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003eWe have now covered all the necessary concepts from linear algebra to understand matrix multiplication. We have seen that matrices can be interpreted as representations of linear maps, and that matrix operations can be interpreted as operations on linear maps. We have also seen that matrix multiplication is not just an arbitrary operation, but rather a composition of linear maps. While this blog barely scratched the surface of math involved in creating AI systems, hopefully it gave you a good intuition on the subject of linear maps and matrices.\u003c/p\u003e\u003cp\u003eIn conclusion, matrices are a fundamental tool in the AI toolkit, enabling efficient data manipulation and transformation. Whether you're building a simple linear regression model or a complex deep learning architecture, a solid grasp of matrix operations will empower you to create more effective and efficient AI solutions.\u003c/p\u003e","comment_id":"6757cf3acb24830001b1d4b1","feature_image":"https://labelbox.ghost.io/blog/content/images/2024/12/Matrices.png","featured":false,"visibility":"public","created_at":"2024-12-09T21:18:50.000-08:00","updated_at":"2025-03-12T11:59:32.000-07:00","published_at":"2024-12-11T10:38:57.000-08:00","custom_excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"}],"tags":[{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},{"id":"65302fb54e99900001fc0525","name":"Build AI","slug":"build-ai","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/build-ai/"},{"id":"65302fc14e99900001fc0527","name":"Building LLMs","slug":"building-llms","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":"#22D3EE","url":"https://labelbox.ghost.io/blog/tag/building-llms/"}],"primary_author":{"id":"6706c454eeb2b1000180d550","name":"Michał Jóźwiak","slug":"michal","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://labelbox.ghost.io/blog/author/michal/"},"primary_tag":{"id":"5f9af89dd8118b0039136165","name":"Engineering","slug":"engineering","description":null,"feature_image":null,"visibility":"public","meta_title":null,"meta_description":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://labelbox.ghost.io/blog/tag/engineering/"},"url":"https://labelbox.ghost.io/blog/inside-the-matrix-a-look-into-the-math-behind-ai/","excerpt":"Matrices are crucial in AI for processing multi-dimensional data in areas like machine learning and computer vision. They represent linear maps and transform input into output, making them central to many AI methods.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}]},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"what-does-it-mean-when-an-llm-hallucinates"},"buildId":"Tltx2tBe97VOu7U0vVrr8","isFallback":false,"gsp":true,"scriptLoader":[]}</script><script id="setOrignalReferrer" type="text/javascript">
          if (typeof jQuery != 'undefined') {
            $('#image-viewer').hide();
            setTimeout(() => {$('#image-viewer').hide();}, 500);
        $(".content img").click(function () {
            if($(this).attr("src"))
            {
              $("#full-image").attr("src", $(this).attr("src"));
              $('#image-viewer').show();
            }
            
        });
        $("#image-viewer").click(function () {
            $('#image-viewer').hide();
        });
            
            $(document).ready(function () {
                var store = window.localStorage;
                var newRef = document.referrer;
                
                if (store) {
                    if (!newRef || newRef == '') {
                        store.removeItem('origin');
                    }
        
                    var origin = store.getItem('origin');
        
                    if ((newRef && !newRef.match(/labelbox.com/i)) && origin != newRef) {
                        origin = newRef;
                        store.setItem('origin', newRef);
                    }
        
                    if (origin) {
                       
                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if (!lHref.match(/_r=/)) {
                                if (lHref.indexOf('?') > 0) {
                                    lHref = lHref + '&';
                                } else {
                                    lHref = lHref + '?';
                                }
                            }
        
                            lHref = lHref + '_r=' + encodeURI(origin);
                            $(e).attr('href', lHref);
                        });
                    }
                }
        
                function getCookie(name) {
                    const cookieString = document.cookie;
                    const cookies = cookieString.split('; ');
                    for (const cookie of cookies) {
                        const [cookieName, cookieValue] = cookie.split('=');
                        if (cookieName === name) {
                            return cookieValue;
                        }
                    }
                    return null;
                }

                function readPPCCookies() {
                  var cookies = document.cookie.split(';');
                  var cookieData = {};
                  
                  for (var i = 0; i < cookies.length; i++) {
                    var parts = cookies[i].split('=');
                    var cookieName = parts[0].trim();
                    
                    if (cookieName.startsWith('ppc')) {
                      var cookieValue = parts[1];
                      cookieData[cookieName] = cookieValue;
                    }
                  }
                  
                  return cookieData;
                }
                

                    var link = '';
                
                    const cookieData = readPPCCookies();
                    
                    for (var cookieName in cookieData) {
                      var utmName = cookieName.replace('ppc', 'utm_').toLowerCase();
                      var utmValue = cookieData[cookieName];
                      link += utmName + '=' + utmValue + '&';
                    }
                    
                    if(getCookie('gclid')) link+='gclid='+getCookie('gclid');
                    if(getCookie('attr')) link+='&attr='+getCookie('attr');
                    if(window.localStorage.getItem('ajs_anonymous_id')) link+='&landingPageAnonymousId='+window.localStorage.getItem('ajs_anonymous_id');
                    if(getCookie('referrer_url')) link+='&referrer_url='+getCookie('referrer_url');

                        $('a').filter((i, e) => {
                            var h = $(e).attr('href');
                            if (h) return h.match(/app.labelbox.com/);
                        }).each((i, e) => {
                            var lHref = $(e).attr('href');
                            if(!lHref.includes('gclid')) {
                               lHref = lHref + '?' + link;
                               $(e).attr('href', lHref);
                            }
                        });
            
            });
        }
        
          
          </script><script src="../../../cdn.lr-in-prod.com/LogRocket.min.js" crossorigin="anonymous"></script></body>
<!-- Mirrored from labelbox.com/blog/what-does-it-mean-when-an-llm-hallucinates/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 02 Aug 2025 12:51:02 GMT -->
</html>